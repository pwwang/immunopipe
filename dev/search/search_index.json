{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Integrative analysis for single-cell RNA sequencing and single-cell TCR/BCR sequencing data immunopipe is a pipeline based on pipen framework. It includes a set of processes for scRNA-seq and scTCR-/scBCR-seq data analysis in R , python and bash . The pipeline is designed to be flexible and configurable. See a more detailed flowchart here . Documentaion \u00b6 https://pwwang.github.io/immunopipe Proposing more analyses \u00b6 If you have any suggestions for more analyses, please feel free to open an issue here Example \u00b6 https://github.com/pwwang/immunopipe-example Gallery \u00b6 There are some datasets with both scRNA-seq and scTCR-/scBCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. Check out the gallery for more details. Citation \u00b6 If you use immunopipe in your research, please cite the following paper: Wang, P., Yu, Y., Dong, H., Zhang, S., Sun, Z., Zeng, H., ... & Li, Y. (2025). Immunopipe: a comprehensive and flexible scRNA-seq and scTCR-seq data analysis pipeline. NAR Genomics and Bioinformatics, 7(2), lqaf063.","title":"Home"},{"location":"#documentaion","text":"https://pwwang.github.io/immunopipe","title":"Documentaion"},{"location":"#proposing-more-analyses","text":"If you have any suggestions for more analyses, please feel free to open an issue here","title":"Proposing more analyses"},{"location":"#example","text":"https://github.com/pwwang/immunopipe-example","title":"Example"},{"location":"#gallery","text":"There are some datasets with both scRNA-seq and scTCR-/scBCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. Check out the gallery for more details.","title":"Gallery"},{"location":"#citation","text":"If you use immunopipe in your research, please cite the following paper: Wang, P., Yu, Y., Dong, H., Zhang, S., Sun, Z., Zeng, H., ... & Li, Y. (2025). Immunopipe: a comprehensive and flexible scRNA-seq and scTCR-seq data analysis pipeline. NAR Genomics and Bioinformatics, 7(2), lqaf063.","title":"Citation"},{"location":"CHANGELOG/","text":"Change Log \u00b6 2.0.3 \u00b6 feat: adopt pipen-cli-gbatch, allowing --mount-as-cwd to infer workdir and outdir fix: fix when running with a configuration file solely fix: fix gbatch deamon workdir not created inside the pipeline working folder for gbatch cli fix: fix outdir not following the pipeline name with gbatch cli docs: update volume mounting syntax in docker and singularity commands docs: update immunopipe gbatch options for running the pipeline on Google Cloud Batch Jobs chore: bump pipen-cli-gbatch to 0.0.7 and pipen-report to 0.23.12 chore: bump biopipen to 0.34.14 fix(scrna_metabolic_landscape): fix report paging issue docs(scrna.MarkersFinder): fix links in docs fix(scrna.SeuratClusterStats): improve error handling in feature plotting when save_code (due to upgrade to ggplot2 v4) feat(MarkersFinder): use scplotter::MarkersPlot (wrapped by biopipen.utils::VizDEGs to visualize marker fix(scrna.CellTypeAnnotation): update logging for celltypist command execution 2.0.2 \u00b6 fix: fix immunopipe -h/--help not working as expected feat(gbatch): enhance validation and default handling in main function feat(gbatch): add --mount-as-cwd option to mount a cloudpath as working directory chore: bump biopipen to 0.34.10 docs(scrna.SeuratPreparing): enhance cell_qc parameter description in SeuratPreparing docs(scrna.ModuleScoreCalculator): update link format in ModuleScoreCalculator docstring 2.0.1 \u00b6 feat: add utility cli for gene checking and dimension verification chore: make tests order work as expected chore: bump biopipen to 0.34.9 fix(scrna.CellCellCommunication): handle numpy product attribute error feat(scrna.ModuleScoreCalculator): add post mutaters functionality to allow compound modules based on added modules docs(scrna.MarkersFinder): correct URL in documentation feat(scrna.CellTypeAnnotation): add support for additional direct cell type annotations feat(scrna.MarkersFinder): enhance enrichment plot descriptions chore(scrna.CellCellCommunicationPlots): set default case to \"Cell-Cell Communication\" feat(scrna.CellCellCommunicationPlots): add table output option for ccc data chore: bump scplotter to 0.6.0 in docker image chore: optimize clonal_size_data feat(featurestatplot): add pos_only parameter to filter positive feature values chore(enrichmentplot) remove preset label_nudge parameter in BarPlot call feat: add downsample parameter to feature statistic plots feat(featurestatplot) default options to TRUE to show row and column names when plot_type is heatmap-alike 2.0.0 (Cloud support, enhanced visualization, new analyses/features, and more ...) \u00b6 Cloud support \u00b6 feat: immunopipe can now be run on Google Cloud Batch Jobs, allowing for scalable and efficient processing of larger datasets. You can either run the pipeline using the gbatch scheduler ; or run the entire pipeline on Gooble Batch Jobs using immunopipe gbatch command. See Run the pipeline using Google Cloud Batch Jobs\u00b6 for more details. Enhanced visualization \u00b6 feat: scplotter and plotthis are now used for plotting, providing enhanced visualization capabilities and uniformity across different processes. feat: default descriptions/captions are now added to plots, making them more informative. Enhanced performance \u00b6 feat: the pipeline now uses qs2 for store the R objects, which speeds up the loading and saving of Seurat objects. feat: step-wise caching (in addition to process-wise) is now supported, especially for Seurat processes, allowing for faster re-running of the pipeline by caching intermediate results and improving results reproducibility. refactor: MetabolicLandscapeAnalysis is refactored for flexibility and performance improvement. BREAKING: enrichR is retired and replaced by enrichit for enrichment analysis, making it offline and more flexible. This enables the entire pipline to run without internet connection. New analyses/features \u00b6 feat: the pipeline now supports cell-cell communication analysis . feat: plots are supported for all cases for MarkersFinder and ScFGSEA , allowing plotting the markers (DEGs) and enriched pathways for all cases (e.g. all seurat clusters) in a single plot. BREAKING: the immunarch package is now replaced by scRepertoire for more features and allowing customized clonotype definition. feat: envs.mutaters is now supported for SeuratPreparing to allow create factor (categorical) columns in the metadata. feat: PseudoBulkDEG is added to perform pseudo-bulk differential expression analysis. feat: BCR-seq data is now supported, allowing users to analyze BCR-seq data paired with scRNA-seq data. feat: Now Seurat object (in RDS or qs2 format) is supported as input for scRNA-seq data. feat: Now loom format is supported for scRNA-seq data, allowing users to use loom files as input for the pipeline. feat: add mcp server functionality to launch mcp server to help compose the configuration file. House keeping \u00b6 build: docker images are now built based on the biopipen base image. ci: the test workflow now caches the running intermediate files to speed up the tests. docs: the citation information is now added to the documentation, allowing users to easily cite the pipeline in their publications. chore(deps): biopipen is bumped to 0.34.8, which includes various bug fixes and enhancements. See the biopipen releases for more details. 1.4.4 \u00b6 chore(deps): add gcc_linux-64 to Docker environment dependencies docs: add input and output sections to multiple process documentation files feat: add PDF output for K-means and T cell plots, enhancing report generation deps: bump biopipen to 0.32.3 0.32.1: fix(scrna.ScFGSEA): fix case gmtfile not working fix(TopExpressingGenes): add InlineNotification component to TopExpressingGenes.svelte fix(scrna.SeuratClusterStats): fix kind not being added to the figure file name for plots of features feat(scrna.SeuratPreparing): support percent.mt, percent.ribo, percent.hb and percent.plat for mouse 0.32.2: feat: add PDF output option for SampleInfo plots feat: add PDF output options for violin and scatter plots in Seurat preparation scripts feat: add PDF output options for volcano, dotplot, venn, and upset plots feat: add PDF output option for Enrichr plots in TopExpressingGenes script feat: add PDF output options for UMAP plots in SeuratMap2Ref script; update image handling in misc.liq feat: add PDF output options for cluster size distribution, shared clusters, and sample diversity plots; update plotting functions to handle multiple output formats feat: add PDF output options for various Immunarch scripts; enhance reporting with downloadable PDF files feat: add PDF output options for cluster size distribution, dimension plots, and feature plots; enhance reporting with downloadable PDF files feat: add PDF output options for radar and bar plots; enhance reporting with downloadable PDF files feat: add PDF output options for CloneResidency script; enhance reporting with downloadable PDF files feat: add PDF output options for GSEA table and enrichment plots; enhance reporting with downloadable PDF files feat: add PDF output options for pie charts, heatmaps, Venn plots, and UpSet plots; enhance reporting with downloadable PDF files feat: add PDF output options for Enrichr plots; enhance reporting with downloadable PDF files feat: add PDF output options for estimated coefficients and distribution plots; enhance reporting with downloadable PDF files 0.32.3: chore: add descriptive summaries for fgsea and enrichr results 1.4.3 \u00b6 deps: update pipen-runinfo dependency to version 0.8.0 (pipen to 0.15.2) deps: update biopipen dependency to version 0.31.4 fix(scrna.SeuratMap2Ref): fix refnorm not detected for NormlizeData'ed reference 1.4.2 \u00b6 deps: add bioconductor-destiny dependency in docker environment files for ModuleScoreCalculator 1.4.1 \u00b6 docs: update tutorial dataset information and links 1.4.0 \u00b6 docs: update Singularity and Apptainer commands to include --writable-tmpfs flag docs: allow collapsing ns/choice items in the docs for processes docker: update Dockerfile to include npm cache configuration to allow the pipeline to run on read-only file system tests: update SeuratPreparing config to use DoubletFinder for doublet detection ci: use latest actions deps: add r-clustree as a dependency in docker environment files deps: update dependencies in docker environment files (python3.10, R4.3) deps: bump biopipen to 0.29.0 fix(tcr.TCRClusterStats): fix envs.shared_clusters.heatmap_meta being broken by envs.shared_clusters.sample_order (@ li.ying@mayo.edu ) choir(scrna.SeuratMap2Ref): present better error message when envs.use or values of envs.MapQuery.refdata not in reference (@ li.ying@mayo.edu ) fix(scrna.MarkersFinder): run PrepSCTFindMarkers when needed choir(scrna.SeuratClustering): use FindClusters to run for multiple resolutions choir(scrna.SeuratSubClustering): use FindClusters to run for multiple resolutions feat(scrna.SeuratClustering): add clustree plot (@ li.ying@mayo.edu ) feat(scrna.SeuratSubClustering): add clustree plot tests(scrna.SeuratClusterStats): add assertion for clustree plot generation deps: bump biopipen to 0.29.1 fix(delim.SampleInfo): fix numbers not split up when each is specified. enh(delim.SampleInfo): make sizes of pie charts proportional to number of samples when each is specified enh(scrna.MarkersFinder): run PrepSCTFindMarkers when necessary before calling FindMarkers feat(scrna.SeuratPreparing): add option to cache Seurat object at different steps feat(scrna.SeuratPreparing): allow doubletfinder to run with a different number of cores chore(scrna.SeuratClustering): record PrepSCTFindMarkers command in sobj@commands tests(scrna.SeuratClusterStats): use less stringent p-value cutoff for DEG/MarkersFinder tests(scrna.SeuratPreparing): add doubletfinder in tests deps: bump biopipen to 0.29.2 chore(scrna.SeuratClusterStats): use ident label length to adjust default height for feature plots fix(scrna.MetaMarkers): fix seurat object not updated when expanding cases and run PrepSCTFindMarkers when necessary before calling meta-markers fix(scrna.MarkersFinder): fix fetching command when composing the PrepSCTFindMarkers command fix(scrna_metabolic_landscape): handle null values in for loop in MetabolicFeatures and MetabolicFeaturesIntraSubset for report generation deps: bump biopipen to 0.30.0 BREAKING(scrna): move clustree plots from SeuratClustering/SeuratSubClustering to SeuratClusterStats feat(scrna.CellTypeAnnotation): allow to merge/not to merge (envs.merge) the clusters with the same labels predicted feat(scrna.SeuratPreparing): add scDblFinder to detect doublets feat(scrna.SeuratMap2Ref): add envs.skip_if_normalized option to skip normalization if query is already normalized using the same - method as the reference refactor(tcr.Immunarch): source the files for Immunarch scripts for better debugging refactor(scnra.SeuratClustering): refactor the script for better debugging refactor(scnra.SeuratPreparing): refactor the script for better debugging fix(scrna): fix resolution expansion for SeuratClustering and SeuratSubClustering fix(scrna): Fix generating PrepSCTFindMarkers command when no previous commands present tests(scrna.ScFGSEA): fix unavailable urls to GMT files chore(scrna.SeuratMap2Ref): optimize memory usage chore(scrna.MetaMarkers): remove plugin_opts.poplog_max chore(tcr.CloneResidency): improve logging when handling subjects deps: bump biopipen to 0.31.3 enh(scrna.SeuratMap2Ref): check if reference has SCTModel if SCTransform'ed (likely prepared by old Seurat) fix(tcr.CDR3AAPhyschem): use sequence from TRB chain only fix(tcr.CDR3AAPhyschem): fix when chain is not available fix(tcr.TCRClustering): fix for multi-chain TCRs, use TRB only if on_multi is false fix(tcr.TCRClustering): fix when chain is not available 1.3.9 \u00b6 docs: update docs for TCellSelection to avoid confusion deps: bump biopipen to 0.27.9 feat(tcr.TCRClusterStats): add sample_order to set sample order on heatmap and cluster_rows to switch row clustering on/off 1.3.8 \u00b6 docs: remove -w option for apptainer/singularity as no writing is necessary since pipen-board 0.15.1 deps: update biopipen to version 0.27.8 fix(scrna.SeuratClusterStats): fix selected columns not unique for stats feat(scrna.SeuratMap2Ref): allow non-SCTransform'ed reference feat(scrna.SeuratMap2Ref): allow splitting query object for mapping (pwwang/immunopipe#61) deps: update pipen-board to version 0.15.1 (allow configuration file path in the URL box on Web UI) 1.3.7 \u00b6 ci: fix docker images building when no essential changes made 1.3.6 \u00b6 ci: fix deploy workflow (#59) ci: add README.md to tests-output branch ci: fix test/test workflow tests: add make test tests: init test data preparation tests: add test for ImmunarchLoading tests: add tests for SeuratPreparing tests: Update configs for SeuratPreparing test to subset cells so tests can run on CI tests: update SeuratPreparing test to disable export tests: add tests for SeuratClusteringOfAllCells/SeuratClustering docs: update installation instructions (@ stein.mariam@mayo.edu ) deps: bump biopipen to version 0.27.7 (0.27.5-0.27.7) fix(scrna.SeuratClusterStats): fix color palette for ridge plots (@ stein.mariam@mayo.edu ) feat(scrna.SeuratPreparing): add envs.cell_qc_per_sample to filter cells before merging instead after fix(scrna_metabolic_landscape.MetabolicFeatures): fix return value of groups with less than 5 cells in do_one_group fix(scrna_metabolic_landscape): fix mutaters not working. fix(scrna_metabolic_landscape.MetabolicFeatures/MetabolicFeaturesIntraSubset): skip groups with less than 5 cells in do_one_group and save a warning file under the case chore: fix typo in class name ExprImpution to ExprImputation 1.3.5 \u00b6 ci/test: add tests in CI and deploy output in a different branch deps: bump biopipen to 0.27.4 choir(delim.SampleInfo): add alpha to the colors of the plots using biopipen color pallete docs(tcr/scrna/scrna_metabolic_landscape): update links of images in docs 1.3.4-post \u00b6 ci/test: init ci for tests docs: introduce versioning for docs 1.3.4 \u00b6 deps: bump biopipen to 0.27.3 deps: bump pipen-poplog to 0.1.2 (quick fix for populating logs when job fails) deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) choir(scrna.ScFGSEA): Skip cases when no cells found (#50) choir(scrna.MarkersFinder): Skip cases when no cells found (#50) choir(scrna.MetaMarkers): Skip cases when no cells found (#50) feat(scrna.SeuratPreparing): support DoubletFinder (#52) 1.3.3 \u00b6 deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) docs: update FAQ.md with instructions for running pipeline on a cluster deps: bump biopipen to 0.27.2 fix(scrna.RadarPlots): fix mutaters not working feat(tcr.CloneResidency): support envs.upset_ymax to set the max value of y axis in upset bar plot. 1.3.2 \u00b6 deps: bump pipen to 0.14.5 deps: add r-complexupset package to environment.yml and environment_full.yml for CloneResidency deps: pin tensorflow to 2.15 for TESSA deps: bump biopipen to 0.27.1 depr(scrna.MarkersFinder): remove envs.use_presto as it's used by Seurat v5 by default enh(tcr.CloneResidency): support log scale for y axis of upset bar plots enh(scrna.SeuratClusterStats): allow to rotate labels in circos plot (pwwang/immunopipe#48) @ li.ying@mayo.edu enh(scrna.SeuratClusterStats): use pal_biopipen for ident colors in circos plot fix(scrna.CellsDistribution): fix the row order of the heatmaps fix(scrna.SeuratClusterStats): fix when envs.split-by is specified feat(scrna.CellsDistribution): support envs.prefix_each feat(scrna.MarkersFinder): allow to set max number of genes to plot in dotplots feat(scrna.MarkersFinder): support setting detailed arguments for overlapping plots feat(scrna.MarkersFinder): support envs.prefix_group feat(scrna.ScFGSEA): support envs.prefix_each feat(scrna.RadarPlots): support envs.prefix_each and envs.subset choir(scrna.SeuratClusterStats): use logger instead of print for log messages choir(tcr.TCRClustering): print session info for clustcr script choir(scrna.MarkersFinder): flatten toc when no section and no ident-1 specified docs: add more detailed docs for envs.section for multiple processes BREAKING(scrna.SeuratMap2Ref): rename envs.name to envs.ident so envs.MapQuery.refdata is not - required anymore. It will be inferred from envs.ident and envs.use. @ li.ying@mayo.edu 1.3.1 \u00b6 deps: bump pipen to 0.14.3 deps: pin ggplot2 to 3.4 for docker due to breaking changes of 3.5 deps: bump biopipen to 0.26.2 deps: bump datar-pandas to 0.5.5 to dismiss deprecated warnings fix(utils.misc.R): replace latin and greek characters with closest ascii chars for slugify() feat(scrna.TopExpressingGenes): support subset fix(scrna.CellsDistribution): fix the row order of the heatmaps. enh(tcr.CloneResidency): add legend for multiplets in upset plots. feat(scrna.SeuratClusterStats): add circos plot for cell composition stats (#46). 1.3.0 \u00b6 deps: bump pipen to 0.14.1 deps: bump pipen-report to 0.18.2 deps: bump biopipen to 0.26.0 fix(scrna.CellTypeAnnotation): keep factor meta data when input and output are RDS for celltypist deps: bump datar to 0.15.4 (support pandas 2.2) fix(utils.single_cell.R): fix immdata_from_expanded missing other data columns fix(tcr.Immunarch): fix mutaters not working when no subset is set fix(scrna.CellsDistribution): fix hm_devpars not working fix(scrna.CellsDistribution): fix multiple cells_by columns and speed up plotting choir(tcr.CloneResidency): mark singletons in Venn diagrams more clear fix(scrna.RadarPlots): fix the order of groups on radar plots choir(scrna.RadarPlots): transpose the count/percentage table to save to files fix(scrna.MarkersFinder): fix generating report json file when no significant genes found choir(scrna.MarkersFinder): Plot maximum 20 genes in dotplots choir(scrna.MarkersFinder): Do not convert dashes in case names to dots see more at https://github.com/pwwang/biopipen/releases/tag/0.26.0 1.2.0 \u00b6 docs: update FAQs to align with Seurat v5 docs: add image from manuscript to README.md docs: center the flowchart image in README.md docs: mention celltypist model prep in preparing input data deps: bump pipen to 0.13.2 deps: bump biopipen to 0.25.2: scrna.MarkersFinder: allow to cache FindAllMarkers results scrna.CellTypeAnnotation: support celltypist (pwwang/biopipen#111) scrna.SeuratSubClustering: add envs_depth = 1 to replace whole envs.cases when new case assigned scrna_metabolic_landscape.MetabolicPathwayHeterogeneit): fix output directory path is not slugified tcr.Immunarch: change case filling log to debug level 1.1.1 \u00b6 deps: Bump biopipen to 0.24.2 chore: use internal slugify instead of slugify library tcr.Immunarch: fix spectratyping output file extension is not png scrna.SeuratPreparing: fix displaying filters in report scrna.SeuratPreparing: fix logging Seurat procedure arguments 1.1.0 \u00b6 docs: update table in gallery deps: use pipen-poplog to populate job logs to pipeline running log deps: bump biopipen to 0.24. Hights: scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112) @yuey11 scrna.SeuratClustering/SeuratSubClustering: cache Seurat procedures step by step (#40) @xyfqwlzoe tcr.Immunarch: add plot_type to support boxplots for diversity metrics see more at https://github.com/pwwang/biopipen/releases/tag/0.24.0 1.0.5 \u00b6 change: do not rescale gene expression in TCellSelection any more fix: fix column names of indicators not aligned with indicator_genes feat: add feature plots in TCellSelection deps: bump biopipen to 0.23.8 scrna.SeuratPreparing: log Seurat procedure arguments scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112) 1.0.4 \u00b6 deps: bump biopipen to 0.23.7 scrna.SeuratPreparing: update log message for transformation/scaling step scrna_metabolic_landscape.MetabolicPathwayHeterogeneity: add utils.gsea script source to support localizeGmtfile 1.0.3 \u00b6 deps: add r-seuratdisk dependency to conda env files. @yuey11 deps: pin r-matrixstats to 1.1.0 in conda env files to fix useNames = NA error. @yuey11 refactor: optimize configuration file validation deps: bump biopipen to 0.23.6 feat: support url for gmtfile wherever GSEA is performed (pwwang/biopipen#113) tcr.Immunarch: add error message for empty filtered/subset data in diversity scrna.SeuratPreparing: correct description of default assay in docstr scrna.SeuratPreparing: run also the normal normalization procedures when SCTransform is used (useful for visualization purposes on RNA assay) scrna.ModuleScoreCalculator: document the names added by cell cycle score (#34) scrna.SeuratPreparing: support sample names as reference for IntegrateLayers 1.0.2 \u00b6 deps: add bioconductor-glmgampoi to conda env files (#33) docs: correct the Seurat object assay description deps: bump biopipen to 0.23.5 fix: fix when no enriched items found for scrna.MarkersFinder , scrna.MetaMarkers and scrna.TopExpressingGenes scrna.SeuratClusterStats: fix when frac or frac_ofall is true and no group-by nor split-by is specified for stats utils.gsea.R: fix when no enriched items found for runEnrichr scrna_metabolic_landscript: fix adding report when ncores > 1 1.0.1 \u00b6 docs: add gallery section to README.md change: set default nstart of kmeans to 25 in TCellSelection deps: add r-hdf5r in conda env files to support Read_10x_h5 from Seurat. @yuey11 deps: bump biopipen to 0.23.4 scrna.TopExpressingGenes: fix colnames while pulling average expression scrna.CellsDistribution: fix when cells_by has multiple column names scrna.CellTypeAnnotation: fix the order of the clusters for direct method scrna.SeuratClusterStats: add position options for bar plots for stats scrna.RadarPlots: add colors to set the colors of the loops in radar and bar plots tcr.Immunarch: add split_by and split_order to put subplots together in one single plots 1.0.0 \u00b6 Highlights \u00b6 feat: support Seurat v5 (integration is now down by Seurat::IntegrateLayers ) feat: support supervised clustering (mapping cells to reference by Seurat ) feat: support dataset with scRNA-seq data only (no scTCR-seq data) feat: support diffusion map calculation (by ModuleScoreCalculator ) feat: support subclassing to cluster subsets of cells (by SeuratSubClustering ) feat: allow to ignore TCR data in TCellSelection and pass kmeans arguments feat: allow to set multiple resolutions ( envs.FindClusters.resolution ) in SeuratClustering / SeuratClusteringOfTCells change: change unsuperved cluster labels to c1 , c2 , ... in SeuratClustering by default docs: add gallery, which contains real-world examples of datasets from publications Breaking changes \u00b6 change: rename SeuratMetadataMutater to IntegratingTCR change: rename SeuratClusteringOfTCells to SeuratClustering change: rename TCRClusters2Seurat to IntegratingTCRClusters refactor: make SeuratClustering (instead of SeuratClusteringOfAllCells ) work for all cells when all are T cells change: move data preparation and integration from SeuratClustering to SeuratPreparing change: default mode of ImmunarchLoading to paired (instead of single ), which requires both alpha and beta chains (instead of beta chain only) to define a clonotype change: default dbs for enrichment analysis wherever applies to KEGG_2021_Human and MSigDB_Hallmark_2020 Changes \u00b6 feat: make TopExpressingGenes optional feat: add validate_config to validate configuration schematically Features \u00b6 feat(SeuratPreparing): allow to filter genes directly (by specifying envs.gene_qc.excludes ) feat(SeuratClusterStats): add ngenes to plot the number of genes expressed in each cluster feat(SeuratClusterStats): add barplot for features and allow aggregation of features feat(SeuratClusterStats): add envs.mutaters to mutate meta data feat(SeuratClusterStats): add histograms to plot number of cells against another variable feat(SeuratClusterStats): Add frac_ofall and transpose for stats to calculate fraction within group or against all cells, and transpose ident and group, respectively Dependencies \u00b6 deps: add r-presto to conda environment files to support using presto to fastly find markers deps: add bioconductor-destiny to conda environment file to support add diffusion map components in ModuleScoreCalculator deps: add r-harmony to support harmony integration by Seurat v5 in conda env file deps: add r-sf to conda env file deps: remove vdjtools from conda env files deps: bump pipen-report to 0.16.3 deps: bump biopipen to 0.23.3 . Hightlight changes: scrna.MarkersFinder: Add envs.use_presto to use presto to speed up finding markers scrna.SeuratPreparing: Set envs.gene_qc.min_cells to 0 by default (instead of 3) scrna.ScFGSEA: Allow to ignore small group when fgsea fails due to all NAs for pre-ranks scrna.CellsDistribution: Allow to order clusters by envs.cluster_orderby scrna.CellsDistribution: Add heatmaps tcr.CloneResidency: Make section works in report tcr.Immunarch: Support paired chain data for VJ conjuction plots tcr.TESSA: Change envs.assay to None to use default assay of Seurat object scrna.SeuratClusterStats: Add avgheatmap to plot more elegant heatmap for average gene expressions scrna.SeuratClusterStats: Fix ident not working for dimplots scrna.SeuratClusterStats: Add cluster_orderby to order clusters for features scrna.SeuratClusterStats: Add na_group to keep NA values in group-by utils.mutate_helpers: Change arguments id_col and compare_col of paired to id and compare , respectively utils.mutate_helpers: Fix that subset can't be an expression for expanded family utils.mutate_helpers: Add top to select top entities (e.g clones) scrna.RadarPlots: Add breakdown and test to break down the cell distribution and run statistic test on the fractions 0.11.2 \u00b6 docs: move Immunarch to the later position in process list docs: Use master tag in getting-started 0.11.1 \u00b6 chore: change line length to 88 for flake8 chore: dismissing warning about wasting columns for SeuratClusteringOfTCells docs: update CHANGELOG.md with missing changes of last version docs: add version of renaming envs.tcell_indicator to envs.tcell_selector docs: remove unused doc files docs: add metadata illustration deps: bump biopipen to 0.22.8. Highlights: deps: bump pipen-board to 0.13.10 (pipen-report to 0.16.2) CellsDistribution: Don't add rownames to the output table file MarkersFinder (ClusterMarkers/ClusterMarkersOfAllCells): Optimize to use FindAllMarkers if ident.1 is not specified SeuratClusterStats: Fix path of expression table file CellTypeAnnotation: Allow using NA to exclude clusters from output Seurat object utils.mutate_helpers: Return ids only when subset is true and group is not NA for uniq = TRUE in expanded , collapsed , emerged and vanished 0.11.0 \u00b6 deps: update biopipen to 0.22.1, highlights: add V-J junction circos plots to Immunarch process add cache option to cache the clustering results if nothing changed except ncores, to SeuratClustering process add dot plots to MarkersFinder ( ClusterMarkersOfAllCells , ClusterMarkers ) process save exported table with only necessary columns for CellsDistribution process add descr to describe cases cases in report for CellsDistribution process add subset for dimplots in SeuratClusterStats process use a new palette ( biopipen ) for related processes optimize report rendering (using render_job() filter from pipen-report ) change metacols to extracols so essential columns get exported for ImmunarchLoading process add cache option to cache the clustering results if nothing changed except ncores for SeuratClustering ( SeuratClusteringOfAllCells ) process see more at https://github.com/pwwang/biopipen/releases/tag/0.22.0 and https://github.com/pwwang/biopipen/releases/tag/0.22.1 deps: update pipen-report to 0.16, highlights: scroll anchor into view on the page build report page when each process is done, instead of the whole pipeline see more at https://github.com/pwwang/pipen-report/releases/tag/0.16.0 change: remove Immunarch2VDJtools and VJUsage processes (vj usage analysis can be done in Immunarch process) change: change tcell_indicator to tcell_selector in TCellSelection process enhance: provide better error message when none barcode matches from RNA and TCR data for TCRClustering process docs: add memory usage reduction tips in FAQ chore: dismiss warnings of wasted input columns for multiple processes 0.10.1 \u00b6 chore: update pipeline description to include version in the logs fix: add fc-cache command to Dockerfile to solve Fontconfig error docker: optimize building full image based off the base image 0.10.0 \u00b6 docker: lock r-matrix version to 1.6_1 for compatibility docs: adopt mkdocs-rtd 0.0.10 (add scrollbar to the table of contents) deps: bump biopipen to 0.21.1 use r-logger for logging in R scripts docs: fix internal references in API docs deps: bump pipen-board to 0.13.6 SampleInfo: refactor data subset logic using subset instead of distinct Immunarch: add in.metafile to allow other meta info (i.e. seurat clusters) for future subsetting (#22) Immunarch: fix empty groups in diversity plot after subsetting Immunarch: allow subset to subset cells for analyses Immunarch: allow separate_by also works on other diversity plots Immunarch: add ymin and ymax to align diversity plots by separate_by Immunarch: add ncol to specify # columns in the combined plots RadarPlots: fix envs.order not working MarkersFinder: add overlap to find overlapping markers between cases (#24) MarkersFinder: allow subset to subset cells for analyses MarkersFinder: add dot plots for significant markers CellsDistribution: allow multiple columns for cells_by CellsDistribution: allow subset to subset cells for analyses utils.mutate_helpers.R: add include_emerged for expanded() and include_vanished for collapsed() 0.9.3 \u00b6 deps: Bump biopipen to 0.20.7 deps: Bump pipen-board to 0.13.4 ClusterMarkers/ClusterMarkersOfAllCells: Choose avg_log2FC > 0 markers by default MarkersFinder: Allow to set assay and set assay to RNA by default CellsDistribution: Add venn/upset plot for overlapping cell groups in different cases SampleInfo: Add distinct to case to perform stats on distinct records 0.9.2 \u00b6 \u2795 Add r-ggnewscale as dependency for CDR3AAPhyschem in docker image \u2b06\ufe0f Bump biopipen to 0.20.5 \ud83e\uddf1 CloneResidency: Integrate RNA data to allow more flexible analysis (i.e. within specific seurat clusters) \ud83c\udfd7\ufe0f CloneResidency: Rename envs.sample_groups to envs.section to be consistent with other processes \ud83d\udcdd ScFGSEA: Remove the link in the summary of the docstring (since they are not transformed in the report) \ud83c\udfa8 CDR3AAPhyschem: Give better error message when wrong group items are given \u2b06\ufe0f Bump pipen-board to 0.13.3 Add items automatically when blurred for list options Add other sections to description on the UI for processes 0.9.1 \u00b6 \ud83d\udc1b Fix docstring for RadarPlots \u2795 Add pipen-diagram as dependency \u2795 Set pipen-runinfo as optional \u2b06\ufe0f Bump biopipen to 0.20.4 \ud83d\udcdd Update version in docs 0.9.0 \u00b6 Housekeeping and docs \u00b6 Bump biopipen to 0.20.3 (pipen to 0.12) Use pipen-cli-ref to generate API for processes (it uses docstring of the process class so that we don't need to maintain two copies of docs) Fixed/Enhanced \u00b6 Make /data directory in container, so it can be mounted Fix a bug when a single gene provided to indicator_genes in TCellSelection Move ModuleScoreCalculator before clustering so that the scores can be used in vars.to.regress of SCTransform while clustering Set default assay to RNA in case module scores only caculated using integrated features in ModuleScoreCalculator Improve QC plots in SeuratPreparing by marking the cells that are removed in the plots instead of doing before/after plots Fix type annotation for envs.features_defaults.ncol in docstring for SeuratPreparing (causing pipen-board not converting to int) Fix the cluster order in pie charts for CellsDistribution Fix the cluster order in pie charts for SeuratClusterStats Fix order in pie charts for SampleInfo Fix docstring for envs.div.args of Immunarch (more clear description of method) Allow mutiple columns in the file for envs.features_defaults.features in SeuratClusterStats Allow order to be optional for CloneResidency (errored when not provided) Add number of clusters at the end of log for SeuratClusteringOfAllCells / SeuratClusteringOfTCells Add stricter checker for input file (#13) Indicate the case name in logs when pie is enabled for group-by in SeuratClusterStats Allow to skip overlap and gene usage analyses by setting method to none for Immunoarch (#11, #12) Don't cluster on heatmap when there are only 2 samples for TCRClusterStats (#11) Import Seurat explictly to avoid satijalab/seurat#2853 in MetabolicFeatures Fix when NA values in data for heatmap in MetabolicPathwayActivity Fix error when no significant pathways selected in MetabolicPathwayHeterogeneity Give better error message in CellsDistribution if group value not found for CellsDistribution (#16) Try including more genes (even though insignificant) in volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells (#17) Add margins to volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells Fix when envs.cell_qc is None (not provided) for SeuratPreparing Fix ident in cases of envs.dimplots not working for SeuratClusterStats Added \u00b6 Add ClusterMarkersOfAllCells and TopExpressingGenesOfAllCells and set them as optional Add dim plots in SeuratClusterStats to overlay TCR presence/absence of cells (#14) Breaking changes-0.9.0 \u00b6 Rename TCRClusteringStats to TCRClusterStats (#15) 0.8.3 \u00b6 \ud83d\udcdd Fix typos in docs \ud83d\udcdd Add links to some optional input files (#9, 5) \ud83d\udd28 Add apptainer to docker entry.sh (#9, 6) \ud83d\udc84 Adjust process order in reports (#9, 1) \u2b06\ufe0f Bump pipen-report to 0.13.1 (#9, 2) 0.8.2 \u00b6 Bump biopipen to 0.18.3 to fix when either ident is empty for MarkersFinder 0.8.1 \u00b6 Bump biopipen to 0.18.2 to fix a bug when the min length of CDR3 seqs > 12 for CDR3AAphyschem 0.8.0 \u00b6 Housekeeping and docs updates \u00b6 Bump biopipen to 0.18.1 Mention function changes with versions in docs Add apptainer in board.toml so the command can be generated in pipen-board Make logo shorter in docs Add docker image with -full tags to include all dependencies Print command help message if run test failed in CI Add singularity/apptainer in FAQ for \"no space left\" question Add -w fro apptainer in docs (as we need to save pipen-board file in home directory) Added-0.8.0 \u00b6 Add TESSA process for tessa analysis Add volcano plot for MarkersFinder and ClusterMarkers Fixed \u00b6 Fix when Sample is the only column in meta for ImmunarchLoading Add clear message when k.weight is too large for IntegrateData in SeuratClustering Allow unique: prefix for on in SampleInfo Fix sample order in plots for SampleInfo Remove tidyseurat:: prefix for filter in scripts of MetaMarkers , ScFGSEA and SeuratClusterStats in case tidyseurat::filter is not exported when installed from conda (but it will make dplyr::filter work anyway on seurat object) Breaking changes-0.8.0 \u00b6 Redesign envs for SeuratClusteringStats to allow setting defaults for cases and switch identities for plots 0.7.0 \u00b6 Housekeeping and docs updates-0.7.0 \u00b6 Fix typos in docs/configurations TCRClustering should be TCRClusteringStats in Multi-case variable design section infile of [SampleInfo.in] should be samples.txt rather than sample.txt Remove unused scripts by deprecated processes Bump pipen-report to 0.12.8 Add master branch and master tag as stable tag for docker image Add pdf version of the flowchart (#4) Add warning for the results in getting started tutorial Bump pipen-board to 0.11.5 Add apptainer to the docs Added-0.7.0 \u00b6 Add ModuleScoreCalculator to calculate module scores or cell cycle scores See: https://pwwang.github.io/immunopipe/processes/ModuleScoreCalculator/ Allow SampleInfo to perform statistics on the sample information See: https://pwwang.github.io/immunopipe/processes/SampleInfo/ Add TCR_Cluster_Size and TCR_Cluster_Size1 from TCRClustering to metadata for further integrative analysis See: https://pwwang.github.io/immunopipe/processes/TCRClusters2Seurat/ Fixed-0.7.0 \u00b6 Fix default height and width for plots in SeuratClusterStats Fix cluster order not kept after annotation using hitype in CellTypeAnnotation Breaking changes-0.7.0 \u00b6 Change seurat_clusters_old to seurat_clusters_id to save old seurat_clusters in CellTypeAnnotation Remove MarkersForClustersOfAllCells and TopExpressingGenesOfAllCells processes Rename MarkersForClustersOfTCells to ClusterMarkers Rename TopExpressingGenesOfTCells to TopExpressingGenes Rename envs.exprs to envs.features for SeuratClusterStats envs.exprs.genes is also renamed to envs.features.features 0.6.0 \u00b6 \u2b06\ufe0f Bump biopipen to 0.16 \ud83d\udcdd Add documentation \ud83d\udc9a Fix docs building in CI \ud83d\udcdd Update README with flowchart 0.5.1 \u00b6 \u2728 Add TopExpressingGenes \ud83c\udfa8 Move RadarPlots to biopipen \u2b06\ufe0f Bump biopipen to 0.15.2 0.5.0 \u00b6 \u2b06\ufe0f Upgrade biopipen to 0.15.0 \ud83d\udc9a Use better strategy docker image building 0.4.0 \u00b6 \u2b06\ufe0f Bump biopipen to 0.6 \u2b06\ufe0f Upgrade other dependencies \ud83d\udc9a Use micromamba for docker image building \u2b06\ufe0f Add procps-ng for vdjtools for docker building 0.3.0 \u00b6 \ud83d\udc9a Use build 2 for genomeinfodbdata from bioconda (0.2.4) \ud83d\udc7d\ufe0f Use config from pipen_args \u2b06\ufe0f Pump biopipen to 0.5.3, pipen-args to 0.3.2 \u2b06\ufe0f Upgrade deps for docker \ud83d\udcdd Add flowchart in README.md \ud83d\udc1b Fix error when --config not passed 0.2.4 \u00b6 \ud83d\udc9a Use lastest miniconda3 for docker build \ud83d\udc9a Use conda channel pwwang for bioconductor-genomeinfodbdata for fix (bioconda/bioconda-recipes#31349) \u2b06\ufe0f Upgrade biopipen to 0.4.9 \ud83d\udcdd Add URL to example in README 0.2.3 \u00b6 \u2b06\ufe0f Upgrade biopipen to 0.4.8 0.2.2 \u00b6 \u2b06\ufe0f Upgrade biopipen to 0.4.7 to fix SeuratPreparing 0.2.1 \u00b6 \ud83d\udd25 Fix the bug of the wrong arguments in help page \u2b06\ufe0f Upgrade clustcr to 1.0.2 \ud83d\udcdd Fix docs for metabolic analysis 0.2.0 \u00b6 \u267b\ufe0f Move in-house processes out of processes.py \u267b\ufe0f Split up MARKERS_FINDER \u267b\ufe0f Refactor RadarPlots \u2728 Add an example config file \u26a1\ufe0f Add filter for RadarPlots \ud83d\udcdd Update docs \u2b06\ufe0f Upgrade deps \ud83d\udd27 Update docker/environment.yml \ud83d\udc1b Fix CloneHeterogeneity when only 1 row in continency table 0.1.1 \u00b6 \ud83d\udc9a Try fix pip in environment.yml \ud83d\udcdd Update readme for requirement checking \ud83d\udcdd Update docs to fix #1 \ud83d\udcdd Update CHANGELOG \u2b06\ufe0f Adopt biopipen 0.4.0 0.1.0 \u00b6 \ud83e\ude79 Disable force-caching for some procs \u2b06\ufe0f Upgrade datar to 0.8.* \u2728 Add dockerfile \u2b06\ufe0f Upgrade pipen to 0.3 \ud83d\udca5 Remove gene lists from start processes \u2b06\ufe0f Upgrade biopipen to 0.3 \u2b06\ufe0f Upgrade pipen to 0.3.5 0.0.7 \u00b6 Add CloneHeterogeneity Allow setting indicator_gene for TCellSelection Adopt latest datar and biopipen 0.0.6 \u00b6 \u2728 Allow dimplots with clonal information 0.0.5 \u00b6 \u2728 Allow more flexible dim plots 0.0.4 \u00b6 \u2728 Refactor markers finder module and add meta-marker analysis 0.0.3 \u00b6 -\u2728 Add metabolic pathway analysis 0.0.2 \u00b6 Adopt biopipen 0.1.3 0.0.1 \u00b6 First release","title":"Change log"},{"location":"CHANGELOG/#change-log","text":"","title":"Change Log"},{"location":"CHANGELOG/#203","text":"feat: adopt pipen-cli-gbatch, allowing --mount-as-cwd to infer workdir and outdir fix: fix when running with a configuration file solely fix: fix gbatch deamon workdir not created inside the pipeline working folder for gbatch cli fix: fix outdir not following the pipeline name with gbatch cli docs: update volume mounting syntax in docker and singularity commands docs: update immunopipe gbatch options for running the pipeline on Google Cloud Batch Jobs chore: bump pipen-cli-gbatch to 0.0.7 and pipen-report to 0.23.12 chore: bump biopipen to 0.34.14 fix(scrna_metabolic_landscape): fix report paging issue docs(scrna.MarkersFinder): fix links in docs fix(scrna.SeuratClusterStats): improve error handling in feature plotting when save_code (due to upgrade to ggplot2 v4) feat(MarkersFinder): use scplotter::MarkersPlot (wrapped by biopipen.utils::VizDEGs to visualize marker fix(scrna.CellTypeAnnotation): update logging for celltypist command execution","title":"2.0.3"},{"location":"CHANGELOG/#202","text":"fix: fix immunopipe -h/--help not working as expected feat(gbatch): enhance validation and default handling in main function feat(gbatch): add --mount-as-cwd option to mount a cloudpath as working directory chore: bump biopipen to 0.34.10 docs(scrna.SeuratPreparing): enhance cell_qc parameter description in SeuratPreparing docs(scrna.ModuleScoreCalculator): update link format in ModuleScoreCalculator docstring","title":"2.0.2"},{"location":"CHANGELOG/#201","text":"feat: add utility cli for gene checking and dimension verification chore: make tests order work as expected chore: bump biopipen to 0.34.9 fix(scrna.CellCellCommunication): handle numpy product attribute error feat(scrna.ModuleScoreCalculator): add post mutaters functionality to allow compound modules based on added modules docs(scrna.MarkersFinder): correct URL in documentation feat(scrna.CellTypeAnnotation): add support for additional direct cell type annotations feat(scrna.MarkersFinder): enhance enrichment plot descriptions chore(scrna.CellCellCommunicationPlots): set default case to \"Cell-Cell Communication\" feat(scrna.CellCellCommunicationPlots): add table output option for ccc data chore: bump scplotter to 0.6.0 in docker image chore: optimize clonal_size_data feat(featurestatplot): add pos_only parameter to filter positive feature values chore(enrichmentplot) remove preset label_nudge parameter in BarPlot call feat: add downsample parameter to feature statistic plots feat(featurestatplot) default options to TRUE to show row and column names when plot_type is heatmap-alike","title":"2.0.1"},{"location":"CHANGELOG/#200-cloud-support-enhanced-visualization-new-analysesfeatures-and-more","text":"","title":"2.0.0 (Cloud support, enhanced visualization, new analyses/features, and more ...)"},{"location":"CHANGELOG/#cloud-support","text":"feat: immunopipe can now be run on Google Cloud Batch Jobs, allowing for scalable and efficient processing of larger datasets. You can either run the pipeline using the gbatch scheduler ; or run the entire pipeline on Gooble Batch Jobs using immunopipe gbatch command. See Run the pipeline using Google Cloud Batch Jobs\u00b6 for more details.","title":"Cloud support"},{"location":"CHANGELOG/#enhanced-visualization","text":"feat: scplotter and plotthis are now used for plotting, providing enhanced visualization capabilities and uniformity across different processes. feat: default descriptions/captions are now added to plots, making them more informative.","title":"Enhanced visualization"},{"location":"CHANGELOG/#enhanced-performance","text":"feat: the pipeline now uses qs2 for store the R objects, which speeds up the loading and saving of Seurat objects. feat: step-wise caching (in addition to process-wise) is now supported, especially for Seurat processes, allowing for faster re-running of the pipeline by caching intermediate results and improving results reproducibility. refactor: MetabolicLandscapeAnalysis is refactored for flexibility and performance improvement. BREAKING: enrichR is retired and replaced by enrichit for enrichment analysis, making it offline and more flexible. This enables the entire pipline to run without internet connection.","title":"Enhanced performance"},{"location":"CHANGELOG/#new-analysesfeatures","text":"feat: the pipeline now supports cell-cell communication analysis . feat: plots are supported for all cases for MarkersFinder and ScFGSEA , allowing plotting the markers (DEGs) and enriched pathways for all cases (e.g. all seurat clusters) in a single plot. BREAKING: the immunarch package is now replaced by scRepertoire for more features and allowing customized clonotype definition. feat: envs.mutaters is now supported for SeuratPreparing to allow create factor (categorical) columns in the metadata. feat: PseudoBulkDEG is added to perform pseudo-bulk differential expression analysis. feat: BCR-seq data is now supported, allowing users to analyze BCR-seq data paired with scRNA-seq data. feat: Now Seurat object (in RDS or qs2 format) is supported as input for scRNA-seq data. feat: Now loom format is supported for scRNA-seq data, allowing users to use loom files as input for the pipeline. feat: add mcp server functionality to launch mcp server to help compose the configuration file.","title":"New analyses/features"},{"location":"CHANGELOG/#house-keeping","text":"build: docker images are now built based on the biopipen base image. ci: the test workflow now caches the running intermediate files to speed up the tests. docs: the citation information is now added to the documentation, allowing users to easily cite the pipeline in their publications. chore(deps): biopipen is bumped to 0.34.8, which includes various bug fixes and enhancements. See the biopipen releases for more details.","title":"House keeping"},{"location":"CHANGELOG/#144","text":"chore(deps): add gcc_linux-64 to Docker environment dependencies docs: add input and output sections to multiple process documentation files feat: add PDF output for K-means and T cell plots, enhancing report generation deps: bump biopipen to 0.32.3 0.32.1: fix(scrna.ScFGSEA): fix case gmtfile not working fix(TopExpressingGenes): add InlineNotification component to TopExpressingGenes.svelte fix(scrna.SeuratClusterStats): fix kind not being added to the figure file name for plots of features feat(scrna.SeuratPreparing): support percent.mt, percent.ribo, percent.hb and percent.plat for mouse 0.32.2: feat: add PDF output option for SampleInfo plots feat: add PDF output options for violin and scatter plots in Seurat preparation scripts feat: add PDF output options for volcano, dotplot, venn, and upset plots feat: add PDF output option for Enrichr plots in TopExpressingGenes script feat: add PDF output options for UMAP plots in SeuratMap2Ref script; update image handling in misc.liq feat: add PDF output options for cluster size distribution, shared clusters, and sample diversity plots; update plotting functions to handle multiple output formats feat: add PDF output options for various Immunarch scripts; enhance reporting with downloadable PDF files feat: add PDF output options for cluster size distribution, dimension plots, and feature plots; enhance reporting with downloadable PDF files feat: add PDF output options for radar and bar plots; enhance reporting with downloadable PDF files feat: add PDF output options for CloneResidency script; enhance reporting with downloadable PDF files feat: add PDF output options for GSEA table and enrichment plots; enhance reporting with downloadable PDF files feat: add PDF output options for pie charts, heatmaps, Venn plots, and UpSet plots; enhance reporting with downloadable PDF files feat: add PDF output options for Enrichr plots; enhance reporting with downloadable PDF files feat: add PDF output options for estimated coefficients and distribution plots; enhance reporting with downloadable PDF files 0.32.3: chore: add descriptive summaries for fgsea and enrichr results","title":"1.4.4"},{"location":"CHANGELOG/#143","text":"deps: update pipen-runinfo dependency to version 0.8.0 (pipen to 0.15.2) deps: update biopipen dependency to version 0.31.4 fix(scrna.SeuratMap2Ref): fix refnorm not detected for NormlizeData'ed reference","title":"1.4.3"},{"location":"CHANGELOG/#142","text":"deps: add bioconductor-destiny dependency in docker environment files for ModuleScoreCalculator","title":"1.4.2"},{"location":"CHANGELOG/#141","text":"docs: update tutorial dataset information and links","title":"1.4.1"},{"location":"CHANGELOG/#140","text":"docs: update Singularity and Apptainer commands to include --writable-tmpfs flag docs: allow collapsing ns/choice items in the docs for processes docker: update Dockerfile to include npm cache configuration to allow the pipeline to run on read-only file system tests: update SeuratPreparing config to use DoubletFinder for doublet detection ci: use latest actions deps: add r-clustree as a dependency in docker environment files deps: update dependencies in docker environment files (python3.10, R4.3) deps: bump biopipen to 0.29.0 fix(tcr.TCRClusterStats): fix envs.shared_clusters.heatmap_meta being broken by envs.shared_clusters.sample_order (@ li.ying@mayo.edu ) choir(scrna.SeuratMap2Ref): present better error message when envs.use or values of envs.MapQuery.refdata not in reference (@ li.ying@mayo.edu ) fix(scrna.MarkersFinder): run PrepSCTFindMarkers when needed choir(scrna.SeuratClustering): use FindClusters to run for multiple resolutions choir(scrna.SeuratSubClustering): use FindClusters to run for multiple resolutions feat(scrna.SeuratClustering): add clustree plot (@ li.ying@mayo.edu ) feat(scrna.SeuratSubClustering): add clustree plot tests(scrna.SeuratClusterStats): add assertion for clustree plot generation deps: bump biopipen to 0.29.1 fix(delim.SampleInfo): fix numbers not split up when each is specified. enh(delim.SampleInfo): make sizes of pie charts proportional to number of samples when each is specified enh(scrna.MarkersFinder): run PrepSCTFindMarkers when necessary before calling FindMarkers feat(scrna.SeuratPreparing): add option to cache Seurat object at different steps feat(scrna.SeuratPreparing): allow doubletfinder to run with a different number of cores chore(scrna.SeuratClustering): record PrepSCTFindMarkers command in sobj@commands tests(scrna.SeuratClusterStats): use less stringent p-value cutoff for DEG/MarkersFinder tests(scrna.SeuratPreparing): add doubletfinder in tests deps: bump biopipen to 0.29.2 chore(scrna.SeuratClusterStats): use ident label length to adjust default height for feature plots fix(scrna.MetaMarkers): fix seurat object not updated when expanding cases and run PrepSCTFindMarkers when necessary before calling meta-markers fix(scrna.MarkersFinder): fix fetching command when composing the PrepSCTFindMarkers command fix(scrna_metabolic_landscape): handle null values in for loop in MetabolicFeatures and MetabolicFeaturesIntraSubset for report generation deps: bump biopipen to 0.30.0 BREAKING(scrna): move clustree plots from SeuratClustering/SeuratSubClustering to SeuratClusterStats feat(scrna.CellTypeAnnotation): allow to merge/not to merge (envs.merge) the clusters with the same labels predicted feat(scrna.SeuratPreparing): add scDblFinder to detect doublets feat(scrna.SeuratMap2Ref): add envs.skip_if_normalized option to skip normalization if query is already normalized using the same - method as the reference refactor(tcr.Immunarch): source the files for Immunarch scripts for better debugging refactor(scnra.SeuratClustering): refactor the script for better debugging refactor(scnra.SeuratPreparing): refactor the script for better debugging fix(scrna): fix resolution expansion for SeuratClustering and SeuratSubClustering fix(scrna): Fix generating PrepSCTFindMarkers command when no previous commands present tests(scrna.ScFGSEA): fix unavailable urls to GMT files chore(scrna.SeuratMap2Ref): optimize memory usage chore(scrna.MetaMarkers): remove plugin_opts.poplog_max chore(tcr.CloneResidency): improve logging when handling subjects deps: bump biopipen to 0.31.3 enh(scrna.SeuratMap2Ref): check if reference has SCTModel if SCTransform'ed (likely prepared by old Seurat) fix(tcr.CDR3AAPhyschem): use sequence from TRB chain only fix(tcr.CDR3AAPhyschem): fix when chain is not available fix(tcr.TCRClustering): fix for multi-chain TCRs, use TRB only if on_multi is false fix(tcr.TCRClustering): fix when chain is not available","title":"1.4.0"},{"location":"CHANGELOG/#139","text":"docs: update docs for TCellSelection to avoid confusion deps: bump biopipen to 0.27.9 feat(tcr.TCRClusterStats): add sample_order to set sample order on heatmap and cluster_rows to switch row clustering on/off","title":"1.3.9"},{"location":"CHANGELOG/#138","text":"docs: remove -w option for apptainer/singularity as no writing is necessary since pipen-board 0.15.1 deps: update biopipen to version 0.27.8 fix(scrna.SeuratClusterStats): fix selected columns not unique for stats feat(scrna.SeuratMap2Ref): allow non-SCTransform'ed reference feat(scrna.SeuratMap2Ref): allow splitting query object for mapping (pwwang/immunopipe#61) deps: update pipen-board to version 0.15.1 (allow configuration file path in the URL box on Web UI)","title":"1.3.8"},{"location":"CHANGELOG/#137","text":"ci: fix docker images building when no essential changes made","title":"1.3.7"},{"location":"CHANGELOG/#136","text":"ci: fix deploy workflow (#59) ci: add README.md to tests-output branch ci: fix test/test workflow tests: add make test tests: init test data preparation tests: add test for ImmunarchLoading tests: add tests for SeuratPreparing tests: Update configs for SeuratPreparing test to subset cells so tests can run on CI tests: update SeuratPreparing test to disable export tests: add tests for SeuratClusteringOfAllCells/SeuratClustering docs: update installation instructions (@ stein.mariam@mayo.edu ) deps: bump biopipen to version 0.27.7 (0.27.5-0.27.7) fix(scrna.SeuratClusterStats): fix color palette for ridge plots (@ stein.mariam@mayo.edu ) feat(scrna.SeuratPreparing): add envs.cell_qc_per_sample to filter cells before merging instead after fix(scrna_metabolic_landscape.MetabolicFeatures): fix return value of groups with less than 5 cells in do_one_group fix(scrna_metabolic_landscape): fix mutaters not working. fix(scrna_metabolic_landscape.MetabolicFeatures/MetabolicFeaturesIntraSubset): skip groups with less than 5 cells in do_one_group and save a warning file under the case chore: fix typo in class name ExprImpution to ExprImputation","title":"1.3.6"},{"location":"CHANGELOG/#135","text":"ci/test: add tests in CI and deploy output in a different branch deps: bump biopipen to 0.27.4 choir(delim.SampleInfo): add alpha to the colors of the plots using biopipen color pallete docs(tcr/scrna/scrna_metabolic_landscape): update links of images in docs","title":"1.3.5"},{"location":"CHANGELOG/#134-post","text":"ci/test: init ci for tests docs: introduce versioning for docs","title":"1.3.4-post"},{"location":"CHANGELOG/#134","text":"deps: bump biopipen to 0.27.3 deps: bump pipen-poplog to 0.1.2 (quick fix for populating logs when job fails) deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) choir(scrna.ScFGSEA): Skip cases when no cells found (#50) choir(scrna.MarkersFinder): Skip cases when no cells found (#50) choir(scrna.MetaMarkers): Skip cases when no cells found (#50) feat(scrna.SeuratPreparing): support DoubletFinder (#52)","title":"1.3.4"},{"location":"CHANGELOG/#133","text":"deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) docs: update FAQ.md with instructions for running pipeline on a cluster deps: bump biopipen to 0.27.2 fix(scrna.RadarPlots): fix mutaters not working feat(tcr.CloneResidency): support envs.upset_ymax to set the max value of y axis in upset bar plot.","title":"1.3.3"},{"location":"CHANGELOG/#132","text":"deps: bump pipen to 0.14.5 deps: add r-complexupset package to environment.yml and environment_full.yml for CloneResidency deps: pin tensorflow to 2.15 for TESSA deps: bump biopipen to 0.27.1 depr(scrna.MarkersFinder): remove envs.use_presto as it's used by Seurat v5 by default enh(tcr.CloneResidency): support log scale for y axis of upset bar plots enh(scrna.SeuratClusterStats): allow to rotate labels in circos plot (pwwang/immunopipe#48) @ li.ying@mayo.edu enh(scrna.SeuratClusterStats): use pal_biopipen for ident colors in circos plot fix(scrna.CellsDistribution): fix the row order of the heatmaps fix(scrna.SeuratClusterStats): fix when envs.split-by is specified feat(scrna.CellsDistribution): support envs.prefix_each feat(scrna.MarkersFinder): allow to set max number of genes to plot in dotplots feat(scrna.MarkersFinder): support setting detailed arguments for overlapping plots feat(scrna.MarkersFinder): support envs.prefix_group feat(scrna.ScFGSEA): support envs.prefix_each feat(scrna.RadarPlots): support envs.prefix_each and envs.subset choir(scrna.SeuratClusterStats): use logger instead of print for log messages choir(tcr.TCRClustering): print session info for clustcr script choir(scrna.MarkersFinder): flatten toc when no section and no ident-1 specified docs: add more detailed docs for envs.section for multiple processes BREAKING(scrna.SeuratMap2Ref): rename envs.name to envs.ident so envs.MapQuery.refdata is not - required anymore. It will be inferred from envs.ident and envs.use. @ li.ying@mayo.edu","title":"1.3.2"},{"location":"CHANGELOG/#131","text":"deps: bump pipen to 0.14.3 deps: pin ggplot2 to 3.4 for docker due to breaking changes of 3.5 deps: bump biopipen to 0.26.2 deps: bump datar-pandas to 0.5.5 to dismiss deprecated warnings fix(utils.misc.R): replace latin and greek characters with closest ascii chars for slugify() feat(scrna.TopExpressingGenes): support subset fix(scrna.CellsDistribution): fix the row order of the heatmaps. enh(tcr.CloneResidency): add legend for multiplets in upset plots. feat(scrna.SeuratClusterStats): add circos plot for cell composition stats (#46).","title":"1.3.1"},{"location":"CHANGELOG/#130","text":"deps: bump pipen to 0.14.1 deps: bump pipen-report to 0.18.2 deps: bump biopipen to 0.26.0 fix(scrna.CellTypeAnnotation): keep factor meta data when input and output are RDS for celltypist deps: bump datar to 0.15.4 (support pandas 2.2) fix(utils.single_cell.R): fix immdata_from_expanded missing other data columns fix(tcr.Immunarch): fix mutaters not working when no subset is set fix(scrna.CellsDistribution): fix hm_devpars not working fix(scrna.CellsDistribution): fix multiple cells_by columns and speed up plotting choir(tcr.CloneResidency): mark singletons in Venn diagrams more clear fix(scrna.RadarPlots): fix the order of groups on radar plots choir(scrna.RadarPlots): transpose the count/percentage table to save to files fix(scrna.MarkersFinder): fix generating report json file when no significant genes found choir(scrna.MarkersFinder): Plot maximum 20 genes in dotplots choir(scrna.MarkersFinder): Do not convert dashes in case names to dots see more at https://github.com/pwwang/biopipen/releases/tag/0.26.0","title":"1.3.0"},{"location":"CHANGELOG/#120","text":"docs: update FAQs to align with Seurat v5 docs: add image from manuscript to README.md docs: center the flowchart image in README.md docs: mention celltypist model prep in preparing input data deps: bump pipen to 0.13.2 deps: bump biopipen to 0.25.2: scrna.MarkersFinder: allow to cache FindAllMarkers results scrna.CellTypeAnnotation: support celltypist (pwwang/biopipen#111) scrna.SeuratSubClustering: add envs_depth = 1 to replace whole envs.cases when new case assigned scrna_metabolic_landscape.MetabolicPathwayHeterogeneit): fix output directory path is not slugified tcr.Immunarch: change case filling log to debug level","title":"1.2.0"},{"location":"CHANGELOG/#111","text":"deps: Bump biopipen to 0.24.2 chore: use internal slugify instead of slugify library tcr.Immunarch: fix spectratyping output file extension is not png scrna.SeuratPreparing: fix displaying filters in report scrna.SeuratPreparing: fix logging Seurat procedure arguments","title":"1.1.1"},{"location":"CHANGELOG/#110","text":"docs: update table in gallery deps: use pipen-poplog to populate job logs to pipeline running log deps: bump biopipen to 0.24. Hights: scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112) @yuey11 scrna.SeuratClustering/SeuratSubClustering: cache Seurat procedures step by step (#40) @xyfqwlzoe tcr.Immunarch: add plot_type to support boxplots for diversity metrics see more at https://github.com/pwwang/biopipen/releases/tag/0.24.0","title":"1.1.0"},{"location":"CHANGELOG/#105","text":"change: do not rescale gene expression in TCellSelection any more fix: fix column names of indicators not aligned with indicator_genes feat: add feature plots in TCellSelection deps: bump biopipen to 0.23.8 scrna.SeuratPreparing: log Seurat procedure arguments scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112)","title":"1.0.5"},{"location":"CHANGELOG/#104","text":"deps: bump biopipen to 0.23.7 scrna.SeuratPreparing: update log message for transformation/scaling step scrna_metabolic_landscape.MetabolicPathwayHeterogeneity: add utils.gsea script source to support localizeGmtfile","title":"1.0.4"},{"location":"CHANGELOG/#103","text":"deps: add r-seuratdisk dependency to conda env files. @yuey11 deps: pin r-matrixstats to 1.1.0 in conda env files to fix useNames = NA error. @yuey11 refactor: optimize configuration file validation deps: bump biopipen to 0.23.6 feat: support url for gmtfile wherever GSEA is performed (pwwang/biopipen#113) tcr.Immunarch: add error message for empty filtered/subset data in diversity scrna.SeuratPreparing: correct description of default assay in docstr scrna.SeuratPreparing: run also the normal normalization procedures when SCTransform is used (useful for visualization purposes on RNA assay) scrna.ModuleScoreCalculator: document the names added by cell cycle score (#34) scrna.SeuratPreparing: support sample names as reference for IntegrateLayers","title":"1.0.3"},{"location":"CHANGELOG/#102","text":"deps: add bioconductor-glmgampoi to conda env files (#33) docs: correct the Seurat object assay description deps: bump biopipen to 0.23.5 fix: fix when no enriched items found for scrna.MarkersFinder , scrna.MetaMarkers and scrna.TopExpressingGenes scrna.SeuratClusterStats: fix when frac or frac_ofall is true and no group-by nor split-by is specified for stats utils.gsea.R: fix when no enriched items found for runEnrichr scrna_metabolic_landscript: fix adding report when ncores > 1","title":"1.0.2"},{"location":"CHANGELOG/#101","text":"docs: add gallery section to README.md change: set default nstart of kmeans to 25 in TCellSelection deps: add r-hdf5r in conda env files to support Read_10x_h5 from Seurat. @yuey11 deps: bump biopipen to 0.23.4 scrna.TopExpressingGenes: fix colnames while pulling average expression scrna.CellsDistribution: fix when cells_by has multiple column names scrna.CellTypeAnnotation: fix the order of the clusters for direct method scrna.SeuratClusterStats: add position options for bar plots for stats scrna.RadarPlots: add colors to set the colors of the loops in radar and bar plots tcr.Immunarch: add split_by and split_order to put subplots together in one single plots","title":"1.0.1"},{"location":"CHANGELOG/#100","text":"","title":"1.0.0"},{"location":"CHANGELOG/#highlights","text":"feat: support Seurat v5 (integration is now down by Seurat::IntegrateLayers ) feat: support supervised clustering (mapping cells to reference by Seurat ) feat: support dataset with scRNA-seq data only (no scTCR-seq data) feat: support diffusion map calculation (by ModuleScoreCalculator ) feat: support subclassing to cluster subsets of cells (by SeuratSubClustering ) feat: allow to ignore TCR data in TCellSelection and pass kmeans arguments feat: allow to set multiple resolutions ( envs.FindClusters.resolution ) in SeuratClustering / SeuratClusteringOfTCells change: change unsuperved cluster labels to c1 , c2 , ... in SeuratClustering by default docs: add gallery, which contains real-world examples of datasets from publications","title":"Highlights"},{"location":"CHANGELOG/#breaking-changes","text":"change: rename SeuratMetadataMutater to IntegratingTCR change: rename SeuratClusteringOfTCells to SeuratClustering change: rename TCRClusters2Seurat to IntegratingTCRClusters refactor: make SeuratClustering (instead of SeuratClusteringOfAllCells ) work for all cells when all are T cells change: move data preparation and integration from SeuratClustering to SeuratPreparing change: default mode of ImmunarchLoading to paired (instead of single ), which requires both alpha and beta chains (instead of beta chain only) to define a clonotype change: default dbs for enrichment analysis wherever applies to KEGG_2021_Human and MSigDB_Hallmark_2020","title":"Breaking changes"},{"location":"CHANGELOG/#changes","text":"feat: make TopExpressingGenes optional feat: add validate_config to validate configuration schematically","title":"Changes"},{"location":"CHANGELOG/#features","text":"feat(SeuratPreparing): allow to filter genes directly (by specifying envs.gene_qc.excludes ) feat(SeuratClusterStats): add ngenes to plot the number of genes expressed in each cluster feat(SeuratClusterStats): add barplot for features and allow aggregation of features feat(SeuratClusterStats): add envs.mutaters to mutate meta data feat(SeuratClusterStats): add histograms to plot number of cells against another variable feat(SeuratClusterStats): Add frac_ofall and transpose for stats to calculate fraction within group or against all cells, and transpose ident and group, respectively","title":"Features"},{"location":"CHANGELOG/#dependencies","text":"deps: add r-presto to conda environment files to support using presto to fastly find markers deps: add bioconductor-destiny to conda environment file to support add diffusion map components in ModuleScoreCalculator deps: add r-harmony to support harmony integration by Seurat v5 in conda env file deps: add r-sf to conda env file deps: remove vdjtools from conda env files deps: bump pipen-report to 0.16.3 deps: bump biopipen to 0.23.3 . Hightlight changes: scrna.MarkersFinder: Add envs.use_presto to use presto to speed up finding markers scrna.SeuratPreparing: Set envs.gene_qc.min_cells to 0 by default (instead of 3) scrna.ScFGSEA: Allow to ignore small group when fgsea fails due to all NAs for pre-ranks scrna.CellsDistribution: Allow to order clusters by envs.cluster_orderby scrna.CellsDistribution: Add heatmaps tcr.CloneResidency: Make section works in report tcr.Immunarch: Support paired chain data for VJ conjuction plots tcr.TESSA: Change envs.assay to None to use default assay of Seurat object scrna.SeuratClusterStats: Add avgheatmap to plot more elegant heatmap for average gene expressions scrna.SeuratClusterStats: Fix ident not working for dimplots scrna.SeuratClusterStats: Add cluster_orderby to order clusters for features scrna.SeuratClusterStats: Add na_group to keep NA values in group-by utils.mutate_helpers: Change arguments id_col and compare_col of paired to id and compare , respectively utils.mutate_helpers: Fix that subset can't be an expression for expanded family utils.mutate_helpers: Add top to select top entities (e.g clones) scrna.RadarPlots: Add breakdown and test to break down the cell distribution and run statistic test on the fractions","title":"Dependencies"},{"location":"CHANGELOG/#0112","text":"docs: move Immunarch to the later position in process list docs: Use master tag in getting-started","title":"0.11.2"},{"location":"CHANGELOG/#0111","text":"chore: change line length to 88 for flake8 chore: dismissing warning about wasting columns for SeuratClusteringOfTCells docs: update CHANGELOG.md with missing changes of last version docs: add version of renaming envs.tcell_indicator to envs.tcell_selector docs: remove unused doc files docs: add metadata illustration deps: bump biopipen to 0.22.8. Highlights: deps: bump pipen-board to 0.13.10 (pipen-report to 0.16.2) CellsDistribution: Don't add rownames to the output table file MarkersFinder (ClusterMarkers/ClusterMarkersOfAllCells): Optimize to use FindAllMarkers if ident.1 is not specified SeuratClusterStats: Fix path of expression table file CellTypeAnnotation: Allow using NA to exclude clusters from output Seurat object utils.mutate_helpers: Return ids only when subset is true and group is not NA for uniq = TRUE in expanded , collapsed , emerged and vanished","title":"0.11.1"},{"location":"CHANGELOG/#0110","text":"deps: update biopipen to 0.22.1, highlights: add V-J junction circos plots to Immunarch process add cache option to cache the clustering results if nothing changed except ncores, to SeuratClustering process add dot plots to MarkersFinder ( ClusterMarkersOfAllCells , ClusterMarkers ) process save exported table with only necessary columns for CellsDistribution process add descr to describe cases cases in report for CellsDistribution process add subset for dimplots in SeuratClusterStats process use a new palette ( biopipen ) for related processes optimize report rendering (using render_job() filter from pipen-report ) change metacols to extracols so essential columns get exported for ImmunarchLoading process add cache option to cache the clustering results if nothing changed except ncores for SeuratClustering ( SeuratClusteringOfAllCells ) process see more at https://github.com/pwwang/biopipen/releases/tag/0.22.0 and https://github.com/pwwang/biopipen/releases/tag/0.22.1 deps: update pipen-report to 0.16, highlights: scroll anchor into view on the page build report page when each process is done, instead of the whole pipeline see more at https://github.com/pwwang/pipen-report/releases/tag/0.16.0 change: remove Immunarch2VDJtools and VJUsage processes (vj usage analysis can be done in Immunarch process) change: change tcell_indicator to tcell_selector in TCellSelection process enhance: provide better error message when none barcode matches from RNA and TCR data for TCRClustering process docs: add memory usage reduction tips in FAQ chore: dismiss warnings of wasted input columns for multiple processes","title":"0.11.0"},{"location":"CHANGELOG/#0101","text":"chore: update pipeline description to include version in the logs fix: add fc-cache command to Dockerfile to solve Fontconfig error docker: optimize building full image based off the base image","title":"0.10.1"},{"location":"CHANGELOG/#0100","text":"docker: lock r-matrix version to 1.6_1 for compatibility docs: adopt mkdocs-rtd 0.0.10 (add scrollbar to the table of contents) deps: bump biopipen to 0.21.1 use r-logger for logging in R scripts docs: fix internal references in API docs deps: bump pipen-board to 0.13.6 SampleInfo: refactor data subset logic using subset instead of distinct Immunarch: add in.metafile to allow other meta info (i.e. seurat clusters) for future subsetting (#22) Immunarch: fix empty groups in diversity plot after subsetting Immunarch: allow subset to subset cells for analyses Immunarch: allow separate_by also works on other diversity plots Immunarch: add ymin and ymax to align diversity plots by separate_by Immunarch: add ncol to specify # columns in the combined plots RadarPlots: fix envs.order not working MarkersFinder: add overlap to find overlapping markers between cases (#24) MarkersFinder: allow subset to subset cells for analyses MarkersFinder: add dot plots for significant markers CellsDistribution: allow multiple columns for cells_by CellsDistribution: allow subset to subset cells for analyses utils.mutate_helpers.R: add include_emerged for expanded() and include_vanished for collapsed()","title":"0.10.0"},{"location":"CHANGELOG/#093","text":"deps: Bump biopipen to 0.20.7 deps: Bump pipen-board to 0.13.4 ClusterMarkers/ClusterMarkersOfAllCells: Choose avg_log2FC > 0 markers by default MarkersFinder: Allow to set assay and set assay to RNA by default CellsDistribution: Add venn/upset plot for overlapping cell groups in different cases SampleInfo: Add distinct to case to perform stats on distinct records","title":"0.9.3"},{"location":"CHANGELOG/#092","text":"\u2795 Add r-ggnewscale as dependency for CDR3AAPhyschem in docker image \u2b06\ufe0f Bump biopipen to 0.20.5 \ud83e\uddf1 CloneResidency: Integrate RNA data to allow more flexible analysis (i.e. within specific seurat clusters) \ud83c\udfd7\ufe0f CloneResidency: Rename envs.sample_groups to envs.section to be consistent with other processes \ud83d\udcdd ScFGSEA: Remove the link in the summary of the docstring (since they are not transformed in the report) \ud83c\udfa8 CDR3AAPhyschem: Give better error message when wrong group items are given \u2b06\ufe0f Bump pipen-board to 0.13.3 Add items automatically when blurred for list options Add other sections to description on the UI for processes","title":"0.9.2"},{"location":"CHANGELOG/#091","text":"\ud83d\udc1b Fix docstring for RadarPlots \u2795 Add pipen-diagram as dependency \u2795 Set pipen-runinfo as optional \u2b06\ufe0f Bump biopipen to 0.20.4 \ud83d\udcdd Update version in docs","title":"0.9.1"},{"location":"CHANGELOG/#090","text":"","title":"0.9.0"},{"location":"CHANGELOG/#housekeeping-and-docs","text":"Bump biopipen to 0.20.3 (pipen to 0.12) Use pipen-cli-ref to generate API for processes (it uses docstring of the process class so that we don't need to maintain two copies of docs)","title":"Housekeeping and docs"},{"location":"CHANGELOG/#fixedenhanced","text":"Make /data directory in container, so it can be mounted Fix a bug when a single gene provided to indicator_genes in TCellSelection Move ModuleScoreCalculator before clustering so that the scores can be used in vars.to.regress of SCTransform while clustering Set default assay to RNA in case module scores only caculated using integrated features in ModuleScoreCalculator Improve QC plots in SeuratPreparing by marking the cells that are removed in the plots instead of doing before/after plots Fix type annotation for envs.features_defaults.ncol in docstring for SeuratPreparing (causing pipen-board not converting to int) Fix the cluster order in pie charts for CellsDistribution Fix the cluster order in pie charts for SeuratClusterStats Fix order in pie charts for SampleInfo Fix docstring for envs.div.args of Immunarch (more clear description of method) Allow mutiple columns in the file for envs.features_defaults.features in SeuratClusterStats Allow order to be optional for CloneResidency (errored when not provided) Add number of clusters at the end of log for SeuratClusteringOfAllCells / SeuratClusteringOfTCells Add stricter checker for input file (#13) Indicate the case name in logs when pie is enabled for group-by in SeuratClusterStats Allow to skip overlap and gene usage analyses by setting method to none for Immunoarch (#11, #12) Don't cluster on heatmap when there are only 2 samples for TCRClusterStats (#11) Import Seurat explictly to avoid satijalab/seurat#2853 in MetabolicFeatures Fix when NA values in data for heatmap in MetabolicPathwayActivity Fix error when no significant pathways selected in MetabolicPathwayHeterogeneity Give better error message in CellsDistribution if group value not found for CellsDistribution (#16) Try including more genes (even though insignificant) in volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells (#17) Add margins to volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells Fix when envs.cell_qc is None (not provided) for SeuratPreparing Fix ident in cases of envs.dimplots not working for SeuratClusterStats","title":"Fixed/Enhanced"},{"location":"CHANGELOG/#added","text":"Add ClusterMarkersOfAllCells and TopExpressingGenesOfAllCells and set them as optional Add dim plots in SeuratClusterStats to overlay TCR presence/absence of cells (#14)","title":"Added"},{"location":"CHANGELOG/#breaking-changes-090","text":"Rename TCRClusteringStats to TCRClusterStats (#15)","title":"Breaking changes-0.9.0"},{"location":"CHANGELOG/#083","text":"\ud83d\udcdd Fix typos in docs \ud83d\udcdd Add links to some optional input files (#9, 5) \ud83d\udd28 Add apptainer to docker entry.sh (#9, 6) \ud83d\udc84 Adjust process order in reports (#9, 1) \u2b06\ufe0f Bump pipen-report to 0.13.1 (#9, 2)","title":"0.8.3"},{"location":"CHANGELOG/#082","text":"Bump biopipen to 0.18.3 to fix when either ident is empty for MarkersFinder","title":"0.8.2"},{"location":"CHANGELOG/#081","text":"Bump biopipen to 0.18.2 to fix a bug when the min length of CDR3 seqs > 12 for CDR3AAphyschem","title":"0.8.1"},{"location":"CHANGELOG/#080","text":"","title":"0.8.0"},{"location":"CHANGELOG/#housekeeping-and-docs-updates","text":"Bump biopipen to 0.18.1 Mention function changes with versions in docs Add apptainer in board.toml so the command can be generated in pipen-board Make logo shorter in docs Add docker image with -full tags to include all dependencies Print command help message if run test failed in CI Add singularity/apptainer in FAQ for \"no space left\" question Add -w fro apptainer in docs (as we need to save pipen-board file in home directory)","title":"Housekeeping and docs updates"},{"location":"CHANGELOG/#added-080","text":"Add TESSA process for tessa analysis Add volcano plot for MarkersFinder and ClusterMarkers","title":"Added-0.8.0"},{"location":"CHANGELOG/#fixed","text":"Fix when Sample is the only column in meta for ImmunarchLoading Add clear message when k.weight is too large for IntegrateData in SeuratClustering Allow unique: prefix for on in SampleInfo Fix sample order in plots for SampleInfo Remove tidyseurat:: prefix for filter in scripts of MetaMarkers , ScFGSEA and SeuratClusterStats in case tidyseurat::filter is not exported when installed from conda (but it will make dplyr::filter work anyway on seurat object)","title":"Fixed"},{"location":"CHANGELOG/#breaking-changes-080","text":"Redesign envs for SeuratClusteringStats to allow setting defaults for cases and switch identities for plots","title":"Breaking changes-0.8.0"},{"location":"CHANGELOG/#070","text":"","title":"0.7.0"},{"location":"CHANGELOG/#housekeeping-and-docs-updates-070","text":"Fix typos in docs/configurations TCRClustering should be TCRClusteringStats in Multi-case variable design section infile of [SampleInfo.in] should be samples.txt rather than sample.txt Remove unused scripts by deprecated processes Bump pipen-report to 0.12.8 Add master branch and master tag as stable tag for docker image Add pdf version of the flowchart (#4) Add warning for the results in getting started tutorial Bump pipen-board to 0.11.5 Add apptainer to the docs","title":"Housekeeping and docs updates-0.7.0"},{"location":"CHANGELOG/#added-070","text":"Add ModuleScoreCalculator to calculate module scores or cell cycle scores See: https://pwwang.github.io/immunopipe/processes/ModuleScoreCalculator/ Allow SampleInfo to perform statistics on the sample information See: https://pwwang.github.io/immunopipe/processes/SampleInfo/ Add TCR_Cluster_Size and TCR_Cluster_Size1 from TCRClustering to metadata for further integrative analysis See: https://pwwang.github.io/immunopipe/processes/TCRClusters2Seurat/","title":"Added-0.7.0"},{"location":"CHANGELOG/#fixed-070","text":"Fix default height and width for plots in SeuratClusterStats Fix cluster order not kept after annotation using hitype in CellTypeAnnotation","title":"Fixed-0.7.0"},{"location":"CHANGELOG/#breaking-changes-070","text":"Change seurat_clusters_old to seurat_clusters_id to save old seurat_clusters in CellTypeAnnotation Remove MarkersForClustersOfAllCells and TopExpressingGenesOfAllCells processes Rename MarkersForClustersOfTCells to ClusterMarkers Rename TopExpressingGenesOfTCells to TopExpressingGenes Rename envs.exprs to envs.features for SeuratClusterStats envs.exprs.genes is also renamed to envs.features.features","title":"Breaking changes-0.7.0"},{"location":"CHANGELOG/#060","text":"\u2b06\ufe0f Bump biopipen to 0.16 \ud83d\udcdd Add documentation \ud83d\udc9a Fix docs building in CI \ud83d\udcdd Update README with flowchart","title":"0.6.0"},{"location":"CHANGELOG/#051","text":"\u2728 Add TopExpressingGenes \ud83c\udfa8 Move RadarPlots to biopipen \u2b06\ufe0f Bump biopipen to 0.15.2","title":"0.5.1"},{"location":"CHANGELOG/#050","text":"\u2b06\ufe0f Upgrade biopipen to 0.15.0 \ud83d\udc9a Use better strategy docker image building","title":"0.5.0"},{"location":"CHANGELOG/#040","text":"\u2b06\ufe0f Bump biopipen to 0.6 \u2b06\ufe0f Upgrade other dependencies \ud83d\udc9a Use micromamba for docker image building \u2b06\ufe0f Add procps-ng for vdjtools for docker building","title":"0.4.0"},{"location":"CHANGELOG/#030","text":"\ud83d\udc9a Use build 2 for genomeinfodbdata from bioconda (0.2.4) \ud83d\udc7d\ufe0f Use config from pipen_args \u2b06\ufe0f Pump biopipen to 0.5.3, pipen-args to 0.3.2 \u2b06\ufe0f Upgrade deps for docker \ud83d\udcdd Add flowchart in README.md \ud83d\udc1b Fix error when --config not passed","title":"0.3.0"},{"location":"CHANGELOG/#024","text":"\ud83d\udc9a Use lastest miniconda3 for docker build \ud83d\udc9a Use conda channel pwwang for bioconductor-genomeinfodbdata for fix (bioconda/bioconda-recipes#31349) \u2b06\ufe0f Upgrade biopipen to 0.4.9 \ud83d\udcdd Add URL to example in README","title":"0.2.4"},{"location":"CHANGELOG/#023","text":"\u2b06\ufe0f Upgrade biopipen to 0.4.8","title":"0.2.3"},{"location":"CHANGELOG/#022","text":"\u2b06\ufe0f Upgrade biopipen to 0.4.7 to fix SeuratPreparing","title":"0.2.2"},{"location":"CHANGELOG/#021","text":"\ud83d\udd25 Fix the bug of the wrong arguments in help page \u2b06\ufe0f Upgrade clustcr to 1.0.2 \ud83d\udcdd Fix docs for metabolic analysis","title":"0.2.1"},{"location":"CHANGELOG/#020","text":"\u267b\ufe0f Move in-house processes out of processes.py \u267b\ufe0f Split up MARKERS_FINDER \u267b\ufe0f Refactor RadarPlots \u2728 Add an example config file \u26a1\ufe0f Add filter for RadarPlots \ud83d\udcdd Update docs \u2b06\ufe0f Upgrade deps \ud83d\udd27 Update docker/environment.yml \ud83d\udc1b Fix CloneHeterogeneity when only 1 row in continency table","title":"0.2.0"},{"location":"CHANGELOG/#011","text":"\ud83d\udc9a Try fix pip in environment.yml \ud83d\udcdd Update readme for requirement checking \ud83d\udcdd Update docs to fix #1 \ud83d\udcdd Update CHANGELOG \u2b06\ufe0f Adopt biopipen 0.4.0","title":"0.1.1"},{"location":"CHANGELOG/#010","text":"\ud83e\ude79 Disable force-caching for some procs \u2b06\ufe0f Upgrade datar to 0.8.* \u2728 Add dockerfile \u2b06\ufe0f Upgrade pipen to 0.3 \ud83d\udca5 Remove gene lists from start processes \u2b06\ufe0f Upgrade biopipen to 0.3 \u2b06\ufe0f Upgrade pipen to 0.3.5","title":"0.1.0"},{"location":"CHANGELOG/#007","text":"Add CloneHeterogeneity Allow setting indicator_gene for TCellSelection Adopt latest datar and biopipen","title":"0.0.7"},{"location":"CHANGELOG/#006","text":"\u2728 Allow dimplots with clonal information","title":"0.0.6"},{"location":"CHANGELOG/#005","text":"\u2728 Allow more flexible dim plots","title":"0.0.5"},{"location":"CHANGELOG/#004","text":"\u2728 Refactor markers finder module and add meta-marker analysis","title":"0.0.4"},{"location":"CHANGELOG/#003","text":"-\u2728 Add metabolic pathway analysis","title":"0.0.3"},{"location":"CHANGELOG/#002","text":"Adopt biopipen 0.1.3","title":"0.0.2"},{"location":"CHANGELOG/#001","text":"First release","title":"0.0.1"},{"location":"configurations/","text":"Configurations \u00b6 In this section, we are discussing how to configure the pipeline itself and some common issues we may encounter or need to be aware of to configure individual processes. For the configurations of each process in details, please refer to the individual process pages. As mentioned in pipen 's docs , the configurations to control the pipeline can be ~/.pipen.toml and/or ./.pipen.toml . You can set the default values in those files. Additionally, you can also pass a configuration file from command line, as described in Running the pipeline section. You can override the default values in the configuration files by passing arguments from command line. The configuration file is in toml format. A schematic example is shown below: forks = 4 # Other pipeline configurations # process configurations [TOrBCellSelection] forks = 2 # override the default value # envs of the process # e.g [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] # other processes # [ProcessName] # ... Tip In the individual process pages, we will list the envs of the process. For example, indicator_genes (list) : The genes to be used to select T cells. This means that the environment variable indicator_genes should be set as follows: [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] Pipeline configurations \u00b6 There are pipeline level configurations and process level configurations. The pipeline level configurations are used to control the pipeline itself. The process level configurations set here are the default values for all the processes. You can override the default values for each process in the process level configurations. You can check all available configuration items and more details here . Here we only list some of the most important ones. The rest ones are not recommended to change unless you know what you are doing. Pipeline level configurations \u00b6 name : The name of the pipeline (Default: \"Immunopipe\" ) It will change the working directory to ./.pipen/<name> , where the pipeline information and intermediate files will be stored. It will also change the default output directory to ./<name>-output . outdir : The output directory (Default: \"./<name>-output\" ) The output directory is where the final results and reports are stored. loglevel : The logging level for the logger (Default: \"info\" ) plugin_opts : The options for the plugins. Following pipen plugins are installed with immunopipe . You may check the links for more details. pipen-board : Visualizing configuration and running of pipen pipelines on the web. pipen-verbose : Adding verbosal information in logs for pipen. pipen-runinfo : Generating running information for jobs in pipen pipelines. pipen-filters : Adding a set of useful filters for pipen templates. pipen-args : Command line argument parser for pipen pipen-annotate : Using docstring to annotate pipen processes. pipen-report : Generating reports for pipen pipelines. pipen-log2file : Logging to files for pipen pipelines. pipen-cli-run : Running pipen processes/process groups from command line. scheduler : The scheduler to use (Default: \"local\" ) scheduler_opts : The options for the scheduler. immunopipe is implemented using pipen , which is backended by xqute . Supported schedulers and options are listed here . See also How to run the pipeline on a cluster? for more details. Output and working directory \u00b6 The output directory is the directory where the final results are stored. The working directory is the directory where the pipeline information and intermediate files are stored. By default, the output directory is ./<name>-output and the working directory is ./.pipen/<name> . The output of processes with final results will be stored in the output directory in sub-directories named after the processes. For example, the output of SeuratClusteringOfAllCells will be stored in ./<outdir>/SeuratClusteringOfAllCells . This is also a special subdirectory named REPORTS that contains the reports of the pipeline. By visiting the <outdir>/REPORTS/index.html with a web browser, you can check the reports of the pipeline. You can change the output directory by setting outdir or name in the configuration file. For example, if you want to change the output directory to ./output , you can set the configurations as follows: outdir = \"./output\" If you change the pipeline name: name = \"my-pipeline\" Then the output directory will be changed to ./my-pipeline-output . Note If both outdir and name are set, outdir will be used. You can do the similar thing to change the working directory. However, you are NOT recommended to change the working directory, especially if you are using pipen-board . This is because that the plugin scans ./.pipen/<name> to get the information for the previous run of the pipeline. If you change the working directory, the plugin will not be able to find the information for the previous run. Tip What if you want to change the working directory anyway? The recommended way is to create a symbolic link to the working directory. For example, if you want to change the working directory to /path/to/the/real/working/directory , you can do: ln -s /path/to/the/real/working/directory ./.pipen Tip You can also then debug the pipeline by inspecting the real scripts in the working directory that run for the jobs of each process at ./.pipen/<name>/<process-name>/<job-index>/job.script . You can also find the other information for the jobs at ./.pipen/<name>/<process-name>/<job-index>/ , including the stdout ( job.stdout ) and stderr ( job.stderr ) of the jobs, the exit code of the jobs ( job.rc ), etc. Process level configurations \u00b6 cache : Should we detect whether the jobs are cached. If true , the jobs will be skipped if the output files exist and newer than the input files. (Default: true ) error_strategy : The strategy to handle the errors. halt : Any failure will just halt the entire pipeline (default) ignore : Ignore the error and keep running (assuming the job runs successfully anyway) retry : Retry to job running. After num_retries times of retrying, if the job is still failing, halt the pipeline. num_retries : The number of retries for the jobs. (Default: 3 ) forks : How many jobs to run simultaneously? (Default: 1 ) scheduler : The scheduler to use. If not specified, the scheduler specified in the pipeline level configurations will be used. scheduler_opts : The options for the scheduler. If not specified, the scheduler options specified in the pipeline level configurations will be used. See also How to run the pipeline on a cluster? for more details. To know more about the configuration items for the pipeline, you can also read the pipen docs . Enabling/disabling processes \u00b6 By default, only the essential processes are enabled. If scTCR-/scBCR-seq data is avaiable, these processes include: SampleInfo ScRepLoading SeuratPreparing SeuratClustering ScRepCombiningExpression ClusterMarkers SeuratClusterStats ClonalStats If only scRNA-seq data is available, these processes include: SampleInfo SeuratPreparing SeuratClustering ClusterMarkers SeuratClusterStats See also Routes of the pipeline for more details. To enable optional processes, you just need to add the corresponding sections for the processes in the configuration file. As long as the process name appears in the configuration file, the process will be enabled. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you can add the following lines to the configuration file: [ModuleScoreCalulator.envs.modules.TCell_Terminal_Differentiation] features = [ \"TIGIT\" , \"PDCD1\" , \"CD274\" , \"CTLA4\" , \"LAG3\" , \"HAVCR2\" , \"CD244\" , \"CD160\" ] Tip You may find out that for some processes, the default configurations are good enough for you to run. For example, TCRClustering is not enabled by default. If you don't change any configurations (by not putting in the configuration file nor changing any items on the web interface of pipen-board ) for the process, it will not be triggered. However, the default configurations are good enough for you to run the process. To enable it, you can either add this process manually in the configuration file: # ... other configurations [TCRClustering] or if you are using pipen-board , you can change a configuration item that does not actually affect the process. For example, you can change the forks of the process to 2 , instead of the default 1 , since the process is a single-job process. Then the process will be put in the configuration file and will be enabled. [TCRClustering] forks = 2 Minimal configurations \u00b6 The minimal configurations are just the configurations with the input file: [SampleInfo.in] infile = [ \"samples.txt\" ] The input file is the metadata file mentioned in Preparing the input . With the minimal configurations, the pipeline will have the essential processes enabled, depending on whether scTCR-/scBCR-seq data is available or not. You can also check the example report here to see what you will get with the minimal configurations, with scTCR-/scBCR-seq data available. Environment variable types \u00b6 The types of environment variables are annotated in the brackets next the name of the environment variables. For example, the type of envs.indicator_genes of TOrBCellSelection is list , and it's annotated as: - indicator_genes (list): The genes to be used to select T cells. By default, the type of environment variables is string . The annotated types are helpful for the environment variables to be passed from the command line. It defines the argument and helps parse the argument from the command line. It is also useful to define the input elements from the pipen-board web interface and parse the values passed from the web interface as desired types. The following types are supported: string : The default type, the values will be used as strings. int : The values will be parsed as integers. float : The values will be parsed as floats. flag : The values will be parsed as boolean values. list / array : The values will be parsed as lists. You can also see the itype of some environment variables, that specifies the type of the elements in the list. It must be atomatic types, such as int , float , string , and flag . json : The values will be reciived as JSON strings and parsed as dictionaries (in python). choice / choices : The value should be chosen from one of the choices listed as sub-items. mchoice / mchoices : The value should be chosen from one or more of the choices listed as sub-items. ns / namespace : There are sub-items for the value. The sub-items will be parsed as key-value pairs. Understanding the data \u00b6 Understanding how the data is presented in the pipeline is helpful for the configuration, especially for the processes, such as SeuratClusterStats and ClonalStats . The configurations of this kind of processes are relying on the metadata. You can refer to the individual process pages for more details. Here we just give an introduction of how it works to set the configurations. The assay of the Seurat object \u00b6 The Seurat object is the main object used in the pipeline. You can have multiple assays in the Seurat object. While preparing the Seurat object at SeuratPreparing process, the default assay is determined. If envs.use_sct is true, meaning SCTransform is used, the default assay will be SCT . If you are using cca or rpca integration, integrated will be used as the default assay. Otherwise, the default assay will be RNA . For downstream processes using the expression values, we provide an option to specify the assay to use. However, the default assay is used. Unless you know what you are doing, you are not recommended to change the default assay. Using existing columns in the metadata \u00b6 In most cases, you can use the existing columns in the metadata to set the configurations. For example, if you want to plot the clone residency for each patient/subject, you need to specify the column name of the sample ID, as well as the column with the paired sample information (i.e. tumor vs blood ). Suppose the metadata (sitting in seurat_obj@meta in R for example) is as follows (showing sample-level information only): Subject Source MM003-Eariler BM MM003-Eariler PB MM005-Eariler BM MM005-Eariler PB Then you can set the configurations as follows: [SeuratClusterStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Subject\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] And you will get the following plots: Mutating the metadata \u00b6 Sometimes, you may want to mutate the metadata to get the desired information. Of course, you can have them prepared in the input file, as those extra columns with meta information will be attached to the object automatically. See Preparing the input for more details. However, sometimes the metadata is specific to some processes, you may not want to have them prepared in the input file to get all processes contaminated. Moreover, those derived columns are usually based on the existing columns, so that is also helpful to create them on the fly to keep the input file clean. In such case, for example, if you want to plot the clone residency for two groups (e.g. BM-Pre vs. BM-Post ) of samples for the same group (e.g. A ). However, the Source and Timepoint information are not in a single column of metadata. Here is when mutaters come in place. Suppose the metadata is as follows: Sample Group Source Timepoint MM003 A BM Pre MM003 A BM Pre MM005 A BM Post MM005 A BM Post ... ... ... ... Then you can set the configurations as follows: [ClonalStats.envs.mutaters] SampleGroup = \"paste0(Sample, '-', Timepoint)\" [ClonalStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Group\" group_by = \"SampleGroup\" groups = [ \"BM-Pre\" , \"BM-Post\" ] Then you will get a clone residency plot for group A with BM-Pre as x-axis and BM-Post as y-axis. The key-value pairs of mutaters are passed to dplyr::mutate() function. The actual code to mutate the metadata is as follows: df %>% mutate ( SampleGroup = paste0 ( Sample , '-' , Timepoint )) So, for this kind of advanced configurations, you need to have some knowledge of dplyr in R . You also need to pay attention to the keys of mutaters . Basically, the keys are the column names you want to create. So you need to make sure that the column names are not in the metadata already. Otherwise, the existing columns will be overwritten. For scRNA-seq data, the existing column names of the metadata are: orig.ident nCount_RNA nFeature_RNA and the meta columns in the input file. See also Preparing the input for more details. There could also be some other columns, depending on the previous processes. For example, if you have the cells clustered, there will be a column named seurat_clusters in the metadata. For scTCR-/scBCR-seq data, Sample is the only existing column in the metadata after loaded. Then the meta columns from the input file will be attached to the metadata. The best practice is to use a prefix for the column names you want to create. For example, if you want to create a column named Sample , you can use my_Sample instead. Then you can make sure that the column names are not in the metadata already. The other thing you need to pay attention to is that you should try to avoid . or - in the column names. For example, if you want to create a column named Sample-Source , you can use Sample_Source instead. This is because that the column names will be used as the keys of the environment variables, and some processes will translate - into . . See also Namespace environment variables for more details. Filtering/Subsetting the data \u00b6 In most processes where we need to filter the data, we don't provide an option for you to set the expression for dplyr::filter() . Instead, you can make use of the mutaters to create a column for filtering. For example, if you only want to plot clone residency for only one patient/subject (e.g. MM003-Eariler ) in ClonalStats , you can set the configurations as follows (suppose we have Sample and Source columns in the metadata): [RadarPlots.envs.mutaters] SingleSample = \"if_else(Sample == 'MM003-Eariler', Sample, NA)\" [RadarPlots.envs] split_by = \"SingleSample\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] Then you will get only one plot for MM003-Eariler , but not for MM005-Eariler . The NA s will be filtered out automatically. Namespace environment variables \u00b6 There are some enviroment variables marked as namespace , which means that you can have sub-keys for them. For example, the envs.SCTransform of SeuratClusteringOfAllCells process is a namespace environment variable. It takes the arguments of Seurat::SCTransform() function. The names of arguments have dot ( . ) in them, such as do.scale , do.center , seed.use , etc. In the configuration file, we need to use dash ( - ) instead of dot ( . ) to set the values for these arguments. For example, if we want to set do.scale to TRUE , we need to set do-scale to true in the configuration file. [SeuratClusteringOfAllCells.envs.SCTransform] do-scale = true This is because that we use pipen-args plugin backended by argx to parse the command line arguments, including the configuration file. If we use . directly in the configuration file: [SeuratClusteringOfAllCells.envs.SCTransform] do . scale = true Then the pipen-args will parse it as do is the key and scale is the sub-key, and the above configuration will be parsed as: [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } which is not what we want. The reason why . is parsed as sub-key is that we want the argument to be able to be passed from command line. For example, if we want to set do.scale to TRUE from command line, we can do: > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do-scale true If we use . instead of - : > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do.scale true Then the pipen-args will parse it as [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } again. Tip You don't need to worry about which environment variables are namespace ones. We will mention it in the individual process pages and the description of the environment variables in pipen-board configuration descriptions. Multi-case variable design \u00b6 Some environment variables are designed to support multiple cases. However, in most cases, we only need to set the values for the default case. In such cases, the environment variable is usually a namespace environment variable with the sub-keys needed for the default case. In order to support multiple cases, a sub-key cases is added to the namespace environment variable. The cases is a dictionary (key-value pairs), where the keys are the names of the cases, and the values are the sub-keys for the corresponding cases. For example, the envs.group_by of ScFGSEA process: [ScFGSEA.envs] group_by = \"Group\" cases = {} If cases is empty, the default case will be added automatically. The name of the default case is GSEA . So the above configuration is equivalent to: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {} } If you want to add more cases, you can add them to the cases dictionary. For example, if you want to add a case named CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {}, CASE1 = {} } Then you can set the values for the default case and CASE1 case. For example, if you want to set the ident_2 to g3 for the default case and g4 for CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" ident_1 = \"g1\" cases = { GSEA = { ident_2 = \"g3\" }, CASE1 = { ident_2 = \"g4\" } } If a key in a case is not specified, the value in [ScFGSEA.envs] case will be used. In the above example, group_by = \"Group\" and ident_1 = \"g1\" will be used for both GSEA and CASE1 cases. Security alert \u00b6 Danger Note that some configuration items will be evaluated in the scripts directly. For example, the mutaters will be passed to R scripts, parsed and evaluated so that they can be used in dplyr::mutate() . Even though some were evaluated by rlang , not all of them are safe. Some of them are evaluated directly. For example, one could inject malicious code in the expressions passed by dplyr::filter() . For example, in the script: df %>% filter ({{ expression }}) The expected expression is something like Sample == \"Sample001\" . However, one could pass Sample == \"Sample001\"); system(\"cat /etc/passwd\") to the expression , which will be evaluated as: df %>% filter ( Sample == \"Sample001\" ); system ( \"cat /etc/passwd\" ) This will cause the pipeline to run the command cat /etc/passwd in the shell. This is just an example. One could do more harm by injecting malicious code. When you give acess of composing the configuration file to others or the public (not recommended), either via the command line or the web interface by pipen-board , you need to be careful about the security issues.","title":"Configurations"},{"location":"configurations/#configurations","text":"In this section, we are discussing how to configure the pipeline itself and some common issues we may encounter or need to be aware of to configure individual processes. For the configurations of each process in details, please refer to the individual process pages. As mentioned in pipen 's docs , the configurations to control the pipeline can be ~/.pipen.toml and/or ./.pipen.toml . You can set the default values in those files. Additionally, you can also pass a configuration file from command line, as described in Running the pipeline section. You can override the default values in the configuration files by passing arguments from command line. The configuration file is in toml format. A schematic example is shown below: forks = 4 # Other pipeline configurations # process configurations [TOrBCellSelection] forks = 2 # override the default value # envs of the process # e.g [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] # other processes # [ProcessName] # ... Tip In the individual process pages, we will list the envs of the process. For example, indicator_genes (list) : The genes to be used to select T cells. This means that the environment variable indicator_genes should be set as follows: [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ]","title":"Configurations"},{"location":"configurations/#pipeline-configurations","text":"There are pipeline level configurations and process level configurations. The pipeline level configurations are used to control the pipeline itself. The process level configurations set here are the default values for all the processes. You can override the default values for each process in the process level configurations. You can check all available configuration items and more details here . Here we only list some of the most important ones. The rest ones are not recommended to change unless you know what you are doing.","title":"Pipeline configurations"},{"location":"configurations/#pipeline-level-configurations","text":"name : The name of the pipeline (Default: \"Immunopipe\" ) It will change the working directory to ./.pipen/<name> , where the pipeline information and intermediate files will be stored. It will also change the default output directory to ./<name>-output . outdir : The output directory (Default: \"./<name>-output\" ) The output directory is where the final results and reports are stored. loglevel : The logging level for the logger (Default: \"info\" ) plugin_opts : The options for the plugins. Following pipen plugins are installed with immunopipe . You may check the links for more details. pipen-board : Visualizing configuration and running of pipen pipelines on the web. pipen-verbose : Adding verbosal information in logs for pipen. pipen-runinfo : Generating running information for jobs in pipen pipelines. pipen-filters : Adding a set of useful filters for pipen templates. pipen-args : Command line argument parser for pipen pipen-annotate : Using docstring to annotate pipen processes. pipen-report : Generating reports for pipen pipelines. pipen-log2file : Logging to files for pipen pipelines. pipen-cli-run : Running pipen processes/process groups from command line. scheduler : The scheduler to use (Default: \"local\" ) scheduler_opts : The options for the scheduler. immunopipe is implemented using pipen , which is backended by xqute . Supported schedulers and options are listed here . See also How to run the pipeline on a cluster? for more details.","title":"Pipeline level configurations"},{"location":"configurations/#output-and-working-directory","text":"The output directory is the directory where the final results are stored. The working directory is the directory where the pipeline information and intermediate files are stored. By default, the output directory is ./<name>-output and the working directory is ./.pipen/<name> . The output of processes with final results will be stored in the output directory in sub-directories named after the processes. For example, the output of SeuratClusteringOfAllCells will be stored in ./<outdir>/SeuratClusteringOfAllCells . This is also a special subdirectory named REPORTS that contains the reports of the pipeline. By visiting the <outdir>/REPORTS/index.html with a web browser, you can check the reports of the pipeline. You can change the output directory by setting outdir or name in the configuration file. For example, if you want to change the output directory to ./output , you can set the configurations as follows: outdir = \"./output\" If you change the pipeline name: name = \"my-pipeline\" Then the output directory will be changed to ./my-pipeline-output . Note If both outdir and name are set, outdir will be used. You can do the similar thing to change the working directory. However, you are NOT recommended to change the working directory, especially if you are using pipen-board . This is because that the plugin scans ./.pipen/<name> to get the information for the previous run of the pipeline. If you change the working directory, the plugin will not be able to find the information for the previous run. Tip What if you want to change the working directory anyway? The recommended way is to create a symbolic link to the working directory. For example, if you want to change the working directory to /path/to/the/real/working/directory , you can do: ln -s /path/to/the/real/working/directory ./.pipen Tip You can also then debug the pipeline by inspecting the real scripts in the working directory that run for the jobs of each process at ./.pipen/<name>/<process-name>/<job-index>/job.script . You can also find the other information for the jobs at ./.pipen/<name>/<process-name>/<job-index>/ , including the stdout ( job.stdout ) and stderr ( job.stderr ) of the jobs, the exit code of the jobs ( job.rc ), etc.","title":"Output and working directory"},{"location":"configurations/#process-level-configurations","text":"cache : Should we detect whether the jobs are cached. If true , the jobs will be skipped if the output files exist and newer than the input files. (Default: true ) error_strategy : The strategy to handle the errors. halt : Any failure will just halt the entire pipeline (default) ignore : Ignore the error and keep running (assuming the job runs successfully anyway) retry : Retry to job running. After num_retries times of retrying, if the job is still failing, halt the pipeline. num_retries : The number of retries for the jobs. (Default: 3 ) forks : How many jobs to run simultaneously? (Default: 1 ) scheduler : The scheduler to use. If not specified, the scheduler specified in the pipeline level configurations will be used. scheduler_opts : The options for the scheduler. If not specified, the scheduler options specified in the pipeline level configurations will be used. See also How to run the pipeline on a cluster? for more details. To know more about the configuration items for the pipeline, you can also read the pipen docs .","title":"Process level configurations"},{"location":"configurations/#enablingdisabling-processes","text":"By default, only the essential processes are enabled. If scTCR-/scBCR-seq data is avaiable, these processes include: SampleInfo ScRepLoading SeuratPreparing SeuratClustering ScRepCombiningExpression ClusterMarkers SeuratClusterStats ClonalStats If only scRNA-seq data is available, these processes include: SampleInfo SeuratPreparing SeuratClustering ClusterMarkers SeuratClusterStats See also Routes of the pipeline for more details. To enable optional processes, you just need to add the corresponding sections for the processes in the configuration file. As long as the process name appears in the configuration file, the process will be enabled. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you can add the following lines to the configuration file: [ModuleScoreCalulator.envs.modules.TCell_Terminal_Differentiation] features = [ \"TIGIT\" , \"PDCD1\" , \"CD274\" , \"CTLA4\" , \"LAG3\" , \"HAVCR2\" , \"CD244\" , \"CD160\" ] Tip You may find out that for some processes, the default configurations are good enough for you to run. For example, TCRClustering is not enabled by default. If you don't change any configurations (by not putting in the configuration file nor changing any items on the web interface of pipen-board ) for the process, it will not be triggered. However, the default configurations are good enough for you to run the process. To enable it, you can either add this process manually in the configuration file: # ... other configurations [TCRClustering] or if you are using pipen-board , you can change a configuration item that does not actually affect the process. For example, you can change the forks of the process to 2 , instead of the default 1 , since the process is a single-job process. Then the process will be put in the configuration file and will be enabled. [TCRClustering] forks = 2","title":"Enabling/disabling processes"},{"location":"configurations/#minimal-configurations","text":"The minimal configurations are just the configurations with the input file: [SampleInfo.in] infile = [ \"samples.txt\" ] The input file is the metadata file mentioned in Preparing the input . With the minimal configurations, the pipeline will have the essential processes enabled, depending on whether scTCR-/scBCR-seq data is available or not. You can also check the example report here to see what you will get with the minimal configurations, with scTCR-/scBCR-seq data available.","title":"Minimal configurations"},{"location":"configurations/#environment-variable-types","text":"The types of environment variables are annotated in the brackets next the name of the environment variables. For example, the type of envs.indicator_genes of TOrBCellSelection is list , and it's annotated as: - indicator_genes (list): The genes to be used to select T cells. By default, the type of environment variables is string . The annotated types are helpful for the environment variables to be passed from the command line. It defines the argument and helps parse the argument from the command line. It is also useful to define the input elements from the pipen-board web interface and parse the values passed from the web interface as desired types. The following types are supported: string : The default type, the values will be used as strings. int : The values will be parsed as integers. float : The values will be parsed as floats. flag : The values will be parsed as boolean values. list / array : The values will be parsed as lists. You can also see the itype of some environment variables, that specifies the type of the elements in the list. It must be atomatic types, such as int , float , string , and flag . json : The values will be reciived as JSON strings and parsed as dictionaries (in python). choice / choices : The value should be chosen from one of the choices listed as sub-items. mchoice / mchoices : The value should be chosen from one or more of the choices listed as sub-items. ns / namespace : There are sub-items for the value. The sub-items will be parsed as key-value pairs.","title":"Environment variable types"},{"location":"configurations/#understanding-the-data","text":"Understanding how the data is presented in the pipeline is helpful for the configuration, especially for the processes, such as SeuratClusterStats and ClonalStats . The configurations of this kind of processes are relying on the metadata. You can refer to the individual process pages for more details. Here we just give an introduction of how it works to set the configurations.","title":"Understanding the data"},{"location":"configurations/#the-assay-of-the-seurat-object","text":"The Seurat object is the main object used in the pipeline. You can have multiple assays in the Seurat object. While preparing the Seurat object at SeuratPreparing process, the default assay is determined. If envs.use_sct is true, meaning SCTransform is used, the default assay will be SCT . If you are using cca or rpca integration, integrated will be used as the default assay. Otherwise, the default assay will be RNA . For downstream processes using the expression values, we provide an option to specify the assay to use. However, the default assay is used. Unless you know what you are doing, you are not recommended to change the default assay.","title":"The assay of the Seurat object"},{"location":"configurations/#using-existing-columns-in-the-metadata","text":"In most cases, you can use the existing columns in the metadata to set the configurations. For example, if you want to plot the clone residency for each patient/subject, you need to specify the column name of the sample ID, as well as the column with the paired sample information (i.e. tumor vs blood ). Suppose the metadata (sitting in seurat_obj@meta in R for example) is as follows (showing sample-level information only): Subject Source MM003-Eariler BM MM003-Eariler PB MM005-Eariler BM MM005-Eariler PB Then you can set the configurations as follows: [SeuratClusterStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Subject\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] And you will get the following plots:","title":"Using existing columns in the metadata"},{"location":"configurations/#mutating-the-metadata","text":"Sometimes, you may want to mutate the metadata to get the desired information. Of course, you can have them prepared in the input file, as those extra columns with meta information will be attached to the object automatically. See Preparing the input for more details. However, sometimes the metadata is specific to some processes, you may not want to have them prepared in the input file to get all processes contaminated. Moreover, those derived columns are usually based on the existing columns, so that is also helpful to create them on the fly to keep the input file clean. In such case, for example, if you want to plot the clone residency for two groups (e.g. BM-Pre vs. BM-Post ) of samples for the same group (e.g. A ). However, the Source and Timepoint information are not in a single column of metadata. Here is when mutaters come in place. Suppose the metadata is as follows: Sample Group Source Timepoint MM003 A BM Pre MM003 A BM Pre MM005 A BM Post MM005 A BM Post ... ... ... ... Then you can set the configurations as follows: [ClonalStats.envs.mutaters] SampleGroup = \"paste0(Sample, '-', Timepoint)\" [ClonalStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Group\" group_by = \"SampleGroup\" groups = [ \"BM-Pre\" , \"BM-Post\" ] Then you will get a clone residency plot for group A with BM-Pre as x-axis and BM-Post as y-axis. The key-value pairs of mutaters are passed to dplyr::mutate() function. The actual code to mutate the metadata is as follows: df %>% mutate ( SampleGroup = paste0 ( Sample , '-' , Timepoint )) So, for this kind of advanced configurations, you need to have some knowledge of dplyr in R . You also need to pay attention to the keys of mutaters . Basically, the keys are the column names you want to create. So you need to make sure that the column names are not in the metadata already. Otherwise, the existing columns will be overwritten. For scRNA-seq data, the existing column names of the metadata are: orig.ident nCount_RNA nFeature_RNA and the meta columns in the input file. See also Preparing the input for more details. There could also be some other columns, depending on the previous processes. For example, if you have the cells clustered, there will be a column named seurat_clusters in the metadata. For scTCR-/scBCR-seq data, Sample is the only existing column in the metadata after loaded. Then the meta columns from the input file will be attached to the metadata. The best practice is to use a prefix for the column names you want to create. For example, if you want to create a column named Sample , you can use my_Sample instead. Then you can make sure that the column names are not in the metadata already. The other thing you need to pay attention to is that you should try to avoid . or - in the column names. For example, if you want to create a column named Sample-Source , you can use Sample_Source instead. This is because that the column names will be used as the keys of the environment variables, and some processes will translate - into . . See also Namespace environment variables for more details.","title":"Mutating the metadata"},{"location":"configurations/#filteringsubsetting-the-data","text":"In most processes where we need to filter the data, we don't provide an option for you to set the expression for dplyr::filter() . Instead, you can make use of the mutaters to create a column for filtering. For example, if you only want to plot clone residency for only one patient/subject (e.g. MM003-Eariler ) in ClonalStats , you can set the configurations as follows (suppose we have Sample and Source columns in the metadata): [RadarPlots.envs.mutaters] SingleSample = \"if_else(Sample == 'MM003-Eariler', Sample, NA)\" [RadarPlots.envs] split_by = \"SingleSample\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] Then you will get only one plot for MM003-Eariler , but not for MM005-Eariler . The NA s will be filtered out automatically.","title":"Filtering/Subsetting the data"},{"location":"configurations/#namespace-environment-variables","text":"There are some enviroment variables marked as namespace , which means that you can have sub-keys for them. For example, the envs.SCTransform of SeuratClusteringOfAllCells process is a namespace environment variable. It takes the arguments of Seurat::SCTransform() function. The names of arguments have dot ( . ) in them, such as do.scale , do.center , seed.use , etc. In the configuration file, we need to use dash ( - ) instead of dot ( . ) to set the values for these arguments. For example, if we want to set do.scale to TRUE , we need to set do-scale to true in the configuration file. [SeuratClusteringOfAllCells.envs.SCTransform] do-scale = true This is because that we use pipen-args plugin backended by argx to parse the command line arguments, including the configuration file. If we use . directly in the configuration file: [SeuratClusteringOfAllCells.envs.SCTransform] do . scale = true Then the pipen-args will parse it as do is the key and scale is the sub-key, and the above configuration will be parsed as: [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } which is not what we want. The reason why . is parsed as sub-key is that we want the argument to be able to be passed from command line. For example, if we want to set do.scale to TRUE from command line, we can do: > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do-scale true If we use . instead of - : > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do.scale true Then the pipen-args will parse it as [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } again. Tip You don't need to worry about which environment variables are namespace ones. We will mention it in the individual process pages and the description of the environment variables in pipen-board configuration descriptions.","title":"Namespace environment variables"},{"location":"configurations/#multi-case-variable-design","text":"Some environment variables are designed to support multiple cases. However, in most cases, we only need to set the values for the default case. In such cases, the environment variable is usually a namespace environment variable with the sub-keys needed for the default case. In order to support multiple cases, a sub-key cases is added to the namespace environment variable. The cases is a dictionary (key-value pairs), where the keys are the names of the cases, and the values are the sub-keys for the corresponding cases. For example, the envs.group_by of ScFGSEA process: [ScFGSEA.envs] group_by = \"Group\" cases = {} If cases is empty, the default case will be added automatically. The name of the default case is GSEA . So the above configuration is equivalent to: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {} } If you want to add more cases, you can add them to the cases dictionary. For example, if you want to add a case named CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {}, CASE1 = {} } Then you can set the values for the default case and CASE1 case. For example, if you want to set the ident_2 to g3 for the default case and g4 for CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" ident_1 = \"g1\" cases = { GSEA = { ident_2 = \"g3\" }, CASE1 = { ident_2 = \"g4\" } } If a key in a case is not specified, the value in [ScFGSEA.envs] case will be used. In the above example, group_by = \"Group\" and ident_1 = \"g1\" will be used for both GSEA and CASE1 cases.","title":"Multi-case variable design"},{"location":"configurations/#security-alert","text":"Danger Note that some configuration items will be evaluated in the scripts directly. For example, the mutaters will be passed to R scripts, parsed and evaluated so that they can be used in dplyr::mutate() . Even though some were evaluated by rlang , not all of them are safe. Some of them are evaluated directly. For example, one could inject malicious code in the expressions passed by dplyr::filter() . For example, in the script: df %>% filter ({{ expression }}) The expected expression is something like Sample == \"Sample001\" . However, one could pass Sample == \"Sample001\"); system(\"cat /etc/passwd\") to the expression , which will be evaluated as: df %>% filter ( Sample == \"Sample001\" ); system ( \"cat /etc/passwd\" ) This will cause the pipeline to run the command cat /etc/passwd in the shell. This is just an example. One could do more harm by injecting malicious code. When you give acess of composing the configuration file to others or the public (not recommended), either via the command line or the web interface by pipen-board , you need to be careful about the security issues.","title":"Security alert"},{"location":"faq/","text":"FAQ \u00b6 immunopipe command not found? Please make sure if you have installed immunopipe on the right python . If you have used pip to install immunopipe , make sure the pip is associated with the right python . You may try /path/to/python -m pip install -U immunopipe to ensure immunopipe is installed with the python you wanted. If immunopipe still can't be found from command line, try /path/to/python -m immunopipe . Why I am getting \"Error writing to connection: No space left on device\"? If you are running the pipeline and it complains about \"No space left on device\", and you are pretty sure that your working directory is way from full, it is likely that your temporary directory does not have enough space. This is because that the pipeline will create a temporary directory to store the intermediate files, and the default temporary directory is /tmp . Make sure that you have enough space in /tmp or you can change the temporary directory by setting the environment variable of the process: envs.tmpdir . It is also likely that you are running the pipeline in a docker container and the docker container does not have enough space in /tmp . In such case, you can try to run the pipeline with the -v option of docker to local directory to /tmp in the container. For example: docker run --rm -w /workdir -v .:/workdir -v path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ justold/immunopipe:<tag> @config.toml If you are using singularity / apptainer , you can try to use the -B option to bind the local directory to /tmp in the container. Singularity Apptainer singularity run \\ --pwd /workdir -B .:/workdir -c -e --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml apptainer run \\ --pwd /workdir -B .:/workdir -c -e --unsquash --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml Why does the pipeline stop at SeuratClusteringOfAllCells and family without a clear error message? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. Please see the following issues for more details: https://github.com/satijalab/seurat/issues/3326 https://github.com/satijalab/seurat/issues/1720 https://github.com/satijalab/seurat/issues/2828 https://github.com/satijalab/seurat/issues/1254 https://github.com/satijalab/seurat/issues/7027 Also check out the tips by the Seurat team: https://satijalab.org/seurat/articles/integration_large_datasets Two possible solutions are: Use reduction = \"rpca\" for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . Use Reference-based integration reference = [1, 2] for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . For Seurat v5, use corresponding parameters for IntegrateLayers . Tip You can also pass a list of sample names instead of the sample indices. For example, reference = [\"sample1\", \"sample2\"] under [SeuratPreparing.envs.IntegrateLayers] to use sample1 and sample2 as the reference samples. See also description about IntegrateLayers here . Can I run one of the processes from the pipeline separately if I have the input files prepared? Only for some of the processes. immunopipe depends on biopipen . Most of the processes in immunopipe are subclasses of processes in biopipen . You can run the processes in biopipen separately by: pipen run scrna SeuratClustering [ options ] Note that only the processes from biopipen can be run separately. The processes in immunopipe are not designed to be run separately. For example, the SeuratClusteringOfAllCells process in immunopipe is a subclass of the SeuratClustering process in biopipen . It's specialized for the immunopipe pipeline. If you want to run a similar process separately, you should use the SeuratClustering process in biopipen instead. Like immunopipe , you can also either provide a configuration file: pipen run scrna SeuratClustering @config.toml or specify the options in the command line: pipen run scrna SeuratClustering --in.srtobj path/to/srtobj.RDS ... You can also use the -h / --help option to see the brief options of the process, or use -h+ / --help+ to see the full options of the process. How to run the pipeline on a cluster? To run the pipeline on a cluster, it's recommended to install the pipeline locally so that the cluster nodes can access the pipeline. immunopipe is built on top of pipen and xqute . A set of schedulers are supported by default. These schedulers are: local : Run the pipeline locally. slurm : Run the pipeline on a slurm cluster. sge : Run the pipeline on a sge cluster. ssh : Run the pipeline on a remote host via ssh. The scheduler can be specified via scheduler_opts for the whole pipeline or for a specific process. For example, to run the whole pipeline on a slurm cluster, you can use the following configuration file: scheduler = \"slurm\" [scheduler_opts] sbatch_partition = \"1-day\" To run a specific process on a slurm cluster, you can use the following configuration file: [ < Process > ] scheduler = \"slurm\" [ < Process > .scheduler_opts] sbatch_partition = \"1-day\" You can also use profiles to switch between different schedulers. See also https://pwwang.github.io/pipen/configurations/#profiles Unlike the pipeline installed locally, using a doker image to run the pipeline on a cluster, we need to run the whole pipeline as a job. For example, to run the pipeline on a slurm cluster using apptainer , you can use slurm to submit the job: srun <srun options> \\ apptainer run --pwd /workdir -B /path/to/workdir:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ -B /path/to/tmp:/tmp \\ docker://justold/immunopipe:<tag> \\ @config.toml If you are using docker and its alternatives, please also refer to: https://slurm.schedmd.com/containers.html Do I have to re-run the entire pipeline if I want to change some parameters? If you want to change some parameters for a specific process, you just modify the configuration file and re-run the pipeline. The pipeline will detect the changes and re-run the necessary processes. For example, if you are changing some environment variables for ScFGSEA , the prior processes, such as the ones for clustering and differential expression analysis, will be cached and will not be re-run. Why I am getting this error when running with apptainer : FATAL: no SIF writable overlay partition found in /tmp/apptainer_cache_xxx/... ? You may need to add --unsquash option for apptainer run . How can I use data with soft links while using docker image to run the pipeline? The container does not have access to the host filesystem directly. You need to mount the directory containing the data to the container. For example, if your real data is under /path/to/data , you can mount it to /data in the container (using -v /path/to/data:/data option for docker or -B /path/to/data:/data option for singularity or apptainer ). Then you can use /data in the container to access the data under /path/to/data on the host. Also remember to change the path of RNAData and TCRData / BCRData in the file (e.g. samples.txt ) that is passed to SampleInfo process. Other than /data , there are other directories that you can use for mounting inside the container, including /mnt and /tmp , in case your want to mount multiple directories. See also The directory structure in the container . Why I am getting disk quota exceeded error while pulling the docker image using apptainer with still plenty of space on the disk? It's probably because that the cache directory of apptainer is full. You can try to use a different cache directory by setting the environment variable APPTAINER_CACHEDIR to a different directory. For example: export APPTAINER_CACHEDIR = /path/to/cache apptainer pull justold/immunopipe:<tag> See also: https://apptainer.org/docs/user/main/build_env.html#cache-folders Unable to fork: Cannot allocate memory or long vectors not supported yet during clustering using Seurat? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. You can try to set envs.ncores to a smaller number to reduce the memory usage. For example: [SeuratClusteringOfAllCells.envs] ncores = 4 # instead of 16 The other strategy is to use Reference-based integration reference = [1, 2] for IntegrateLayers with method rpca or cca . See also description about IntegrateLayers here . For example: [SeuratPreparing.envs.IntegrateLayers] method = \"rpca\" reference = [ 1 , 2 ] # You can also use sample names instead of indices See also these issues for more details: https://github.com/satijalab/seurat/issues/1029 https://github.com/satijalab/seurat/issues/7419 Got error Not all stats values are finite numbers while running ScFGSEA ? It's probably because that there are too many missing values in the expression matrix and signal_to_noise is not able to detect the rank of the genes. You can try a different method for gene preranking. For example: [ScFGSEA.envs] method = \"diff_of_classes\"","title":"FAQ"},{"location":"faq/#faq","text":"immunopipe command not found? Please make sure if you have installed immunopipe on the right python . If you have used pip to install immunopipe , make sure the pip is associated with the right python . You may try /path/to/python -m pip install -U immunopipe to ensure immunopipe is installed with the python you wanted. If immunopipe still can't be found from command line, try /path/to/python -m immunopipe . Why I am getting \"Error writing to connection: No space left on device\"? If you are running the pipeline and it complains about \"No space left on device\", and you are pretty sure that your working directory is way from full, it is likely that your temporary directory does not have enough space. This is because that the pipeline will create a temporary directory to store the intermediate files, and the default temporary directory is /tmp . Make sure that you have enough space in /tmp or you can change the temporary directory by setting the environment variable of the process: envs.tmpdir . It is also likely that you are running the pipeline in a docker container and the docker container does not have enough space in /tmp . In such case, you can try to run the pipeline with the -v option of docker to local directory to /tmp in the container. For example: docker run --rm -w /workdir -v .:/workdir -v path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ justold/immunopipe:<tag> @config.toml If you are using singularity / apptainer , you can try to use the -B option to bind the local directory to /tmp in the container. Singularity Apptainer singularity run \\ --pwd /workdir -B .:/workdir -c -e --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml apptainer run \\ --pwd /workdir -B .:/workdir -c -e --unsquash --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml Why does the pipeline stop at SeuratClusteringOfAllCells and family without a clear error message? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. Please see the following issues for more details: https://github.com/satijalab/seurat/issues/3326 https://github.com/satijalab/seurat/issues/1720 https://github.com/satijalab/seurat/issues/2828 https://github.com/satijalab/seurat/issues/1254 https://github.com/satijalab/seurat/issues/7027 Also check out the tips by the Seurat team: https://satijalab.org/seurat/articles/integration_large_datasets Two possible solutions are: Use reduction = \"rpca\" for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . Use Reference-based integration reference = [1, 2] for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . For Seurat v5, use corresponding parameters for IntegrateLayers . Tip You can also pass a list of sample names instead of the sample indices. For example, reference = [\"sample1\", \"sample2\"] under [SeuratPreparing.envs.IntegrateLayers] to use sample1 and sample2 as the reference samples. See also description about IntegrateLayers here . Can I run one of the processes from the pipeline separately if I have the input files prepared? Only for some of the processes. immunopipe depends on biopipen . Most of the processes in immunopipe are subclasses of processes in biopipen . You can run the processes in biopipen separately by: pipen run scrna SeuratClustering [ options ] Note that only the processes from biopipen can be run separately. The processes in immunopipe are not designed to be run separately. For example, the SeuratClusteringOfAllCells process in immunopipe is a subclass of the SeuratClustering process in biopipen . It's specialized for the immunopipe pipeline. If you want to run a similar process separately, you should use the SeuratClustering process in biopipen instead. Like immunopipe , you can also either provide a configuration file: pipen run scrna SeuratClustering @config.toml or specify the options in the command line: pipen run scrna SeuratClustering --in.srtobj path/to/srtobj.RDS ... You can also use the -h / --help option to see the brief options of the process, or use -h+ / --help+ to see the full options of the process. How to run the pipeline on a cluster? To run the pipeline on a cluster, it's recommended to install the pipeline locally so that the cluster nodes can access the pipeline. immunopipe is built on top of pipen and xqute . A set of schedulers are supported by default. These schedulers are: local : Run the pipeline locally. slurm : Run the pipeline on a slurm cluster. sge : Run the pipeline on a sge cluster. ssh : Run the pipeline on a remote host via ssh. The scheduler can be specified via scheduler_opts for the whole pipeline or for a specific process. For example, to run the whole pipeline on a slurm cluster, you can use the following configuration file: scheduler = \"slurm\" [scheduler_opts] sbatch_partition = \"1-day\" To run a specific process on a slurm cluster, you can use the following configuration file: [ < Process > ] scheduler = \"slurm\" [ < Process > .scheduler_opts] sbatch_partition = \"1-day\" You can also use profiles to switch between different schedulers. See also https://pwwang.github.io/pipen/configurations/#profiles Unlike the pipeline installed locally, using a doker image to run the pipeline on a cluster, we need to run the whole pipeline as a job. For example, to run the pipeline on a slurm cluster using apptainer , you can use slurm to submit the job: srun <srun options> \\ apptainer run --pwd /workdir -B /path/to/workdir:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ -B /path/to/tmp:/tmp \\ docker://justold/immunopipe:<tag> \\ @config.toml If you are using docker and its alternatives, please also refer to: https://slurm.schedmd.com/containers.html Do I have to re-run the entire pipeline if I want to change some parameters? If you want to change some parameters for a specific process, you just modify the configuration file and re-run the pipeline. The pipeline will detect the changes and re-run the necessary processes. For example, if you are changing some environment variables for ScFGSEA , the prior processes, such as the ones for clustering and differential expression analysis, will be cached and will not be re-run. Why I am getting this error when running with apptainer : FATAL: no SIF writable overlay partition found in /tmp/apptainer_cache_xxx/... ? You may need to add --unsquash option for apptainer run . How can I use data with soft links while using docker image to run the pipeline? The container does not have access to the host filesystem directly. You need to mount the directory containing the data to the container. For example, if your real data is under /path/to/data , you can mount it to /data in the container (using -v /path/to/data:/data option for docker or -B /path/to/data:/data option for singularity or apptainer ). Then you can use /data in the container to access the data under /path/to/data on the host. Also remember to change the path of RNAData and TCRData / BCRData in the file (e.g. samples.txt ) that is passed to SampleInfo process. Other than /data , there are other directories that you can use for mounting inside the container, including /mnt and /tmp , in case your want to mount multiple directories. See also The directory structure in the container . Why I am getting disk quota exceeded error while pulling the docker image using apptainer with still plenty of space on the disk? It's probably because that the cache directory of apptainer is full. You can try to use a different cache directory by setting the environment variable APPTAINER_CACHEDIR to a different directory. For example: export APPTAINER_CACHEDIR = /path/to/cache apptainer pull justold/immunopipe:<tag> See also: https://apptainer.org/docs/user/main/build_env.html#cache-folders Unable to fork: Cannot allocate memory or long vectors not supported yet during clustering using Seurat? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. You can try to set envs.ncores to a smaller number to reduce the memory usage. For example: [SeuratClusteringOfAllCells.envs] ncores = 4 # instead of 16 The other strategy is to use Reference-based integration reference = [1, 2] for IntegrateLayers with method rpca or cca . See also description about IntegrateLayers here . For example: [SeuratPreparing.envs.IntegrateLayers] method = \"rpca\" reference = [ 1 , 2 ] # You can also use sample names instead of indices See also these issues for more details: https://github.com/satijalab/seurat/issues/1029 https://github.com/satijalab/seurat/issues/7419 Got error Not all stats values are finite numbers while running ScFGSEA ? It's probably because that there are too many missing values in the expression matrix and signal_to_noise is not able to detect the rank of the genes. You can try a different method for gene preranking. For example: [ScFGSEA.envs] method = \"diff_of_classes\"","title":"FAQ"},{"location":"gallery/","text":"Gallery \u00b6 The following are some datasets with both scRNA-seq and scTCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. In the README file of each repository, you can find the links to the original publications and the reports generated by immunopipe . ID GEO Repository Condition 1 GSE144469 immunopipe-AdrienneML-2020 Melanoma and therapy 2 GSE176201 immunopipe-CheonIS-2021 COVID-19 lung tissue 3 GSE180268 immunopipe-EberhardtCS-2021 HPV and Head and Neck cancer 4 GSE114724 immunopipe-ElhamA-2018 Breast Cancer 5 GSE161192 immunopipe-GateD-2021 LB dementia 6 GSE179994 immunopipe-LiuB-2022 anti-PD-1 therapy in lung cancer 7 GSE148190 immunopipe-MahuronKM-2020 Skin cancer 8 GSE139555 immunopipe-ThomasW-2020 Anti-PD1 therapy 9 GSE145370 immunopipe-ZhengY-2020 Oesophageal cancer ID # Individuals # Samples # Cells # matched TCR seqs 1 22 22 75,569 68,760 2 5 6 34,781 23,081 3 6 6 53,303 26,844 4 3 5 28,341 24,039 5 2 4 6,438 5,642 6 38 47 150,849 77,030 7 1 2 8,794 4,904 8 14 32 194,519 67,700 9 7 14 108,226 35,449 ID Reference 1 Luoma, Adrienne M., et al. 2020 2 Cheon, I. S., et al. 2021 3 Eberhardt, Christian S., et al. 2021 4 Alizadeh, Elham, et al. 2018 5 Gate, David, et al. 2021 6 Liu, B., et al. 2022 7 Mahuron, Kelly M., et al. 2020 8 Wu, Thomas D., et al. 2020 9 Zheng, Y., et al. 2020","title":"Gallery"},{"location":"gallery/#gallery","text":"The following are some datasets with both scRNA-seq and scTCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. In the README file of each repository, you can find the links to the original publications and the reports generated by immunopipe . ID GEO Repository Condition 1 GSE144469 immunopipe-AdrienneML-2020 Melanoma and therapy 2 GSE176201 immunopipe-CheonIS-2021 COVID-19 lung tissue 3 GSE180268 immunopipe-EberhardtCS-2021 HPV and Head and Neck cancer 4 GSE114724 immunopipe-ElhamA-2018 Breast Cancer 5 GSE161192 immunopipe-GateD-2021 LB dementia 6 GSE179994 immunopipe-LiuB-2022 anti-PD-1 therapy in lung cancer 7 GSE148190 immunopipe-MahuronKM-2020 Skin cancer 8 GSE139555 immunopipe-ThomasW-2020 Anti-PD1 therapy 9 GSE145370 immunopipe-ZhengY-2020 Oesophageal cancer ID # Individuals # Samples # Cells # matched TCR seqs 1 22 22 75,569 68,760 2 5 6 34,781 23,081 3 6 6 53,303 26,844 4 3 5 28,341 24,039 5 2 4 6,438 5,642 6 38 47 150,849 77,030 7 1 2 8,794 4,904 8 14 32 194,519 67,700 9 7 14 108,226 35,449 ID Reference 1 Luoma, Adrienne M., et al. 2020 2 Cheon, I. S., et al. 2021 3 Eberhardt, Christian S., et al. 2021 4 Alizadeh, Elham, et al. 2018 5 Gate, David, et al. 2021 6 Liu, B., et al. 2022 7 Mahuron, Kelly M., et al. 2020 8 Wu, Thomas D., et al. 2020 9 Zheng, Y., et al. 2020","title":"Gallery"},{"location":"getting-started/","text":"Getting started \u00b6 You can find the nessary files and source code of this tutorial in the example repository . In this tutorial we will show you how to run the immunopipe pipeline on a small dataset of 6 patients from 3 groups: colitis (n=2), non-colitis(n=2) and control(n=2). The dataset is part of the data used in the publication below: Luoma, Adrienne M., et al. \"Molecular pathways of colon inflammation induced by cancer immunotherapy.\" Cell 182.3 (2020): 655-671. We are using a small subset of the data to make the tutorial run faster. The full dataset can be downloaded from Gene Expression Omnibus (GEO) GSE144469 . Download and prepare the data \u00b6 The data can be downloaded and prepared by running the following commands: # Clone the example repository git clone https://github.com/pwwang/immunopipe-example.git # Enter the example directory cd immunopipe-example # Download and prepare the data bash prepare-data.sh # The data from GSE144469 (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE144469) # will be downloaded and extracted into: # # ./prepared-data/C1 # ./prepared-data/C2 # ... # You may also check other files in the data/ directory, especially the samples.txt file, which contains the sample information for the dataset we prepared above. Prepare the configuration file \u00b6 To run the pipeline, we need to prepare a configuration file (recommended) or pass the arguments directly via command line. Here we will use the configuration file. See also Configurations for more details. As explained in the Configurations page, we can provide a configuration file with a minimal set of configuration items to get the pipeline running. The only required configuration item is the input file for the SampleInfo process. However, here we want to give the pipeline a different name and output directory to distinguish it from other runs with a different set of configurations. The configuration file shall be in the TOML format. We can create a file named ImmunopipeMinimal.config.toml with the following content: name = \"ImmunopipeMinimal\" outdir = \"minimal\" [SampleInfo.in] infile = [ \"data/samples.txt\" ] Run the pipeline \u00b6 The easiest way to run the pipeline is to run it within the docker container. We can use the following command to run the pipeline with the configuration file we just created: Using docker Using singularity Using apptainer docker run \\ --rm -w /workdir -v .:/workdir \\ justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml singularity run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml apptainer run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml Tip docker , singularity and apptainer commands map the current directory ( . ) to the /workdir directory in the container. To get the detailed directory structure in the container, please refer to the The directory structure in the container . Tip If you want to install and run the pipeline without docker, please refer to the Installation and Running the pipeline pages for more details. Note You need at least 16GB of memory to run the pipeline with the example dataset and minimal configuration. You may also need to decrease ncores of some processes to avoid running out of memory. For example: [SeuratClusteringOfAllCells.envs] - ncores = 8 + ncores = 4 Check the results \u00b6 With that \"minimal\" configuration file, only a subset of the processes will be run. See also Enabling/Disabling processes . The results will be saved in the minimal directory. You can also check the reports at minimal/REPORTS/index.html with a web browser. You can also visit the following link to see the reports of the pipeline we just ran: http://imp.pwwang.com/minimal/REPORTS/index.html Next steps \u00b6 You may read through this documentation to learn more about the pipeline and how to configure it. There is also a configuration file, named Immunopipe.config.toml in the example repository, with more processes enabled. You can use it to run the pipeline with the dataset prepared above. Check out the following link for the reports: http://imp.pwwang.com/output/REPORTS/index.html Note The results provided by this example configuration files are for demonstration purpose only. They are not intended to be used for any scientific analysis. You may also want to try other routes of the pipeline with the prepared data. These routes are defined in: ImmunopipeMinimalNoTCR.config.toml : The configuration for minimal analyses without scTCR-/scBCR-seq data. ImmunopipeMinimalSupervised.config.toml : The configuration for minimal analyses with supervised clustering of T cells. ImmunopipeNoTCR.config.toml : The configuration for full analyses without scTCR-/scBCR-seq data. ImmunopipeWSNoTCR.config.toml : The configuration for full analyses without scTCR-/scBCR-seq data, but with selection of T cells. ImmunopipeSupervised.config.toml : The configuration for full analyses with supervised clustering of T cells. Also check out the gallery for more real-world examples.","title":"Geting started"},{"location":"getting-started/#getting-started","text":"You can find the nessary files and source code of this tutorial in the example repository . In this tutorial we will show you how to run the immunopipe pipeline on a small dataset of 6 patients from 3 groups: colitis (n=2), non-colitis(n=2) and control(n=2). The dataset is part of the data used in the publication below: Luoma, Adrienne M., et al. \"Molecular pathways of colon inflammation induced by cancer immunotherapy.\" Cell 182.3 (2020): 655-671. We are using a small subset of the data to make the tutorial run faster. The full dataset can be downloaded from Gene Expression Omnibus (GEO) GSE144469 .","title":"Getting started"},{"location":"getting-started/#download-and-prepare-the-data","text":"The data can be downloaded and prepared by running the following commands: # Clone the example repository git clone https://github.com/pwwang/immunopipe-example.git # Enter the example directory cd immunopipe-example # Download and prepare the data bash prepare-data.sh # The data from GSE144469 (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE144469) # will be downloaded and extracted into: # # ./prepared-data/C1 # ./prepared-data/C2 # ... # You may also check other files in the data/ directory, especially the samples.txt file, which contains the sample information for the dataset we prepared above.","title":"Download and prepare the data"},{"location":"getting-started/#prepare-the-configuration-file","text":"To run the pipeline, we need to prepare a configuration file (recommended) or pass the arguments directly via command line. Here we will use the configuration file. See also Configurations for more details. As explained in the Configurations page, we can provide a configuration file with a minimal set of configuration items to get the pipeline running. The only required configuration item is the input file for the SampleInfo process. However, here we want to give the pipeline a different name and output directory to distinguish it from other runs with a different set of configurations. The configuration file shall be in the TOML format. We can create a file named ImmunopipeMinimal.config.toml with the following content: name = \"ImmunopipeMinimal\" outdir = \"minimal\" [SampleInfo.in] infile = [ \"data/samples.txt\" ]","title":"Prepare the configuration file"},{"location":"getting-started/#run-the-pipeline","text":"The easiest way to run the pipeline is to run it within the docker container. We can use the following command to run the pipeline with the configuration file we just created: Using docker Using singularity Using apptainer docker run \\ --rm -w /workdir -v .:/workdir \\ justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml singularity run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml apptainer run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml Tip docker , singularity and apptainer commands map the current directory ( . ) to the /workdir directory in the container. To get the detailed directory structure in the container, please refer to the The directory structure in the container . Tip If you want to install and run the pipeline without docker, please refer to the Installation and Running the pipeline pages for more details. Note You need at least 16GB of memory to run the pipeline with the example dataset and minimal configuration. You may also need to decrease ncores of some processes to avoid running out of memory. For example: [SeuratClusteringOfAllCells.envs] - ncores = 8 + ncores = 4","title":"Run the pipeline"},{"location":"getting-started/#check-the-results","text":"With that \"minimal\" configuration file, only a subset of the processes will be run. See also Enabling/Disabling processes . The results will be saved in the minimal directory. You can also check the reports at minimal/REPORTS/index.html with a web browser. You can also visit the following link to see the reports of the pipeline we just ran: http://imp.pwwang.com/minimal/REPORTS/index.html","title":"Check the results"},{"location":"getting-started/#next-steps","text":"You may read through this documentation to learn more about the pipeline and how to configure it. There is also a configuration file, named Immunopipe.config.toml in the example repository, with more processes enabled. You can use it to run the pipeline with the dataset prepared above. Check out the following link for the reports: http://imp.pwwang.com/output/REPORTS/index.html Note The results provided by this example configuration files are for demonstration purpose only. They are not intended to be used for any scientific analysis. You may also want to try other routes of the pipeline with the prepared data. These routes are defined in: ImmunopipeMinimalNoTCR.config.toml : The configuration for minimal analyses without scTCR-/scBCR-seq data. ImmunopipeMinimalSupervised.config.toml : The configuration for minimal analyses with supervised clustering of T cells. ImmunopipeNoTCR.config.toml : The configuration for full analyses without scTCR-/scBCR-seq data. ImmunopipeWSNoTCR.config.toml : The configuration for full analyses without scTCR-/scBCR-seq data, but with selection of T cells. ImmunopipeSupervised.config.toml : The configuration for full analyses with supervised clustering of T cells. Also check out the gallery for more real-world examples.","title":"Next steps"},{"location":"installation/","text":"Installation \u00b6 Install the pipline and the dependencies using conda \u00b6 Tip If you plan to use the docker image, you can skip this section. immunopipe is built upon pipen framework, and a number of packages written in R and python . It's not recommended to install the packages manually. Instead, you can use the provided environment.yml to create a conda environment. $ conda env create \\ -n immunopipe \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment.yml Attention The environment.yml includes only a subset of the packages required by the pipeline. The dependencies of the TESSA process are not included. If you want to enable TESSA process , please use the environment_full.yml ( https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_full.yml ) instead. See also Choose the right tag of the docker image . If the URL doesn't work, you can download the file and create the environment locally. For more detailed instructions of conda env create , please refer to conda docs . Attention The pipeline itself is NOT included in the conda environment. You need to install it separately. $ conda activate immunopipe $ pip install -U immunopipe $ # If you want to create diagram and generate running information $ pip install -U immunopipe [ diagram,runinfo ] $ # You also need to install the frontend dependencies to generate reports $ pipen report update Use the docker image \u00b6 You can also use the docker image to run the pipeline. The image is built upon miniconda3 and micromamba is used as the package manager. The image is available at Docker Hub . To pull the image: Using docker Using singularity Using apptainer $ docker pull justold/immunopipe:<tag> If you are using singularity , you can pull and convert the image to sif format: $ singularity pull docker://justold/immunopipe:<tag> $ apptainer pull docker://justold/immunopipe:<tag> To run the pipeline use the image, please refer to Running the pipeline . The directory structure in the container \u00b6 The docker image is build upon mambaorg/micromamba:1.4.3 . The OS is linux/amd64. Other than the default directories, the following directories are also created or should be mapped during the run: /immunopipe : The directory where the source code of the pipeline is. It is general a clone of the repository . The pipeline is also installed from this directory. /workdir : The working directory. It is the directory where the pipeline is run. It is recommended to map the current directory ( . ) to this directory. /data : An empty directory. You can map your data directory to this directory.","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#install-the-pipline-and-the-dependencies-using-conda","text":"Tip If you plan to use the docker image, you can skip this section. immunopipe is built upon pipen framework, and a number of packages written in R and python . It's not recommended to install the packages manually. Instead, you can use the provided environment.yml to create a conda environment. $ conda env create \\ -n immunopipe \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment.yml Attention The environment.yml includes only a subset of the packages required by the pipeline. The dependencies of the TESSA process are not included. If you want to enable TESSA process , please use the environment_full.yml ( https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_full.yml ) instead. See also Choose the right tag of the docker image . If the URL doesn't work, you can download the file and create the environment locally. For more detailed instructions of conda env create , please refer to conda docs . Attention The pipeline itself is NOT included in the conda environment. You need to install it separately. $ conda activate immunopipe $ pip install -U immunopipe $ # If you want to create diagram and generate running information $ pip install -U immunopipe [ diagram,runinfo ] $ # You also need to install the frontend dependencies to generate reports $ pipen report update","title":"Install the pipline and the dependencies using conda"},{"location":"installation/#use-the-docker-image","text":"You can also use the docker image to run the pipeline. The image is built upon miniconda3 and micromamba is used as the package manager. The image is available at Docker Hub . To pull the image: Using docker Using singularity Using apptainer $ docker pull justold/immunopipe:<tag> If you are using singularity , you can pull and convert the image to sif format: $ singularity pull docker://justold/immunopipe:<tag> $ apptainer pull docker://justold/immunopipe:<tag> To run the pipeline use the image, please refer to Running the pipeline .","title":"Use the docker image"},{"location":"installation/#the-directory-structure-in-the-container","text":"The docker image is build upon mambaorg/micromamba:1.4.3 . The OS is linux/amd64. Other than the default directories, the following directories are also created or should be mapped during the run: /immunopipe : The directory where the source code of the pipeline is. It is general a clone of the repository . The pipeline is also installed from this directory. /workdir : The working directory. It is the directory where the pipeline is run. It is recommended to map the current directory ( . ) to this directory. /data : An empty directory. You can map your data directory to this directory.","title":"The directory structure in the container"},{"location":"introduction/","text":"Introduction \u00b6 The pipeline architecture \u00b6 immunopipe is built upon pipen . It is recommended to read the pipen docs first to get a better understanding of the pipeline. Here, we just want to highlight some concepts that are helpful to use the pipeline as a user. A process is a unit of work in the pipeline. immunopipe includes a set of processes. Some of them are reused from biopipen and some are written specifically for immunopipe . The input of a process is typically a pandas DataFrame , which serves as the channel passing data between processes. The rows of the data frame are distributed to the jobs of the process, and columns are spreaded to the input variables of the job s. See more illustration here . In our case, most processes are just single-job processes. Other than the start processes, the input of a process is the output of other process(es). So users don't need to worry about the input of the processes in the configurations. envs of a process is the most important part of immunopipe that a user needs to configure. It defines the environment variables of the process. The environment variables are shared by all the jobs of the process. Attention These environment variables are not the same as the environment variables of the system. They are just variables that are used in the process across its jobs. See individual process pages for more details about the envs of each process. Analyses and processes \u00b6 As shown in the figure above, immunopipe includes a set of processes for scRNA-seq and scTCR-/scBCR-seq data analysis. The processes are grouped into categories below: Data input and QC \u00b6 SampleInfo : Read sample information from a CSV file and list the sample information in the report. ScRepLoading : Load the VDJ data into ScRepertoire objects. SeuratPreparing : Read the data into Seurat objects and perform QC. T cell selection \u00b6 SeuratClusteringOfAllCells : Perform clustering on all cells if non-T cells are present in the data. ClusterMarkersOfAllCells : Find markers for each cluster of all the cells and perform enrichment analysis. TopExpressingGenesOfAllCells : Find top expressing genes for each cluster of all the cells and perform enrichment analysis. TOrBCellSelection : Select T cells from all cells. Clustering of T cells \u00b6 SeuratClustering : Perform clustering on all or T cells selected above. SeuratMap2Ref : Map the cells to a reference dataset. CellTypeAnnotation : Annotate cell types for each T-cell cluster. SeuratSubClustering : Perform sub-clustering on subsets of cells. ClusterMarkers : Find markers for each T-cell cluster and perform enrichment analysis. TopExpressingGenes : Find top expressing genes for each T-cell cluster and perform enrichment analysis. ModuleScoreCalculator : Calculate module scores or cell cycle scores for each cell. Clonotype refinement \u00b6 TCRClustering : Perform clustering on TCR clones based on CDR3 amino acid sequences. TESSA : Perform integrative analyses using Tessa . Integration of scRNA-seq and scTCR-/scBCR-seq data \u00b6 ScRepCombiningExpression : Combine the VDJ data with the expression data (into a Seurat object). Downstream analyses \u00b6 SeuratClusterStats : Investigate statistics for each T-cell cluster (i.e. the number of cells in each cluster, the number of cells in each sample for each cluster, feature/gene expression visualization, dimension reduction plots, etc.). It's also possible to perform stats on TCR/BCR clones/clusters for each T-cell cluster. ClonalStats : Investigate statistics for clones. MarkersFinder : Find markers (differentially expressed genes) for any two groups, including clones or clone groups. PseudoBulkDEG : Perform pseudo-bulk differential expression analysis. CDR3AAPhyschem : Investigate the physicochemical properties of CDR3 amino acid sequences of one cell type over another (i.e. Treg vs Tconv ). ScFGSEA : Perform GSEA analysis for comparisons between two groups of cells. For example, between two cell types, clone groups, TCR/BCR clusters or clinical groups. CellCellCommunication : Perform cell-cell communication analysis. CellCellCommunicationPlots : Generate plots for cell-cell communication analysis. Metabolic landscape analyses \u00b6 ScrnaMetabolicLandscape : A group of folowwing processes to perform metabolic landscape analyses. MetabolicInput : Prepare the input files for metabolic landscape analyses. MetabolicExprImputation : Impute the dropout values in the expression matrix. MetabolicPathwayActivity : Investigate the metabolic pathways of the cells in different groups and subsets. MetabolicPathwayHeterogeneity : Show metabolic pathways enriched in genes with highest contribution to the metabolic heterogeneities. MetabolicFeatures : Perform gene set enrichment analysis against the metabolic pathways for groups in different subsets. Routes of the pipeline \u00b6 immunopipe is designed to be flexible. It can be used in different ways. Here we list some common routes of the pipeline: Both scRNA-seq and scTCR-/scBCR-seq data avaiable \u00b6 To enable this route, you need to: tell the pipeline that scTCR-seq data is available by adding a column named TCRData / BCRData in the sample information file. put the path of the sample information file in the configuration file [SampleInfo.in.infile] , instead of passing it as a command line argument ( --Sample.in.infile ). Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If so, SeuratClustering will be replaced by SeuratMap2Ref in the pipeline. If you need to select T/B cells from all cells available for later analyses, you need to add [TOrBCellSelection] in the configuration file. If so, the processes annotated as something like For selected cells will be added to the pipeline. This is the most common route of the pipeline: The optional processes are enabled only when the corresponding sections are added in the configuration file. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you need to add [ModuleScoreCalculator] in the configuration file. Only scRNA-seq data avaiable \u00b6 When you have only scRNA-seq data, you just don't need to add the TCRData / BCRData column in the sample information file. The pipeline will automatically skip the processes related to scTCR-/scBCR-seq data analysis. Attention You need to specify the sample information file in the configuration file [SampleInfo.in.infile] to enable this route. Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger this route. Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If so, SeuratClustering will be replaced by SeuratMap2Ref in the pipeline.","title":"Introduction"},{"location":"introduction/#introduction","text":"","title":"Introduction"},{"location":"introduction/#the-pipeline-architecture","text":"immunopipe is built upon pipen . It is recommended to read the pipen docs first to get a better understanding of the pipeline. Here, we just want to highlight some concepts that are helpful to use the pipeline as a user. A process is a unit of work in the pipeline. immunopipe includes a set of processes. Some of them are reused from biopipen and some are written specifically for immunopipe . The input of a process is typically a pandas DataFrame , which serves as the channel passing data between processes. The rows of the data frame are distributed to the jobs of the process, and columns are spreaded to the input variables of the job s. See more illustration here . In our case, most processes are just single-job processes. Other than the start processes, the input of a process is the output of other process(es). So users don't need to worry about the input of the processes in the configurations. envs of a process is the most important part of immunopipe that a user needs to configure. It defines the environment variables of the process. The environment variables are shared by all the jobs of the process. Attention These environment variables are not the same as the environment variables of the system. They are just variables that are used in the process across its jobs. See individual process pages for more details about the envs of each process.","title":"The pipeline architecture"},{"location":"introduction/#analyses-and-processes","text":"As shown in the figure above, immunopipe includes a set of processes for scRNA-seq and scTCR-/scBCR-seq data analysis. The processes are grouped into categories below:","title":"Analyses and processes"},{"location":"introduction/#data-input-and-qc","text":"SampleInfo : Read sample information from a CSV file and list the sample information in the report. ScRepLoading : Load the VDJ data into ScRepertoire objects. SeuratPreparing : Read the data into Seurat objects and perform QC.","title":"Data input and QC"},{"location":"introduction/#t-cell-selection","text":"SeuratClusteringOfAllCells : Perform clustering on all cells if non-T cells are present in the data. ClusterMarkersOfAllCells : Find markers for each cluster of all the cells and perform enrichment analysis. TopExpressingGenesOfAllCells : Find top expressing genes for each cluster of all the cells and perform enrichment analysis. TOrBCellSelection : Select T cells from all cells.","title":"T cell selection"},{"location":"introduction/#clustering-of-t-cells","text":"SeuratClustering : Perform clustering on all or T cells selected above. SeuratMap2Ref : Map the cells to a reference dataset. CellTypeAnnotation : Annotate cell types for each T-cell cluster. SeuratSubClustering : Perform sub-clustering on subsets of cells. ClusterMarkers : Find markers for each T-cell cluster and perform enrichment analysis. TopExpressingGenes : Find top expressing genes for each T-cell cluster and perform enrichment analysis. ModuleScoreCalculator : Calculate module scores or cell cycle scores for each cell.","title":"Clustering of T cells"},{"location":"introduction/#clonotype-refinement","text":"TCRClustering : Perform clustering on TCR clones based on CDR3 amino acid sequences. TESSA : Perform integrative analyses using Tessa .","title":"Clonotype refinement"},{"location":"introduction/#integration-of-scrna-seq-and-sctcr-scbcr-seq-data","text":"ScRepCombiningExpression : Combine the VDJ data with the expression data (into a Seurat object).","title":"Integration of scRNA-seq and scTCR-/scBCR-seq data"},{"location":"introduction/#downstream-analyses","text":"SeuratClusterStats : Investigate statistics for each T-cell cluster (i.e. the number of cells in each cluster, the number of cells in each sample for each cluster, feature/gene expression visualization, dimension reduction plots, etc.). It's also possible to perform stats on TCR/BCR clones/clusters for each T-cell cluster. ClonalStats : Investigate statistics for clones. MarkersFinder : Find markers (differentially expressed genes) for any two groups, including clones or clone groups. PseudoBulkDEG : Perform pseudo-bulk differential expression analysis. CDR3AAPhyschem : Investigate the physicochemical properties of CDR3 amino acid sequences of one cell type over another (i.e. Treg vs Tconv ). ScFGSEA : Perform GSEA analysis for comparisons between two groups of cells. For example, between two cell types, clone groups, TCR/BCR clusters or clinical groups. CellCellCommunication : Perform cell-cell communication analysis. CellCellCommunicationPlots : Generate plots for cell-cell communication analysis.","title":"Downstream analyses"},{"location":"introduction/#metabolic-landscape-analyses","text":"ScrnaMetabolicLandscape : A group of folowwing processes to perform metabolic landscape analyses. MetabolicInput : Prepare the input files for metabolic landscape analyses. MetabolicExprImputation : Impute the dropout values in the expression matrix. MetabolicPathwayActivity : Investigate the metabolic pathways of the cells in different groups and subsets. MetabolicPathwayHeterogeneity : Show metabolic pathways enriched in genes with highest contribution to the metabolic heterogeneities. MetabolicFeatures : Perform gene set enrichment analysis against the metabolic pathways for groups in different subsets.","title":"Metabolic landscape analyses"},{"location":"introduction/#routes-of-the-pipeline","text":"immunopipe is designed to be flexible. It can be used in different ways. Here we list some common routes of the pipeline:","title":"Routes of the pipeline"},{"location":"introduction/#both-scrna-seq-and-sctcr-scbcr-seq-data-avaiable","text":"To enable this route, you need to: tell the pipeline that scTCR-seq data is available by adding a column named TCRData / BCRData in the sample information file. put the path of the sample information file in the configuration file [SampleInfo.in.infile] , instead of passing it as a command line argument ( --Sample.in.infile ). Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If so, SeuratClustering will be replaced by SeuratMap2Ref in the pipeline. If you need to select T/B cells from all cells available for later analyses, you need to add [TOrBCellSelection] in the configuration file. If so, the processes annotated as something like For selected cells will be added to the pipeline. This is the most common route of the pipeline: The optional processes are enabled only when the corresponding sections are added in the configuration file. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you need to add [ModuleScoreCalculator] in the configuration file.","title":"Both scRNA-seq and scTCR-/scBCR-seq data avaiable"},{"location":"introduction/#only-scrna-seq-data-avaiable","text":"When you have only scRNA-seq data, you just don't need to add the TCRData / BCRData column in the sample information file. The pipeline will automatically skip the processes related to scTCR-/scBCR-seq data analysis. Attention You need to specify the sample information file in the configuration file [SampleInfo.in.infile] to enable this route. Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger this route. Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If so, SeuratClustering will be replaced by SeuratMap2Ref in the pipeline.","title":"Only scRNA-seq data avaiable"},{"location":"mcp-server/","text":"MCP Server \u00b6 The Immunopipe MCP Server is a Model Context Protocol (MCP) server that provides intelligent configuration generation for immunopipe pipelines. It allows AI assistants like Claude to understand and generate complex TOML configuration files for single-cell RNA-seq and TCR/BCR analysis workflows. Overview \u00b6 The MCP server exposes a comprehensive set of tools for: Discovery : List available pipeline options, processes, and Google Batch configurations Generation : Create TOML configuration files, templates, and process-specific configs Manipulation : Merge, validate, and format configuration files AI-Assisted Configuration : Generate configurations from natural language descriptions Installation \u00b6 The MCP server is included with immunopipe. You can run it directly using: # Run with stdio transport (for VSCode/Claude integration) immunopipe mcp --transport stdio # Run with HTTP transport (for testing) immunopipe mcp --transport http --port 8000 VSCode Integration \u00b6 To integrate with VSCode and Claude, add the following to your VSCode settings: { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe.mcp\" , \"--transport\" , \"stdio\" ] } } } } Available Tools \u00b6 Discovery Tools \u00b6 list_pipeline_options \u00b6 Lists all available pipeline-level configuration options. Parameters : None Returns : Dictionary of pipeline options with descriptions, types, defaults, and requirements. list_processes \u00b6 Lists all available immunopipe processes. Parameters : None Returns : Dictionary of processes with descriptions, environment variables, and requirements. list_gbatch_options \u00b6 Lists all Google Batch configuration options. Parameters : None Returns : Dictionary of Google Batch options with descriptions, types, and defaults. get_process_details \u00b6 Gets detailed information about a specific process. Parameters : - process_name (string): Name of the process to get details for Returns : Detailed process information including configuration options. Generation Tools \u00b6 generate_full_config \u00b6 Generates a complete immunopipe TOML configuration file. Parameters : - pipeline_options (object, optional): Pipeline-level options - processes (object, optional): Process configurations - gbatch_options (object, optional): Google Batch options - description (string, optional): Description for the configuration file Returns : Complete TOML configuration as a string. generate_pipeline_config \u00b6 Generates pipeline-level configuration section. Parameters : - options (object): Pipeline options to include Returns : Pipeline configuration TOML section. generate_process_config \u00b6 Generates configuration for a specific process. Parameters : - process_name (string): Name of the process - config (object): Process configuration options Returns : Process configuration TOML section. generate_gbatch_config \u00b6 Generates Google Batch configuration section. Parameters : - options (object): Google Batch options Returns : Google Batch configuration TOML section. Template Tools \u00b6 generate_basic_template \u00b6 Generates a basic immunopipe configuration template. Parameters : None Returns : Basic TOML template suitable for standard scRNA-seq analysis. generate_tcr_template \u00b6 Generates a template optimized for TCR analysis. Parameters : None Returns : TOML template configured for single-cell TCR/BCR analysis. generate_gbatch_template \u00b6 Generates a template for Google Batch execution. Parameters : None Returns : TOML template configured for cloud execution via Google Batch. Manipulation Tools \u00b6 merge_configs \u00b6 Merges two TOML configuration files or strings. Parameters : - base_config (string): Base configuration (TOML string) - new_config (string): New configuration to merge (TOML string) Returns : Merged TOML configuration. validate_config \u00b6 Validates a TOML configuration file. Parameters : - config_content (string): TOML configuration content to validate Returns : Validation results with success status and error messages. format_config \u00b6 Formats and enhances a TOML configuration. Parameters : - config_content (string): TOML configuration content to format - add_comments (boolean, optional): Whether to add helpful comments Returns : Formatted TOML configuration with optional comments. AI-Assisted Tools \u00b6 configure_immunopipe \u00b6 Generates immunopipe configuration from natural language requirements. This is the most intelligent tool that can understand complex analysis requirements and automatically select appropriate processes. Parameters : - requirements (string): Natural language description of analysis needs - specific_processes (array, optional): Specific process names to configure - parameters (object, optional): Specific parameter values to set Examples : - \"clustering with resolution 0.5\" - \"TCR analysis with clustering\" - \"set SeuratPreparing QC parameters\" Returns : Complete TOML configuration tailored to the requirements. help_generate_config \u00b6 Provides configuration suggestions based on natural language descriptions. Parameters : - description (string): Natural language description of analysis goals Returns : Suggestions and recommended tools for the analysis. suggest_processes \u00b6 Suggests processes based on analysis type. Parameters : - analysis_type (string): Type of analysis (e.g., 'tcr', 'bcr', 'clustering', 'differential') Returns : List of recommended processes for the analysis type. Usage Examples \u00b6 Basic Usage \u00b6 from immunopipe.mcp.tools import ImmunopipeConfigTools # Initialize the tools tools = ImmunopipeConfigTools () # Generate a basic template result = await tools . generate_basic_template () print ( result . content ) Natural Language Configuration \u00b6 # Configure immunopipe using natural language result = await tools . configure_immunopipe ( requirements = \"I want to analyze single-cell TCR data with clustering resolution 0.8\" ) print ( result . content ) # Complete TOML configuration Process Discovery \u00b6 # List available processes processes = await tools . list_processes () print ( f \"Found { len ( processes . content ) } processes\" ) # Get details for a specific process details = await tools . get_process_details ( \"SeuratClustering\" ) print ( details . content ) Configuration Manipulation \u00b6 # Generate base config base = await tools . generate_basic_template () # Generate TCR-specific additions tcr_config = await tools . generate_tcr_template () # Merge configurations merged = await tools . merge_configs ( base . content , tcr_config . content ) print ( merged . content ) Integration with Claude/AI Assistants \u00b6 The MCP server is designed to work seamlessly with AI assistants. With immunopipe installed, you can add the MCP server to your Claude or VSCode setup to enable intelligent configuration generation: claude mcp add --transport http immunopipe-mcp http://localhost:80000 { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe\" , \"mcp\" , \"--transport\" , \"stdio\" ] } } } Here are some example prompts that work well: Configuration Generation \u00b6 \"Generate an immunopipe configuration for TCR analysis\" \"Create a config for single-cell clustering with resolution 0.5\" \"Set up immunopipe for differential expression analysis\" Process Selection \u00b6 \"What processes do I need for BCR analysis?\" \"Suggest processes for clustering analysis\" \"Show me options for Google Batch execution\" Configuration Management \u00b6 \"Validate this immunopipe configuration\" \"Format and add comments to my config file\" \"Merge these two immunopipe configurations\" Architecture \u00b6 The MCP server consists of several key components: McpServer : Main server implementation with JSON-RPC over HTTP MCPServer : Standards-compliant MCP server for VSCode integration ImmunopipeConfigTools : Core tool collection with hierarchical capabilities OptionsDiscovery : Discovers available configuration options and processes TOMLGenerator : Generates and manipulates TOML configuration files ProcessDocumentationExtractor : Extracts process documentation for intelligent configuration Error Handling \u00b6 The MCP server provides comprehensive error handling: Tool Validation : Validates tool parameters and provides helpful error messages Configuration Validation : Checks TOML syntax and immunopipe-specific requirements Process Discovery : Handles missing or unavailable processes gracefully Natural Language Processing : Provides fallback configurations when analysis fails Development and Testing \u00b6 To test the MCP server locally: # Run the example demonstration python -m immunopipe.mcp.example # Run interactive demo python -m immunopipe.mcp.example interactive # Test with HTTP transport immunopipe mcp --transport http --port 8000 The server includes comprehensive test coverage and example usage patterns to help with development and integration. Performance \u00b6 The MCP server is optimized for: Fast Discovery : Efficient caching of process and option information Incremental Configuration : Tools can be chained for complex configurations Memory Efficiency : Lazy loading of process documentation Scalability : Async/await support for concurrent tool execution Support and Troubleshooting \u00b6 Common issues and solutions: Process Not Found : Ensure immunopipe is properly installed and processes are available Configuration Validation Errors : Check TOML syntax and parameter validity Natural Language Analysis Failures : Use more specific descriptions or explicit process names VSCode Integration Issues : Verify MCP server configuration in VSCode settings For additional help, open an issue on the GitHub repository .","title":"MCP Sever"},{"location":"mcp-server/#mcp-server","text":"The Immunopipe MCP Server is a Model Context Protocol (MCP) server that provides intelligent configuration generation for immunopipe pipelines. It allows AI assistants like Claude to understand and generate complex TOML configuration files for single-cell RNA-seq and TCR/BCR analysis workflows.","title":"MCP Server"},{"location":"mcp-server/#overview","text":"The MCP server exposes a comprehensive set of tools for: Discovery : List available pipeline options, processes, and Google Batch configurations Generation : Create TOML configuration files, templates, and process-specific configs Manipulation : Merge, validate, and format configuration files AI-Assisted Configuration : Generate configurations from natural language descriptions","title":"Overview"},{"location":"mcp-server/#installation","text":"The MCP server is included with immunopipe. You can run it directly using: # Run with stdio transport (for VSCode/Claude integration) immunopipe mcp --transport stdio # Run with HTTP transport (for testing) immunopipe mcp --transport http --port 8000","title":"Installation"},{"location":"mcp-server/#vscode-integration","text":"To integrate with VSCode and Claude, add the following to your VSCode settings: { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe.mcp\" , \"--transport\" , \"stdio\" ] } } } }","title":"VSCode Integration"},{"location":"mcp-server/#available-tools","text":"","title":"Available Tools"},{"location":"mcp-server/#discovery-tools","text":"","title":"Discovery Tools"},{"location":"mcp-server/#list_pipeline_options","text":"Lists all available pipeline-level configuration options. Parameters : None Returns : Dictionary of pipeline options with descriptions, types, defaults, and requirements.","title":"list_pipeline_options"},{"location":"mcp-server/#list_processes","text":"Lists all available immunopipe processes. Parameters : None Returns : Dictionary of processes with descriptions, environment variables, and requirements.","title":"list_processes"},{"location":"mcp-server/#list_gbatch_options","text":"Lists all Google Batch configuration options. Parameters : None Returns : Dictionary of Google Batch options with descriptions, types, and defaults.","title":"list_gbatch_options"},{"location":"mcp-server/#get_process_details","text":"Gets detailed information about a specific process. Parameters : - process_name (string): Name of the process to get details for Returns : Detailed process information including configuration options.","title":"get_process_details"},{"location":"mcp-server/#generation-tools","text":"","title":"Generation Tools"},{"location":"mcp-server/#generate_full_config","text":"Generates a complete immunopipe TOML configuration file. Parameters : - pipeline_options (object, optional): Pipeline-level options - processes (object, optional): Process configurations - gbatch_options (object, optional): Google Batch options - description (string, optional): Description for the configuration file Returns : Complete TOML configuration as a string.","title":"generate_full_config"},{"location":"mcp-server/#generate_pipeline_config","text":"Generates pipeline-level configuration section. Parameters : - options (object): Pipeline options to include Returns : Pipeline configuration TOML section.","title":"generate_pipeline_config"},{"location":"mcp-server/#generate_process_config","text":"Generates configuration for a specific process. Parameters : - process_name (string): Name of the process - config (object): Process configuration options Returns : Process configuration TOML section.","title":"generate_process_config"},{"location":"mcp-server/#generate_gbatch_config","text":"Generates Google Batch configuration section. Parameters : - options (object): Google Batch options Returns : Google Batch configuration TOML section.","title":"generate_gbatch_config"},{"location":"mcp-server/#template-tools","text":"","title":"Template Tools"},{"location":"mcp-server/#generate_basic_template","text":"Generates a basic immunopipe configuration template. Parameters : None Returns : Basic TOML template suitable for standard scRNA-seq analysis.","title":"generate_basic_template"},{"location":"mcp-server/#generate_tcr_template","text":"Generates a template optimized for TCR analysis. Parameters : None Returns : TOML template configured for single-cell TCR/BCR analysis.","title":"generate_tcr_template"},{"location":"mcp-server/#generate_gbatch_template","text":"Generates a template for Google Batch execution. Parameters : None Returns : TOML template configured for cloud execution via Google Batch.","title":"generate_gbatch_template"},{"location":"mcp-server/#manipulation-tools","text":"","title":"Manipulation Tools"},{"location":"mcp-server/#merge_configs","text":"Merges two TOML configuration files or strings. Parameters : - base_config (string): Base configuration (TOML string) - new_config (string): New configuration to merge (TOML string) Returns : Merged TOML configuration.","title":"merge_configs"},{"location":"mcp-server/#validate_config","text":"Validates a TOML configuration file. Parameters : - config_content (string): TOML configuration content to validate Returns : Validation results with success status and error messages.","title":"validate_config"},{"location":"mcp-server/#format_config","text":"Formats and enhances a TOML configuration. Parameters : - config_content (string): TOML configuration content to format - add_comments (boolean, optional): Whether to add helpful comments Returns : Formatted TOML configuration with optional comments.","title":"format_config"},{"location":"mcp-server/#ai-assisted-tools","text":"","title":"AI-Assisted Tools"},{"location":"mcp-server/#configure_immunopipe","text":"Generates immunopipe configuration from natural language requirements. This is the most intelligent tool that can understand complex analysis requirements and automatically select appropriate processes. Parameters : - requirements (string): Natural language description of analysis needs - specific_processes (array, optional): Specific process names to configure - parameters (object, optional): Specific parameter values to set Examples : - \"clustering with resolution 0.5\" - \"TCR analysis with clustering\" - \"set SeuratPreparing QC parameters\" Returns : Complete TOML configuration tailored to the requirements.","title":"configure_immunopipe"},{"location":"mcp-server/#help_generate_config","text":"Provides configuration suggestions based on natural language descriptions. Parameters : - description (string): Natural language description of analysis goals Returns : Suggestions and recommended tools for the analysis.","title":"help_generate_config"},{"location":"mcp-server/#suggest_processes","text":"Suggests processes based on analysis type. Parameters : - analysis_type (string): Type of analysis (e.g., 'tcr', 'bcr', 'clustering', 'differential') Returns : List of recommended processes for the analysis type.","title":"suggest_processes"},{"location":"mcp-server/#usage-examples","text":"","title":"Usage Examples"},{"location":"mcp-server/#basic-usage","text":"from immunopipe.mcp.tools import ImmunopipeConfigTools # Initialize the tools tools = ImmunopipeConfigTools () # Generate a basic template result = await tools . generate_basic_template () print ( result . content )","title":"Basic Usage"},{"location":"mcp-server/#natural-language-configuration","text":"# Configure immunopipe using natural language result = await tools . configure_immunopipe ( requirements = \"I want to analyze single-cell TCR data with clustering resolution 0.8\" ) print ( result . content ) # Complete TOML configuration","title":"Natural Language Configuration"},{"location":"mcp-server/#process-discovery","text":"# List available processes processes = await tools . list_processes () print ( f \"Found { len ( processes . content ) } processes\" ) # Get details for a specific process details = await tools . get_process_details ( \"SeuratClustering\" ) print ( details . content )","title":"Process Discovery"},{"location":"mcp-server/#configuration-manipulation","text":"# Generate base config base = await tools . generate_basic_template () # Generate TCR-specific additions tcr_config = await tools . generate_tcr_template () # Merge configurations merged = await tools . merge_configs ( base . content , tcr_config . content ) print ( merged . content )","title":"Configuration Manipulation"},{"location":"mcp-server/#integration-with-claudeai-assistants","text":"The MCP server is designed to work seamlessly with AI assistants. With immunopipe installed, you can add the MCP server to your Claude or VSCode setup to enable intelligent configuration generation: claude mcp add --transport http immunopipe-mcp http://localhost:80000 { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe\" , \"mcp\" , \"--transport\" , \"stdio\" ] } } } Here are some example prompts that work well:","title":"Integration with Claude/AI Assistants"},{"location":"mcp-server/#configuration-generation","text":"\"Generate an immunopipe configuration for TCR analysis\" \"Create a config for single-cell clustering with resolution 0.5\" \"Set up immunopipe for differential expression analysis\"","title":"Configuration Generation"},{"location":"mcp-server/#process-selection","text":"\"What processes do I need for BCR analysis?\" \"Suggest processes for clustering analysis\" \"Show me options for Google Batch execution\"","title":"Process Selection"},{"location":"mcp-server/#configuration-management","text":"\"Validate this immunopipe configuration\" \"Format and add comments to my config file\" \"Merge these two immunopipe configurations\"","title":"Configuration Management"},{"location":"mcp-server/#architecture","text":"The MCP server consists of several key components: McpServer : Main server implementation with JSON-RPC over HTTP MCPServer : Standards-compliant MCP server for VSCode integration ImmunopipeConfigTools : Core tool collection with hierarchical capabilities OptionsDiscovery : Discovers available configuration options and processes TOMLGenerator : Generates and manipulates TOML configuration files ProcessDocumentationExtractor : Extracts process documentation for intelligent configuration","title":"Architecture"},{"location":"mcp-server/#error-handling","text":"The MCP server provides comprehensive error handling: Tool Validation : Validates tool parameters and provides helpful error messages Configuration Validation : Checks TOML syntax and immunopipe-specific requirements Process Discovery : Handles missing or unavailable processes gracefully Natural Language Processing : Provides fallback configurations when analysis fails","title":"Error Handling"},{"location":"mcp-server/#development-and-testing","text":"To test the MCP server locally: # Run the example demonstration python -m immunopipe.mcp.example # Run interactive demo python -m immunopipe.mcp.example interactive # Test with HTTP transport immunopipe mcp --transport http --port 8000 The server includes comprehensive test coverage and example usage patterns to help with development and integration.","title":"Development and Testing"},{"location":"mcp-server/#performance","text":"The MCP server is optimized for: Fast Discovery : Efficient caching of process and option information Incremental Configuration : Tools can be chained for complex configurations Memory Efficiency : Lazy loading of process documentation Scalability : Async/await support for concurrent tool execution","title":"Performance"},{"location":"mcp-server/#support-and-troubleshooting","text":"Common issues and solutions: Process Not Found : Ensure immunopipe is properly installed and processes are available Configuration Validation Errors : Check TOML syntax and parameter validity Natural Language Analysis Failures : Use more specific descriptions or explicit process names VSCode Integration Issues : Verify MCP server configuration in VSCode settings For additional help, open an issue on the GitHub repository .","title":"Support and Troubleshooting"},{"location":"preparing-input/","text":"Preparing the input data \u00b6 Single-cell RNA-seq (scRNA-seq) data \u00b6 Currently supported data formats: 10X Genomics by CellRanger loom For each sample, you need to provide the path to the data file or a directory containing the files. Specifically, the directory should be able to be read by Seurat::Read_10X() . For example, the directory should contain matrix.mtx , barcodes.tsv and features.tsv . These files can also be gzipped. For 10X Genomics data, you can also provide the h5 file generated by CellRanger . With v2+, we also support loading expression data directly from a Seurat object in RDS or qs/qs2 file. To do so, you need to enable the LoadingRNAFromSeurat process in the configuration file, and provide the path to the RDS or qs2 file: [LoadingRNAFromSeurat.in] infile = \"path/to/seurat_object.rds\" [LoadingRNAFromSeurat.envs] # When true, SeuratPreparing will be skipped # Suppose the Seurat object is already prepared prepared = false # When true (assuming prepared is also true), SeuratClusteringOfAllCells/SeuratClustering will be skipped # Suppose the Seurat object already contains the clustering information clustered = false # The column name in meta.data to use for sample identity sample = \"Sample\" Single-cell TCR-/BCR-seq (scTCR-seq/scBCR-seq) data \u00b6 The scTCR-/scBCR-seq data is optional for the pipeline. However, the scRNA-seq data is required for the pipeline. The scTCR-/scBCR-seq data, if available, should be paired with the scRNA-seq data. Theoratically, as long as the data can be loaded by scRepertoire::loadContigs() , it should be fine. Following formats are supported: 10X: 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR: AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD: Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion: Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation: Immcantation data, which is usually in a file with data.tsv file. JSON: JSON format, which is usually in a file with .json extension. ParseBio: ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR: MiXCR data, which is usually in a file with clones.tsv file. Omniscope: Omniscope data, which is usually in a file with .csv extension. TRUST4: TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R: WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html Metadata \u00b6 A metadata file is required as an input file for the pipeline. It should be a TAB delimited file with 3 required columns: Sample : A unique id for each sample RNAData : The directory or h5 file for single-cell RNA data for this sample, as described above. TCRData (optional): The directory for single-cell TCR data for this sample as described above. BCRData (optional): The directory for single-cell BCR data for this sample as described above. When TCRData / BCRData is not provided, the pipeline will skip the processes related to scTCR-/scBCR-seq data (see Routes of the pipeline for more details). You can also add other columns to the metadata file. The columns will be added the Seurat object as metadata, and can be used for downstream analysis. For example, you can add a column Condition to indicate the condition of each sample, or Batch to indicate the batch effect. This file should be provided to SampleInfo process. See SampleInfo for more details. An example metadata file can be found here . You can also use SampleInfo with envs.save_mutated = true and/or SeuratPreparing to add columns to metadata by configuration. These columns are persisted for downstream analysis. The difference is that SampleInfo can not pass along the factor (categorical) columns, while you are able to do so with SeuratPreparing . Other optional files \u00b6 Genes/Features to visualize for Seurat object \u00b6 If you have a set of genes/features of interest, you can provide a file with those genes, one gene per line, to SeuratClusterStats.envs.features.features for visualization the feature values, which finally is implemented by scplotter::FeatureStatPlot() . Note The genes should exist in the RNA-seq data (i.e features.tsv or the h5 file from cellranger). See SeuratClusterStats for more details. Pathways for Gene Set Enrichment Analysis (GSEA) \u00b6 If you want to perform GSEA, you need to provide a file containing the pathways. The file should be in the GMT format . You can provide the file to ScFGSEA.envs.gmtfile . Similarly, the genes should exist (be in the same format) in the features.tsv file. See ScFGSEA for more details. You can also find an example here: https://github.com/pwwang/immunopipe-example/blob/master/data/MSigDB_Hallmark_v7.5.1.gmt Cell type database for cell type annotation by sctype or hitype \u00b6 If you want to perform cell type annotation, you need to provide a file containing the cell type database if you are using sctype or hitype . The database file should be fed to CellTypeAnnotation.envs.sctype_db if you are using sctype , or CellTypeAnnotation.envs.hitype_db if you are using hitype . Again, the markers in the database should exist (be in the same format) in the features.tsv file or the h5 file. See CellTypeAnnotation for more details. Examples can be found here: ScTypeDB_short.xlsx and ScTypeDB_full.xlsx . Model for cell type annotation by celltypist \u00b6 If you want to perform cell type annotation by celltypist , you need to provide a model file. The model file should be fed to CellTypeAnnotation.envs.celltypist_args.model . The information of models can be found here . Download the one you want to use and provide the path to the file. Metabolic pathway for Metabolic Landscape Analysis \u00b6 Similarly, if you want to perform metabolic landscape analysis, you need to provide a file containing the metabolic pathways. The file should be in the GMT format . You can provide the file to ScMetabolicLandscape.envs.gmtfile . This file can also be used for GSEA. A pathway file for KEGG metabolism is provided here . See ScrnaMetabolicLandscape for more details. Reference for Seurat mapping if you want to perform supervised clustering \u00b6 If you want to perform supervised clustering, you need to provide a reference for SeuratMap2Ref . The reference should be a Seurat object in RDS or h5seurat file. You can provide the reference to SeuratMap2Ref.envs.ref . See SeuratMap2Ref for more details.","title":"Preparing the input"},{"location":"preparing-input/#preparing-the-input-data","text":"","title":"Preparing the input data"},{"location":"preparing-input/#single-cell-rna-seq-scrna-seq-data","text":"Currently supported data formats: 10X Genomics by CellRanger loom For each sample, you need to provide the path to the data file or a directory containing the files. Specifically, the directory should be able to be read by Seurat::Read_10X() . For example, the directory should contain matrix.mtx , barcodes.tsv and features.tsv . These files can also be gzipped. For 10X Genomics data, you can also provide the h5 file generated by CellRanger . With v2+, we also support loading expression data directly from a Seurat object in RDS or qs/qs2 file. To do so, you need to enable the LoadingRNAFromSeurat process in the configuration file, and provide the path to the RDS or qs2 file: [LoadingRNAFromSeurat.in] infile = \"path/to/seurat_object.rds\" [LoadingRNAFromSeurat.envs] # When true, SeuratPreparing will be skipped # Suppose the Seurat object is already prepared prepared = false # When true (assuming prepared is also true), SeuratClusteringOfAllCells/SeuratClustering will be skipped # Suppose the Seurat object already contains the clustering information clustered = false # The column name in meta.data to use for sample identity sample = \"Sample\"","title":"Single-cell RNA-seq (scRNA-seq) data"},{"location":"preparing-input/#single-cell-tcr-bcr-seq-sctcr-seqscbcr-seq-data","text":"The scTCR-/scBCR-seq data is optional for the pipeline. However, the scRNA-seq data is required for the pipeline. The scTCR-/scBCR-seq data, if available, should be paired with the scRNA-seq data. Theoratically, as long as the data can be loaded by scRepertoire::loadContigs() , it should be fine. Following formats are supported: 10X: 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR: AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD: Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion: Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation: Immcantation data, which is usually in a file with data.tsv file. JSON: JSON format, which is usually in a file with .json extension. ParseBio: ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR: MiXCR data, which is usually in a file with clones.tsv file. Omniscope: Omniscope data, which is usually in a file with .csv extension. TRUST4: TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R: WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html","title":"Single-cell TCR-/BCR-seq (scTCR-seq/scBCR-seq) data"},{"location":"preparing-input/#metadata","text":"A metadata file is required as an input file for the pipeline. It should be a TAB delimited file with 3 required columns: Sample : A unique id for each sample RNAData : The directory or h5 file for single-cell RNA data for this sample, as described above. TCRData (optional): The directory for single-cell TCR data for this sample as described above. BCRData (optional): The directory for single-cell BCR data for this sample as described above. When TCRData / BCRData is not provided, the pipeline will skip the processes related to scTCR-/scBCR-seq data (see Routes of the pipeline for more details). You can also add other columns to the metadata file. The columns will be added the Seurat object as metadata, and can be used for downstream analysis. For example, you can add a column Condition to indicate the condition of each sample, or Batch to indicate the batch effect. This file should be provided to SampleInfo process. See SampleInfo for more details. An example metadata file can be found here . You can also use SampleInfo with envs.save_mutated = true and/or SeuratPreparing to add columns to metadata by configuration. These columns are persisted for downstream analysis. The difference is that SampleInfo can not pass along the factor (categorical) columns, while you are able to do so with SeuratPreparing .","title":"Metadata"},{"location":"preparing-input/#other-optional-files","text":"","title":"Other optional files"},{"location":"preparing-input/#genesfeatures-to-visualize-for-seurat-object","text":"If you have a set of genes/features of interest, you can provide a file with those genes, one gene per line, to SeuratClusterStats.envs.features.features for visualization the feature values, which finally is implemented by scplotter::FeatureStatPlot() . Note The genes should exist in the RNA-seq data (i.e features.tsv or the h5 file from cellranger). See SeuratClusterStats for more details.","title":"Genes/Features to visualize for Seurat object"},{"location":"preparing-input/#pathways-for-gene-set-enrichment-analysis-gsea","text":"If you want to perform GSEA, you need to provide a file containing the pathways. The file should be in the GMT format . You can provide the file to ScFGSEA.envs.gmtfile . Similarly, the genes should exist (be in the same format) in the features.tsv file. See ScFGSEA for more details. You can also find an example here: https://github.com/pwwang/immunopipe-example/blob/master/data/MSigDB_Hallmark_v7.5.1.gmt","title":"Pathways for Gene Set Enrichment Analysis (GSEA)"},{"location":"preparing-input/#cell-type-database-for-cell-type-annotation-by-sctype-or-hitype","text":"If you want to perform cell type annotation, you need to provide a file containing the cell type database if you are using sctype or hitype . The database file should be fed to CellTypeAnnotation.envs.sctype_db if you are using sctype , or CellTypeAnnotation.envs.hitype_db if you are using hitype . Again, the markers in the database should exist (be in the same format) in the features.tsv file or the h5 file. See CellTypeAnnotation for more details. Examples can be found here: ScTypeDB_short.xlsx and ScTypeDB_full.xlsx .","title":"Cell type database for cell type annotation by sctype or hitype"},{"location":"preparing-input/#model-for-cell-type-annotation-by-celltypist","text":"If you want to perform cell type annotation by celltypist , you need to provide a model file. The model file should be fed to CellTypeAnnotation.envs.celltypist_args.model . The information of models can be found here . Download the one you want to use and provide the path to the file.","title":"Model for cell type annotation by celltypist"},{"location":"preparing-input/#metabolic-pathway-for-metabolic-landscape-analysis","text":"Similarly, if you want to perform metabolic landscape analysis, you need to provide a file containing the metabolic pathways. The file should be in the GMT format . You can provide the file to ScMetabolicLandscape.envs.gmtfile . This file can also be used for GSEA. A pathway file for KEGG metabolism is provided here . See ScrnaMetabolicLandscape for more details.","title":"Metabolic pathway for Metabolic Landscape Analysis"},{"location":"preparing-input/#reference-for-seurat-mapping-if-you-want-to-perform-supervised-clustering","text":"If you want to perform supervised clustering, you need to provide a reference for SeuratMap2Ref . The reference should be a Seurat object in RDS or h5seurat file. You can provide the reference to SeuratMap2Ref.envs.ref . See SeuratMap2Ref for more details.","title":"Reference for Seurat mapping if you want to perform supervised clustering"},{"location":"running/","text":"Running the pipeline \u00b6 Run the pipeline locally via CLI \u00b6 Once the pipeline is installed, you can run it via CLI: $ immunopipe --help You can specify the options directly in the CLI. For example: $ immunopipe --forks 4 --TopExpressingGenes.envs.n 100 ... It's recommended to use a configuration file to specify all the options. For example: $ immunopipe @config.toml You can also use both ways together. The options specified in the CLI will override the ones in the configuration file. $ immunopipe @config.toml --forks 4 --TopExpressingGenes.envs.n 100 ... For configuration items, see configurations for more details. Tip If you want to run the pipeline on a cluster, see How to run the pipeline on a cluster? for more details. Attention For settings that determine the routes of the pipeline, you should define them in the configuration file. For example, if you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If you just pass the section as a command line argument ( --SeuratMap2Ref ), it will not trigger the corresponding processes. To indicator whether the scTCR-/scBCR-seq data is available or not, you also need to specify the sample information file in the configuration file [SampleInfo.in.infile] . Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger the corresponding processes. See Routes of the pipeline for more details. Run the pipeline via pipen-board \u00b6 pipen-board is a web-based dashboard for pipen . It provides a user-friendly interface to configure and run the pipeline. It also provides a way to monitor the running progress of the pipeline. pipen-board is installed by default with immunopipe . You can run it via CLI: $ pipen board immunopipe:Immunopipe * * __ __ __. . __ __ + __ __ * | __ )|| __ ) | _ | \\ | __ | __ ) / \\ / \\ | __ ) | \\ * | || | __ | \\| | __ ) \\_ _//-- \\| \\ | __/ * * version: 0 .11.1 * * Configure and run pipen pipelines from the web * * Serving Quart app 'pipen_board' * Environment: development * Debug mode: True * Running on http://0.0.0.0:18521 ( CTRL + C to quit ) [ 07 /31/23 21 :23:27 ] INFO Running on http://0.0.0.0:18521 ( CTRL + C to quit ) Then you can open the dashboard in your browser at http://localhost:18521 . In the Configuration tab, you can configure the pipeline and the processes. Then you can use the Generate Configuration button to generate the configuration file and then use the generated configuration file to run the pipeline via CLI. If you want to run the pipeline via pipen-board , you need an additional configuration file to tell pipen-board how to run the pipeline: $ pipen board immunopipe:Immunopipe -a gh:pwwang/immunopipe/board.toml@dev The additional file is available at immunopipe 's GitHub repo. You can also download it and modify it to fit your needs, but in most cases, you don't have to. With the additional file, you can find four running options , LOCAL , DOCKER , SINGULARITY and APPTAINER , on the left side of the Configuration tab. You can choose one of them to run the pipeline. Take LOCAL as an example. When clicking the Run the command button, a configuration file specified by configfile is saved and used to run the pipeline via CLI. Then the Previous Run tab is replaced by the Running tab to track the progress of the pipeline. Run the pipeline using docker image \u00b6 Choose the right tag of the docker image \u00b6 The docker image is tagged with the version of immunopipe , together with master and dev . They are listed here: https://hub.docker.com/repository/docker/justold/immunopipe/tags . dev is the latest development version of immunopipe . It may have unstable features. If you want to use a more stable version, please try master , or a specific semantic version. Any tags with a -full suffix are the full version of the image. It contains all the dependencies of the pipeline, especially keras and tensorflow that are required by the embedding procedure of TESSA . Those packages take quite a lot of the space of the image. If you don't need the TESSA process, you can use the minimal version of the image. Any tags without the -full suffix are the minimal version of the image. TESSA process is also NOT supported in the minimal version. keras and tensorflow are also NOT included in the image. Please also keep in mind that there is no GPU support with either type of the image. You can pull the images in advance using docker , singularity or apptainer . See help options of docker pull , singularity pull or apptainer pull for more details. You can also specify the tag when running the pipeline. See the following sections for more details. Using docker Using singularity Using apptainer To run the pipeline using the docker image with docker , you need to mount the current working directory to the /workdir directory in the container. You also need to specify the configuration file via @<configfile> option. For example: $ docker run \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using singularity . You also need to specify the configuration file via @<configfile> option. For example: $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using apptainer . You also need to specify the configuration file via @<configfile> option. For example: $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml Run the pipeline via pipen-board using docker image \u00b6 Using docker Using singularity Using apptainer You can also run the pipeline via pipen-board using the docker image with docker : $ docker run -p 18521 :18521 \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Note You should use LOCAL instead of DOCKER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the docker container. You can also run the pipeline via pipen-board using the docker image with singularity : $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Similarly, you should use LOCAL instead of SINGULARITY to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. You can also run the pipeline via pipen-board using the docker image with apptainer : $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml Also similarly, you should use LOCAL instead of APPTAINER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. When the command is running, you will see the following message: Then, You can open the dashboard in your browser at http://localhost:18521 . Run the pipeline using Google Cloud Batch Jobs \u00b6 There are two ways to run the pipeline using Google Cloud Batch Jobs: Use the gbatch scheduler of pipen \u00b6 When using the gbatch , the metadata of the processes (job status, job output, etc) are managed locally. Even though they are on the cloud, they are manipuated locally (using the API provided by cloudpathlib ). The processes are submitted to Google Cloud Batch Jobs using gcloud batch jobs submit . And the processes are run on Google Cloud Compute Engine VMs, and they need to be sumbitted one after another. See the documentation of cloud support of pipen . Use pipen-cli-gbatch \u00b6 You need install the dependencies via pip install -U immunopipe[cli-gbatch] to use this feature. immunopipe has integrated with pipen-cli-gbatch to provide a seamless way to run the pipeline using Google Cloud Batch Jobs. The entire pipeline is wrapped (like it is running locally) and submitted as a single job to Google Cloud Batch Jobs. You just need to run the following: > immunopipe gbatch @config.toml To provide the scheduler options to run the wrapped job (daemon) on Google Cloud Batch Jobs, you can specify them by --gbatch.machine-type , --gbatch.provisioning-model , --gbatch.disk-size-gb , etc. See the help message of immunopipe gbatch --help for more details. > immunopipe gbatch --help # pipeline options Options For Pipen-cli-gbatch ( extra Options ) : --gbatch.profile PROFILE Use the ` scheduler_opts ` as the Scheduler Options of a given profile from pipen configuration files, including ~/.pipen.toml and ./pipen.toml. Note that if not provided, nothing will be loaded from the configuration files. --gbatch.loglevel { DEBUG,INFO,WARNING,ERROR,CRITICAL,debug,info,warning,error,critical } Set the logging level for the daemon process. [ default: INFO ] --gbatch.error-strategy { retry,halt } The strategy when there is error happened [ default: halt ] --gbatch.num-retries NUM_RETRIES The number of retries when there is error happened. Only valid when --error-strategy is 'retry' . [ default: 0 ] --gbatch.prescript PRESCRIPT The prescript to run before the main command. --gbatch.postscript POSTSCRIPT The postscript to run after the main command. --gbatch.recheck-interval RECHECK_INTERVAL The interval to recheck the job status, each takes about 0 .1 seconds. [ default: 600 ] --gbatch.cwd CWD The working directory to run the command. If not provided, the current directory is used. You can pass either a mounted path ( inside the VM ) or a Google Storage Bucket path ( gs://... ) . If a Google Storage Bucket path is provided, the mounted path will be inferred from the mounted paths of the VM. --gbatch.project PROJECT The Google Cloud project to run the job. --gbatch.location LOCATION The location to run the job. --gbatch.mount MOUNT The list of mounts to mount to the VM, each in the format of SOURCE:TARGET, where SOURCE must be either a Google Storage Bucket path ( gs://... ) . You can also use named mounts like ` INDIR = gs://my-bucket/inputs ` and the directory will be mounted to ` /mnt/disks/INDIR ` in the VM ; then you can use environment variable ` $INDIR ` in the command/script to refer to the mounted path. You can also mount a file like ` INFILE = gs://my-bucket/inputs/file.txt ` . The parent directory will be mounted to ` /mnt/disks/INFILE/inputs ` in the VM, and the file will be available at ` /mnt/disks/INFILE/inputs/file.txt ` in the VM. ` $INFILE ` can also be used in the command/script to refer to the mounted path. [ default: []] --gbatch.mount-as-cwd MOUNT_AS_CWD The directory to mount as the current working directory of the command. This is a shortcut for ` --mount <cloudpath>:/mnt/disks/.cwd --cwd /mnt/disks/.cwd ` . The <cloudpath> must be a Google Storage Bucket path ( gs://... ) . When this option is used, and ` --workdir ` is not provided, the workdir will be set to ` <cloudpath>/.pipen/<command_name> ` , where <command_name> is the name of the command ( or the value of ` --name ` if provided ) . --gbatch.service-account SERVICE_ACCOUNT The service account to run the job. --gbatch.network NETWORK The network to run the job. --gbatch.subnetwork SUBNETWORK The subnetwork to run the job. --gbatch.no-external-ip-address Whether to disable external IP address for the VM. --gbatch.machine-type MACHINE_TYPE The machine type of the VM. --gbatch.provisioning-model { STANDARD,SPOT } The provisioning model of the VM. --gbatch.image-uri IMAGE_URI The custom image URI of the VM. --gbatch.runnables RUNNABLES The JSON string of extra settings of runnables add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Runnable for details. You can have an extra key 'order' for each runnable, where negative values mean to run before the main command, and positive values mean to run after the main command. --gbatch.allocationPolicy ALLOCATIONPOLICY The JSON string of extra settings of allocationPolicy add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#AllocationPolicy for details. [ default: {}] --gbatch.taskGroups TASKGROUPS The JSON string of extra settings of taskGroups add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#TaskGroup for details. [ default: []] --gbatch.labels LABELS The strings of labels to add to the job ( key = value ) . Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Job.FIELDS.labels for details. [ default: []] --gbatch.gcloud GCLOUD The path to the gcloud command. [ default: gcloud ] When --gbatch.profile is provided, the default scheduler options will be used from ~/.pipen.toml and ./pipen.toml . For example, you can add the following to ~/.pipen.toml : [gbatch.scheduler_opts] project = \"my-project\" location = \"us-central1\" Then you can run the pipeline using the following command: > immunopipe gbatch @config.toml --gbatch.profile gbatch To use the default project and location . You can also specify these options directly in the command line or under a section cli-gbatch in the configuration file. The options specified in the command line will override the ones in the configuration file, which will override the ones in the profile. For example, you may have the following in config.toml : name = \"Immunopipe\" workdir = \"gs://my-bucket/immunopipe_workdir\" outdir = \"gs://my-bucket/immunopipe_outdir\" [cli-gbatch] project = \"my-project\" location = \"us-central1\" machine-type = \"n2d-standard-4\" provisioning-model = \"SPOT\" ... There are other actions you can do with gbatch : immunopipe gbatch @config.toml --nowait : submit the job and exit without waiting for the job to finish. immunopipe gbatch @config.toml --view-logs : view the logs of the job for the detached job. immunopipe gbatch @config.toml --version : show the version of immunopipe , pipen-cli-gbatch and pipen . Here is a diagram showing the difference between using the gbatch scheduler and using pipen-cli-gbatch : Use Google Cloud Batch Jobs directly (not recommended) \u00b6 You can also run the pipeline using Google Cloud Batch Jobs directly. In this case, you need to create a job definition file and submit the job using gcloud batch jobs submit . The job definition file should specify the container image, the command to run the pipeline, and the resources required for the job. Here is an example of a job definition file ( job.json ): { \"allocationPolicy\" : { \"serviceAccount\" : { \"email\" : \"...\" }, \"network\" : \"...\" , \"instances\" : [ { \"policy\" : { \"machineType\" : \"n2d-standard-4\" , \"provisioningModel\" : \"SPOT\" } } ] }, \"taskGroups\" : [ { \"taskSpec\" : { \"runnables\" : [ { \"container\" : { \"image_uri\" : \"docker.io/justold/immunopipe:dev\" , \"entrypoint\" : \"/usr/local/bin/_entrypoint.sh\" , \"commands\" : [ \"immunopipe\" , \"@/mnt/disks/workdir/Immunopipe.config.toml\" ] } } ], \"volumes\" : [ { \"gcs\" : { \"remotePath\" : \"<bucket>/path/to/workdir\" }, \"mountPath\" : \"/mnt/disks/workdir\" } ] } } ], \"logsPolicy\" : { \"destination\" : \"CLOUD_LOGGING\" }, \"labels\" : \"...\" } Then you can submit the job using the following command: $ gcloud batch jobs submit <job-name> --location <location> --project <project-id> --config job.json","title":"Running the pipeline"},{"location":"running/#running-the-pipeline","text":"","title":"Running the pipeline"},{"location":"running/#run-the-pipeline-locally-via-cli","text":"Once the pipeline is installed, you can run it via CLI: $ immunopipe --help You can specify the options directly in the CLI. For example: $ immunopipe --forks 4 --TopExpressingGenes.envs.n 100 ... It's recommended to use a configuration file to specify all the options. For example: $ immunopipe @config.toml You can also use both ways together. The options specified in the CLI will override the ones in the configuration file. $ immunopipe @config.toml --forks 4 --TopExpressingGenes.envs.n 100 ... For configuration items, see configurations for more details. Tip If you want to run the pipeline on a cluster, see How to run the pipeline on a cluster? for more details. Attention For settings that determine the routes of the pipeline, you should define them in the configuration file. For example, if you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If you just pass the section as a command line argument ( --SeuratMap2Ref ), it will not trigger the corresponding processes. To indicator whether the scTCR-/scBCR-seq data is available or not, you also need to specify the sample information file in the configuration file [SampleInfo.in.infile] . Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger the corresponding processes. See Routes of the pipeline for more details.","title":"Run the pipeline locally via CLI"},{"location":"running/#run-the-pipeline-via-pipen-board","text":"pipen-board is a web-based dashboard for pipen . It provides a user-friendly interface to configure and run the pipeline. It also provides a way to monitor the running progress of the pipeline. pipen-board is installed by default with immunopipe . You can run it via CLI: $ pipen board immunopipe:Immunopipe * * __ __ __. . __ __ + __ __ * | __ )|| __ ) | _ | \\ | __ | __ ) / \\ / \\ | __ ) | \\ * | || | __ | \\| | __ ) \\_ _//-- \\| \\ | __/ * * version: 0 .11.1 * * Configure and run pipen pipelines from the web * * Serving Quart app 'pipen_board' * Environment: development * Debug mode: True * Running on http://0.0.0.0:18521 ( CTRL + C to quit ) [ 07 /31/23 21 :23:27 ] INFO Running on http://0.0.0.0:18521 ( CTRL + C to quit ) Then you can open the dashboard in your browser at http://localhost:18521 . In the Configuration tab, you can configure the pipeline and the processes. Then you can use the Generate Configuration button to generate the configuration file and then use the generated configuration file to run the pipeline via CLI. If you want to run the pipeline via pipen-board , you need an additional configuration file to tell pipen-board how to run the pipeline: $ pipen board immunopipe:Immunopipe -a gh:pwwang/immunopipe/board.toml@dev The additional file is available at immunopipe 's GitHub repo. You can also download it and modify it to fit your needs, but in most cases, you don't have to. With the additional file, you can find four running options , LOCAL , DOCKER , SINGULARITY and APPTAINER , on the left side of the Configuration tab. You can choose one of them to run the pipeline. Take LOCAL as an example. When clicking the Run the command button, a configuration file specified by configfile is saved and used to run the pipeline via CLI. Then the Previous Run tab is replaced by the Running tab to track the progress of the pipeline.","title":"Run the pipeline via pipen-board"},{"location":"running/#run-the-pipeline-using-docker-image","text":"","title":"Run the pipeline using docker image"},{"location":"running/#choose-the-right-tag-of-the-docker-image","text":"The docker image is tagged with the version of immunopipe , together with master and dev . They are listed here: https://hub.docker.com/repository/docker/justold/immunopipe/tags . dev is the latest development version of immunopipe . It may have unstable features. If you want to use a more stable version, please try master , or a specific semantic version. Any tags with a -full suffix are the full version of the image. It contains all the dependencies of the pipeline, especially keras and tensorflow that are required by the embedding procedure of TESSA . Those packages take quite a lot of the space of the image. If you don't need the TESSA process, you can use the minimal version of the image. Any tags without the -full suffix are the minimal version of the image. TESSA process is also NOT supported in the minimal version. keras and tensorflow are also NOT included in the image. Please also keep in mind that there is no GPU support with either type of the image. You can pull the images in advance using docker , singularity or apptainer . See help options of docker pull , singularity pull or apptainer pull for more details. You can also specify the tag when running the pipeline. See the following sections for more details. Using docker Using singularity Using apptainer To run the pipeline using the docker image with docker , you need to mount the current working directory to the /workdir directory in the container. You also need to specify the configuration file via @<configfile> option. For example: $ docker run \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using singularity . You also need to specify the configuration file via @<configfile> option. For example: $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using apptainer . You also need to specify the configuration file via @<configfile> option. For example: $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml","title":"Choose the right tag of the docker image"},{"location":"running/#run-the-pipeline-via-pipen-board-using-docker-image","text":"Using docker Using singularity Using apptainer You can also run the pipeline via pipen-board using the docker image with docker : $ docker run -p 18521 :18521 \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Note You should use LOCAL instead of DOCKER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the docker container. You can also run the pipeline via pipen-board using the docker image with singularity : $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Similarly, you should use LOCAL instead of SINGULARITY to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. You can also run the pipeline via pipen-board using the docker image with apptainer : $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml Also similarly, you should use LOCAL instead of APPTAINER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. When the command is running, you will see the following message: Then, You can open the dashboard in your browser at http://localhost:18521 .","title":"Run the pipeline via pipen-board using docker image"},{"location":"running/#run-the-pipeline-using-google-cloud-batch-jobs","text":"There are two ways to run the pipeline using Google Cloud Batch Jobs:","title":"Run the pipeline using Google Cloud Batch Jobs"},{"location":"running/#use-the-gbatch-scheduler-of-pipen","text":"When using the gbatch , the metadata of the processes (job status, job output, etc) are managed locally. Even though they are on the cloud, they are manipuated locally (using the API provided by cloudpathlib ). The processes are submitted to Google Cloud Batch Jobs using gcloud batch jobs submit . And the processes are run on Google Cloud Compute Engine VMs, and they need to be sumbitted one after another. See the documentation of cloud support of pipen .","title":"Use the gbatch scheduler of pipen"},{"location":"running/#use-pipen-cli-gbatch","text":"You need install the dependencies via pip install -U immunopipe[cli-gbatch] to use this feature. immunopipe has integrated with pipen-cli-gbatch to provide a seamless way to run the pipeline using Google Cloud Batch Jobs. The entire pipeline is wrapped (like it is running locally) and submitted as a single job to Google Cloud Batch Jobs. You just need to run the following: > immunopipe gbatch @config.toml To provide the scheduler options to run the wrapped job (daemon) on Google Cloud Batch Jobs, you can specify them by --gbatch.machine-type , --gbatch.provisioning-model , --gbatch.disk-size-gb , etc. See the help message of immunopipe gbatch --help for more details. > immunopipe gbatch --help # pipeline options Options For Pipen-cli-gbatch ( extra Options ) : --gbatch.profile PROFILE Use the ` scheduler_opts ` as the Scheduler Options of a given profile from pipen configuration files, including ~/.pipen.toml and ./pipen.toml. Note that if not provided, nothing will be loaded from the configuration files. --gbatch.loglevel { DEBUG,INFO,WARNING,ERROR,CRITICAL,debug,info,warning,error,critical } Set the logging level for the daemon process. [ default: INFO ] --gbatch.error-strategy { retry,halt } The strategy when there is error happened [ default: halt ] --gbatch.num-retries NUM_RETRIES The number of retries when there is error happened. Only valid when --error-strategy is 'retry' . [ default: 0 ] --gbatch.prescript PRESCRIPT The prescript to run before the main command. --gbatch.postscript POSTSCRIPT The postscript to run after the main command. --gbatch.recheck-interval RECHECK_INTERVAL The interval to recheck the job status, each takes about 0 .1 seconds. [ default: 600 ] --gbatch.cwd CWD The working directory to run the command. If not provided, the current directory is used. You can pass either a mounted path ( inside the VM ) or a Google Storage Bucket path ( gs://... ) . If a Google Storage Bucket path is provided, the mounted path will be inferred from the mounted paths of the VM. --gbatch.project PROJECT The Google Cloud project to run the job. --gbatch.location LOCATION The location to run the job. --gbatch.mount MOUNT The list of mounts to mount to the VM, each in the format of SOURCE:TARGET, where SOURCE must be either a Google Storage Bucket path ( gs://... ) . You can also use named mounts like ` INDIR = gs://my-bucket/inputs ` and the directory will be mounted to ` /mnt/disks/INDIR ` in the VM ; then you can use environment variable ` $INDIR ` in the command/script to refer to the mounted path. You can also mount a file like ` INFILE = gs://my-bucket/inputs/file.txt ` . The parent directory will be mounted to ` /mnt/disks/INFILE/inputs ` in the VM, and the file will be available at ` /mnt/disks/INFILE/inputs/file.txt ` in the VM. ` $INFILE ` can also be used in the command/script to refer to the mounted path. [ default: []] --gbatch.mount-as-cwd MOUNT_AS_CWD The directory to mount as the current working directory of the command. This is a shortcut for ` --mount <cloudpath>:/mnt/disks/.cwd --cwd /mnt/disks/.cwd ` . The <cloudpath> must be a Google Storage Bucket path ( gs://... ) . When this option is used, and ` --workdir ` is not provided, the workdir will be set to ` <cloudpath>/.pipen/<command_name> ` , where <command_name> is the name of the command ( or the value of ` --name ` if provided ) . --gbatch.service-account SERVICE_ACCOUNT The service account to run the job. --gbatch.network NETWORK The network to run the job. --gbatch.subnetwork SUBNETWORK The subnetwork to run the job. --gbatch.no-external-ip-address Whether to disable external IP address for the VM. --gbatch.machine-type MACHINE_TYPE The machine type of the VM. --gbatch.provisioning-model { STANDARD,SPOT } The provisioning model of the VM. --gbatch.image-uri IMAGE_URI The custom image URI of the VM. --gbatch.runnables RUNNABLES The JSON string of extra settings of runnables add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Runnable for details. You can have an extra key 'order' for each runnable, where negative values mean to run before the main command, and positive values mean to run after the main command. --gbatch.allocationPolicy ALLOCATIONPOLICY The JSON string of extra settings of allocationPolicy add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#AllocationPolicy for details. [ default: {}] --gbatch.taskGroups TASKGROUPS The JSON string of extra settings of taskGroups add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#TaskGroup for details. [ default: []] --gbatch.labels LABELS The strings of labels to add to the job ( key = value ) . Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Job.FIELDS.labels for details. [ default: []] --gbatch.gcloud GCLOUD The path to the gcloud command. [ default: gcloud ] When --gbatch.profile is provided, the default scheduler options will be used from ~/.pipen.toml and ./pipen.toml . For example, you can add the following to ~/.pipen.toml : [gbatch.scheduler_opts] project = \"my-project\" location = \"us-central1\" Then you can run the pipeline using the following command: > immunopipe gbatch @config.toml --gbatch.profile gbatch To use the default project and location . You can also specify these options directly in the command line or under a section cli-gbatch in the configuration file. The options specified in the command line will override the ones in the configuration file, which will override the ones in the profile. For example, you may have the following in config.toml : name = \"Immunopipe\" workdir = \"gs://my-bucket/immunopipe_workdir\" outdir = \"gs://my-bucket/immunopipe_outdir\" [cli-gbatch] project = \"my-project\" location = \"us-central1\" machine-type = \"n2d-standard-4\" provisioning-model = \"SPOT\" ... There are other actions you can do with gbatch : immunopipe gbatch @config.toml --nowait : submit the job and exit without waiting for the job to finish. immunopipe gbatch @config.toml --view-logs : view the logs of the job for the detached job. immunopipe gbatch @config.toml --version : show the version of immunopipe , pipen-cli-gbatch and pipen . Here is a diagram showing the difference between using the gbatch scheduler and using pipen-cli-gbatch :","title":"Use pipen-cli-gbatch"},{"location":"running/#use-google-cloud-batch-jobs-directly-not-recommended","text":"You can also run the pipeline using Google Cloud Batch Jobs directly. In this case, you need to create a job definition file and submit the job using gcloud batch jobs submit . The job definition file should specify the container image, the command to run the pipeline, and the resources required for the job. Here is an example of a job definition file ( job.json ): { \"allocationPolicy\" : { \"serviceAccount\" : { \"email\" : \"...\" }, \"network\" : \"...\" , \"instances\" : [ { \"policy\" : { \"machineType\" : \"n2d-standard-4\" , \"provisioningModel\" : \"SPOT\" } } ] }, \"taskGroups\" : [ { \"taskSpec\" : { \"runnables\" : [ { \"container\" : { \"image_uri\" : \"docker.io/justold/immunopipe:dev\" , \"entrypoint\" : \"/usr/local/bin/_entrypoint.sh\" , \"commands\" : [ \"immunopipe\" , \"@/mnt/disks/workdir/Immunopipe.config.toml\" ] } } ], \"volumes\" : [ { \"gcs\" : { \"remotePath\" : \"<bucket>/path/to/workdir\" }, \"mountPath\" : \"/mnt/disks/workdir\" } ] } } ], \"logsPolicy\" : { \"destination\" : \"CLOUD_LOGGING\" }, \"labels\" : \"...\" } Then you can submit the job using the following command: $ gcloud batch jobs submit <job-name> --location <location> --project <project-id> --config job.json","title":"Use Google Cloud Batch Jobs directly (not recommended)"},{"location":"processes/CDR3AAPhyschem/","text":"CDR3AAPhyschem \u00b6 CDR3 AA physicochemical feature analysis The idea is to perform a regression between two groups of cells (e.g. Treg vs Tconv) at different length of CDR3 AA sequences. The regression will be performed for each physicochemical feature of the AA (hydrophobicity, volume and isolectric point). Input \u00b6 scrfile : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains. Output \u00b6 outdir : Default: {{in.immdata | stem}}.cdr3aaphyschem . The output directory Environment Variables \u00b6 group : The key of group in metadata to define the groups to compare. For example, CellType , which has cell types annotated for each cell in the combined object (immdata + Seurat metadata) comparison ( type=auto ) : A dict of two groups, with keys as the group names and values as the group labels. For example, Treg = [ \"CD4 CTL\" , \"CD4 Naive\" , \"CD4 TCM\" , \"CD4 TEM\" ] Tconv = \"Tconv\" Or simply a list of two groups, for example, [\"Treg\", \"Tconv\"] when they are both in the group column. target : Which group to use as the target group. The target group will be labeled as 1, and the other group will be labeled as 0 in the regression. If not specified, the first group in comparison will be used as the target group. each ( auto ) : A column, or a list of columns or a string of columns separated by comma. The columns will be used to split the data into multiple groups and the regression will be applied to each group separately. If not provided, all the cells will be used. Reference \u00b6 Stadinski, Brian D., et al. \"Hydrophobic CDR3 residues promote the development of self-reactive T cells.\" Nature immunology 17.8 (2016): 946-955. Lagattuta, Kaitlyn A., et al. \"Repertoire analyses reveal T cell antigen receptor sequence features that influence T cell fate.\" Nature immunology 23.3 (2022): 446-457. Wimley, W. C. & White, S. H. Experimentally determined hydrophobicity scale for proteins at membrane - interfaces. Nat. Struct. Biol. 3, 842-848 (1996). Handbook of chemistry & physics 72nd edition. (CRC Press, 1991). Zamyatnin, A. A. Protein volume in solution. Prog. Biophys. Mol. Biol. 24, 107-123 (1972).","title":"CDR3AAPhyschem"},{"location":"processes/CDR3AAPhyschem/#cdr3aaphyschem","text":"CDR3 AA physicochemical feature analysis The idea is to perform a regression between two groups of cells (e.g. Treg vs Tconv) at different length of CDR3 AA sequences. The regression will be performed for each physicochemical feature of the AA (hydrophobicity, volume and isolectric point).","title":"CDR3AAPhyschem"},{"location":"processes/CDR3AAPhyschem/#input","text":"scrfile : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains.","title":"Input"},{"location":"processes/CDR3AAPhyschem/#output","text":"outdir : Default: {{in.immdata | stem}}.cdr3aaphyschem . The output directory","title":"Output"},{"location":"processes/CDR3AAPhyschem/#environment-variables","text":"group : The key of group in metadata to define the groups to compare. For example, CellType , which has cell types annotated for each cell in the combined object (immdata + Seurat metadata) comparison ( type=auto ) : A dict of two groups, with keys as the group names and values as the group labels. For example, Treg = [ \"CD4 CTL\" , \"CD4 Naive\" , \"CD4 TCM\" , \"CD4 TEM\" ] Tconv = \"Tconv\" Or simply a list of two groups, for example, [\"Treg\", \"Tconv\"] when they are both in the group column. target : Which group to use as the target group. The target group will be labeled as 1, and the other group will be labeled as 0 in the regression. If not specified, the first group in comparison will be used as the target group. each ( auto ) : A column, or a list of columns or a string of columns separated by comma. The columns will be used to split the data into multiple groups and the regression will be applied to each group separately. If not provided, all the cells will be used.","title":"Environment Variables"},{"location":"processes/CDR3AAPhyschem/#reference","text":"Stadinski, Brian D., et al. \"Hydrophobic CDR3 residues promote the development of self-reactive T cells.\" Nature immunology 17.8 (2016): 946-955. Lagattuta, Kaitlyn A., et al. \"Repertoire analyses reveal T cell antigen receptor sequence features that influence T cell fate.\" Nature immunology 23.3 (2022): 446-457. Wimley, W. C. & White, S. H. Experimentally determined hydrophobicity scale for proteins at membrane - interfaces. Nat. Struct. Biol. 3, 842-848 (1996). Handbook of chemistry & physics 72nd edition. (CRC Press, 1991). Zamyatnin, A. A. Protein volume in solution. Prog. Biophys. Mol. Biol. 24, 107-123 (1972).","title":"Reference"},{"location":"processes/CellCellCommunication/","text":"CellCellCommunication \u00b6 Cell-cell communication inference This is implemented based on LIANA , which is a Python package for cell-cell communication inference and provides a list of existing methods including CellPhoneDB , Connectome , log2FC, NATMI , SingleCellSignalR , Rank_Aggregate, Geometric Mean, scSeqComm , and CellChat . You can also try python -c 'import liana; liana.mt.show_methods()' to see the methods available. Note that this process does not do any visualization. You can use CellCellCommunicationPlots to visualize the results. Input \u00b6 sobjfile : The seurat object file in RDS or h5seurat format or AnnData file. Output \u00b6 outfile : Default: {{in.sobjfile | stem}}-ccc.txt . The output file with the 'liana_res' data frame. Stats are provided for both ligand and receptor entities, more specifically: ligand and receptor are the two entities that potentially interact. As a reminder, CCC events are not limited to secreted signalling, but we refer to them as ligand and receptor for simplicity. Also, in the case of heteromeric complexes, the ligand and receptor columns represent the subunit with minimum expression, while * complex corresponds to the actual complex, with subunits being separated by . source and target columns represent the source/sender and target/receiver cell identity for each interaction, respectively *_props : represents the proportion of cells that express the entity. By default, any interactions in which either entity is not expressed in above 10%% of cells per cell type is considered as a false positive, under the assumption that since CCC occurs between cell types, a sufficient proportion of cells within should express the genes. *_means : entity expression mean per cell type. lr_means : mean ligand-receptor expression, as a measure of ligand-receptor interaction magnitude. cellphone_pvals : permutation-based p-values, as a measure of interaction specificity. Environment Variables \u00b6 method ( choice ) : Default: cellchat . The method to use for cell-cell communication inference. CellPhoneDB : Use CellPhoneDB method. Magnitude Score: lr_means; Specificity Score: cellphone_pvals. Connectome : Use Connectome method. log2FC : Use log2FC method. NATMI : Use NATMI method. SingleCellSignalR : Use SingleCellSignalR method. Rank_Aggregate : Use Rank_Aggregate method. Geometric_Mean : Use Geometric Mean method. scSeqComm : Use scSeqComm method. CellChat : Use CellChat method. cellphonedb : alias for CellPhoneDB connectome : alias for Connectome log2fc : alias for log2FC natmi : alias for NATMI singlesignaler : alias for SingleCellSignalR rank_aggregate : alias for Rank_Aggregate geometric_mean : alias for Geometric_Mean scseqcomm : alias for scSeqComm cellchat : alias for CellChat subset : An expression in string to subset the cells. When a .rds or .h5seurat file is provided for in.sobjfile , you can provide an expression in R , which will be passed to base::subset() in R to subset the cells. But you can always pass an expression in python to subset the cells. See https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html#subsetting-using-metadata . You should use adata to refer to the AnnData object. For example, adata.obs.groups == \"g1\" will subset the cells with groups equal to g1 . subset_using : Default: auto . The method to subset the cells. auto : Automatically detect the method to use. Note that this is not always accurate. We simply check if [ is in the expression. If so, we use python to subset the cells; otherwise, we use R . python : Use python to subset the cells. r : Use R to subset the cells. split_by : The column name in metadata to split the cells to run the method separately. The results will be combined together with this column in the final output. assay : The assay to use for the analysis. Only works for Seurat object. seed ( type=int ) : Default: 1337 . The seed for the random number generator. ncores ( type=int ) : Default: 1 . The number of cores to use. groupby : Default: seurat_clusters . The column name in metadata to group the cells. Typically, this column should be the cluster id. species ( choice ) : Default: human . The species of the cells. human : Human cells, the 'consensus' resource will be used. mouse : Mouse cells, the 'mouseconsensus' resource will be used. expr_prop ( type=float ) : Default: 0.1 . Minimum expression proportion for the ligands and receptors (+ their subunits) in the corresponding cell identities. Set to 0 to return unfiltered results. min_cells ( type=int ) : Default: 5 . Minimum cells (per cell identity if grouped by groupby ) to be considered for downstream analysis. n_perms ( type=int ) : Default: 1000 . Number of permutations for the permutation test. Relevant only for permutation-based methods (e.g., CellPhoneDB ). If 0 is passed, no permutation testing is performed. rscript : Default: Rscript . The path to the Rscript executable used to convert RDS file to AnnData. if in.sobjfile is an RDS file, it will be converted to AnnData file (h5ad). You need Seurat , SeuratDisk and digest installed. <more> : Other arguments for the method. The arguments are passed to the method directly. See the method documentation for more details and also help(liana.mt.<method>.__call__) in Python. Reference \u00b6 Review . LIANA .","title":"CellCellCommunication"},{"location":"processes/CellCellCommunication/#cellcellcommunication","text":"Cell-cell communication inference This is implemented based on LIANA , which is a Python package for cell-cell communication inference and provides a list of existing methods including CellPhoneDB , Connectome , log2FC, NATMI , SingleCellSignalR , Rank_Aggregate, Geometric Mean, scSeqComm , and CellChat . You can also try python -c 'import liana; liana.mt.show_methods()' to see the methods available. Note that this process does not do any visualization. You can use CellCellCommunicationPlots to visualize the results.","title":"CellCellCommunication"},{"location":"processes/CellCellCommunication/#input","text":"sobjfile : The seurat object file in RDS or h5seurat format or AnnData file.","title":"Input"},{"location":"processes/CellCellCommunication/#output","text":"outfile : Default: {{in.sobjfile | stem}}-ccc.txt . The output file with the 'liana_res' data frame. Stats are provided for both ligand and receptor entities, more specifically: ligand and receptor are the two entities that potentially interact. As a reminder, CCC events are not limited to secreted signalling, but we refer to them as ligand and receptor for simplicity. Also, in the case of heteromeric complexes, the ligand and receptor columns represent the subunit with minimum expression, while * complex corresponds to the actual complex, with subunits being separated by . source and target columns represent the source/sender and target/receiver cell identity for each interaction, respectively *_props : represents the proportion of cells that express the entity. By default, any interactions in which either entity is not expressed in above 10%% of cells per cell type is considered as a false positive, under the assumption that since CCC occurs between cell types, a sufficient proportion of cells within should express the genes. *_means : entity expression mean per cell type. lr_means : mean ligand-receptor expression, as a measure of ligand-receptor interaction magnitude. cellphone_pvals : permutation-based p-values, as a measure of interaction specificity.","title":"Output"},{"location":"processes/CellCellCommunication/#environment-variables","text":"method ( choice ) : Default: cellchat . The method to use for cell-cell communication inference. CellPhoneDB : Use CellPhoneDB method. Magnitude Score: lr_means; Specificity Score: cellphone_pvals. Connectome : Use Connectome method. log2FC : Use log2FC method. NATMI : Use NATMI method. SingleCellSignalR : Use SingleCellSignalR method. Rank_Aggregate : Use Rank_Aggregate method. Geometric_Mean : Use Geometric Mean method. scSeqComm : Use scSeqComm method. CellChat : Use CellChat method. cellphonedb : alias for CellPhoneDB connectome : alias for Connectome log2fc : alias for log2FC natmi : alias for NATMI singlesignaler : alias for SingleCellSignalR rank_aggregate : alias for Rank_Aggregate geometric_mean : alias for Geometric_Mean scseqcomm : alias for scSeqComm cellchat : alias for CellChat subset : An expression in string to subset the cells. When a .rds or .h5seurat file is provided for in.sobjfile , you can provide an expression in R , which will be passed to base::subset() in R to subset the cells. But you can always pass an expression in python to subset the cells. See https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html#subsetting-using-metadata . You should use adata to refer to the AnnData object. For example, adata.obs.groups == \"g1\" will subset the cells with groups equal to g1 . subset_using : Default: auto . The method to subset the cells. auto : Automatically detect the method to use. Note that this is not always accurate. We simply check if [ is in the expression. If so, we use python to subset the cells; otherwise, we use R . python : Use python to subset the cells. r : Use R to subset the cells. split_by : The column name in metadata to split the cells to run the method separately. The results will be combined together with this column in the final output. assay : The assay to use for the analysis. Only works for Seurat object. seed ( type=int ) : Default: 1337 . The seed for the random number generator. ncores ( type=int ) : Default: 1 . The number of cores to use. groupby : Default: seurat_clusters . The column name in metadata to group the cells. Typically, this column should be the cluster id. species ( choice ) : Default: human . The species of the cells. human : Human cells, the 'consensus' resource will be used. mouse : Mouse cells, the 'mouseconsensus' resource will be used. expr_prop ( type=float ) : Default: 0.1 . Minimum expression proportion for the ligands and receptors (+ their subunits) in the corresponding cell identities. Set to 0 to return unfiltered results. min_cells ( type=int ) : Default: 5 . Minimum cells (per cell identity if grouped by groupby ) to be considered for downstream analysis. n_perms ( type=int ) : Default: 1000 . Number of permutations for the permutation test. Relevant only for permutation-based methods (e.g., CellPhoneDB ). If 0 is passed, no permutation testing is performed. rscript : Default: Rscript . The path to the Rscript executable used to convert RDS file to AnnData. if in.sobjfile is an RDS file, it will be converted to AnnData file (h5ad). You need Seurat , SeuratDisk and digest installed. <more> : Other arguments for the method. The arguments are passed to the method directly. See the method documentation for more details and also help(liana.mt.<method>.__call__) in Python.","title":"Environment Variables"},{"location":"processes/CellCellCommunication/#reference","text":"Review . LIANA .","title":"Reference"},{"location":"processes/CellCellCommunicationPlots/","text":"CellCellCommunicationPlots \u00b6 Visualization for cell-cell communication inference. Input \u00b6 cccfile : The output file from CellCellCommunication Output \u00b6 outdir : Default: {{in.cccfile | stem}}_plots . The output directory for the plots. Environment Variables \u00b6 subset : An expression to pass to dplyr::filter() to subset the ccc data. magnitude : The column name in the data to use as the magnitude of the communication. By default, the second last column will be used. See li.mt.show_methods() for the available methods in LIANA. or https://liana-py.readthedocs.io/en/latest/notebooks/basic_usage.html#Tileplot specificity : The column name in the data to use as the specificity of the communication. By default, the last column will be used. If the method doesn't have a specificity, set it to None. devpars ( ns ) : The parameters for the plot. res ( type=int ) : Default: 100 . The resolution of the plot height ( type=int ) : The height of the plot width ( type=int ) : The width of the plot more_formats ( type=list ) : Default: [] . The additional formats to save the plots. descr : Default: Cell-cell communication plot . The description of the plot. cases ( type=json ) : Default: {} . The cases for the plots. The keys are the names of the cases and the values are the arguments for the plots. The arguments include the ones inherited from envs . You can have a special plot_type \"table\" to generate a table for the ccc data to save as a text file and show in the report. If no cases are given, a default case will be used, with the key Cell-Cell Communication . <more> : Other arguments passed to scplotter::CCCPlot","title":"CellCellCommunicationPlots"},{"location":"processes/CellCellCommunicationPlots/#cellcellcommunicationplots","text":"Visualization for cell-cell communication inference.","title":"CellCellCommunicationPlots"},{"location":"processes/CellCellCommunicationPlots/#input","text":"cccfile : The output file from CellCellCommunication","title":"Input"},{"location":"processes/CellCellCommunicationPlots/#output","text":"outdir : Default: {{in.cccfile | stem}}_plots . The output directory for the plots.","title":"Output"},{"location":"processes/CellCellCommunicationPlots/#environment-variables","text":"subset : An expression to pass to dplyr::filter() to subset the ccc data. magnitude : The column name in the data to use as the magnitude of the communication. By default, the second last column will be used. See li.mt.show_methods() for the available methods in LIANA. or https://liana-py.readthedocs.io/en/latest/notebooks/basic_usage.html#Tileplot specificity : The column name in the data to use as the specificity of the communication. By default, the last column will be used. If the method doesn't have a specificity, set it to None. devpars ( ns ) : The parameters for the plot. res ( type=int ) : Default: 100 . The resolution of the plot height ( type=int ) : The height of the plot width ( type=int ) : The width of the plot more_formats ( type=list ) : Default: [] . The additional formats to save the plots. descr : Default: Cell-cell communication plot . The description of the plot. cases ( type=json ) : Default: {} . The cases for the plots. The keys are the names of the cases and the values are the arguments for the plots. The arguments include the ones inherited from envs . You can have a special plot_type \"table\" to generate a table for the ccc data to save as a text file and show in the report. If no cases are given, a default case will be used, with the key Cell-Cell Communication . <more> : Other arguments passed to scplotter::CCCPlot","title":"Environment Variables"},{"location":"processes/CellTypeAnnotation/","text":"CellTypeAnnotation \u00b6 Annotate all or selected T/B cell clusters. Annotate the cell clusters. Currently, four ways are supported: Pass the cell type annotation directly Use ScType Use scCATCH Use hitype The annotated cell types will replace the original seurat_clusters column in the metadata, so that the downstream processes will use the annotated cell types. The old seurat_clusters column will be renamed to seurat_clusters_id . If you are using ScType , scCATCH , or hitype , a text file containing the mapping from the old seurat_clusters to the new cell types will be generated and saved to cluster2celltype.tsv under <workdir>/<pipline_name>/CellTypeAnnotation/0/output/ . The <workdir> is typically ./.pipen and the <pipline_name> is Immunopipe by default. Note When supervised clustering SeuratMap2Ref is used, this process will be ignored. Note When cell types are annotated, the old seurat_clusters column will be renamed to seurat_clusters_id , and the new seurat_clusters column will be added. Input \u00b6 sobjfile : The single-cell object in RDS/qs/qs2/h5ad format. Output \u00b6 outfile : Default: {{in.sobjfile | stem}}.annotated.{{- ext0(in.sobjfile) if envs.outtype == 'input' else envs.outtype -}} . The rds/qs/qs2/h5ad file of seurat object with cell type annotated. A text file containing the mapping from the old seurat_clusters to the new cell types will be generated and saved to cluster2celltype.tsv under the job output directory. Environment Variables \u00b6 tool ( choice ) : Default: direct . The tool to use for cell type annotation. sctype : Use scType to annotate cell types. See https://github.com/IanevskiAleksandr/sc-type hitype : Use hitype to annotate cell types. See https://github.com/pwwang/hitype sccatch : Use scCATCH to annotate cell types. See https://github.com/ZJUFanLab/scCATCH celltypist : Use celltypist to annotate cell types. See https://github.com/Teichlab/celltypist direct : Directly assign cell types sctype_tissue : The tissue to use for sctype . Avaiable tissues should be the first column ( tissueType ) of sctype_db . If not specified, all rows in sctype_db will be used. sctype_db : The database to use for sctype. Check examples at https://github.com/IanevskiAleksandr/sc-type/blob/master/ScTypeDB_full.xlsx hitype_tissue : The tissue to use for hitype . Avaiable tissues should be the first column ( tissueType ) of hitype_db . If not specified, all rows in hitype_db will be used. hitype_db : The database to use for hitype. Compatible with sctype_db . See also https://pwwang.github.io/hitype/articles/prepare-gene-sets.html You can also use built-in databases, including hitypedb_short , hitypedb_full , and hitypedb_pbmc3k . cell_types ( list ) : Default: [] . The cell types to use for direct annotation. You can use \"-\" or \"\" as the placeholder for the clusters that you want to keep the original cell types ( seurat_clusters ). If the length of cell_types is shorter than the number of clusters, the remaining clusters will be kept as the original cell types. You can also use NA to remove the clusters from downstream analysis. This only works when envs.newcol is not specified. Note If tool is direct and cell_types is not specified or an empty list, the original cell types will be kept and nothing will be changed. more_cell_types ( type=json ) : The additional cell type annotations to add to the metadata. The keys are the new column names and the values are the cell types lists. The cell type lists work the same as cell_types above. This is useful when you want to keep multiple annotations of cell types. sccatch_args ( ns ) : The arguments for scCATCH::findmarkergene() if tool is sccatch . species : The specie of cells. cancer : Default: Normal . If the sample is from cancer tissue, then the cancer type may be defined. tissue : Tissue origin of cells must be defined. marker : The marker genes for cell type identification. if_use_custom_marker ( flag ) : Default: False . Whether to use custom marker genes. If True , no species , cancer , and tissue are needed. <more> : Other arguments for scCATCH::findmarkergene() . You can pass an RDS file to sccatch_args.marker to work as custom marker. If so, if_use_custom_marker will be set to TRUE automatically. celltypist_args ( ns ) : The arguments for celltypist::celltypist() if tool is celltypist . model : The path to model file. python : Default: python . The python path where celltypist is installed. majority_voting : Default: True . When true, it refines cell identities within local subclusters after an over-clustering approach at the cost of increased runtime. over_clustering ( type=auto ) : The column name in metadata to use as clusters for majority voting. Set to False to disable over-clustering. When in.sobjfile is rds/qs/qs2 (supposing we have a Seurat object), the default ident is used by default. Otherwise, it is False by default. assay : When converting a Seurat object to AnnData, the assay to use. If input is h5seurat, this defaults to RNA. If input is Seurat object in RDS, this defaults to the default assay. merge ( flag ) : Default: False . Whether to merge the clusters with the same cell types. Otherwise, a suffix will be added to the cell types (ie. .1 , .2 , etc). newcol : The new column name to store the cell types. If not specified, the seurat_clusters column will be overwritten. If specified, the original seurat_clusters column will be kept and Idents will be kept as the original seurat_clusters . outtype ( choice ) : Default: input . The output file type. Currently only works for celltypist . An RDS file will be generated for other tools. input : Use the same file type as the input. rds : Use RDS file. qs : Use qs2 file. qs2 : Use qs2 file. h5ad : Use AnnData file. Examples \u00b6 [CellTypeAnnotation.envs] tool = \"direct\" cell_types = [ \"CellType1\" , \"CellType2\" , \"-\" , \"CellType4\" ] The cell types will be assigned as: 0 -> CellType1 1 -> CellType2 2 -> 2 3 -> CellType4 Metadata \u00b6 When envs.tool is direct and envs.cell_types is empty, the metadata of the Seurat object will be kept as is. When envs.newcol is specified, the original seurat_clusters column will be kept is, and the annotated cell types will be saved in the new column. Otherwise, the original seurat_clusters column will be replaced by the annotated cell types and the original seurat_clusters column will be saved at seurat_clusters_id .","title":"CellTypeAnnotation"},{"location":"processes/CellTypeAnnotation/#celltypeannotation","text":"Annotate all or selected T/B cell clusters. Annotate the cell clusters. Currently, four ways are supported: Pass the cell type annotation directly Use ScType Use scCATCH Use hitype The annotated cell types will replace the original seurat_clusters column in the metadata, so that the downstream processes will use the annotated cell types. The old seurat_clusters column will be renamed to seurat_clusters_id . If you are using ScType , scCATCH , or hitype , a text file containing the mapping from the old seurat_clusters to the new cell types will be generated and saved to cluster2celltype.tsv under <workdir>/<pipline_name>/CellTypeAnnotation/0/output/ . The <workdir> is typically ./.pipen and the <pipline_name> is Immunopipe by default. Note When supervised clustering SeuratMap2Ref is used, this process will be ignored. Note When cell types are annotated, the old seurat_clusters column will be renamed to seurat_clusters_id , and the new seurat_clusters column will be added.","title":"CellTypeAnnotation"},{"location":"processes/CellTypeAnnotation/#input","text":"sobjfile : The single-cell object in RDS/qs/qs2/h5ad format.","title":"Input"},{"location":"processes/CellTypeAnnotation/#output","text":"outfile : Default: {{in.sobjfile | stem}}.annotated.{{- ext0(in.sobjfile) if envs.outtype == 'input' else envs.outtype -}} . The rds/qs/qs2/h5ad file of seurat object with cell type annotated. A text file containing the mapping from the old seurat_clusters to the new cell types will be generated and saved to cluster2celltype.tsv under the job output directory.","title":"Output"},{"location":"processes/CellTypeAnnotation/#environment-variables","text":"tool ( choice ) : Default: direct . The tool to use for cell type annotation. sctype : Use scType to annotate cell types. See https://github.com/IanevskiAleksandr/sc-type hitype : Use hitype to annotate cell types. See https://github.com/pwwang/hitype sccatch : Use scCATCH to annotate cell types. See https://github.com/ZJUFanLab/scCATCH celltypist : Use celltypist to annotate cell types. See https://github.com/Teichlab/celltypist direct : Directly assign cell types sctype_tissue : The tissue to use for sctype . Avaiable tissues should be the first column ( tissueType ) of sctype_db . If not specified, all rows in sctype_db will be used. sctype_db : The database to use for sctype. Check examples at https://github.com/IanevskiAleksandr/sc-type/blob/master/ScTypeDB_full.xlsx hitype_tissue : The tissue to use for hitype . Avaiable tissues should be the first column ( tissueType ) of hitype_db . If not specified, all rows in hitype_db will be used. hitype_db : The database to use for hitype. Compatible with sctype_db . See also https://pwwang.github.io/hitype/articles/prepare-gene-sets.html You can also use built-in databases, including hitypedb_short , hitypedb_full , and hitypedb_pbmc3k . cell_types ( list ) : Default: [] . The cell types to use for direct annotation. You can use \"-\" or \"\" as the placeholder for the clusters that you want to keep the original cell types ( seurat_clusters ). If the length of cell_types is shorter than the number of clusters, the remaining clusters will be kept as the original cell types. You can also use NA to remove the clusters from downstream analysis. This only works when envs.newcol is not specified. Note If tool is direct and cell_types is not specified or an empty list, the original cell types will be kept and nothing will be changed. more_cell_types ( type=json ) : The additional cell type annotations to add to the metadata. The keys are the new column names and the values are the cell types lists. The cell type lists work the same as cell_types above. This is useful when you want to keep multiple annotations of cell types. sccatch_args ( ns ) : The arguments for scCATCH::findmarkergene() if tool is sccatch . species : The specie of cells. cancer : Default: Normal . If the sample is from cancer tissue, then the cancer type may be defined. tissue : Tissue origin of cells must be defined. marker : The marker genes for cell type identification. if_use_custom_marker ( flag ) : Default: False . Whether to use custom marker genes. If True , no species , cancer , and tissue are needed. <more> : Other arguments for scCATCH::findmarkergene() . You can pass an RDS file to sccatch_args.marker to work as custom marker. If so, if_use_custom_marker will be set to TRUE automatically. celltypist_args ( ns ) : The arguments for celltypist::celltypist() if tool is celltypist . model : The path to model file. python : Default: python . The python path where celltypist is installed. majority_voting : Default: True . When true, it refines cell identities within local subclusters after an over-clustering approach at the cost of increased runtime. over_clustering ( type=auto ) : The column name in metadata to use as clusters for majority voting. Set to False to disable over-clustering. When in.sobjfile is rds/qs/qs2 (supposing we have a Seurat object), the default ident is used by default. Otherwise, it is False by default. assay : When converting a Seurat object to AnnData, the assay to use. If input is h5seurat, this defaults to RNA. If input is Seurat object in RDS, this defaults to the default assay. merge ( flag ) : Default: False . Whether to merge the clusters with the same cell types. Otherwise, a suffix will be added to the cell types (ie. .1 , .2 , etc). newcol : The new column name to store the cell types. If not specified, the seurat_clusters column will be overwritten. If specified, the original seurat_clusters column will be kept and Idents will be kept as the original seurat_clusters . outtype ( choice ) : Default: input . The output file type. Currently only works for celltypist . An RDS file will be generated for other tools. input : Use the same file type as the input. rds : Use RDS file. qs : Use qs2 file. qs2 : Use qs2 file. h5ad : Use AnnData file.","title":"Environment Variables"},{"location":"processes/CellTypeAnnotation/#examples","text":"[CellTypeAnnotation.envs] tool = \"direct\" cell_types = [ \"CellType1\" , \"CellType2\" , \"-\" , \"CellType4\" ] The cell types will be assigned as: 0 -> CellType1 1 -> CellType2 2 -> 2 3 -> CellType4","title":"Examples"},{"location":"processes/CellTypeAnnotation/#metadata","text":"When envs.tool is direct and envs.cell_types is empty, the metadata of the Seurat object will be kept as is. When envs.newcol is specified, the original seurat_clusters column will be kept is, and the annotated cell types will be saved in the new column. Otherwise, the original seurat_clusters column will be replaced by the annotated cell types and the original seurat_clusters column will be saved at seurat_clusters_id .","title":"Metadata"},{"location":"processes/ClonalStats/","text":"ClonalStats \u00b6 Visualize the clonal information. Using scplotter to visualize the clonal information. Input \u00b6 screpfile : The scRepertoire object in RDS/qs format Output \u00b6 outdir : Default: {{in.screpfile | stem}}.clonalstats . The output directory containing the plots Environment Variables \u00b6 mutaters ( type=json;order=-9 ) : Default: {} . The mutaters passed to dplyr::mutate() to add new variables. When the object loaded form in.screpfile is a list, the mutaters will be applied to each element. The keys are the names of the new variables, and the values are the expressions. When it is a Seurat object, typically an output of scRepertoire::combineExpression() , the mutaters will be applied to the meta.data . viz_type ( choice ) : The type of visualization to generate. volume : The volume of the clones using ClonalVolumePlot abundance : The abundance of the clones using ClonalAbundancePlot length : The length of the CDR3 sequences using ClonalLengthPlot residency : The residency of the clones using ClonalResidencyPlot dynamics : The dynamics of the clones using ClonalDynamicsPlot composition : The composition of the clones using ClonalCompositionPlot overlap : The overlap of the clones using ClonalOverlapPlot diversity : The diversity of the clones using ClonalDiversityPlot geneusage : The gene usage of the clones using ClonalGeneUsagePlot positional : The positional information of the clones using ClonalPositionalPlot kmer : The kmer information of the clones using ClonalKmerPlot rarefaction : The rarefaction curve of the clones using ClonalRarefactionPlot subset : An expression to subset the data before plotting. Similar to mutaters , it will be applied to each element by dplyr::filter() if the object loaded form in.screpfile is a list; otherwise, it will be applied to subset(sobj, subset = <expr>) if the object is a Seurat object. devpars ( ns ) : The parameters for the plotting device. width ( type=int ) : The width of the device height ( type=int ) : The height of the device res ( type=int ) : Default: 100 . The resolution of the device more_formats ( list ) : Default: [] . The extra formats to save the plots in, other than PNG. save_code ( flag ) : Default: False . Whether to save the code used to generate the plots Note that the data directly used to generate the plots will also be saved in an rda file. Be careful if the data is large as it may take a lot of disk space. descr : The description of the plot, used to show in the report. <more> : The arguments for the plot function See the documentation of the corresponding plot function for the details cases ( type=json ) : Default: {'Clonal Volume': Diot({'viz_type': 'volume'}), 'Clonal Abundance': Diot({'viz_type': 'abundance'}), 'CDR3 Length': Diot({'viz_type': 'length'}), 'Clonal Diversity': Diot({'viz_type': 'diversity'})} . The cases to generate the plots if we have multiple cases. The keys are the names of the cases, and the values are the arguments for the plot function. The arguments in envs will be used if not specified in cases , except for mutaters . Sections can be specified as the prefix of the case name, separated by :: . For example, if you have a case named Clonal Volume::Case1 , the plot will be put in the section Clonal Volume . By default, when there are multiple cases for the same 'viz_type', the name of the 'viz_type' will be used as the default section name (for example, when 'viz_type' is 'volume', the section name will be 'Clonal Volume'). When there is only a single case, the section name will default to 'DEFAULT', which will not be shown in the report.","title":"ClonalStats"},{"location":"processes/ClonalStats/#clonalstats","text":"Visualize the clonal information. Using scplotter to visualize the clonal information.","title":"ClonalStats"},{"location":"processes/ClonalStats/#input","text":"screpfile : The scRepertoire object in RDS/qs format","title":"Input"},{"location":"processes/ClonalStats/#output","text":"outdir : Default: {{in.screpfile | stem}}.clonalstats . The output directory containing the plots","title":"Output"},{"location":"processes/ClonalStats/#environment-variables","text":"mutaters ( type=json;order=-9 ) : Default: {} . The mutaters passed to dplyr::mutate() to add new variables. When the object loaded form in.screpfile is a list, the mutaters will be applied to each element. The keys are the names of the new variables, and the values are the expressions. When it is a Seurat object, typically an output of scRepertoire::combineExpression() , the mutaters will be applied to the meta.data . viz_type ( choice ) : The type of visualization to generate. volume : The volume of the clones using ClonalVolumePlot abundance : The abundance of the clones using ClonalAbundancePlot length : The length of the CDR3 sequences using ClonalLengthPlot residency : The residency of the clones using ClonalResidencyPlot dynamics : The dynamics of the clones using ClonalDynamicsPlot composition : The composition of the clones using ClonalCompositionPlot overlap : The overlap of the clones using ClonalOverlapPlot diversity : The diversity of the clones using ClonalDiversityPlot geneusage : The gene usage of the clones using ClonalGeneUsagePlot positional : The positional information of the clones using ClonalPositionalPlot kmer : The kmer information of the clones using ClonalKmerPlot rarefaction : The rarefaction curve of the clones using ClonalRarefactionPlot subset : An expression to subset the data before plotting. Similar to mutaters , it will be applied to each element by dplyr::filter() if the object loaded form in.screpfile is a list; otherwise, it will be applied to subset(sobj, subset = <expr>) if the object is a Seurat object. devpars ( ns ) : The parameters for the plotting device. width ( type=int ) : The width of the device height ( type=int ) : The height of the device res ( type=int ) : Default: 100 . The resolution of the device more_formats ( list ) : Default: [] . The extra formats to save the plots in, other than PNG. save_code ( flag ) : Default: False . Whether to save the code used to generate the plots Note that the data directly used to generate the plots will also be saved in an rda file. Be careful if the data is large as it may take a lot of disk space. descr : The description of the plot, used to show in the report. <more> : The arguments for the plot function See the documentation of the corresponding plot function for the details cases ( type=json ) : Default: {'Clonal Volume': Diot({'viz_type': 'volume'}), 'Clonal Abundance': Diot({'viz_type': 'abundance'}), 'CDR3 Length': Diot({'viz_type': 'length'}), 'Clonal Diversity': Diot({'viz_type': 'diversity'})} . The cases to generate the plots if we have multiple cases. The keys are the names of the cases, and the values are the arguments for the plot function. The arguments in envs will be used if not specified in cases , except for mutaters . Sections can be specified as the prefix of the case name, separated by :: . For example, if you have a case named Clonal Volume::Case1 , the plot will be put in the section Clonal Volume . By default, when there are multiple cases for the same 'viz_type', the name of the 'viz_type' will be used as the default section name (for example, when 'viz_type' is 'volume', the section name will be 'Clonal Volume'). When there is only a single case, the section name will default to 'DEFAULT', which will not be shown in the report.","title":"Environment Variables"},{"location":"processes/ClusterMarkers/","text":"ClusterMarkers \u00b6 Markers for clusters of all or selected T/B cells. This process is extended from MarkersFinder from the biopipen package. MarkersFinder is a pipen process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found. The enrichment analysis is done by enrichr . Note Since this process is extended from MarkersFinder , other environment variables from MarkersFinder are also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for marker finding (See MarkersFinder for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform . Output \u00b6 outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified.","title":"ClusterMarkers"},{"location":"processes/ClusterMarkers/#clustermarkers","text":"Markers for clusters of all or selected T/B cells. This process is extended from MarkersFinder from the biopipen package. MarkersFinder is a pipen process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found. The enrichment analysis is done by enrichr . Note Since this process is extended from MarkersFinder , other environment variables from MarkersFinder are also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for marker finding (See MarkersFinder for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly.","title":"ClusterMarkers"},{"location":"processes/ClusterMarkers/#input","text":"srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform .","title":"Input"},{"location":"processes/ClusterMarkers/#output","text":"outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots","title":"Output"},{"location":"processes/ClusterMarkers/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified.","title":"Environment Variables"},{"location":"processes/ClusterMarkersOfAllCells/","text":"ClusterMarkersOfAllCells \u00b6 Markers for clusters of all cells. See also ClusterMarkers . Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform . Output \u00b6 outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html group_by : The column name in metadata to group the cells. If only group_by is specified, and ident-1 and ident-2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified.","title":"ClusterMarkersOfAllCells"},{"location":"processes/ClusterMarkersOfAllCells/#clustermarkersofallcells","text":"Markers for clusters of all cells. See also ClusterMarkers .","title":"ClusterMarkersOfAllCells"},{"location":"processes/ClusterMarkersOfAllCells/#input","text":"srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform .","title":"Input"},{"location":"processes/ClusterMarkersOfAllCells/#output","text":"outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots","title":"Output"},{"location":"processes/ClusterMarkersOfAllCells/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html group_by : The column name in metadata to group the cells. If only group_by is specified, and ident-1 and ident-2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified.","title":"Environment Variables"},{"location":"processes/LoadingRNAFromSeurat/","text":"LoadingRNAFromSeurat \u00b6 Load RNA data from a Seurat object, instead of RNAData from SampleInfo Input \u00b6 infile : An RDS or qs2 format file containing a Seurat object. Output \u00b6 outfile : Default: {{in.infile | basename}} . Environment Variables \u00b6 prepared ( flag ) : Default: False . Whether the Seurat object is well-prepared for the pipeline (so that SeuratPreparing process is not needed). clustered ( flag ) : Default: False . Whether the Seurat object is clustered, so that SeuratClustering ( SeuratClusteringOfAllCells ) process or SeuratMap2Ref is not needed. Force prepared to be True if this is True . sample : Default: Sample . The column name in the metadata of the Seurat object that indicates the sample name.","title":"LoadingRNAFromSeurat"},{"location":"processes/LoadingRNAFromSeurat/#loadingrnafromseurat","text":"Load RNA data from a Seurat object, instead of RNAData from SampleInfo","title":"LoadingRNAFromSeurat"},{"location":"processes/LoadingRNAFromSeurat/#input","text":"infile : An RDS or qs2 format file containing a Seurat object.","title":"Input"},{"location":"processes/LoadingRNAFromSeurat/#output","text":"outfile : Default: {{in.infile | basename}} .","title":"Output"},{"location":"processes/LoadingRNAFromSeurat/#environment-variables","text":"prepared ( flag ) : Default: False . Whether the Seurat object is well-prepared for the pipeline (so that SeuratPreparing process is not needed). clustered ( flag ) : Default: False . Whether the Seurat object is clustered, so that SeuratClustering ( SeuratClusteringOfAllCells ) process or SeuratMap2Ref is not needed. Force prepared to be True if this is True . sample : Default: Sample . The column name in the metadata of the Seurat object that indicates the sample name.","title":"Environment Variables"},{"location":"processes/MarkersFinder/","text":"MarkersFinder \u00b6 Find markers between different groups of cells MarkersFinder is a process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform . Output \u00b6 outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html .. See also mutating the metadata . group_by : The column name in metadata to group the cells. If only group_by is specified, and ident-1 and ident-2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. ident_1 : The first group of cells to compare When this is empty, the comparisons will be expanded to each group v.s. the rest of the cells in group_by . ident_2 : The second group of cells to compare If not provided, the rest of the cells are used for ident-2 . each : The column name in metadata to separate the cells into different cases. When this is specified, the case will be expanded for each value of the column in metadata. For example, when you have envs.cases.\"Cluster Markers\".each = \"Sample\" , then the case will be expanded as envs.cases.\"Cluster Markers - Sample1\" , envs.cases.\"Cluster Markers - Sample2\" , etc. You can specify allmarker_plots and overlaps to plot the markers for all cases in the same plot and plot the overlaps of the markers between different cases by values in this column. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified. cases ( type=json ) : Default: {} . If you have multiple cases for marker discovery, you can specify them here. The keys are the names of the cases and the values are the above options. If some options are not specified, the default values specified above (under envs ) will be used. If no cases are specified, the default case will be added with the default values under envs with the name Marker Discovery . Examples \u00b6 The examples are for more general use of MarkersFinder , in order to demonstrate how the final cases are constructed. Suppose we have a metadata like this: id seurat_clusters Group 1 1 A 2 1 A 3 2 A 4 2 A 5 3 B 6 3 B 7 4 B 8 4 B Default \u00b6 By default, group_by is seurat_clusters , and ident_1 and ident_2 are not specified. So markers will be found for all clusters in the manner of \"cluster vs rest\" comparison. Cluster 1 (vs 2, 3, 4) 2 (vs 1, 3, 4) 3 (vs 1, 2, 4) 4 (vs 1, 2, 3) Each case will have the markers and the enrichment analysis for the markers as the results. With each group \u00b6 each is used to separate the cells into different cases. group_by is still seurat_clusters . [ < Proc > .envs] group_by = \"seurat_clusters\" each = \"Group\" A:Cluster 1 (vs 2) 2 (vs 1) B:Cluster 3 (vs 4) 4 (vs 3) With ident_1 only \u00b6 ident_1 is used to specify the first group of cells to compare. Then the rest of the cells in the case are used for ident_2 . [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" Cluster 1 (vs 2, 3, 4) With both ident_1 and ident_2 \u00b6 ident_1 and ident_2 are used to specify the two groups of cells to compare. [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" ident_2 = \"2\" Cluster 1 (vs 2) Multiple cases \u00b6 [ < Proc > .envs.cases] c1_vs_c2 = { ident_1 = \"1\" , ident_2 = \"2\" } c3_vs_c4 = { ident_1 = \"3\" , ident_2 = \"4\" } DEFAULT:c1_vs_c2 1 (vs 2) DEFAULT:c3_vs_c4 3 (vs 4) The DEFAULT section name will be ignored in the report. You can specify a section name other than DEFAULT for each case to group them in the report.","title":"MarkersFinder"},{"location":"processes/MarkersFinder/#markersfinder","text":"Find markers between different groups of cells MarkersFinder is a process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found.","title":"MarkersFinder"},{"location":"processes/MarkersFinder/#input","text":"srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform .","title":"Input"},{"location":"processes/MarkersFinder/#output","text":"outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots","title":"Output"},{"location":"processes/MarkersFinder/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html .. See also mutating the metadata . group_by : The column name in metadata to group the cells. If only group_by is specified, and ident-1 and ident-2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. ident_1 : The first group of cells to compare When this is empty, the comparisons will be expanded to each group v.s. the rest of the cells in group_by . ident_2 : The second group of cells to compare If not provided, the rest of the cells are used for ident-2 . each : The column name in metadata to separate the cells into different cases. When this is specified, the case will be expanded for each value of the column in metadata. For example, when you have envs.cases.\"Cluster Markers\".each = \"Sample\" , then the case will be expanded as envs.cases.\"Cluster Markers - Sample1\" , envs.cases.\"Cluster Markers - Sample2\" , etc. You can specify allmarker_plots and overlaps to plot the markers for all cases in the same plot and plot the overlaps of the markers between different cases by values in this column. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified. cases ( type=json ) : Default: {} . If you have multiple cases for marker discovery, you can specify them here. The keys are the names of the cases and the values are the above options. If some options are not specified, the default values specified above (under envs ) will be used. If no cases are specified, the default case will be added with the default values under envs with the name Marker Discovery .","title":"Environment Variables"},{"location":"processes/MarkersFinder/#examples","text":"The examples are for more general use of MarkersFinder , in order to demonstrate how the final cases are constructed. Suppose we have a metadata like this: id seurat_clusters Group 1 1 A 2 1 A 3 2 A 4 2 A 5 3 B 6 3 B 7 4 B 8 4 B","title":"Examples"},{"location":"processes/MarkersFinder/#default","text":"By default, group_by is seurat_clusters , and ident_1 and ident_2 are not specified. So markers will be found for all clusters in the manner of \"cluster vs rest\" comparison. Cluster 1 (vs 2, 3, 4) 2 (vs 1, 3, 4) 3 (vs 1, 2, 4) 4 (vs 1, 2, 3) Each case will have the markers and the enrichment analysis for the markers as the results.","title":"Default"},{"location":"processes/MarkersFinder/#with-each-group","text":"each is used to separate the cells into different cases. group_by is still seurat_clusters . [ < Proc > .envs] group_by = \"seurat_clusters\" each = \"Group\" A:Cluster 1 (vs 2) 2 (vs 1) B:Cluster 3 (vs 4) 4 (vs 3)","title":"With each group"},{"location":"processes/MarkersFinder/#with-ident_1-only","text":"ident_1 is used to specify the first group of cells to compare. Then the rest of the cells in the case are used for ident_2 . [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" Cluster 1 (vs 2, 3, 4)","title":"With ident_1 only"},{"location":"processes/MarkersFinder/#with-both-ident_1-and-ident_2","text":"ident_1 and ident_2 are used to specify the two groups of cells to compare. [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" ident_2 = \"2\" Cluster 1 (vs 2)","title":"With both ident_1 and ident_2"},{"location":"processes/MarkersFinder/#multiple-cases","text":"[ < Proc > .envs.cases] c1_vs_c2 = { ident_1 = \"1\" , ident_2 = \"2\" } c3_vs_c4 = { ident_1 = \"3\" , ident_2 = \"4\" } DEFAULT:c1_vs_c2 1 (vs 2) DEFAULT:c3_vs_c4 3 (vs 4) The DEFAULT section name will be ignored in the report. You can specify a section name other than DEFAULT for each case to group them in the report.","title":"Multiple cases"},{"location":"processes/MetabolicExprImputation/","text":"MetabolicExprImputation \u00b6 This process imputes the dropout values in scRNA-seq data. It takes the Seurat object as input and outputs the Seurat object with imputed expression data. You can turn off the imputation by setting the noimpute option of the process group to True . Input \u00b6 infile : The input file in RDS/qs format of Seurat object Output \u00b6 outfile : Default: {{in.infile | stem}}.imputed.qs . The output file in RDS format of Seurat object Note that with rmagic and alra, the original default assay will be renamed to RAW and the imputed RNA assay will be renamed to RNA and set as default assay. Environment Variables \u00b6 tool ( choice ) : Default: alra . Either alra, scimpute or rmagic alra : Use RunALRA() from Seurat scimpute : Use scImpute() from scimpute rmagic : Use magic() from Rmagic scimpute_args ( ns ) : The arguments for scimpute drop_thre ( type=float ) : Default: 0.5 . The dropout threshold kcluster ( type=int ) : Number of clusters to use ncores ( type=int ) : Default: 1 . Number of cores to use refgene : Default: \"\" . The reference gene file rmagic_args ( ns ) : The arguments for rmagic python : Default: python . The python path where magic-impute is installed. threshold ( type=float ) : Default: 0.5 . The threshold for magic imputation. Only the genes with dropout rates greater than this threshold (No. of cells with non-zero expression / total number of cells) will be imputed. alra_args ( type=json ) : Default: {} . The arguments for RunALRA() Reference \u00b6 Linderman, George C., Jun Zhao, and Yuval Kluger. \"Zero-preserving imputation of scRNA-seq data using low-rank approximation.\" BioRxiv (2018): 397588. Li, Wei Vivian, and Jingyi Jessica Li. \"An accurate and robust imputation method scImpute for single-cell RNA-seq data.\" Nature communications 9.1 (2018): 997. Dijk, David van, et al. \"MAGIC: A diffusion-based imputation method reveals gene-gene interactions in single-cell RNA-sequencing data.\" BioRxiv (2017): 111591.","title":"MetabolicExprImputation"},{"location":"processes/MetabolicExprImputation/#metabolicexprimputation","text":"This process imputes the dropout values in scRNA-seq data. It takes the Seurat object as input and outputs the Seurat object with imputed expression data. You can turn off the imputation by setting the noimpute option of the process group to True .","title":"MetabolicExprImputation"},{"location":"processes/MetabolicExprImputation/#input","text":"infile : The input file in RDS/qs format of Seurat object","title":"Input"},{"location":"processes/MetabolicExprImputation/#output","text":"outfile : Default: {{in.infile | stem}}.imputed.qs . The output file in RDS format of Seurat object Note that with rmagic and alra, the original default assay will be renamed to RAW and the imputed RNA assay will be renamed to RNA and set as default assay.","title":"Output"},{"location":"processes/MetabolicExprImputation/#environment-variables","text":"tool ( choice ) : Default: alra . Either alra, scimpute or rmagic alra : Use RunALRA() from Seurat scimpute : Use scImpute() from scimpute rmagic : Use magic() from Rmagic scimpute_args ( ns ) : The arguments for scimpute drop_thre ( type=float ) : Default: 0.5 . The dropout threshold kcluster ( type=int ) : Number of clusters to use ncores ( type=int ) : Default: 1 . Number of cores to use refgene : Default: \"\" . The reference gene file rmagic_args ( ns ) : The arguments for rmagic python : Default: python . The python path where magic-impute is installed. threshold ( type=float ) : Default: 0.5 . The threshold for magic imputation. Only the genes with dropout rates greater than this threshold (No. of cells with non-zero expression / total number of cells) will be imputed. alra_args ( type=json ) : Default: {} . The arguments for RunALRA()","title":"Environment Variables"},{"location":"processes/MetabolicExprImputation/#reference","text":"Linderman, George C., Jun Zhao, and Yuval Kluger. \"Zero-preserving imputation of scRNA-seq data using low-rank approximation.\" BioRxiv (2018): 397588. Li, Wei Vivian, and Jingyi Jessica Li. \"An accurate and robust imputation method scImpute for single-cell RNA-seq data.\" Nature communications 9.1 (2018): 997. Dijk, David van, et al. \"MAGIC: A diffusion-based imputation method reveals gene-gene interactions in single-cell RNA-sequencing data.\" BioRxiv (2017): 111591.","title":"Reference"},{"location":"processes/MetabolicFeatures/","text":"MetabolicFeatures \u00b6 This process performs enrichment analysis for the metabolic pathways for each group in each subset. The enrichment analysis is done with fgsea package or the GSEA_R package. Input \u00b6 sobjfile : The Seurat object file in rds. It should be loaded as a Seurat object Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pathwayfeatures . The output directory. It will contain the GSEA results and plots. Environment Variables \u00b6 ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization for the comparisons for each subset and group. Defaults to ScrnaMetabolicLandscape.ncores . prerank_method ( choice ) : Default: signal_to_noise . Method to use for gene preranking. Signal to noise: the larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \u201cclass marker.\u201d. Absolute signal to noise: the absolute value of the signal to noise. T test: Uses the difference of means scaled by the standard deviation and number of samples. Ratio of classes: Uses the ratio of class means to calculate fold change for natural scale data. Diff of classes: Uses the difference of class means to calculate fold change for nature scale data Log2 ratio of classes: Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. signal_to_noise : Signal to noise s2n : Alias of signal_to_noise abs_signal_to_noise : absolute signal to noise abs_s2n : Alias of abs_signal_to_noise t_test : T test ratio_of_classes : Also referred to as fold change diff_of_classes : Difference of class means log2_ratio_of_classes : Log2 ratio of class means gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by comparisons ( type=list ) : Default: [] . The comparison groups to use for the analysis. If not provided, each group in the group_by column will be used to compare with the other groups. If a single group is provided as an element, it will be used to compare with all the other groups. For example, if we have group_by = \"cluster\" and we have 1 , 2 and 3 in the group_by column, we could have comparisons = [\"1\", \"2\"] , which will compare the group 1 with groups 2 and 3 , and the group 2 with groups 1 and 3 . We could also have comparisons = [\"1:2\", \"1:3\"] , which will compare the group 1 with group 2 and group 1 with group 3 . fgsea_args ( type=json ) : Default: {} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Summary Plot': Diot({'plot_type': 'summary', 'top_term': 10, 'devpars': Diot({'res': 100})}), 'Enrichment Plots': Diot({'plot_type': 'gsea', 'top_term': 10, 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . A key level is supported to specify the level of the plot. Possible values are case , which includes all subsets and groups in the case; subset , which includes all groups in the subset; otherwise, it will plot for the groups. For case / subset level plots, current plot_type only \"dot\" is supported for now, then the values will be passed to plotthis::DotPlot() cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots .","title":"MetabolicFeatures"},{"location":"processes/MetabolicFeatures/#metabolicfeatures","text":"This process performs enrichment analysis for the metabolic pathways for each group in each subset. The enrichment analysis is done with fgsea package or the GSEA_R package.","title":"MetabolicFeatures"},{"location":"processes/MetabolicFeatures/#input","text":"sobjfile : The Seurat object file in rds. It should be loaded as a Seurat object","title":"Input"},{"location":"processes/MetabolicFeatures/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pathwayfeatures . The output directory. It will contain the GSEA results and plots.","title":"Output"},{"location":"processes/MetabolicFeatures/#environment-variables","text":"ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization for the comparisons for each subset and group. Defaults to ScrnaMetabolicLandscape.ncores . prerank_method ( choice ) : Default: signal_to_noise . Method to use for gene preranking. Signal to noise: the larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \u201cclass marker.\u201d. Absolute signal to noise: the absolute value of the signal to noise. T test: Uses the difference of means scaled by the standard deviation and number of samples. Ratio of classes: Uses the ratio of class means to calculate fold change for natural scale data. Diff of classes: Uses the difference of class means to calculate fold change for nature scale data Log2 ratio of classes: Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. signal_to_noise : Signal to noise s2n : Alias of signal_to_noise abs_signal_to_noise : absolute signal to noise abs_s2n : Alias of abs_signal_to_noise t_test : T test ratio_of_classes : Also referred to as fold change diff_of_classes : Difference of class means log2_ratio_of_classes : Log2 ratio of class means gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by comparisons ( type=list ) : Default: [] . The comparison groups to use for the analysis. If not provided, each group in the group_by column will be used to compare with the other groups. If a single group is provided as an element, it will be used to compare with all the other groups. For example, if we have group_by = \"cluster\" and we have 1 , 2 and 3 in the group_by column, we could have comparisons = [\"1\", \"2\"] , which will compare the group 1 with groups 2 and 3 , and the group 2 with groups 1 and 3 . We could also have comparisons = [\"1:2\", \"1:3\"] , which will compare the group 1 with group 2 and group 1 with group 3 . fgsea_args ( type=json ) : Default: {} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Summary Plot': Diot({'plot_type': 'summary', 'top_term': 10, 'devpars': Diot({'res': 100})}), 'Enrichment Plots': Diot({'plot_type': 'gsea', 'top_term': 10, 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . A key level is supported to specify the level of the plot. Possible values are case , which includes all subsets and groups in the case; subset , which includes all groups in the subset; otherwise, it will plot for the groups. For case / subset level plots, current plot_type only \"dot\" is supported for now, then the values will be passed to plotthis::DotPlot() cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots .","title":"Environment Variables"},{"location":"processes/MetabolicInput/","text":"MetabolicInput \u00b6 This process takes Seurat object as input and pass it to the next processes in the ScrnaMetabolicLandscape group. There is no configuration for this process. Input \u00b6 infile : The input file Output \u00b6 outfile : Default: {{in.infile | basename}} . The output symbolic link to the input file","title":"MetabolicInput"},{"location":"processes/MetabolicInput/#metabolicinput","text":"This process takes Seurat object as input and pass it to the next processes in the ScrnaMetabolicLandscape group. There is no configuration for this process.","title":"MetabolicInput"},{"location":"processes/MetabolicInput/#input","text":"infile : The input file","title":"Input"},{"location":"processes/MetabolicInput/#output","text":"outfile : Default: {{in.infile | basename}} . The output symbolic link to the input file","title":"Output"},{"location":"processes/MetabolicPathwayActivity/","text":"MetabolicPathwayActivity \u00b6 This process calculates the pathway activities in different groups and subsets. The cells are first grouped by subsets and then the metabolic activities are examined for each groups in different subsets. For each subset, a heatmap and a violin plot will be generated. The heatmap shows the pathway activities for each group and each metabolic pathway The violin plot shows the distribution of the pathway activities for each group Input \u00b6 sobjfile : The Seurat object file. It should be loaded as a Seurat object Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pathwayactivity . The output directory. It will contain the pathway activity score files and plots. Environment Variables \u00b6 ntimes ( type=int ) : Default: 5000 . Number of permutations to estimate the p-values ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by plots ( type=json ) : Default: {'Pathway Activity (violin plot)': Diot({'plot_type': 'violin', 'add_box': True, 'devpars': Diot({'res': 100})}), 'Pathway Activity (heatmap)': Diot({'plot_type': 'heatmap', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the prefix for the output files. Values will be a dictionary with the following keys: plot_type is the type of plot to generate. One of heatmap , box , violin or merged_heatmap (all subsets in one plot). devpars is a dictionary with the device parameters for the plot. Other arguments for plotthis::Heatmap() , plotthis::BoxPlot() or plotthis::ViolinPlot() , depending on the plot_type . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots . The name of the case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots .","title":"MetabolicPathwayActivity"},{"location":"processes/MetabolicPathwayActivity/#metabolicpathwayactivity","text":"This process calculates the pathway activities in different groups and subsets. The cells are first grouped by subsets and then the metabolic activities are examined for each groups in different subsets. For each subset, a heatmap and a violin plot will be generated. The heatmap shows the pathway activities for each group and each metabolic pathway The violin plot shows the distribution of the pathway activities for each group","title":"MetabolicPathwayActivity"},{"location":"processes/MetabolicPathwayActivity/#input","text":"sobjfile : The Seurat object file. It should be loaded as a Seurat object","title":"Input"},{"location":"processes/MetabolicPathwayActivity/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pathwayactivity . The output directory. It will contain the pathway activity score files and plots.","title":"Output"},{"location":"processes/MetabolicPathwayActivity/#environment-variables","text":"ntimes ( type=int ) : Default: 5000 . Number of permutations to estimate the p-values ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by plots ( type=json ) : Default: {'Pathway Activity (violin plot)': Diot({'plot_type': 'violin', 'add_box': True, 'devpars': Diot({'res': 100})}), 'Pathway Activity (heatmap)': Diot({'plot_type': 'heatmap', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the prefix for the output files. Values will be a dictionary with the following keys: plot_type is the type of plot to generate. One of heatmap , box , violin or merged_heatmap (all subsets in one plot). devpars is a dictionary with the device parameters for the plot. Other arguments for plotthis::Heatmap() , plotthis::BoxPlot() or plotthis::ViolinPlot() , depending on the plot_type . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots . The name of the case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots .","title":"Environment Variables"},{"location":"processes/MetabolicPathwayHeterogeneity/","text":"MetabolicPathwayHeterogeneity \u00b6 Calculate Metabolic Pathway heterogeneity. For each subset, the normalized enrichment score (NES) of each metabolic pathway is calculated for each group. The NES is calculated by comparing the enrichment score of the subset to the enrichment scores of the same subset in the permutations. The p-value is calculated by comparing the NES to the NESs of the same subset in the permutations. The heterogeneity can be reflected by the NES values and the p-values in different groups for the metabolic pathways. Input \u00b6 sobjfile : Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pathwayhetero . Environment Variables \u00b6 gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile select_pcs ( type=float ) : Default: 0.8 . Select the PCs to use for the analysis. pathway_pval_cutoff ( type=float ) : Default: 0.01 . The p-value cutoff to select the enriched pathways ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores subset_by ( pgarg;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by fgsea_args ( type=json ) : Default: {'scoreType': 'std', 'nproc': 1} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Pathway Heterogeneity': Diot({'plot_type': 'dot', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff .","title":"MetabolicPathwayHeterogeneity"},{"location":"processes/MetabolicPathwayHeterogeneity/#metabolicpathwayheterogeneity","text":"Calculate Metabolic Pathway heterogeneity. For each subset, the normalized enrichment score (NES) of each metabolic pathway is calculated for each group. The NES is calculated by comparing the enrichment score of the subset to the enrichment scores of the same subset in the permutations. The p-value is calculated by comparing the NES to the NESs of the same subset in the permutations. The heterogeneity can be reflected by the NES values and the p-values in different groups for the metabolic pathways.","title":"MetabolicPathwayHeterogeneity"},{"location":"processes/MetabolicPathwayHeterogeneity/#input","text":"sobjfile :","title":"Input"},{"location":"processes/MetabolicPathwayHeterogeneity/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pathwayhetero .","title":"Output"},{"location":"processes/MetabolicPathwayHeterogeneity/#environment-variables","text":"gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile select_pcs ( type=float ) : Default: 0.8 . Select the PCs to use for the analysis. pathway_pval_cutoff ( type=float ) : Default: 0.01 . The p-value cutoff to select the enriched pathways ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores subset_by ( pgarg;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by fgsea_args ( type=json ) : Default: {'scoreType': 'std', 'nproc': 1} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Pathway Heterogeneity': Diot({'plot_type': 'dot', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff .","title":"Environment Variables"},{"location":"processes/ModuleScoreCalculator/","text":"ModuleScoreCalculator \u00b6 Calculate the module scores for each cell The module scores are calculated by Seurat::AddModuleScore() or Seurat::CellCycleScoring() for cell cycle scores. The module scores are calculated as the average expression levels of each program on single cell level, subtracted by the aggregated expression of control feature sets. All analyzed features are binned based on averaged expression, and the control features are randomly selected from each bin. Input \u00b6 srtobj : The seurat object loaded by SeuratClustering Output \u00b6 rdsfile : Default: {{in.srtobj | stem}}.qs . The seurat object with module scores added to the metadata. Environment Variables \u00b6 defaults ( ns ) : The default parameters for modules . features : The features to calculate the scores. Multiple features should be separated by comma. You can also specify cc.genes or cc.genes.updated.2019 to use the cell cycle genes to calculate cell cycle scores. If so, three columns will be added to the metadata, including S.Score , G2M.Score and Phase . Only one type of cell cycle scores can be calculated at a time. nbin ( type=int ) : Default: 24 . Number of bins of aggregate expression levels for all analyzed features. ctrl ( type=int ) : Default: 100 . Number of control features selected from the same bin per analyzed feature. k ( flag ) : Default: False . Use feature clusters returned from DoKMeans . assay : The assay to use. seed ( type=int ) : Default: 8525 . Set a random seed. search ( flag ) : Default: False . Search for symbol synonyms for features in features that don't match features in object? keep ( flag ) : Default: False . Keep the scores for each feature? Only works for non-cell cycle scores. agg ( choice ) : Default: mean . The aggregation function to use. Only works for non-cell cycle scores. mean : The mean of the expression levels median : The median of the expression levels sum : The sum of the expression levels max : The max of the expression levels min : The min of the expression levels var : The variance of the expression levels sd : The standard deviation of the expression levels modules ( type=json ) : Default: {} . The modules to calculate the scores. Keys are the names of the expression programs and values are the dicts inherited from env.defaults . Here are some examples - { \"CellCycle\" : { \"features\" : \"cc.genes.updated.2019\" }, \"Exhaustion\" : { \"features\" : \"HAVCR2,ENTPD1,LAYN,LAG3\" }, \"Activation\" : { \"features\" : \"IFNG\" }, \"Proliferation\" : { \"features\" : \"STMN1,TUBB\" } } For CellCycle , the columns S.Score , G2M.Score and Phase will be added to the metadata. S.Score and G2M.Score are the cell cycle scores for each cell, and Phase is the cell cycle phase for each cell. You can also add Diffusion Components (DC) to the modules { \"DC\" : { \"features\" : 2 , \"kind\" : \"diffmap\" }} will perform diffusion map as a reduction and add the first 2 components as DC_1 and DC_2 to the metadata. diffmap is a shortcut for diffusion_map . Other key-value pairs will pass to destiny::DiffusionMap() . You can later plot the diffusion map by using reduction = \"DC\" in env.dimplots in SeuratClusterStats . This requires SingleCellExperiment and destiny R packages. - post_mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata after calculating the module scores. The mutaters will be applied in the order specified. This is useful when you want to create new scores based on the calculated module scores. Metadata \u00b6 The metadata of the Seurat object will be updated with the module scores:","title":"ModuleScoreCalculator"},{"location":"processes/ModuleScoreCalculator/#modulescorecalculator","text":"Calculate the module scores for each cell The module scores are calculated by Seurat::AddModuleScore() or Seurat::CellCycleScoring() for cell cycle scores. The module scores are calculated as the average expression levels of each program on single cell level, subtracted by the aggregated expression of control feature sets. All analyzed features are binned based on averaged expression, and the control features are randomly selected from each bin.","title":"ModuleScoreCalculator"},{"location":"processes/ModuleScoreCalculator/#input","text":"srtobj : The seurat object loaded by SeuratClustering","title":"Input"},{"location":"processes/ModuleScoreCalculator/#output","text":"rdsfile : Default: {{in.srtobj | stem}}.qs . The seurat object with module scores added to the metadata.","title":"Output"},{"location":"processes/ModuleScoreCalculator/#environment-variables","text":"defaults ( ns ) : The default parameters for modules . features : The features to calculate the scores. Multiple features should be separated by comma. You can also specify cc.genes or cc.genes.updated.2019 to use the cell cycle genes to calculate cell cycle scores. If so, three columns will be added to the metadata, including S.Score , G2M.Score and Phase . Only one type of cell cycle scores can be calculated at a time. nbin ( type=int ) : Default: 24 . Number of bins of aggregate expression levels for all analyzed features. ctrl ( type=int ) : Default: 100 . Number of control features selected from the same bin per analyzed feature. k ( flag ) : Default: False . Use feature clusters returned from DoKMeans . assay : The assay to use. seed ( type=int ) : Default: 8525 . Set a random seed. search ( flag ) : Default: False . Search for symbol synonyms for features in features that don't match features in object? keep ( flag ) : Default: False . Keep the scores for each feature? Only works for non-cell cycle scores. agg ( choice ) : Default: mean . The aggregation function to use. Only works for non-cell cycle scores. mean : The mean of the expression levels median : The median of the expression levels sum : The sum of the expression levels max : The max of the expression levels min : The min of the expression levels var : The variance of the expression levels sd : The standard deviation of the expression levels modules ( type=json ) : Default: {} . The modules to calculate the scores. Keys are the names of the expression programs and values are the dicts inherited from env.defaults . Here are some examples - { \"CellCycle\" : { \"features\" : \"cc.genes.updated.2019\" }, \"Exhaustion\" : { \"features\" : \"HAVCR2,ENTPD1,LAYN,LAG3\" }, \"Activation\" : { \"features\" : \"IFNG\" }, \"Proliferation\" : { \"features\" : \"STMN1,TUBB\" } } For CellCycle , the columns S.Score , G2M.Score and Phase will be added to the metadata. S.Score and G2M.Score are the cell cycle scores for each cell, and Phase is the cell cycle phase for each cell. You can also add Diffusion Components (DC) to the modules { \"DC\" : { \"features\" : 2 , \"kind\" : \"diffmap\" }} will perform diffusion map as a reduction and add the first 2 components as DC_1 and DC_2 to the metadata. diffmap is a shortcut for diffusion_map . Other key-value pairs will pass to destiny::DiffusionMap() . You can later plot the diffusion map by using reduction = \"DC\" in env.dimplots in SeuratClusterStats . This requires SingleCellExperiment and destiny R packages. - post_mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata after calculating the module scores. The mutaters will be applied in the order specified. This is useful when you want to create new scores based on the calculated module scores.","title":"Environment Variables"},{"location":"processes/ModuleScoreCalculator/#metadata","text":"The metadata of the Seurat object will be updated with the module scores:","title":"Metadata"},{"location":"processes/PseudoBulkDEG/","text":"PseudoBulkDEG \u00b6 Pseduo-bulk differential gene expression analysis This process performs differential gene expression analysis, instead of on single-cell level, on the pseudo-bulk data, aggregated from the single-cell data. Input \u00b6 sobjfile : The seurat object file in RDS or qs/qs2 format. Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pseudobulk_deg . The output containing the results of the differential gene expression analysis. Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallelization. mutaters ( type=json ) : Default: {} . Mutaters to mutate the metadata of the seurat object. Keys are the new column names and values are the expressions to mutate the columns. These new columns can be used to define your cases. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . each : The column name in metadata to separate the cells into different cases. When specified, the case will be expanded to multiple cases for each value in the column. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. subset : An expression in string to subset the cells. aggregate_by : The column names in metadata to aggregate the cells. layer : Default: counts . The layer to pull and aggregate the data. assay : Default: RNA . The assay to pull and aggregate the data. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. group_by : The column name in metadata to group the cells. ident_1 : The first identity to compare. ident_2 : The second identity to compare. If not specified, the rest of the identities will be compared with ident_1 . paired_by : The column name in metadata to mark the paired samples. For example, subject. If specified, the paired test will be performed. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The databases to use for enrichment analysis. The databases are passed to biopipen.utils::Enrichr() to do the enrichment analysis. The default databases are KEGG_2021_Human and MSigDB_Hallmark_2020 . See https://maayanlab.cloud/Enrichr/#libraries for the available libraries. sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. The default is p_val_adj < 0.05 . If tool = 'DESeq2' , the variables that can be used for filtering are: baseMean , log2FC , lfcSE , stat , p_val , p_val_adj . If tool = 'edgeR' , the variables that can be used for filtering are: logCPM , log2FC , LR , p_val , p_val_adj . enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. enrichr : Use enrichr -style for the enrichment analysis. clusterProfiler : Use clusterProfiler -style for the enrichment analysis. allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot': Diot({'plot_type': 'volcano'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified. tool ( choice ) : Default: DESeq2 . The method to use for the differential expression analysis. DESeq2 : Use DESeq2 for the analysis. edgeR : Use edgeR for the analysis. plots_defaults ( ns ) : The default parameters for the plots. <more> : Parameters passed to biopipen.utils::VizBulkDEGs() . See: https://pwwang.github.io/biopipen.utils.R/reference/VizBulkDEGs.html plots ( type=json ) : The parameters for the plots. The keys are the names of the plots and the values are the parameters for the plots. The parameters will override the defaults in plots_defaults . If not specified, no plots will be generated. cases ( type=json ) : Default: {} . The cases for the analysis. The keys are the names of the cases and the values are the arguments for the analysis. The arguments include the ones inherited from envs . If no cases are specified, a default case will be added with the name DEG Analysis and the default values specified above.","title":"PseudoBulkDEG"},{"location":"processes/PseudoBulkDEG/#pseudobulkdeg","text":"Pseduo-bulk differential gene expression analysis This process performs differential gene expression analysis, instead of on single-cell level, on the pseudo-bulk data, aggregated from the single-cell data.","title":"PseudoBulkDEG"},{"location":"processes/PseudoBulkDEG/#input","text":"sobjfile : The seurat object file in RDS or qs/qs2 format.","title":"Input"},{"location":"processes/PseudoBulkDEG/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pseudobulk_deg . The output containing the results of the differential gene expression analysis.","title":"Output"},{"location":"processes/PseudoBulkDEG/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallelization. mutaters ( type=json ) : Default: {} . Mutaters to mutate the metadata of the seurat object. Keys are the new column names and values are the expressions to mutate the columns. These new columns can be used to define your cases. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . each : The column name in metadata to separate the cells into different cases. When specified, the case will be expanded to multiple cases for each value in the column. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. subset : An expression in string to subset the cells. aggregate_by : The column names in metadata to aggregate the cells. layer : Default: counts . The layer to pull and aggregate the data. assay : Default: RNA . The assay to pull and aggregate the data. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. group_by : The column name in metadata to group the cells. ident_1 : The first identity to compare. ident_2 : The second identity to compare. If not specified, the rest of the identities will be compared with ident_1 . paired_by : The column name in metadata to mark the paired samples. For example, subject. If specified, the paired test will be performed. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The databases to use for enrichment analysis. The databases are passed to biopipen.utils::Enrichr() to do the enrichment analysis. The default databases are KEGG_2021_Human and MSigDB_Hallmark_2020 . See https://maayanlab.cloud/Enrichr/#libraries for the available libraries. sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. The default is p_val_adj < 0.05 . If tool = 'DESeq2' , the variables that can be used for filtering are: baseMean , log2FC , lfcSE , stat , p_val , p_val_adj . If tool = 'edgeR' , the variables that can be used for filtering are: logCPM , log2FC , LR , p_val , p_val_adj . enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. enrichr : Use enrichr -style for the enrichment analysis. clusterProfiler : Use clusterProfiler -style for the enrichment analysis. allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident-1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot': Diot({'plot_type': 'volcano'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident-1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident-1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident-1 must be specified. tool ( choice ) : Default: DESeq2 . The method to use for the differential expression analysis. DESeq2 : Use DESeq2 for the analysis. edgeR : Use edgeR for the analysis. plots_defaults ( ns ) : The default parameters for the plots. <more> : Parameters passed to biopipen.utils::VizBulkDEGs() . See: https://pwwang.github.io/biopipen.utils.R/reference/VizBulkDEGs.html plots ( type=json ) : The parameters for the plots. The keys are the names of the plots and the values are the parameters for the plots. The parameters will override the defaults in plots_defaults . If not specified, no plots will be generated. cases ( type=json ) : Default: {} . The cases for the analysis. The keys are the names of the cases and the values are the arguments for the analysis. The arguments include the ones inherited from envs . If no cases are specified, a default case will be added with the name DEG Analysis and the default values specified above.","title":"Environment Variables"},{"location":"processes/SampleInfo/","text":"SampleInfo \u00b6 List sample information and perform statistics Input \u00b6 infile : The input file to list sample information The input file should be a csv/tsv file with header Output \u00b6 outfile : Default: {{in.infile | basename}} . The output file with sample information, with mutated columns if envs.save_mutated is True. The basename of the output file will be the same as the input file. The file name of each plot will be slugified from the case name. Each plot has 3 formats: pdf, png and code.zip, which contains the data and R code to reproduce the plot. Environment Variables \u00b6 sep : Default: . The separator of the input file. mutaters ( type=json ) : Default: {} . A dict of mutaters to mutate the data frame. The key is the column name and the value is the R expression to mutate the column. The dict will be transformed to a list in R and passed to dplyr::mutate . You may also use paired() to identify paired samples. The function takes following arguments: df : The data frame. Use . if the function is called in a dplyr pipe. id_col : The column name in df for the ids to be returned in the final output. compare_col : The column name in df to compare the values for each id in id_col . idents : The values in compare_col to compare. It could be either an an integer or a vector. If it is an integer, the number of values in compare_col must be the same as the integer for the id to be regarded as paired. If it is a vector, the values in compare_col must be the same as the values in idents for the id to be regarded as paired. uniq : Whether to return unique ids or not. Default is TRUE . If FALSE , you can mutate the meta data frame with the returned ids. Non-paired ids will be NA . save_mutated ( flag ) : Default: False . Whether to save the mutated columns. exclude_cols ( auto ) : Default: TCRData,BCRData,RNAData . The columns to exclude in the table in the report. Could be a list or a string separated by comma. defaults ( ns ) : The default parameters for envs.stats . plot_type : Default: bar . The type of the plot. See the supported plot types here: https://pwwang.github.io/plotthis/reference/index.html The plot_type should be lower case and the plot function used in plotthis should be used. The mapping from plot_type to the plot function is like bar -> BarPlot , box -> BoxPlot , etc. more_formats ( list ) : Default: [] . The additional formats to save the plot. By default, the plot will be saved in png, which is also used to display in the report. You can add more formats to save the plot. For example, more_formats = [\"pdf\", \"svg\"] . save_code ( flag ) : Default: False . Whether to save the R code to reproduce the plot. The data used to plot will also be saved. subset : An expression to subset the data frame before plotting. The expression should be a string of R expression that will be passed to dplyr::filter . For example, subset = \"Sample == 'A'\" . section : The section name in the report. In case you want to group the plots in the report. devpars ( ns ) : The device parameters for the plot. width ( type=int ) : The width of the plot. height ( type=int ) : The height of the plot. res ( type=int ) : Default: 100 . The resolution of the plot. descr : The description of the plot, shown in the report. <more> : You can add more parameters to the defaults. These parameters will be expanded to the envs.stats for each case, and passed to individual plot functions. stats ( type=json ) : Default: {} . The statistics to perform. The keys are the case names and the values are the parameters inheirted from envs.defaults .","title":"SampleInfo"},{"location":"processes/SampleInfo/#sampleinfo","text":"List sample information and perform statistics","title":"SampleInfo"},{"location":"processes/SampleInfo/#input","text":"infile : The input file to list sample information The input file should be a csv/tsv file with header","title":"Input"},{"location":"processes/SampleInfo/#output","text":"outfile : Default: {{in.infile | basename}} . The output file with sample information, with mutated columns if envs.save_mutated is True. The basename of the output file will be the same as the input file. The file name of each plot will be slugified from the case name. Each plot has 3 formats: pdf, png and code.zip, which contains the data and R code to reproduce the plot.","title":"Output"},{"location":"processes/SampleInfo/#environment-variables","text":"sep : Default: . The separator of the input file. mutaters ( type=json ) : Default: {} . A dict of mutaters to mutate the data frame. The key is the column name and the value is the R expression to mutate the column. The dict will be transformed to a list in R and passed to dplyr::mutate . You may also use paired() to identify paired samples. The function takes following arguments: df : The data frame. Use . if the function is called in a dplyr pipe. id_col : The column name in df for the ids to be returned in the final output. compare_col : The column name in df to compare the values for each id in id_col . idents : The values in compare_col to compare. It could be either an an integer or a vector. If it is an integer, the number of values in compare_col must be the same as the integer for the id to be regarded as paired. If it is a vector, the values in compare_col must be the same as the values in idents for the id to be regarded as paired. uniq : Whether to return unique ids or not. Default is TRUE . If FALSE , you can mutate the meta data frame with the returned ids. Non-paired ids will be NA . save_mutated ( flag ) : Default: False . Whether to save the mutated columns. exclude_cols ( auto ) : Default: TCRData,BCRData,RNAData . The columns to exclude in the table in the report. Could be a list or a string separated by comma. defaults ( ns ) : The default parameters for envs.stats . plot_type : Default: bar . The type of the plot. See the supported plot types here: https://pwwang.github.io/plotthis/reference/index.html The plot_type should be lower case and the plot function used in plotthis should be used. The mapping from plot_type to the plot function is like bar -> BarPlot , box -> BoxPlot , etc. more_formats ( list ) : Default: [] . The additional formats to save the plot. By default, the plot will be saved in png, which is also used to display in the report. You can add more formats to save the plot. For example, more_formats = [\"pdf\", \"svg\"] . save_code ( flag ) : Default: False . Whether to save the R code to reproduce the plot. The data used to plot will also be saved. subset : An expression to subset the data frame before plotting. The expression should be a string of R expression that will be passed to dplyr::filter . For example, subset = \"Sample == 'A'\" . section : The section name in the report. In case you want to group the plots in the report. devpars ( ns ) : The device parameters for the plot. width ( type=int ) : The width of the plot. height ( type=int ) : The height of the plot. res ( type=int ) : Default: 100 . The resolution of the plot. descr : The description of the plot, shown in the report. <more> : You can add more parameters to the defaults. These parameters will be expanded to the envs.stats for each case, and passed to individual plot functions. stats ( type=json ) : Default: {} . The statistics to perform. The keys are the case names and the values are the parameters inheirted from envs.defaults .","title":"Environment Variables"},{"location":"processes/ScFGSEA/","text":"ScFGSEA \u00b6 Gene set enrichment analysis for cells in different groups using fgsea This process allows us to do Gene Set Enrichment Analysis (GSEA) on the expression data, but based on variaties of grouping, including the from the meta data and the scTCR-seq data as well. The GSEA is done using the fgsea package, which allows to quickly and accurately calculate arbitrarily low GSEA P-values for a collection of gene sets. The fgsea package is based on the fast algorithm for preranked GSEA described in Subramanian et al. 2005 . For each case, the process will generate a table with the enrichment scores for each gene set, and GSEA plots for the top gene sets. Input \u00b6 srtobj : The seurat object in RDS format Output \u00b6 outdir : Default: {{(in.casefile or in.srtobj) | stem0}}.fgsea . The output directory for the results and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores for parallelization Passed to nproc of fgseaMultilevel() . mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. The key-value pairs will be passed the dplyr::mutate() to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . group_by : The column name in metadata to group the cells. ident_1 : The first group of cells to compare ident_2 : The second group of cells to compare, if not provided, the rest of the cells that are not NA s in group_by column are used for ident-2 . each : The column name in metadata to separate the cells into different subsets to do the analysis. subset : An expression to subset the cells. gmtfile : Default: KEGG_2021_Human . The pathways in GMT format, with the gene names/ids in the same format as the seurat object. One could also use a URL to a GMT file. For example, from https://download.baderlab.org/EM_Genesets/current_release/Human/symbol/Pathways/ . method ( choice ) : Default: s2n . The method to do the preranking. signal_to_noise : Signal to noise. The larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \"class marker\". s2n : Alias of signal_to_noise. abs_signal_to_noise : The absolute value of signal_to_noise. abs_s2n : Alias of abs_signal_to_noise. t_test : T test. Uses the difference of means scaled by the standard deviation and number of samples. ratio_of_classes : Also referred to as fold change. Uses the ratio of class means to calculate fold change for natural scale data. diff_of_classes : Difference of class means. Uses the difference of class means to calculate fold change for nature scale data log2_ratio_of_classes : Log2 ratio of class means. Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. top ( type=auto ) : Default: 20 . Do gsea table and enrich plot for top N pathways. If it is < 1, will apply it to padj , selecting pathways with padj < top . eps ( type=float ) : Default: 0 . This parameter sets the boundary for calculating the p value. See https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html alleach_plots_defaults ( ns ) : Default options for the plots to generate for all pathways. plot_type : Default: heatmap . The type of the plot, currently either dot or heatmap (default) devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . alleach_plots ( type=json ) : Default: {} . Cases of the plots to generate for all pathways. The keys are the names of the cases and the values are the dicts inherited from alleach_plots_defaults . minsize ( type=int ) : Default: 10 . Minimal size of a gene set to test. All pathways below the threshold are excluded. maxsize ( type=int ) : Default: 100 . Maximal size of a gene set to test. All pathways above the threshold are excluded. rest ( type=json;order=98 ) : Default: {} . Rest arguments for fgsea() See also https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html cases ( type=json;order=99 ) : Default: {} . If you have multiple cases, you can specify them here. The keys are the names of the cases and the values are the above options except mutaters . If some options are not specified, the default values specified above will be used. If no cases are specified, the default case will be added with the name GSEA .","title":"ScFGSEA"},{"location":"processes/ScFGSEA/#scfgsea","text":"Gene set enrichment analysis for cells in different groups using fgsea This process allows us to do Gene Set Enrichment Analysis (GSEA) on the expression data, but based on variaties of grouping, including the from the meta data and the scTCR-seq data as well. The GSEA is done using the fgsea package, which allows to quickly and accurately calculate arbitrarily low GSEA P-values for a collection of gene sets. The fgsea package is based on the fast algorithm for preranked GSEA described in Subramanian et al. 2005 . For each case, the process will generate a table with the enrichment scores for each gene set, and GSEA plots for the top gene sets.","title":"ScFGSEA"},{"location":"processes/ScFGSEA/#input","text":"srtobj : The seurat object in RDS format","title":"Input"},{"location":"processes/ScFGSEA/#output","text":"outdir : Default: {{(in.casefile or in.srtobj) | stem0}}.fgsea . The output directory for the results and plots","title":"Output"},{"location":"processes/ScFGSEA/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores for parallelization Passed to nproc of fgseaMultilevel() . mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. The key-value pairs will be passed the dplyr::mutate() to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . group_by : The column name in metadata to group the cells. ident_1 : The first group of cells to compare ident_2 : The second group of cells to compare, if not provided, the rest of the cells that are not NA s in group_by column are used for ident-2 . each : The column name in metadata to separate the cells into different subsets to do the analysis. subset : An expression to subset the cells. gmtfile : Default: KEGG_2021_Human . The pathways in GMT format, with the gene names/ids in the same format as the seurat object. One could also use a URL to a GMT file. For example, from https://download.baderlab.org/EM_Genesets/current_release/Human/symbol/Pathways/ . method ( choice ) : Default: s2n . The method to do the preranking. signal_to_noise : Signal to noise. The larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \"class marker\". s2n : Alias of signal_to_noise. abs_signal_to_noise : The absolute value of signal_to_noise. abs_s2n : Alias of abs_signal_to_noise. t_test : T test. Uses the difference of means scaled by the standard deviation and number of samples. ratio_of_classes : Also referred to as fold change. Uses the ratio of class means to calculate fold change for natural scale data. diff_of_classes : Difference of class means. Uses the difference of class means to calculate fold change for nature scale data log2_ratio_of_classes : Log2 ratio of class means. Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. top ( type=auto ) : Default: 20 . Do gsea table and enrich plot for top N pathways. If it is < 1, will apply it to padj , selecting pathways with padj < top . eps ( type=float ) : Default: 0 . This parameter sets the boundary for calculating the p value. See https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html alleach_plots_defaults ( ns ) : Default options for the plots to generate for all pathways. plot_type : Default: heatmap . The type of the plot, currently either dot or heatmap (default) devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . alleach_plots ( type=json ) : Default: {} . Cases of the plots to generate for all pathways. The keys are the names of the cases and the values are the dicts inherited from alleach_plots_defaults . minsize ( type=int ) : Default: 10 . Minimal size of a gene set to test. All pathways below the threshold are excluded. maxsize ( type=int ) : Default: 100 . Maximal size of a gene set to test. All pathways above the threshold are excluded. rest ( type=json;order=98 ) : Default: {} . Rest arguments for fgsea() See also https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html cases ( type=json;order=99 ) : Default: {} . If you have multiple cases, you can specify them here. The keys are the names of the cases and the values are the above options except mutaters . If some options are not specified, the default values specified above will be used. If no cases are specified, the default case will be added with the name GSEA .","title":"Environment Variables"},{"location":"processes/ScRepCombiningExpression/","text":"ScRepCombiningExpression \u00b6 Combine the scTCR/BCR data with the expression data This process combines the scTCR/BCR data with the expression data using scRepertoire::combineExpression function. The expression data should be in Seurat format. The scRepertoire object should be a combined contig object, usually generated by scRepertoire::combineTCR or scRepertoire::combineBCR . See also: https://www.borch.dev/uploads/screpertoire/reference/combineexpression . Input \u00b6 screpfile : The scRepertoire object in RDS/qs format srtobj : The Seurat object, saved in RDS/qs format Output \u00b6 outfile : Default: {{in.screpfile | stem}}.qs . The Seurat object with the TCR/BCR data combined In addition to the meta columns added by scRepertoire::combineExpression() , a new column VDJ_Presence will be added to the metadata. It indicates whether the cell has a TCR/BCR sequence or not. The value is TRUE if the cell has a TCR/BCR sequence, and FALSE otherwise. Environment Variables \u00b6 cloneCall : Default: aa . How to call the clone - VDJC gene (gene), CDR3 nucleotide (nt), CDR3 amino acid (aa), VDJC gene + CDR3 nucleotide (strict) or a custom variable in the data. chain : Default: both . indicate if both or a specific chain should be used e.g. \"both\", \"TRA\", \"TRG\", \"IGH\", \"IGL\". group_by : Default: Sample . The column label in the combined clones in which clone frequency will be calculated. NULL or \"none\" will keep the format of input.data. proportion ( flag ) : Default: True . Whether to proportion (TRUE) or total frequency (FALSE) of the clone based on the group_by variable. filterNA ( flag ) : Default: False . Method to subset Seurat/SCE object of barcodes without clone information cloneSize ( type=json ) : Default: {'Rare': 0.0001, 'Small': 0.001, 'Medium': 0.01, 'Large': 0.1, 'Hyperexpanded': 1} . The bins for the grouping based on proportion or frequency. If proportion is FALSE and the cloneSizes are not set high enough based on frequency, the upper limit of cloneSizes will be automatically updated. addLabel ( flag ) : Default: False . This will add a label to the frequency header, allowing the user to try multiple group_by variables or recalculate frequencies after subsetting the data.","title":"ScRepCombiningExpression"},{"location":"processes/ScRepCombiningExpression/#screpcombiningexpression","text":"Combine the scTCR/BCR data with the expression data This process combines the scTCR/BCR data with the expression data using scRepertoire::combineExpression function. The expression data should be in Seurat format. The scRepertoire object should be a combined contig object, usually generated by scRepertoire::combineTCR or scRepertoire::combineBCR . See also: https://www.borch.dev/uploads/screpertoire/reference/combineexpression .","title":"ScRepCombiningExpression"},{"location":"processes/ScRepCombiningExpression/#input","text":"screpfile : The scRepertoire object in RDS/qs format srtobj : The Seurat object, saved in RDS/qs format","title":"Input"},{"location":"processes/ScRepCombiningExpression/#output","text":"outfile : Default: {{in.screpfile | stem}}.qs . The Seurat object with the TCR/BCR data combined In addition to the meta columns added by scRepertoire::combineExpression() , a new column VDJ_Presence will be added to the metadata. It indicates whether the cell has a TCR/BCR sequence or not. The value is TRUE if the cell has a TCR/BCR sequence, and FALSE otherwise.","title":"Output"},{"location":"processes/ScRepCombiningExpression/#environment-variables","text":"cloneCall : Default: aa . How to call the clone - VDJC gene (gene), CDR3 nucleotide (nt), CDR3 amino acid (aa), VDJC gene + CDR3 nucleotide (strict) or a custom variable in the data. chain : Default: both . indicate if both or a specific chain should be used e.g. \"both\", \"TRA\", \"TRG\", \"IGH\", \"IGL\". group_by : Default: Sample . The column label in the combined clones in which clone frequency will be calculated. NULL or \"none\" will keep the format of input.data. proportion ( flag ) : Default: True . Whether to proportion (TRUE) or total frequency (FALSE) of the clone based on the group_by variable. filterNA ( flag ) : Default: False . Method to subset Seurat/SCE object of barcodes without clone information cloneSize ( type=json ) : Default: {'Rare': 0.0001, 'Small': 0.001, 'Medium': 0.01, 'Large': 0.1, 'Hyperexpanded': 1} . The bins for the grouping based on proportion or frequency. If proportion is FALSE and the cloneSizes are not set high enough based on frequency, the upper limit of cloneSizes will be automatically updated. addLabel ( flag ) : Default: False . This will add a label to the frequency header, allowing the user to try multiple group_by variables or recalculate frequencies after subsetting the data.","title":"Environment Variables"},{"location":"processes/ScRepLoading/","text":"ScRepLoading \u00b6 Load the single cell TCR/BCR data into a scRepertoire compatible object This process loads the single cell TCR/BCR data into a scRepertoire (>= v2.0.8, < v2.3.2) compatible object. Later, scRepertoire::combineExpression can be used to combine the expression data with the TCR/BCR data. For the data path specified at TCRData / BCRData in the input file ( in.metafile ), will be used to find the TCR/BCR data files and scRepertoire::loadContigs() will be used to load the data. A directory can be specified in TCRData / BCRData , then scRepertoire::loadContigs() will be used directly to load the data from the directory. Otherwise if a file is specified, it will be symbolically linked to a directory for scRepertoire::loadContigs() to load. Note that when the file name can not be recognized by scRepertoire::loadContigs() , envs.format must be set for the correct format of the data. Input \u00b6 metafile : The meta data of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. TCRData / BCRData to assign the path of the data to the samples, and this column will be excluded as metadata. Output \u00b6 outfile : Default: {{in.metafile | stem}}.scRep.qs . The scRepertoire compatible object in qs/qs2 format Environment Variables \u00b6 type ( choice ) : Default: auto . The type of the data to load. TCR : T cell receptor data BCR : B cell receptor data auto : Automatically detect the type from the metadata. If auto is selected, the type will be determined by the presence of TCRData or BCRData columns in the metadata. If both columns are present, TCR will be selected by default. combineTCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineTCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinetcr combineBCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineBCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinebcr exclude ( auto ) : Default: ['BCRData', 'TCRData', 'RNAData'] . The columns to exclude from the metadata to add to the object. A list of column names to exclude or a string with column names separated by , . By default, BCRData , TCRData and RNAData will be excluded. tmpdir : Default: /tmp . The temporary directory to store the symbolic links to the TCR/BCR data files. format ( choice ) : The format of the TCR/BCR data files. 10X : 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR : AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD : Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion : Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation : Immcantation data, which is usually in a file with data.tsv file. JSON : JSON format, which is usually in a file with .json extension. ParseBio : ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR : MiXCR data, which is usually in a file with clones.tsv file. Omniscope : Omniscope data, which is usually in a file with .csv extension. TRUST4 : TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R : WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html If not provided, the format will be guessed from the file name by scRepertoire::loadContigs() .","title":"ScRepLoading"},{"location":"processes/ScRepLoading/#screploading","text":"Load the single cell TCR/BCR data into a scRepertoire compatible object This process loads the single cell TCR/BCR data into a scRepertoire (>= v2.0.8, < v2.3.2) compatible object. Later, scRepertoire::combineExpression can be used to combine the expression data with the TCR/BCR data. For the data path specified at TCRData / BCRData in the input file ( in.metafile ), will be used to find the TCR/BCR data files and scRepertoire::loadContigs() will be used to load the data. A directory can be specified in TCRData / BCRData , then scRepertoire::loadContigs() will be used directly to load the data from the directory. Otherwise if a file is specified, it will be symbolically linked to a directory for scRepertoire::loadContigs() to load. Note that when the file name can not be recognized by scRepertoire::loadContigs() , envs.format must be set for the correct format of the data.","title":"ScRepLoading"},{"location":"processes/ScRepLoading/#input","text":"metafile : The meta data of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. TCRData / BCRData to assign the path of the data to the samples, and this column will be excluded as metadata.","title":"Input"},{"location":"processes/ScRepLoading/#output","text":"outfile : Default: {{in.metafile | stem}}.scRep.qs . The scRepertoire compatible object in qs/qs2 format","title":"Output"},{"location":"processes/ScRepLoading/#environment-variables","text":"type ( choice ) : Default: auto . The type of the data to load. TCR : T cell receptor data BCR : B cell receptor data auto : Automatically detect the type from the metadata. If auto is selected, the type will be determined by the presence of TCRData or BCRData columns in the metadata. If both columns are present, TCR will be selected by default. combineTCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineTCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinetcr combineBCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineBCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinebcr exclude ( auto ) : Default: ['BCRData', 'TCRData', 'RNAData'] . The columns to exclude from the metadata to add to the object. A list of column names to exclude or a string with column names separated by , . By default, BCRData , TCRData and RNAData will be excluded. tmpdir : Default: /tmp . The temporary directory to store the symbolic links to the TCR/BCR data files. format ( choice ) : The format of the TCR/BCR data files. 10X : 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR : AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD : Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion : Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation : Immcantation data, which is usually in a file with data.tsv file. JSON : JSON format, which is usually in a file with .json extension. ParseBio : ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR : MiXCR data, which is usually in a file with clones.tsv file. Omniscope : Omniscope data, which is usually in a file with .csv extension. TRUST4 : TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R : WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html If not provided, the format will be guessed from the file name by scRepertoire::loadContigs() .","title":"Environment Variables"},{"location":"processes/ScrnaMetabolicLandscape/","text":"ScrnaMetabolicLandscape \u00b6 Metabolic landscape analysis for scRNA-seq data An abstract from https://github.com/LocasaleLab/Single-Cell-Metabolic-Landscape . See also https://pwwang.github.io/biopipen/pipelines/scrna_metabolic/ . This is a group of processes to analyze the metabolic landscape of single cell RNA-seq data. It collects a set of processes and owns a set of arguments. These arguments could either preset the default values for the processes or define the relationships between the processes. Processes \u00b6 The processes in this group implement part of the pipeline below from the original paper. The data preparation, preprocessing and clustering already done by other processes of this pipeline. The processes in this group are used to analyze the metabolic landscape of the data. MetabolicInput : Input for the metabolic pathway analysis pipeline for scRNA-seq data MetabolicExprImputation : Impute the missing values in the expression data MetabolicPathwayActivity : Calculate the pathway activities for each group MetabolicPathwayHeterogeneity : Calculate the pathway heterogeneity MetabolicFeatures : Inter-subset metabolic features - Enrichment analysis in details Group arguments \u00b6 noimpute ( flag ): Whether to do imputation for the dropouts. If False , the values will be left as is. gmtfile : The GMT file with the metabolic pathways. The gene names should match the gene names in the gene list in RNAData or the Seurat object. You can also provide a URL to the GMT file. For example, from https://download.baderlab.org/EM_Genesets/current_release/Human/symbol/ . subset_by (pgarg;readonly): Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. If None, the data will not be subsetted. group_by (pgarg;readonly): Group the data by the given column in the metadata. For example, cluster . mutaters (type=json): Add new columns to the metadata for grouping/subsetting. They are passed to sobj@meta.data |> mutate(...) . For example, {\"timepoint\": \"if_else(treatment == 'control', 'pre', 'post')\"} will add a new column timepoint to the metadata with values of pre and post based on the treatment column. ncores (type=int): Number of cores to use for parallelization for each process Reference \u00b6 Xiao, Zhengtao, Ziwei Dai, and Jason W. Locasale. \"Metabolic landscape of the tumor microenvironment at single cell resolution.\" Nature communications 10.1 (2019): 1-12.","title":"Introduction & Group Arguments"},{"location":"processes/ScrnaMetabolicLandscape/#scrnametaboliclandscape","text":"Metabolic landscape analysis for scRNA-seq data An abstract from https://github.com/LocasaleLab/Single-Cell-Metabolic-Landscape . See also https://pwwang.github.io/biopipen/pipelines/scrna_metabolic/ . This is a group of processes to analyze the metabolic landscape of single cell RNA-seq data. It collects a set of processes and owns a set of arguments. These arguments could either preset the default values for the processes or define the relationships between the processes.","title":"ScrnaMetabolicLandscape"},{"location":"processes/ScrnaMetabolicLandscape/#processes","text":"The processes in this group implement part of the pipeline below from the original paper. The data preparation, preprocessing and clustering already done by other processes of this pipeline. The processes in this group are used to analyze the metabolic landscape of the data. MetabolicInput : Input for the metabolic pathway analysis pipeline for scRNA-seq data MetabolicExprImputation : Impute the missing values in the expression data MetabolicPathwayActivity : Calculate the pathway activities for each group MetabolicPathwayHeterogeneity : Calculate the pathway heterogeneity MetabolicFeatures : Inter-subset metabolic features - Enrichment analysis in details","title":"Processes"},{"location":"processes/ScrnaMetabolicLandscape/#group-arguments","text":"noimpute ( flag ): Whether to do imputation for the dropouts. If False , the values will be left as is. gmtfile : The GMT file with the metabolic pathways. The gene names should match the gene names in the gene list in RNAData or the Seurat object. You can also provide a URL to the GMT file. For example, from https://download.baderlab.org/EM_Genesets/current_release/Human/symbol/ . subset_by (pgarg;readonly): Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. If None, the data will not be subsetted. group_by (pgarg;readonly): Group the data by the given column in the metadata. For example, cluster . mutaters (type=json): Add new columns to the metadata for grouping/subsetting. They are passed to sobj@meta.data |> mutate(...) . For example, {\"timepoint\": \"if_else(treatment == 'control', 'pre', 'post')\"} will add a new column timepoint to the metadata with values of pre and post based on the treatment column. ncores (type=int): Number of cores to use for parallelization for each process","title":"Group arguments"},{"location":"processes/ScrnaMetabolicLandscape/#reference","text":"Xiao, Zhengtao, Ziwei Dai, and Jason W. Locasale. \"Metabolic landscape of the tumor microenvironment at single cell resolution.\" Nature communications 10.1 (2019): 1-12.","title":"Reference"},{"location":"processes/SeuratClusterStats/","text":"SeuratClusterStats \u00b6 Statistics of the clustering. Including the number/fraction of cells in each cluster, the gene expression values and dimension reduction plots. It's also possible to perform stats on TCR clones/clusters or other metadata for each T-cell cluster. Input \u00b6 srtobj : The seurat object loaded by SeuratClustering Output \u00b6 outdir : Default: {{in.srtobj | stem}}.cluster_stats . The output directory. Different types of plots will be saved in different subdirectories. For example, clustree plots will be saved in clustrees subdirectory. For each case in envs.clustrees , both the png and pdf files will be saved. Environment Variables \u00b6 mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . cache ( type=auto ) : Default: /tmp . Whether to cache the plots. Currently only plots for features are supported, since creating the those plots can be time consuming. If True , the plots will be cached in the job output directory, which will be not cleaned up when job is rerunning. clustrees_defaults ( ns ) : The parameters for the clustree plots. devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. prefix ( type=auto ) : Default: True . string indicating columns containing clustering information. The trailing dot is not necessary and will be added automatically. When TRUE , clustrees will be plotted when there is FindClusters or FindClusters.* in the obj@commands . The latter is generated by SeuratSubClustering . This will be ignored when envs.clustrees is specified (the prefix of each case must be specified separately). <more> : Other arguments passed to scplotter::ClustreePlot . See https://pwwang.github.io/scplotter/reference/ClustreePlot.html clustrees ( type=json ) : Default: {} . The cases for clustree plots. Keys are the names of the plots and values are the dicts inherited from env.clustrees_defaults except prefix . There is no default case for clustrees . stats_defaults ( ns ) : The default parameters for stats . This is to do some basic statistics on the clusters/cells. For more comprehensive analysis, see https://pwwang.github.io/scplotter/reference/CellStatPlot.html . The parameters from the cases can overwrite the default parameters. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::CellStatPlot . See https://pwwang.github.io/scplotter/reference/CellStatPlot.html . stats ( type=json ) : Default: {'Number of cells in each cluster (Bar Chart)': Diot({'plot_type': 'bar', 'x_text_angle': 90}), 'Number of cells in each cluster by Sample (Bar Chart)': Diot({'plot_type': 'bar', 'group_by': 'Sample', 'x_text_angle': 90})} . The number/fraction of cells to plot. Keys are the names of the plots and values are the dicts inherited from env.stats_defaults . Here are some examples - { \"nCells_All\" : {}, \"nCells_Sample\" : { \"group_by\" : \"Sample\" }, \"fracCells_Sample\" : { \"scale_y\" : True , \"group_by\" : \"Sample\" , plot_type = \"pie\" }, } ngenes_defaults ( ns ) : The default parameters for ngenes . The default parameters to plot the number of genes expressed in each cell. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : Default: 800 . The height of the plots. width ( type=int ) : Default: 1000 . The width of the plots. ngenes ( type=json ) : Default: {'Number of genes expressed in each cluster': Diot({})} . The number of genes expressed in each cell. Keys are the names of the plots and values are the dicts inherited from env.ngenes_defaults . features_defaults ( ns ) : The default parameters for features . features ( type=auto ) : The features to plot. It can be either a string with comma separated features, a list of features, a file path with file:// prefix with features (one per line), or an integer to use the top N features from VariantFeatures(srtobj) . It can also be a dict with the keys as the feature group names and the values as the features, which is used for heatmap to group the features. order_by ( type=auto ) : The order of the clusters to show on the plot. An expression passed to dplyr::arrange() on the grouped meta data frame (by ident ). For example, you can order the clusters by the activation score of the cluster: desc(mean(ActivationScore, na.rm = TRUE)) , suppose you have a column ActivationScore in the metadata. You may also specify the literal order of the clusters by a list of strings (at least two). subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::FeatureStatPlot . See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html features ( type=json ) : Default: {} . The plots for features, include gene expressions, and columns from metadata. Keys are the titles of the cases and values are the dicts inherited from env.features_defaults . dimplots_defaults ( ns ) : The default parameters for dimplots . group_by : Default: seurat_clusters . The identity to use. If it is from subclustering (reduction sub_umap_<ident> exists), this reduction will be used if reduction is set to dim or auto . split_by : The column name in metadata to split the cells into different plots. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. reduction ( choice ) : Default: dim . Which dimensionality reduction to use. dim : Use Seurat::DimPlot . First searches for umap , then tsne , then pca . If ident is from subclustering, sub_umap_<ident> will be used. auto : Same as dim umap : Use Seurat::UMAPPlot . tsne : Use Seurat::TSNEPlot . pca : Use Seurat::PCAPlot . <more> : See https://pwwang.github.io/scplotter/reference/CellDimPlot.html dimplots ( type=json ) : Default: {'Dimensional reduction plot': Diot({'label': True}), 'VDJ Presence': Diot({'group_by': 'VDJ_Presence'})} . The dimensional reduction plots. Keys are the titles of the plots and values are the dicts inherited from env.dimplots_defaults . It can also have other parameters from scplotter::CellDimPlot . Examples \u00b6 Number of cells in each cluster \u00b6 [SeuratClusterStats.envs.stats] # suppose you have nothing set in `envs.stats_defaults` # otherwise, the settings will be inherited here nCells_All = { } Number of cells in each cluster by groups \u00b6 [SeuratClusterStats.envs.stats] nCells_Sample = { group_by = \"Sample\" } Violin plots for the gene expressions \u00b6 [SeuratClusterStats.envs.features] features = \"CD4,CD8A\" # Remove the dots in the violin plots vlnplots = { pt-size = 0 , kind = \"vln\" } # Don't use the default genes vlnplots_1 = { features = [ \"FOXP3\" , \"IL2RA\" ], pt-size = 0 , kind = \"vln\" } Dimension reduction plot with labels \u00b6 [SeuratClusterStats.envs.dimplots.Idents] label = true","title":"SeuratClusterStats"},{"location":"processes/SeuratClusterStats/#seuratclusterstats","text":"Statistics of the clustering. Including the number/fraction of cells in each cluster, the gene expression values and dimension reduction plots. It's also possible to perform stats on TCR clones/clusters or other metadata for each T-cell cluster.","title":"SeuratClusterStats"},{"location":"processes/SeuratClusterStats/#input","text":"srtobj : The seurat object loaded by SeuratClustering","title":"Input"},{"location":"processes/SeuratClusterStats/#output","text":"outdir : Default: {{in.srtobj | stem}}.cluster_stats . The output directory. Different types of plots will be saved in different subdirectories. For example, clustree plots will be saved in clustrees subdirectory. For each case in envs.clustrees , both the png and pdf files will be saved.","title":"Output"},{"location":"processes/SeuratClusterStats/#environment-variables","text":"mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . cache ( type=auto ) : Default: /tmp . Whether to cache the plots. Currently only plots for features are supported, since creating the those plots can be time consuming. If True , the plots will be cached in the job output directory, which will be not cleaned up when job is rerunning. clustrees_defaults ( ns ) : The parameters for the clustree plots. devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. prefix ( type=auto ) : Default: True . string indicating columns containing clustering information. The trailing dot is not necessary and will be added automatically. When TRUE , clustrees will be plotted when there is FindClusters or FindClusters.* in the obj@commands . The latter is generated by SeuratSubClustering . This will be ignored when envs.clustrees is specified (the prefix of each case must be specified separately). <more> : Other arguments passed to scplotter::ClustreePlot . See https://pwwang.github.io/scplotter/reference/ClustreePlot.html clustrees ( type=json ) : Default: {} . The cases for clustree plots. Keys are the names of the plots and values are the dicts inherited from env.clustrees_defaults except prefix . There is no default case for clustrees . stats_defaults ( ns ) : The default parameters for stats . This is to do some basic statistics on the clusters/cells. For more comprehensive analysis, see https://pwwang.github.io/scplotter/reference/CellStatPlot.html . The parameters from the cases can overwrite the default parameters. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::CellStatPlot . See https://pwwang.github.io/scplotter/reference/CellStatPlot.html . stats ( type=json ) : Default: {'Number of cells in each cluster (Bar Chart)': Diot({'plot_type': 'bar', 'x_text_angle': 90}), 'Number of cells in each cluster by Sample (Bar Chart)': Diot({'plot_type': 'bar', 'group_by': 'Sample', 'x_text_angle': 90})} . The number/fraction of cells to plot. Keys are the names of the plots and values are the dicts inherited from env.stats_defaults . Here are some examples - { \"nCells_All\" : {}, \"nCells_Sample\" : { \"group_by\" : \"Sample\" }, \"fracCells_Sample\" : { \"scale_y\" : True , \"group_by\" : \"Sample\" , plot_type = \"pie\" }, } ngenes_defaults ( ns ) : The default parameters for ngenes . The default parameters to plot the number of genes expressed in each cell. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : Default: 800 . The height of the plots. width ( type=int ) : Default: 1000 . The width of the plots. ngenes ( type=json ) : Default: {'Number of genes expressed in each cluster': Diot({})} . The number of genes expressed in each cell. Keys are the names of the plots and values are the dicts inherited from env.ngenes_defaults . features_defaults ( ns ) : The default parameters for features . features ( type=auto ) : The features to plot. It can be either a string with comma separated features, a list of features, a file path with file:// prefix with features (one per line), or an integer to use the top N features from VariantFeatures(srtobj) . It can also be a dict with the keys as the feature group names and the values as the features, which is used for heatmap to group the features. order_by ( type=auto ) : The order of the clusters to show on the plot. An expression passed to dplyr::arrange() on the grouped meta data frame (by ident ). For example, you can order the clusters by the activation score of the cluster: desc(mean(ActivationScore, na.rm = TRUE)) , suppose you have a column ActivationScore in the metadata. You may also specify the literal order of the clusters by a list of strings (at least two). subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::FeatureStatPlot . See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html features ( type=json ) : Default: {} . The plots for features, include gene expressions, and columns from metadata. Keys are the titles of the cases and values are the dicts inherited from env.features_defaults . dimplots_defaults ( ns ) : The default parameters for dimplots . group_by : Default: seurat_clusters . The identity to use. If it is from subclustering (reduction sub_umap_<ident> exists), this reduction will be used if reduction is set to dim or auto . split_by : The column name in metadata to split the cells into different plots. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. reduction ( choice ) : Default: dim . Which dimensionality reduction to use. dim : Use Seurat::DimPlot . First searches for umap , then tsne , then pca . If ident is from subclustering, sub_umap_<ident> will be used. auto : Same as dim umap : Use Seurat::UMAPPlot . tsne : Use Seurat::TSNEPlot . pca : Use Seurat::PCAPlot . <more> : See https://pwwang.github.io/scplotter/reference/CellDimPlot.html dimplots ( type=json ) : Default: {'Dimensional reduction plot': Diot({'label': True}), 'VDJ Presence': Diot({'group_by': 'VDJ_Presence'})} . The dimensional reduction plots. Keys are the titles of the plots and values are the dicts inherited from env.dimplots_defaults . It can also have other parameters from scplotter::CellDimPlot .","title":"Environment Variables"},{"location":"processes/SeuratClusterStats/#examples","text":"","title":"Examples"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster","text":"[SeuratClusterStats.envs.stats] # suppose you have nothing set in `envs.stats_defaults` # otherwise, the settings will be inherited here nCells_All = { }","title":"Number of cells in each cluster"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-by-groups","text":"[SeuratClusterStats.envs.stats] nCells_Sample = { group_by = \"Sample\" }","title":"Number of cells in each cluster by groups"},{"location":"processes/SeuratClusterStats/#violin-plots-for-the-gene-expressions","text":"[SeuratClusterStats.envs.features] features = \"CD4,CD8A\" # Remove the dots in the violin plots vlnplots = { pt-size = 0 , kind = \"vln\" } # Don't use the default genes vlnplots_1 = { features = [ \"FOXP3\" , \"IL2RA\" ], pt-size = 0 , kind = \"vln\" }","title":"Violin plots for the gene expressions"},{"location":"processes/SeuratClusterStats/#dimension-reduction-plot-with-labels","text":"[SeuratClusterStats.envs.dimplots.Idents] label = true","title":"Dimension reduction plot with labels"},{"location":"processes/SeuratClustering/","text":"SeuratClustering \u00b6 Cluster all cells or selected T/B cells selected by TOrBCellSelection . If [TOrBCellSelection] is not set in the configuration, meaning all cells are T/B cells, this process will be run on all T/B cells. Otherwise, this process will be run on the selected T/B cells by TOrBCellSelection . See also: SeuratClusteringOfAllCells . Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters . Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in seurat_clusters and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in seurat_clusters_<resolution> . The final resolution will be used to define the clusters at seurat_clusters . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. Metadata \u00b6 The metadata of the Seurat object will be updated with the cluster assignments:","title":"SeuratClustering"},{"location":"processes/SeuratClustering/#seuratclustering","text":"Cluster all cells or selected T/B cells selected by TOrBCellSelection . If [TOrBCellSelection] is not set in the configuration, meaning all cells are T/B cells, this process will be run on all T/B cells. Otherwise, this process will be run on the selected T/B cells by TOrBCellSelection . See also: SeuratClusteringOfAllCells .","title":"SeuratClustering"},{"location":"processes/SeuratClustering/#input","text":"srtobj : The seurat object loaded by SeuratPreparing","title":"Input"},{"location":"processes/SeuratClustering/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters .","title":"Output"},{"location":"processes/SeuratClustering/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in seurat_clusters and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in seurat_clusters_<resolution> . The final resolution will be used to define the clusters at seurat_clusters . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results.","title":"Environment Variables"},{"location":"processes/SeuratClustering/#metadata","text":"The metadata of the Seurat object will be updated with the cluster assignments:","title":"Metadata"},{"location":"processes/SeuratClusteringOfAllCells/","text":"SeuratClusteringOfAllCells \u00b6 Cluster all cells, including T cells/non-T cells and B cells/non-Bcells using Seurat. This process will perform clustering on all cells using Seurat package. The clusters will then be used to select T/B cells by TOrBCellSelection process. Note If all your cells are all T/B cells ( TOrBCellSelection is not set in configuration), you should not use this process. Instead, you should use SeuratClustering process for unsupervised clustering, or SeuratMap2Ref process for supervised clustering. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters . Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in seurat_clusters and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in seurat_clusters_<resolution> . The final resolution will be used to define the clusters at seurat_clusters . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results.","title":"SeuratClusteringOfAllCells"},{"location":"processes/SeuratClusteringOfAllCells/#seuratclusteringofallcells","text":"Cluster all cells, including T cells/non-T cells and B cells/non-Bcells using Seurat. This process will perform clustering on all cells using Seurat package. The clusters will then be used to select T/B cells by TOrBCellSelection process. Note If all your cells are all T/B cells ( TOrBCellSelection is not set in configuration), you should not use this process. Instead, you should use SeuratClustering process for unsupervised clustering, or SeuratMap2Ref process for supervised clustering.","title":"SeuratClusteringOfAllCells"},{"location":"processes/SeuratClusteringOfAllCells/#input","text":"srtobj : The seurat object loaded by SeuratPreparing","title":"Input"},{"location":"processes/SeuratClusteringOfAllCells/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters .","title":"Output"},{"location":"processes/SeuratClusteringOfAllCells/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in seurat_clusters and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in seurat_clusters_<resolution> . The final resolution will be used to define the clusters at seurat_clusters . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results.","title":"Environment Variables"},{"location":"processes/SeuratMap2Ref/","text":"SeuratMap2Ref \u00b6 Map the seurat object to reference See: https://satijalab.org/seurat/articles/integration_mapping.html and https://satijalab.org/seurat/articles/multimodal_reference_mapping.html Input \u00b6 sobjfile : The seurat object Output \u00b6 outfile : Default: {{in.sobjfile | stem}}.qs . The rds file of seurat object with cell type annotated. Note that the reduction name will be ref.umap for the mapping. To visualize the mapping, you should use ref.umap as the reduction name. Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. When split_by is used, this will be the number of cores for each object to map to the reference. When split_by is not used, this is used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/archive/v3.0/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. This is helpful when we want to create new columns for split_by . use : A column name of metadata from the reference (e.g. celltype.l1 , celltype.l2 ) to transfer to the query as the cell types (ident) for downstream analysis. This field is required. If you want to transfer multiple columns, you can use envs.MapQuery.refdata . ident : Default: seurat_clusters . The name of the ident for query transferred from envs.use of the reference. ref : The reference seurat object file. Either an RDS file or a h5seurat file that can be loaded by Seurat::LoadH5Seurat() . The file type is determined by the extension. .rds or .RDS for RDS file, .h5seurat or .h5 for h5seurat file. refnorm ( choice ) : Default: auto . Normalization method the reference used. The same method will be used for the query. LogNormalize : Using NormalizeData . SCTransform : Using SCTransform . SCT : Alias of SCTransform. auto : Automatically detect the normalization method. If the default assay of reference is SCT , then SCTransform will be used. split_by : The column name in metadata to split the query into multiple objects. This helps when the original query is too large to process. skip_if_normalized : Default: True . Skip normalization if the query is already normalized. Since the object is supposed to be generated by SeuratPreparing , it is already normalized. However, a different normalization method may be used. If the reference is normalized by the same method as the query, the normalization can be skipped. Otherwise, the normalization cannot be skipped. The normalization method used for the query set is determined by the default assay. If SCT , then SCTransform is used; otherwise, NormalizeData is used. You can set this to False to force re-normalization (with or without the arguments previously used). SCTransform ( ns ) : Arguments for SCTransform() do-correct-umi ( flag ) : Default: False . Place corrected UMI matrix in assay counts layer? do-scale ( flag ) : Default: False . Whether to scale residuals to have unit variance? do-center ( flag ) : Default: True . Whether to center residuals to have mean zero? <more> : See https://satijalab.org/seurat/reference/sctransform . Note that the hyphen ( - ) will be transformed into . for the keys. NormalizeData ( ns ) : Arguments for NormalizeData() normalization-method : Default: LogNormalize . Normalization method. <more> : See https://satijalab.org/seurat/reference/normalizedata . Note that the hyphen ( - ) will be transformed into . for the keys. FindTransferAnchors ( ns ) : Arguments for FindTransferAnchors() normalization-method ( choice ) : Name of normalization method used. LogNormalize : Log-normalize the data matrix SCT : Scale data using the SCTransform method auto : Automatically detect the normalization method. See envs.refnorm . reference-reduction : Name of dimensional reduction to use from the reference if running the pcaproject workflow. Optionally enables reuse of precomputed reference dimensional reduction. <more> : See https://satijalab.org/seurat/reference/findtransferanchors . Note that the hyphen ( - ) will be transformed into . for the keys. MapQuery ( ns ) : Arguments for MapQuery() reference-reduction : Name of reduction to use from the reference for neighbor finding reduction-model : DimReduc object that contains the umap model. refdata ( type=json ) : Default: {} . Extra data to transfer from the reference to the query. <more> : See https://satijalab.org/seurat/reference/mapquery . Note that the hyphen ( - ) will be transformed into . for the keys. cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory. plots ( type=json ) : Default: {'Mapped Identity': Diot({'features': '{ident}:{use}'}), 'Mapping Score': Diot({'features': '{ident}.score'})} . The plots to generate. The keys are the names of the plots and the values are the arguments for the plot. The arguments will be passed to biopipen.utils::VizSeuratMap2Ref() to generate the plots. The plots will be saved to the output directory. See https://pwwang.github.io/biopipen.utils.R/reference/VizSeuratMap2Ref.html . Metadata \u00b6 The metadata of the Seurat object will be updated with the cluster assignments (column name determined by envs.name ):","title":"SeuratMap2Ref"},{"location":"processes/SeuratMap2Ref/#seuratmap2ref","text":"Map the seurat object to reference See: https://satijalab.org/seurat/articles/integration_mapping.html and https://satijalab.org/seurat/articles/multimodal_reference_mapping.html","title":"SeuratMap2Ref"},{"location":"processes/SeuratMap2Ref/#input","text":"sobjfile : The seurat object","title":"Input"},{"location":"processes/SeuratMap2Ref/#output","text":"outfile : Default: {{in.sobjfile | stem}}.qs . The rds file of seurat object with cell type annotated. Note that the reduction name will be ref.umap for the mapping. To visualize the mapping, you should use ref.umap as the reduction name.","title":"Output"},{"location":"processes/SeuratMap2Ref/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. When split_by is used, this will be the number of cores for each object to map to the reference. When split_by is not used, this is used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/archive/v3.0/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. This is helpful when we want to create new columns for split_by . use : A column name of metadata from the reference (e.g. celltype.l1 , celltype.l2 ) to transfer to the query as the cell types (ident) for downstream analysis. This field is required. If you want to transfer multiple columns, you can use envs.MapQuery.refdata . ident : Default: seurat_clusters . The name of the ident for query transferred from envs.use of the reference. ref : The reference seurat object file. Either an RDS file or a h5seurat file that can be loaded by Seurat::LoadH5Seurat() . The file type is determined by the extension. .rds or .RDS for RDS file, .h5seurat or .h5 for h5seurat file. refnorm ( choice ) : Default: auto . Normalization method the reference used. The same method will be used for the query. LogNormalize : Using NormalizeData . SCTransform : Using SCTransform . SCT : Alias of SCTransform. auto : Automatically detect the normalization method. If the default assay of reference is SCT , then SCTransform will be used. split_by : The column name in metadata to split the query into multiple objects. This helps when the original query is too large to process. skip_if_normalized : Default: True . Skip normalization if the query is already normalized. Since the object is supposed to be generated by SeuratPreparing , it is already normalized. However, a different normalization method may be used. If the reference is normalized by the same method as the query, the normalization can be skipped. Otherwise, the normalization cannot be skipped. The normalization method used for the query set is determined by the default assay. If SCT , then SCTransform is used; otherwise, NormalizeData is used. You can set this to False to force re-normalization (with or without the arguments previously used). SCTransform ( ns ) : Arguments for SCTransform() do-correct-umi ( flag ) : Default: False . Place corrected UMI matrix in assay counts layer? do-scale ( flag ) : Default: False . Whether to scale residuals to have unit variance? do-center ( flag ) : Default: True . Whether to center residuals to have mean zero? <more> : See https://satijalab.org/seurat/reference/sctransform . Note that the hyphen ( - ) will be transformed into . for the keys. NormalizeData ( ns ) : Arguments for NormalizeData() normalization-method : Default: LogNormalize . Normalization method. <more> : See https://satijalab.org/seurat/reference/normalizedata . Note that the hyphen ( - ) will be transformed into . for the keys. FindTransferAnchors ( ns ) : Arguments for FindTransferAnchors() normalization-method ( choice ) : Name of normalization method used. LogNormalize : Log-normalize the data matrix SCT : Scale data using the SCTransform method auto : Automatically detect the normalization method. See envs.refnorm . reference-reduction : Name of dimensional reduction to use from the reference if running the pcaproject workflow. Optionally enables reuse of precomputed reference dimensional reduction. <more> : See https://satijalab.org/seurat/reference/findtransferanchors . Note that the hyphen ( - ) will be transformed into . for the keys. MapQuery ( ns ) : Arguments for MapQuery() reference-reduction : Name of reduction to use from the reference for neighbor finding reduction-model : DimReduc object that contains the umap model. refdata ( type=json ) : Default: {} . Extra data to transfer from the reference to the query. <more> : See https://satijalab.org/seurat/reference/mapquery . Note that the hyphen ( - ) will be transformed into . for the keys. cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory. plots ( type=json ) : Default: {'Mapped Identity': Diot({'features': '{ident}:{use}'}), 'Mapping Score': Diot({'features': '{ident}.score'})} . The plots to generate. The keys are the names of the plots and the values are the arguments for the plot. The arguments will be passed to biopipen.utils::VizSeuratMap2Ref() to generate the plots. The plots will be saved to the output directory. See https://pwwang.github.io/biopipen.utils.R/reference/VizSeuratMap2Ref.html .","title":"Environment Variables"},{"location":"processes/SeuratMap2Ref/#metadata","text":"The metadata of the Seurat object will be updated with the cluster assignments (column name determined by envs.name ):","title":"Metadata"},{"location":"processes/SeuratPreparing/","text":"SeuratPreparing \u00b6 Load, prepare and apply QC to data, using Seurat This process will - - Prepare the seurat object - Apply QC to the data - Integrate the data from different samples See also - https://satijalab.org/seurat/articles/pbmc3k_tutorial.html#standard-pre-processing-workflow-1) - https://satijalab.org/seurat/articles/integration_introduction This process will read the scRNA-seq data, based on the information provided by SampleInfo , specifically, the paths specified by the RNAData column. Those paths should be either paths to directoies containing matrix.mtx , barcodes.tsv and features.tsv files that can be loaded by Seurat::Read10X() , or paths of loom files that can be loaded by SeuratDisk::LoadLoom() , or paths to h5 files that can be loaded by Seurat::Read10X_h5() . Each sample will be loaded individually and then merged into one Seurat object, and then perform QC. In order to perform QC, some additional columns are added to the meta data of the Seurat object. They are: precent.mt : The percentage of mitochondrial genes. percent.ribo : The percentage of ribosomal genes. precent.hb : The percentage of hemoglobin genes. percent.plat : The percentage of platelet genes. For integration, two routes are available: Performing integration on datasets normalized with SCTransform Using NormalizeData and FindIntegrationAnchors Note When using SCTransform , the default Assay will be set to SCT in output, rather than RNA . If you are using cca or rpca interation, the default assay will be integrated . Note From biopipen v0.23.0, this requires Seurat v5.0.0 or higher. See also Preparing the input . Input \u00b6 metafile : The metadata of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. RNAData to assign the path of the data to the samples The path will be read by Read10X() from Seurat , or the path to the h5 file that can be read by Read10X_h5() from Seurat . It can also be an RDS or qs2 file containing a Seurat object. Note that it must has a column named Sample in the meta.data to specify the sample names. Output \u00b6 outfile : Default: {{in.metafile | stem}}.seurat.qs . The qs2 file with the Seurat object with all samples integrated. Note that the cell ids are prefixied with sample names. Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to the cells. These new columns will be added to the metadata of the Seurat object and will be saved in the output file. min_cells ( type=int ) : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. min_features ( type=int ) : Default: 0 . The minimum number of features that a cell must express to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. cell_qc : Filter expression to filter cells, using tidyrseurat::filter() . It can also be a dictionary of expressions, where the names of the list are sample names. You can have a default expression in the list with the name \"DEFAULT\" for the samples that are not listed. Available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . Example Including the columns added above, all available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . For example: [SeuratPreparing.envs] cell_qc = \"nFeature_RNA > 200 & percent.mt < 5\" will keep cells with more than 200 genes and less than 5%% mitochondrial genes. gene_qc ( ns ) : Filter genes. gene_qc is applied after cell_qc . min_cells : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. excludes : Default: [] . The genes to exclude. Multiple genes can be specified by comma separated values, or as a list. Example [SeuratPreparing.envs] gene_qc = { min_cells = 3 } will keep genes that are expressed in at least 3 cells. qc_plots ( type=json ) : Default: {'Violin Plots': Diot({'kind': 'cell', 'plot_type': 'violin', 'devpars': Diot({'res': 100, 'height': 600, 'width': 1200})}), 'Scatter Plots': Diot({'kind': 'cell', 'plot_type': 'scatter', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Ridge Plots': Diot({'kind': 'cell', 'plot_type': 'ridge', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Distribution of number of cells a gene is expressed in': Diot({'kind': 'gene', 'plot_type': 'histogram', 'devpars': Diot({'res': 100, 'height': 1200, 'width': 1200})})} . The plots for QC metrics. It should be a json (or python dict) with the keys as the names of the plots and the values also as dicts with the following keys: kind: The kind of QC. Either gene or cell (default). devpars: The device parameters for the plot. A dict with res , height , and width . more_formats: The formats to save the plots other than png . save_code: Whether to save the code to reproduce the plot. other arguments passed to biopipen.utils::VizSeuratCellQC when kind is cell or biopipen.utils::VizSeuratGeneQC when kind is gene . use_sct ( flag ) : Default: False . Whether use SCTransform routine to integrate samples or not. Before the following procedures, the RNA layer will be split by samples. If False , following procedures will be performed in the order: * NormalizeData . * FindVariableFeatures . * ScaleData . See https://satijalab.org/seurat/articles/seurat5_integration#layers-in-the-seurat-v5-object and https://satijalab.org/seurat/articles/pbmc3k_tutorial.html If True , following procedures will be performed in the order: * SCTransform . See https://satijalab.org/seurat/articles/seurat5_integration#perform-streamlined-one-line-integrative-analysis no_integration ( flag ) : Default: False . Whether to skip integration or not. NormalizeData ( ns ) : Arguments for NormalizeData() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/normalizedata FindVariableFeatures ( ns ) : Arguments for FindVariableFeatures() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/findvariablefeatures ScaleData ( ns ) : Arguments for ScaleData() . object and features is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/scaledata RunPCA ( ns ) : Arguments for RunPCA() . object and features is specified internally, and - in the key will be replaced with . . npcs ( type=int ) : The number of PCs to compute. For each sample, npcs will be no larger than the number of columns - 1. <more> : See https://satijalab.org/seurat/reference/runpca SCTransform ( ns ) : Arguments for SCTransform() . object is specified internally, and - in the key will be replaced with . . return-only-var-genes : Default: True . Whether to return only variable genes. min_cells : Default: 5 . The minimum number of cells that a gene must be expressed in to be kept. A hidden argument of SCTransform to filter genes. If you try to keep all genes in the RNA assay, you can set min_cells to 0 and return-only-var-genes to False . See https://github.com/satijalab/seurat/issues/3598#issuecomment-715505537 <more> : See https://satijalab.org/seurat/reference/sctransform verbose : Default: True . IntegrateLayers ( ns ) : Arguments for IntegrateLayers() . object is specified internally, and - in the key will be replaced with . . When use_sct is True , normalization-method defaults to SCT . method ( choice ) : Default: harmony . The method to use for integration. CCAIntegration : Use Seurat::CCAIntegration . CCA : Same as CCAIntegration . cca : Same as CCAIntegration . RPCAIntegration : Use Seurat::RPCAIntegration . RPCA : Same as RPCAIntegration . rpca : Same as RPCAIntegration . HarmonyIntegration : Use Seurat::HarmonyIntegration . Harmony : Same as HarmonyIntegration . harmony : Same as HarmonyIntegration . FastMNNIntegration : Use Seurat::FastMNNIntegration . FastMNN : Same as FastMNNIntegration . fastmnn : Same as FastMNNIntegration . scVIIntegration : Use Seurat::scVIIntegration . scVI : Same as scVIIntegration . scvi : Same as scVIIntegration . <more> : See https://satijalab.org/seurat/reference/integratelayers doublet_detector ( choice ) : Default: none . The doublet detector to use. none : Do not use any doublet detector. DoubletFinder : Use DoubletFinder to detect doublets. doubletfinder : Same as DoubletFinder . scDblFinder : Use scDblFinder to detect doublets. scdblfinder : Same as scDblFinder . DoubletFinder ( ns ) : Arguments to run DoubletFinder . See also https://demultiplexing-doublet-detecting-docs.readthedocs.io/en/latest/DoubletFinder.html . PCs ( type=int ) : Default: 10 . Number of PCs to use for 'doubletFinder' function. doublets ( type=float ) : Default: 0.075 . Number of expected doublets as a proportion of the pool size. pN ( type=float ) : Default: 0.25 . Number of doublets to simulate as a proportion of the pool size. ncores ( type=int ) : Default: 1 . Number of cores to use for DoubletFinder::paramSweep . Set to None to use envs.ncores . Since parallelization of the function usually exhausts memory, if big envs.ncores does not work for DoubletFinder , set this to a smaller number. scDblFinder ( ns ) : Arguments to run scDblFinder . dbr ( type=float ) : Default: 0.075 . The expected doublet rate. ncores ( type=int ) : Default: 1 . Number of cores to use for scDblFinder . Set to None to use envs.ncores . <more> : See https://rdrr.io/bioc/scDblFinder/man/scDblFinder.html . cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory. Metadata \u00b6 Here is the demonstration of basic metadata for the Seurat object. Future processes will use it and/or add more metadata to the Seurat object.","title":"SeuratPreparing"},{"location":"processes/SeuratPreparing/#seuratpreparing","text":"Load, prepare and apply QC to data, using Seurat This process will - - Prepare the seurat object - Apply QC to the data - Integrate the data from different samples See also - https://satijalab.org/seurat/articles/pbmc3k_tutorial.html#standard-pre-processing-workflow-1) - https://satijalab.org/seurat/articles/integration_introduction This process will read the scRNA-seq data, based on the information provided by SampleInfo , specifically, the paths specified by the RNAData column. Those paths should be either paths to directoies containing matrix.mtx , barcodes.tsv and features.tsv files that can be loaded by Seurat::Read10X() , or paths of loom files that can be loaded by SeuratDisk::LoadLoom() , or paths to h5 files that can be loaded by Seurat::Read10X_h5() . Each sample will be loaded individually and then merged into one Seurat object, and then perform QC. In order to perform QC, some additional columns are added to the meta data of the Seurat object. They are: precent.mt : The percentage of mitochondrial genes. percent.ribo : The percentage of ribosomal genes. precent.hb : The percentage of hemoglobin genes. percent.plat : The percentage of platelet genes. For integration, two routes are available: Performing integration on datasets normalized with SCTransform Using NormalizeData and FindIntegrationAnchors Note When using SCTransform , the default Assay will be set to SCT in output, rather than RNA . If you are using cca or rpca interation, the default assay will be integrated . Note From biopipen v0.23.0, this requires Seurat v5.0.0 or higher. See also Preparing the input .","title":"SeuratPreparing"},{"location":"processes/SeuratPreparing/#input","text":"metafile : The metadata of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. RNAData to assign the path of the data to the samples The path will be read by Read10X() from Seurat , or the path to the h5 file that can be read by Read10X_h5() from Seurat . It can also be an RDS or qs2 file containing a Seurat object. Note that it must has a column named Sample in the meta.data to specify the sample names.","title":"Input"},{"location":"processes/SeuratPreparing/#output","text":"outfile : Default: {{in.metafile | stem}}.seurat.qs . The qs2 file with the Seurat object with all samples integrated. Note that the cell ids are prefixied with sample names.","title":"Output"},{"location":"processes/SeuratPreparing/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to the cells. These new columns will be added to the metadata of the Seurat object and will be saved in the output file. min_cells ( type=int ) : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. min_features ( type=int ) : Default: 0 . The minimum number of features that a cell must express to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. cell_qc : Filter expression to filter cells, using tidyrseurat::filter() . It can also be a dictionary of expressions, where the names of the list are sample names. You can have a default expression in the list with the name \"DEFAULT\" for the samples that are not listed. Available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . Example Including the columns added above, all available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . For example: [SeuratPreparing.envs] cell_qc = \"nFeature_RNA > 200 & percent.mt < 5\" will keep cells with more than 200 genes and less than 5%% mitochondrial genes. gene_qc ( ns ) : Filter genes. gene_qc is applied after cell_qc . min_cells : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. excludes : Default: [] . The genes to exclude. Multiple genes can be specified by comma separated values, or as a list. Example [SeuratPreparing.envs] gene_qc = { min_cells = 3 } will keep genes that are expressed in at least 3 cells. qc_plots ( type=json ) : Default: {'Violin Plots': Diot({'kind': 'cell', 'plot_type': 'violin', 'devpars': Diot({'res': 100, 'height': 600, 'width': 1200})}), 'Scatter Plots': Diot({'kind': 'cell', 'plot_type': 'scatter', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Ridge Plots': Diot({'kind': 'cell', 'plot_type': 'ridge', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Distribution of number of cells a gene is expressed in': Diot({'kind': 'gene', 'plot_type': 'histogram', 'devpars': Diot({'res': 100, 'height': 1200, 'width': 1200})})} . The plots for QC metrics. It should be a json (or python dict) with the keys as the names of the plots and the values also as dicts with the following keys: kind: The kind of QC. Either gene or cell (default). devpars: The device parameters for the plot. A dict with res , height , and width . more_formats: The formats to save the plots other than png . save_code: Whether to save the code to reproduce the plot. other arguments passed to biopipen.utils::VizSeuratCellQC when kind is cell or biopipen.utils::VizSeuratGeneQC when kind is gene . use_sct ( flag ) : Default: False . Whether use SCTransform routine to integrate samples or not. Before the following procedures, the RNA layer will be split by samples. If False , following procedures will be performed in the order: * NormalizeData . * FindVariableFeatures . * ScaleData . See https://satijalab.org/seurat/articles/seurat5_integration#layers-in-the-seurat-v5-object and https://satijalab.org/seurat/articles/pbmc3k_tutorial.html If True , following procedures will be performed in the order: * SCTransform . See https://satijalab.org/seurat/articles/seurat5_integration#perform-streamlined-one-line-integrative-analysis no_integration ( flag ) : Default: False . Whether to skip integration or not. NormalizeData ( ns ) : Arguments for NormalizeData() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/normalizedata FindVariableFeatures ( ns ) : Arguments for FindVariableFeatures() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/findvariablefeatures ScaleData ( ns ) : Arguments for ScaleData() . object and features is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/scaledata RunPCA ( ns ) : Arguments for RunPCA() . object and features is specified internally, and - in the key will be replaced with . . npcs ( type=int ) : The number of PCs to compute. For each sample, npcs will be no larger than the number of columns - 1. <more> : See https://satijalab.org/seurat/reference/runpca SCTransform ( ns ) : Arguments for SCTransform() . object is specified internally, and - in the key will be replaced with . . return-only-var-genes : Default: True . Whether to return only variable genes. min_cells : Default: 5 . The minimum number of cells that a gene must be expressed in to be kept. A hidden argument of SCTransform to filter genes. If you try to keep all genes in the RNA assay, you can set min_cells to 0 and return-only-var-genes to False . See https://github.com/satijalab/seurat/issues/3598#issuecomment-715505537 <more> : See https://satijalab.org/seurat/reference/sctransform verbose : Default: True . IntegrateLayers ( ns ) : Arguments for IntegrateLayers() . object is specified internally, and - in the key will be replaced with . . When use_sct is True , normalization-method defaults to SCT . method ( choice ) : Default: harmony . The method to use for integration. CCAIntegration : Use Seurat::CCAIntegration . CCA : Same as CCAIntegration . cca : Same as CCAIntegration . RPCAIntegration : Use Seurat::RPCAIntegration . RPCA : Same as RPCAIntegration . rpca : Same as RPCAIntegration . HarmonyIntegration : Use Seurat::HarmonyIntegration . Harmony : Same as HarmonyIntegration . harmony : Same as HarmonyIntegration . FastMNNIntegration : Use Seurat::FastMNNIntegration . FastMNN : Same as FastMNNIntegration . fastmnn : Same as FastMNNIntegration . scVIIntegration : Use Seurat::scVIIntegration . scVI : Same as scVIIntegration . scvi : Same as scVIIntegration . <more> : See https://satijalab.org/seurat/reference/integratelayers doublet_detector ( choice ) : Default: none . The doublet detector to use. none : Do not use any doublet detector. DoubletFinder : Use DoubletFinder to detect doublets. doubletfinder : Same as DoubletFinder . scDblFinder : Use scDblFinder to detect doublets. scdblfinder : Same as scDblFinder . DoubletFinder ( ns ) : Arguments to run DoubletFinder . See also https://demultiplexing-doublet-detecting-docs.readthedocs.io/en/latest/DoubletFinder.html . PCs ( type=int ) : Default: 10 . Number of PCs to use for 'doubletFinder' function. doublets ( type=float ) : Default: 0.075 . Number of expected doublets as a proportion of the pool size. pN ( type=float ) : Default: 0.25 . Number of doublets to simulate as a proportion of the pool size. ncores ( type=int ) : Default: 1 . Number of cores to use for DoubletFinder::paramSweep . Set to None to use envs.ncores . Since parallelization of the function usually exhausts memory, if big envs.ncores does not work for DoubletFinder , set this to a smaller number. scDblFinder ( ns ) : Arguments to run scDblFinder . dbr ( type=float ) : Default: 0.075 . The expected doublet rate. ncores ( type=int ) : Default: 1 . Number of cores to use for scDblFinder . Set to None to use envs.ncores . <more> : See https://rdrr.io/bioc/scDblFinder/man/scDblFinder.html . cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory.","title":"Environment Variables"},{"location":"processes/SeuratPreparing/#metadata","text":"Here is the demonstration of basic metadata for the Seurat object. Future processes will use it and/or add more metadata to the Seurat object.","title":"Metadata"},{"location":"processes/SeuratSubClustering/","text":"SeuratSubClustering \u00b6 Sub-clustering for all or selected T/B cells. Find clusters of a subset of cells. It's unlike [ Seurat::FindSubCluster ], which only finds subclusters of a single cluster. Instead, it will perform the whole clustering procedure on the subset of cells. One can use metadata to specify the subset of cells to perform clustering on. For the subset of cells, the reductions will be re-performed on the subset of cells, and then the clustering will be performed on the subset of cells. The reduction will be saved in object@reduction$<casename>.<reduction> of the original object and the clustering will be saved in the metadata of the original object using the casename as the column name. Input \u00b6 srtobj : The seurat object in RDS or qs/qs2 format. Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with the subclustering information in qs/qs2 format. Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. subset : An expression to subset the cells, will be passed to tidyseurat::filter() . RunPCA ( ns ) : Arguments for RunPCA() . object is specified internally as the subset object, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/runpca RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally as the subset object, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, object@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be prefixed with \"s\". The first cluster will be \"s1\", instead of \"s0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <casename>_<resolution> . The final resolution will be used to define the clusters at <casename> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Whether to cache the results. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. cases ( type=json ) : Default: {} . The cases to perform subclustering. Keys are the names of the cases and values are the dicts inherited from envs except mutaters and cache . If empty, a case with name subcluster will be created with default parameters. The case name will be passed to biopipen.utils::SeuratSubCluster() as name . It will be used as the prefix for the reduction name, keys and cluster names. For reduction keys, it will be toupper(<name>) + \"PC_\" and toupper(<name>) + \"UMAP_\". For cluster names, it will be <name> + \".\" + resolution. And the final cluster name will be <name> . Note that the name should be alphanumeric and anything other than alphanumeric will be removed. Metadata \u00b6 The metadata of the Seurat object will be updated with the sub-clusters specified by names (keys) of envs.cases :","title":"SeuratSubClustering"},{"location":"processes/SeuratSubClustering/#seuratsubclustering","text":"Sub-clustering for all or selected T/B cells. Find clusters of a subset of cells. It's unlike [ Seurat::FindSubCluster ], which only finds subclusters of a single cluster. Instead, it will perform the whole clustering procedure on the subset of cells. One can use metadata to specify the subset of cells to perform clustering on. For the subset of cells, the reductions will be re-performed on the subset of cells, and then the clustering will be performed on the subset of cells. The reduction will be saved in object@reduction$<casename>.<reduction> of the original object and the clustering will be saved in the metadata of the original object using the casename as the column name.","title":"SeuratSubClustering"},{"location":"processes/SeuratSubClustering/#input","text":"srtobj : The seurat object in RDS or qs/qs2 format.","title":"Input"},{"location":"processes/SeuratSubClustering/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with the subclustering information in qs/qs2 format.","title":"Output"},{"location":"processes/SeuratSubClustering/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. subset : An expression to subset the cells, will be passed to tidyseurat::filter() . RunPCA ( ns ) : Arguments for RunPCA() . object is specified internally as the subset object, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/runpca RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally as the subset object, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, object@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be prefixed with \"s\". The first cluster will be \"s1\", instead of \"s0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <casename>_<resolution> . The final resolution will be used to define the clusters at <casename> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Whether to cache the results. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. cases ( type=json ) : Default: {} . The cases to perform subclustering. Keys are the names of the cases and values are the dicts inherited from envs except mutaters and cache . If empty, a case with name subcluster will be created with default parameters. The case name will be passed to biopipen.utils::SeuratSubCluster() as name . It will be used as the prefix for the reduction name, keys and cluster names. For reduction keys, it will be toupper(<name>) + \"PC_\" and toupper(<name>) + \"UMAP_\". For cluster names, it will be <name> + \".\" + resolution. And the final cluster name will be <name> . Note that the name should be alphanumeric and anything other than alphanumeric will be removed.","title":"Environment Variables"},{"location":"processes/SeuratSubClustering/#metadata","text":"The metadata of the Seurat object will be updated with the sub-clusters specified by names (keys) of envs.cases :","title":"Metadata"},{"location":"processes/TCRClustering/","text":"TCRClustering \u00b6 Cluster the TCR clones by their CDR3 sequences You can disable this by remving the whole sections of TCRClustering in the config file. This process is used to cluster TCR clones based on their CDR3 sequences. It uses either GIANA Zhang, Hongyi, Xiaowei Zhan, and Bo Li. \"GIANA allows computationally-efficient TCR clustering and multi-disease repertoire classification by isometric transformation.\" Nature communications 12.1 (2021): 1-11. Or ClusTCR Sebastiaan Valkiers, Max Van Houcke, Kris Laukens, Pieter Meysman, ClusTCR: a Python interface for rapid clustering of large sets of CDR3 sequences with unknown antigen specificity, Bioinformatics, 2021. Both methods are based on the Faiss Clustering Library , for efficient similarity search and clustering of dense vectors, so both methods yield similar results. A text file will be generated with the cluster assignments for each cell, together with the immunarch object (in R ) with the cluster assignments at TCR_Clsuter column. This information will then be merged to a Seurat object for further downstream analysis. The cluster assignments are prefixed with S_ or M_ to indicate whether a cluster has only one unique CDR3 sequence or multiple CDR3 sequences. Note that a cluster with S_ prefix may still have multiple cells, as the same CDR3 sequence may be shared by multiple cells. Input \u00b6 screpfile : The TCR data object loaded by scRepertoire::CombineTCR() or scRepertoire::CombineExpression() Output \u00b6 outfile : Default: {{in.screpfile | stem}}.tcr_clustered.qs . The scRepertoire object in qs with TCR cluster information. Column TCR_Cluster will be added to the metadata. Environment Variables \u00b6 tool ( choice ) : Default: GIANA . The tool used to do the clustering, either GIANA or ClusTCR . For GIANA, using TRBV mutations is not supported GIANA : by Li lab at UT Southwestern Medical Center ClusTCR : by Sebastiaan Valkiers, etc python : Default: python . The path of python with GIANA 's dependencies installed or with clusTCR installed. Depending on the tool you choose. within_sample ( flag ) : Default: True . Whether to cluster the TCR clones within each sample. When in.screpfile is a Seurat object, the samples are marked by the Sample column in the metadata. args ( type=json ) : Default: {} . The arguments for the clustering tool For GIANA, they will be passed to python GIAna.py See https://github.com/s175573/GIANA#usage . For ClusTCR, they will be passed to clustcr.Clustering(...) See https://svalkiers.github.io/clusTCR/docs/clustering/how-to-use.html#clustering . chain ( choice ) : Default: both . The TCR chain to use for clustering. alpha : TCR alpha chain (the first sequence in CTaa, separated by _ ) beta : TCR beta chain (the second sequence in CTaa, separated by _ ) both : Both TCR alpha and beta chains","title":"TCRClustering"},{"location":"processes/TCRClustering/#tcrclustering","text":"Cluster the TCR clones by their CDR3 sequences You can disable this by remving the whole sections of TCRClustering in the config file. This process is used to cluster TCR clones based on their CDR3 sequences. It uses either GIANA Zhang, Hongyi, Xiaowei Zhan, and Bo Li. \"GIANA allows computationally-efficient TCR clustering and multi-disease repertoire classification by isometric transformation.\" Nature communications 12.1 (2021): 1-11. Or ClusTCR Sebastiaan Valkiers, Max Van Houcke, Kris Laukens, Pieter Meysman, ClusTCR: a Python interface for rapid clustering of large sets of CDR3 sequences with unknown antigen specificity, Bioinformatics, 2021. Both methods are based on the Faiss Clustering Library , for efficient similarity search and clustering of dense vectors, so both methods yield similar results. A text file will be generated with the cluster assignments for each cell, together with the immunarch object (in R ) with the cluster assignments at TCR_Clsuter column. This information will then be merged to a Seurat object for further downstream analysis. The cluster assignments are prefixed with S_ or M_ to indicate whether a cluster has only one unique CDR3 sequence or multiple CDR3 sequences. Note that a cluster with S_ prefix may still have multiple cells, as the same CDR3 sequence may be shared by multiple cells.","title":"TCRClustering"},{"location":"processes/TCRClustering/#input","text":"screpfile : The TCR data object loaded by scRepertoire::CombineTCR() or scRepertoire::CombineExpression()","title":"Input"},{"location":"processes/TCRClustering/#output","text":"outfile : Default: {{in.screpfile | stem}}.tcr_clustered.qs . The scRepertoire object in qs with TCR cluster information. Column TCR_Cluster will be added to the metadata.","title":"Output"},{"location":"processes/TCRClustering/#environment-variables","text":"tool ( choice ) : Default: GIANA . The tool used to do the clustering, either GIANA or ClusTCR . For GIANA, using TRBV mutations is not supported GIANA : by Li lab at UT Southwestern Medical Center ClusTCR : by Sebastiaan Valkiers, etc python : Default: python . The path of python with GIANA 's dependencies installed or with clusTCR installed. Depending on the tool you choose. within_sample ( flag ) : Default: True . Whether to cluster the TCR clones within each sample. When in.screpfile is a Seurat object, the samples are marked by the Sample column in the metadata. args ( type=json ) : Default: {} . The arguments for the clustering tool For GIANA, they will be passed to python GIAna.py See https://github.com/s175573/GIANA#usage . For ClusTCR, they will be passed to clustcr.Clustering(...) See https://svalkiers.github.io/clusTCR/docs/clustering/how-to-use.html#clustering . chain ( choice ) : Default: both . The TCR chain to use for clustering. alpha : TCR alpha chain (the first sequence in CTaa, separated by _ ) beta : TCR beta chain (the second sequence in CTaa, separated by _ ) both : Both TCR alpha and beta chains","title":"Environment Variables"},{"location":"processes/TESSA/","text":"TESSA \u00b6 Tessa is a Bayesian model to integrate T cell receptor (TCR) sequence profiling with transcriptomes of T cells. Enabled by the recently developed single cell sequencing techniques, which provide both TCR sequences and RNA sequences of each T cell concurrently, Tessa maps the functional landscape of the TCR repertoire, and generates insights into understanding human immune response to diseases. As the first part of tessa, BriseisEncoder is employed prior to the Bayesian algorithm to capture the TCR sequence features and create numerical embeddings. We showed that the reconstructed Atchley Factor matrices and CDR3 sequences, generated through the numerical embeddings, are highly similar to their original counterparts. The CDR3 peptide sequences are constructed via a RandomForest model applied on the reconstructed Atchley Factor matrices. See https://github.com/jcao89757/TESSA When finished, two columns will be added to the meta.data of the Seurat object: TESSA_Cluster : The cluster assignments from TESSA. TESSA_Cluster_Size : The number of cells in each cluster. These columns can be then used for further downstream analysis to explore the functional landscape of the TCR repertoire. Note The dependencies of TESSA are not included in the docker image of immunopipe with tag without -full suffix. If you want to use TESSA, please use the docker image with tag with -full suffix, or install the dependencies manually. Input \u00b6 screpdata : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains. Output \u00b6 outfile : Default: {{in.screpdata | stem}}.tessa.qs . a qs fileof a Seurat object, with TESSA_Cluster and TESSA_Cluster_Size added to the meta.data Environment Variables \u00b6 python : Default: python . The path of python with TESSA 's dependencies installed within_sample ( flag ) : Default: False . Whether the TCR networks are constructed only within TCRs from the same sample/patient (True) or with all the TCRs in the meta data matrix (False). assay : Which assay to use to extract the expression matrix. Only works if in.srtobj is an RDS file of a Seurat object. By default, if SCTransform is performed, SCT will be used. predefined_b ( flag ) : Default: False . Whether use the predefined b or not. Please check the paper of tessa for more details about the b vector. If True, the tessa will not update b in the MCMC iterations. max_iter ( type=int ) : Default: 1000 . The maximum number of iterations for MCMC. save_tessa ( flag ) : Default: False . Save tessa detailed results to seurat object? It will be saved to sobj@misc$tessa . Reference \u00b6 'Mapping the Functional Landscape of TCR Repertoire.', Zhang, Z., Xiong, D., Wang, X. et al. 2021. link 'Deep learning-based prediction of the T cell receptor-antigen binding specificity.', Lu, T., Zhang, Z., Zhu, J. et al. 2021. link Metadata \u00b6 The metadata of the Seurat object will be updated with the TESSA clusters and the cluster sizes:","title":"TESSA"},{"location":"processes/TESSA/#tessa","text":"Tessa is a Bayesian model to integrate T cell receptor (TCR) sequence profiling with transcriptomes of T cells. Enabled by the recently developed single cell sequencing techniques, which provide both TCR sequences and RNA sequences of each T cell concurrently, Tessa maps the functional landscape of the TCR repertoire, and generates insights into understanding human immune response to diseases. As the first part of tessa, BriseisEncoder is employed prior to the Bayesian algorithm to capture the TCR sequence features and create numerical embeddings. We showed that the reconstructed Atchley Factor matrices and CDR3 sequences, generated through the numerical embeddings, are highly similar to their original counterparts. The CDR3 peptide sequences are constructed via a RandomForest model applied on the reconstructed Atchley Factor matrices. See https://github.com/jcao89757/TESSA When finished, two columns will be added to the meta.data of the Seurat object: TESSA_Cluster : The cluster assignments from TESSA. TESSA_Cluster_Size : The number of cells in each cluster. These columns can be then used for further downstream analysis to explore the functional landscape of the TCR repertoire. Note The dependencies of TESSA are not included in the docker image of immunopipe with tag without -full suffix. If you want to use TESSA, please use the docker image with tag with -full suffix, or install the dependencies manually.","title":"TESSA"},{"location":"processes/TESSA/#input","text":"screpdata : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains.","title":"Input"},{"location":"processes/TESSA/#output","text":"outfile : Default: {{in.screpdata | stem}}.tessa.qs . a qs fileof a Seurat object, with TESSA_Cluster and TESSA_Cluster_Size added to the meta.data","title":"Output"},{"location":"processes/TESSA/#environment-variables","text":"python : Default: python . The path of python with TESSA 's dependencies installed within_sample ( flag ) : Default: False . Whether the TCR networks are constructed only within TCRs from the same sample/patient (True) or with all the TCRs in the meta data matrix (False). assay : Which assay to use to extract the expression matrix. Only works if in.srtobj is an RDS file of a Seurat object. By default, if SCTransform is performed, SCT will be used. predefined_b ( flag ) : Default: False . Whether use the predefined b or not. Please check the paper of tessa for more details about the b vector. If True, the tessa will not update b in the MCMC iterations. max_iter ( type=int ) : Default: 1000 . The maximum number of iterations for MCMC. save_tessa ( flag ) : Default: False . Save tessa detailed results to seurat object? It will be saved to sobj@misc$tessa .","title":"Environment Variables"},{"location":"processes/TESSA/#reference","text":"'Mapping the Functional Landscape of TCR Repertoire.', Zhang, Z., Xiong, D., Wang, X. et al. 2021. link 'Deep learning-based prediction of the T cell receptor-antigen binding specificity.', Lu, T., Zhang, Z., Zhu, J. et al. 2021. link","title":"Reference"},{"location":"processes/TESSA/#metadata","text":"The metadata of the Seurat object will be updated with the TESSA clusters and the cluster sizes:","title":"Metadata"},{"location":"processes/TOrBCellSelection/","text":"TOrBCellSelection \u00b6 Separate T and non-T cells and select T cells; or separate B and non-B cells and select B cells. If all of your cells are T/B cells, do not set any configurations for this process. In such a case, SeuratClusteringOfAllCells should not be used, and SeuratClustering will be clustering all of the cells, which are all T/B cells. There are two ways to separate T and non-T cells; or B and non-B cells: Use the an expression indicator directly from the metadata. Use the expression values of indicator genes, and the clonotype percentage of the clusters. You can also use indicator gene expression values only to select T/B cells by setting envs.ignore_vdj to true. Input \u00b6 srtobj : Seurat object file in RDS/qs2 immdata : Immune repertoire data file in RDS/qs2 Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . Seurat object file in qs2 format outdir : Default: details . Output directory with details Environment Variables \u00b6 ignore_vdj ( flag ) : Default: False . Ignore VDJ information for T/B cell selection. Use only the expression values of indicator genes if True. In this case, the Clonotype_Pct column does not exist in the metadata. If you want to use k-means to select T/B cells, you must have more than 1 indicator gene, and the first indicator gene in envs.indicator_genes must be a positive marker, which will be used to select the cluster with higher expression values as T/B cells. selector : The expression passed to tidyseurat::mutate(is_TCell = ...) to indicate whether a cell is a T cell. For example, Clonotype_Pct > 0.25 to indicate cells with clonotype percentage > 25% are T cells. If indicator_genes is provided, the expression values can also be used in the expression. For example, Clonotype_Pct > 0.25 & CD3E > 0 . If selector is not provided, a kmeans clustering will be performed on the expression values of indicator_genes and Clonotype_Pct , with K=2, and the cluster with higher clonotype percentage will be selected as T/B cells. indicator_genes ( list ) : Default: ['CD3E'] . A list of indicator genes whose expression values and clonotype percentage will be used to determine T/B cells. The markers could be either positive, such as CD3E , CD3D , CD3G , or negative, such as CD19 , CD14 , CD68 , for T cells. For B cells, markers such as CD19 , MS4A1 (CD20), CD79A , CD79B could be used. kmeans ( type=json ) : Default: {'nstart': 25} . The parameters for kmeans clustering. Other arguments for stats::kmeans can be provided here. If there are dots in the argument names, replace them with - . Examples \u00b6 Use T cell indicator directly \u00b6 If you have a metadata like this: id Clonotype_Pct seurat_clusters 1 0.1 1 2 0.3 2 3 0.5 3 With the configuration below: [TOrBCellSelection.envs] selector = \"Clonotype_Pct > 0.25\" The T cells will be selected as: id Clonotype_Pct seurat_clusters is_TCell 1 0.1 1 FALSE 2 0.3 2 TRUE 3 0.5 3 TRUE Use indicator genes \u00b6 Let's say we set the indicator genes to [\"CD3D\", \"CD3E\", \"CD3G\"] . The mean expression values will be calculated for each cluster: id Clonotype_Pct seurat_clusters CD3D CD3E CD3G 1 0.1 1 0.1 0.0 0.1 2 0.3 2 1.2 1.3 0.6 3 0.5 3 1.5 0.8 0.9 Then a kmeans clustering will be performed on the mean expression values of the indicator genes, together with Clonotype_Pct , with K=2. id Clonotype_Pct seurat_clusters CD3D CD3E CD3G is_TCell 1 0.1 1 0.1 0.0 0.1 FALSE 2 0.3 2 1.2 1.3 0.6 TRUE 3 0.5 3 1.5 0.8 0.9 TRUE The cluster with higher clonoype percentage will be selected as T/B cells ( is_selected = TRUE ), and sent to SeuratClustering for further clustering and downstream analysis.","title":"TOrBCellSelection"},{"location":"processes/TOrBCellSelection/#torbcellselection","text":"Separate T and non-T cells and select T cells; or separate B and non-B cells and select B cells. If all of your cells are T/B cells, do not set any configurations for this process. In such a case, SeuratClusteringOfAllCells should not be used, and SeuratClustering will be clustering all of the cells, which are all T/B cells. There are two ways to separate T and non-T cells; or B and non-B cells: Use the an expression indicator directly from the metadata. Use the expression values of indicator genes, and the clonotype percentage of the clusters. You can also use indicator gene expression values only to select T/B cells by setting envs.ignore_vdj to true.","title":"TOrBCellSelection"},{"location":"processes/TOrBCellSelection/#input","text":"srtobj : Seurat object file in RDS/qs2 immdata : Immune repertoire data file in RDS/qs2","title":"Input"},{"location":"processes/TOrBCellSelection/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . Seurat object file in qs2 format outdir : Default: details . Output directory with details","title":"Output"},{"location":"processes/TOrBCellSelection/#environment-variables","text":"ignore_vdj ( flag ) : Default: False . Ignore VDJ information for T/B cell selection. Use only the expression values of indicator genes if True. In this case, the Clonotype_Pct column does not exist in the metadata. If you want to use k-means to select T/B cells, you must have more than 1 indicator gene, and the first indicator gene in envs.indicator_genes must be a positive marker, which will be used to select the cluster with higher expression values as T/B cells. selector : The expression passed to tidyseurat::mutate(is_TCell = ...) to indicate whether a cell is a T cell. For example, Clonotype_Pct > 0.25 to indicate cells with clonotype percentage > 25% are T cells. If indicator_genes is provided, the expression values can also be used in the expression. For example, Clonotype_Pct > 0.25 & CD3E > 0 . If selector is not provided, a kmeans clustering will be performed on the expression values of indicator_genes and Clonotype_Pct , with K=2, and the cluster with higher clonotype percentage will be selected as T/B cells. indicator_genes ( list ) : Default: ['CD3E'] . A list of indicator genes whose expression values and clonotype percentage will be used to determine T/B cells. The markers could be either positive, such as CD3E , CD3D , CD3G , or negative, such as CD19 , CD14 , CD68 , for T cells. For B cells, markers such as CD19 , MS4A1 (CD20), CD79A , CD79B could be used. kmeans ( type=json ) : Default: {'nstart': 25} . The parameters for kmeans clustering. Other arguments for stats::kmeans can be provided here. If there are dots in the argument names, replace them with - .","title":"Environment Variables"},{"location":"processes/TOrBCellSelection/#examples","text":"","title":"Examples"},{"location":"processes/TOrBCellSelection/#use-t-cell-indicator-directly","text":"If you have a metadata like this: id Clonotype_Pct seurat_clusters 1 0.1 1 2 0.3 2 3 0.5 3 With the configuration below: [TOrBCellSelection.envs] selector = \"Clonotype_Pct > 0.25\" The T cells will be selected as: id Clonotype_Pct seurat_clusters is_TCell 1 0.1 1 FALSE 2 0.3 2 TRUE 3 0.5 3 TRUE","title":"Use T cell indicator directly"},{"location":"processes/TOrBCellSelection/#use-indicator-genes","text":"Let's say we set the indicator genes to [\"CD3D\", \"CD3E\", \"CD3G\"] . The mean expression values will be calculated for each cluster: id Clonotype_Pct seurat_clusters CD3D CD3E CD3G 1 0.1 1 0.1 0.0 0.1 2 0.3 2 1.2 1.3 0.6 3 0.5 3 1.5 0.8 0.9 Then a kmeans clustering will be performed on the mean expression values of the indicator genes, together with Clonotype_Pct , with K=2. id Clonotype_Pct seurat_clusters CD3D CD3E CD3G is_TCell 1 0.1 1 0.1 0.0 0.1 FALSE 2 0.3 2 1.2 1.3 0.6 TRUE 3 0.5 3 1.5 0.8 0.9 TRUE The cluster with higher clonoype percentage will be selected as T/B cells ( is_selected = TRUE ), and sent to SeuratClustering for further clustering and downstream analysis.","title":"Use indicator genes"},{"location":"processes/TopExpressingGenes/","text":"TopExpressingGenes \u00b6 Top expressing genes for clusters of all or selected T/B cells. This process finds the top expressing genes of clusters of T/B cells, and also performs the enrichment analysis against the genes. The enrichment analysis is done by enrichr . Note There are other environment variables also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for investigating top genes (See biopipen.ns.scrna.TopExpressingGenes for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly. Input \u00b6 srtobj : The seurat object in RDS or qs/qs2 format Output \u00b6 outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots Environment Variables \u00b6 dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case.","title":"TopExpressingGenes"},{"location":"processes/TopExpressingGenes/#topexpressinggenes","text":"Top expressing genes for clusters of all or selected T/B cells. This process finds the top expressing genes of clusters of T/B cells, and also performs the enrichment analysis against the genes. The enrichment analysis is done by enrichr . Note There are other environment variables also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for investigating top genes (See biopipen.ns.scrna.TopExpressingGenes for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly.","title":"TopExpressingGenes"},{"location":"processes/TopExpressingGenes/#input","text":"srtobj : The seurat object in RDS or qs/qs2 format","title":"Input"},{"location":"processes/TopExpressingGenes/#output","text":"outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots","title":"Output"},{"location":"processes/TopExpressingGenes/#environment-variables","text":"dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case.","title":"Environment Variables"},{"location":"processes/TopExpressingGenesOfAllCells/","text":"TopExpressingGenesOfAllCells \u00b6 Top expressing genes for clusters of all cells. See also TopExpressingGenes . Input \u00b6 srtobj : The seurat object in RDS or qs/qs2 format Output \u00b6 outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots Environment Variables \u00b6 dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case.","title":"TopExpressingGenesOfAllCells"},{"location":"processes/TopExpressingGenesOfAllCells/#topexpressinggenesofallcells","text":"Top expressing genes for clusters of all cells. See also TopExpressingGenes .","title":"TopExpressingGenesOfAllCells"},{"location":"processes/TopExpressingGenesOfAllCells/#input","text":"srtobj : The seurat object in RDS or qs/qs2 format","title":"Input"},{"location":"processes/TopExpressingGenesOfAllCells/#output","text":"outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots","title":"Output"},{"location":"processes/TopExpressingGenesOfAllCells/#environment-variables","text":"dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers See below for all libraries. https://maayanlab.cloud/Enrichr/#libraries n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case.","title":"Environment Variables"}]}