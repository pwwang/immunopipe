{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Integrative analysis for single-cell RNA sequencing and single-cell TCR/BCR sequencing data immunopipe is a pipeline based on pipen framework. It includes a set of processes for scRNA-seq and scTCR-/scBCR-seq data analysis in R , python and bash . The pipeline is designed to be flexible and configurable. See a more detailed flowchart here . Documentaion \u00b6 https://pwwang.github.io/immunopipe Proposing more analyses \u00b6 If you have any suggestions for more analyses, please feel free to open an issue here Example \u00b6 https://github.com/pwwang/immunopipe-example Gallery \u00b6 There are some datasets with both scRNA-seq and scTCR-/scBCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. Check out the gallery for more details. Citation \u00b6 If you use immunopipe in your research, please cite the following paper: Wang, P., Yu, Y., Dong, H., Zhang, S., Sun, Z., Zeng, H., ... & Li, Y. (2025). Immunopipe: a comprehensive and flexible scRNA-seq and scTCR-seq data analysis pipeline. NAR Genomics and Bioinformatics, 7(2), lqaf063.","title":"Home"},{"location":"#documentaion","text":"https://pwwang.github.io/immunopipe","title":"Documentaion"},{"location":"#proposing-more-analyses","text":"If you have any suggestions for more analyses, please feel free to open an issue here","title":"Proposing more analyses"},{"location":"#example","text":"https://github.com/pwwang/immunopipe-example","title":"Example"},{"location":"#gallery","text":"There are some datasets with both scRNA-seq and scTCR-/scBCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. Check out the gallery for more details.","title":"Gallery"},{"location":"#citation","text":"If you use immunopipe in your research, please cite the following paper: Wang, P., Yu, Y., Dong, H., Zhang, S., Sun, Z., Zeng, H., ... & Li, Y. (2025). Immunopipe: a comprehensive and flexible scRNA-seq and scTCR-seq data analysis pipeline. NAR Genomics and Bioinformatics, 7(2), lqaf063.","title":"Citation"},{"location":"CHANGELOG/","text":"Change Log \u00b6 2.3.2 \u00b6 chore: update r-biopipen.utils version to 0.3.5=r43_6 in environment_rpkgs.yml chore: update r-scplotter version to 0.6.5=r43_3 in environment_rpkgs.yml chore: update blessed to version 1.26.0, pipen to 1.1.8, and pipen-runinfo to 1.1.1 chore: update r-hitype dependency in environment_base.yml to support sctype feat: add agent skills to construct configuration to run the pipeline chore: bump biopipen to 1.1.7 (support mutliple subset_by columns for metabolic landscape analysis) 2.3.1 \u00b6 chore: chore: update Dockerfile to install numpy version 2.3 for compatibility with scanpy chore: add pwwang::r-sccatch to environment_base.yml chore: update r-plotthis dependency version to 0.9.4 chore: update r-scplotter dependency version to 0.6.5 feat: clone selectors gain a within option to select clones within a specific subset feat: clone selectors and / or support multiple selectors (more than 2) chore: update biopipen dependency version to 1.1.5 fix(scrna.MarkersFinder): update database handling in enrichment plots in case it is from gmt files fix(scrna.PseudoBulkDEG): update database handling in enrichment plots to use unique databases in case gmt files were used fix(scrna.CellTypeAnnotation): ensure at least 2 clusters for cell type annotation for scCATCH feat(tcr.ClonalStats): add caching functionality for plots feat(scrna.ScFGSEA): add caching functionality for GSEA results feat(scrna.CellTypeAnnotation): enhance cell type annotation functionality to support dict input for direct annotations 2.3.0 \u00b6 chore: bump pipen to v1.1 so asynchronous path operations are supported refactor: convert synchronous methods to asynchronous in gbatch.py feat: add example configuration file fix: update header reading method in validate_config to use read_text docs: update process documentation with additional references and image links docs: update installation and running documentation to reflect dependency changes docs: add FAQ entry for mouse data support in the pipeline chore: update r-biopipen.utils version to 0.3.5 in environment_rpkgs.yml fix(RunSeuratDEAnalysis): handle +Inf/-Inf values in avg_log2FC to make visualization works chore: bump biopipen to 1.1.1 docs(tcr.ClonalStats): correct typo in documentation for ClonalStatsPlot reference 2.2.2 \u00b6 chore: force conda to rebuild with biopipen.utils.R v0.3.4-7 make sure 'direct' method of CellTypeAnnotation keeps the order chore: update r-plotthis dependency version to 0.9.0=r43_3 chore: update biopipen dependency to version 1.0.0 fix(scrna.CellTypeAnnotation): handle NA values in cell type processing to prevent errors chore(scrna.SeuratPreparing): update min_cells parameter to require at least 3 cells for SCTransform fix: enhance seurat path resolution and error handling in check_genes function fix: improve seurat path resolution for containerized environments in check_dim function 2.2.1 \u00b6 docs: add FAQ entries for process reruns after updating and skipping essential processes docs: add installation note for pipen-dry package in FAQ chore: add pipen-dry as an optional dependency and include it in extras ci(docker): use multi-staging building and make the packages relying numpy v1 to be merged to the base environment, which largely reduce the size of the image chore: bump pipen-cli-gbatch to 0.1.5 (make default running profile work) chore: update pipen-report version to 0.23.15 chore: update clustcr version in environment_base.yml to be compatible with numpy v2 chore: add .dockerignore file to exclude unnecessary files from Docker builds chore: update Python version to 3.12 and adjust biopipen.utils version in environment files chore: add Dockerhub descriptions for immunopipe, immunopipe-base, and immunopipe-rpkgs chore: update r-scplotter version to 0.6.4=r43_2 in environment_rpkgs.yml fix(ClonalDiversityPlot): fix calculating Gini coefficient fix(MarkersPlot): handle errors when subsetting object features fix(MarkersPlot): exclude groups that failed DE analysis from plotting chore: update r-plotthis version to 0.9.0=r43_1 in environment_rpkgs.yml fix(boxviolinplot): skip processing for data frames with less than 2 rows fix(network): update ggplot2 version check for link_type_by support fix(velocityplot): update ggplot2 version check for arrow length handling chore(heatmap): add warning for unknown arguments in HeatmapAtomic function feat: add list_fonts and import_font utilities chore: update r-biopipen.utils version in environment_rpkgs.yml to 0.3.4=r43_7 fix(RunSeuratDEAnalysis): improve error handling by returning empty data frame on logic error and adding traceback on stop feat: set default font to \"LiberationSans\" for plotthis plots fix: update RunUMAPArgs to use the correct reduction and improve dims handling fix(RunSeuratUMAP): avoid changing of identity when using features for RunUMAP chore(RunSeuratTransformation, RunSeuratMap2Ref): ensure return.only.var.genes defaults to FALSE when using SCTransform chore: update biopipen version to ^0.34.28 in pyproject.toml feat(tcr.ClonalStats): add save_data parameter to ClonalStats for saving plot data fix(scrna.PseudoBulkDEG): change default assay from \"RNA\" to None so that default assay can be used by default feat(scrna.ScFGSEA): add assay parameter to allow specification of assay in analysis fix(scrna.CellTypeAnnotation): correct assignment of identities in rename_idents function feat(tcr.CDR3Clustering): add verbose output option for GIANA command fix(scrna.CellTypeAnnotation): update package requirement from celltypist to celltypist2 (a version adopts numpy v2) fix(tcr.TESSA): add Keras model migration support for v2 and v3 fix(scrna.CellTypeAnnotation): improve handling of over_clustering assignment from Seurat object for celltypist 2.2.0 \u00b6 BREAKING: restructure Docker workflows and update environment configurations using multiple-image/stage building, no \"-full\" suffix for image tags needed anymore. BREAKING: rename TCRClustering to CDR3Clustering across documentation and codebase to adopt for BCR data BREAKING: prevent export of RDS/qs files in SeuratPreparing and SeuratMap2Ref classes. NOTE that this may break reruning with cached SeuratPreparing and SeuratMap2Ref processes. The RDS/qs output files are no longer exported to output directory to reduce the report size. Instead, they are staying in the working directory for downstream processes to use. But the the figures will be still displayed in the report as before. fix: swap SeuratMap2Ref and SeuratClustering to make sure graph doesn't get overwritten fix: refactor VDJ configuration detection in validate_config when running with gbatch fix: default group_by to None for ClusterMarkers/ClusterMarkersOfAllCells so default ident will be used docs: update configuration options in getting started guide docs: update notes in Seurat processes to prevent overwriting cluster information docs: update column naming in SeuratClustering and CellTypeAnnotation documentation docs: update figures after CDR3Clustering renaming ci: add cache deletion step to save space in Docker workflow test: update configuration files and tests test: update assertions in test_route_sampleinfo_full for correct flow after refactoring test: reorder assertions in test_route_sampleinfo_full for correct flow due to the swapping of SeuratMap2Ref and SeuratClustering chore: bump biopipen version to 0.34.23 (related changes below) docs(scrna.SeuratPreparing): improve documentation for SeuratPreparing to make sure new lines in code blocks docs(scrna.SeuratClusterStats): enhance documentation for cluster statistics plots docs(tcr.ClonalStats): add exapmle configurations and plots docs(scrna.ScFGSEA): add examples and usage details for GSEA plots docs(CellCellCommunication): add example output for ligand-receptor interactions docs(CellCellCommunicationPlots): add examples for various plot types docs(scrna.MetabolicPathwayActivity): add merged heatmap example docs: improve documentation for SeuratPreparing to make sure new line\u2026 (#180) fix(scrna): update group_by assignment to use GetIdentityColumn feat(scrna.SeuratClustering): add envs.ident as shortcut for custom cluster name chore(scrna.SeuratClusterStats): set default group_by for dimplots to None docs(scrna): correct parameter names in docstring (ident-1 to ident_1, and ident-2 to ident-2) feat(scrna): add return option for identity column in convert_seurat_to_anndata function feat(scrna.CellCellCommunication): enhance groupby handling for Seurat objects feat(scrna.CellTypeAnnotation): add support for specifying identity column in CellTypeAnnotation for celltypist feat(scrna.CellTypeAnnotation): enhance identity column handling and add backup column support feat(scrna.CellTypeAnnotation): enhance classifier initialization and input handling for celltypist enh(scrna.MarkersFinder): add logging for plot processing in marker and enrichment functions feat(scrna.CellTypeAnnotation): require celltypist package with specified version and python interpreter docs(scrna): update dbs/gmtfile parameter description for enrichment analysis chore(scrna): update future.globals.maxSize to Inf for improved memory handling feat(tcr.CDR3Clustering): rename TCRClustering to CDR3Clustering and adopt BCR data docs(scrna.CellTypeAnnotation): clarify renaming of original identity column during cell type annotation see full changelog at https://pwwang.github.io/biopipen/CHANGELOG/ . 2.1.3 \u00b6 docs: update docs for ClusterMarkers with examples ci: update biopipen dependency for tests feat: add new tests and configuration for ScRepLoading, ScRepCombiningExpression and SeuratClusterStats test: add test for clustermarkers test: add test for TOrBCellSelection docs: enhance documentation for PseudoBulkDEG and MarkersFinder test: add ClonalStats tests and configuration test: add ScFGSEA tests and configuration test: add CellCellCommunication and CellCellCommunicationPlots tests docs: update ScrnaMetabolicLandscape doc images chore: bump biopipen to 0.34.17 fix(scrna.MarkersFinder): enhance error handling in enrichment plotting and fix all-enrich plots when ident_1 is NULL fix(tcr.ClonalStats): replace deprecated ClonalDynamicsPlot with ClonalStatPlot 2.1.2 \u00b6 test: update order of ScRepLoading and SeuratClustering in assertions in route tests docs: update configuration section name from cli-gbatch to gbatch docs: enhance installation and introduction documentation fix: better infer has_vdj when running by gbatch 2.1.1 \u00b6 fix: correct order of input requirements for ScRepCombiningExpression 2.1.0 \u00b6 BREAKING: rename process LoadRNAFromSeurat to LoadingRNAFromSeurat feat: enhance configuration validation logic feat: implement LoadRNAFromSeurat process to allow specifying sample column feat: allow SeuratClustering, SeuratMap2Ref and CellTypeAnnotation at the same time in a run feat: add \"help\" subcommand to show help for specific processes fix: make sure the routes of the pipeline work as expected (tests added) fix: ensure correct handling of kp_mount in main function docs: documentation and update processes for T/B cell selection and clustering ci: improve immunopipe installation check docs: update configurations and introduction for LoadingRNAFromSeurat process chore: bump xqute to 0.10.17 chore: bump pipen to 0.17.24 chore: bump pipen-cli-gbatch to v0.1.3 chore: bump pipen-args to v0.17.7 chore: bump pipen-report to 0.23.13 chore: update biopipen to version 0.34.16 feat(scrna.MarkersFinder): allow using other metadata columns from object for enrichment plot of all subcases 2.0.3 \u00b6 feat: adopt pipen-cli-gbatch, allowing --mount-as-cwd to infer workdir and outdir fix: fix when running with a configuration file solely fix: fix gbatch deamon workdir not created inside the pipeline working folder for gbatch cli fix: fix outdir not following the pipeline name with gbatch cli docs: update volume mounting syntax in docker and singularity commands docs: update immunopipe gbatch options for running the pipeline on Google Cloud Batch Jobs chore: bump pipen-cli-gbatch to 0.0.7 and pipen-report to 0.23.12 chore: bump biopipen to 0.34.14 fix(scrna_metabolic_landscape): fix report paging issue docs(scrna.MarkersFinder): fix links in docs fix(scrna.SeuratClusterStats): improve error handling in feature plotting when save_code (due to upgrade to ggplot2 v4) feat(MarkersFinder): use scplotter::MarkersPlot (wrapped by biopipen.utils::VizDEGs to visualize marker fix(scrna.CellTypeAnnotation): update logging for celltypist command execution 2.0.2 \u00b6 fix: fix immunopipe -h/--help not working as expected feat(gbatch): enhance validation and default handling in main function feat(gbatch): add --mount-as-cwd option to mount a cloudpath as working directory chore: bump biopipen to 0.34.10 docs(scrna.SeuratPreparing): enhance cell_qc parameter description in SeuratPreparing docs(scrna.ModuleScoreCalculator): update link format in ModuleScoreCalculator docstring 2.0.1 \u00b6 feat: add utility cli for gene checking and dimension verification chore: make tests order work as expected chore: bump biopipen to 0.34.9 fix(scrna.CellCellCommunication): handle numpy product attribute error feat(scrna.ModuleScoreCalculator): add post mutaters functionality to allow compound modules based on added modules docs(scrna.MarkersFinder): correct URL in documentation feat(scrna.CellTypeAnnotation): add support for additional direct cell type annotations feat(scrna.MarkersFinder): enhance enrichment plot descriptions chore(scrna.CellCellCommunicationPlots): set default case to \"Cell-Cell Communication\" feat(scrna.CellCellCommunicationPlots): add table output option for ccc data chore: bump scplotter to 0.6.0 in docker image chore: optimize clonal_size_data feat(featurestatplot): add pos_only parameter to filter positive feature values chore(enrichmentplot) remove preset label_nudge parameter in BarPlot call feat: add downsample parameter to feature statistic plots feat(featurestatplot) default options to TRUE to show row and column names when plot_type is heatmap-alike 2.0.0 (Cloud support, enhanced visualization, new analyses/features, and more ...) \u00b6 Cloud support \u00b6 feat: immunopipe can now be run on Google Cloud Batch Jobs, allowing for scalable and efficient processing of larger datasets. You can either run the pipeline using the gbatch scheduler ; or run the entire pipeline on Gooble Batch Jobs using immunopipe gbatch command. See Run the pipeline using Google Cloud Batch Jobs\u00b6 for more details. Enhanced visualization \u00b6 feat: scplotter and plotthis are now used for plotting, providing enhanced visualization capabilities and uniformity across different processes. feat: default descriptions/captions are now added to plots, making them more informative. Enhanced performance \u00b6 feat: the pipeline now uses qs2 for store the R objects, which speeds up the loading and saving of Seurat objects. feat: step-wise caching (in addition to process-wise) is now supported, especially for Seurat processes, allowing for faster re-running of the pipeline by caching intermediate results and improving results reproducibility. refactor: MetabolicLandscapeAnalysis is refactored for flexibility and performance improvement. BREAKING: enrichR is retired and replaced by enrichit for enrichment analysis, making it offline and more flexible. This enables the entire pipline to run without internet connection. New analyses/features \u00b6 feat: the pipeline now supports cell-cell communication analysis . feat: plots are supported for all cases for MarkersFinder and ScFGSEA , allowing plotting the markers (DEGs) and enriched pathways for all cases (e.g. all seurat clusters) in a single plot. BREAKING: the immunarch package is now replaced by scRepertoire for more features and allowing customized clonotype definition. feat: envs.mutaters is now supported for SeuratPreparing to allow create factor (categorical) columns in the metadata. feat: PseudoBulkDEG is added to perform pseudo-bulk differential expression analysis. feat: BCR-seq data is now supported, allowing users to analyze BCR-seq data paired with scRNA-seq data. feat: Now Seurat object (in RDS or qs2 format) is supported as input for scRNA-seq data. feat: Now loom format is supported for scRNA-seq data, allowing users to use loom files as input for the pipeline. feat: add mcp server functionality to launch mcp server to help compose the configuration file. House keeping \u00b6 build: docker images are now built based on the biopipen base image. ci: the test workflow now caches the running intermediate files to speed up the tests. docs: the citation information is now added to the documentation, allowing users to easily cite the pipeline in their publications. chore(deps): biopipen is bumped to 0.34.8, which includes various bug fixes and enhancements. See the biopipen releases for more details. 1.4.4 \u00b6 chore(deps): add gcc_linux-64 to Docker environment dependencies docs: add input and output sections to multiple process documentation files feat: add PDF output for K-means and T cell plots, enhancing report generation deps: bump biopipen to 0.32.3 0.32.1: fix(scrna.ScFGSEA): fix case gmtfile not working fix(TopExpressingGenes): add InlineNotification component to TopExpressingGenes.svelte fix(scrna.SeuratClusterStats): fix kind not being added to the figure file name for plots of features feat(scrna.SeuratPreparing): support percent.mt, percent.ribo, percent.hb and percent.plat for mouse 0.32.2: feat: add PDF output option for SampleInfo plots feat: add PDF output options for violin and scatter plots in Seurat preparation scripts feat: add PDF output options for volcano, dotplot, venn, and upset plots feat: add PDF output option for Enrichr plots in TopExpressingGenes script feat: add PDF output options for UMAP plots in SeuratMap2Ref script; update image handling in misc.liq feat: add PDF output options for cluster size distribution, shared clusters, and sample diversity plots; update plotting functions to handle multiple output formats feat: add PDF output options for various Immunarch scripts; enhance reporting with downloadable PDF files feat: add PDF output options for cluster size distribution, dimension plots, and feature plots; enhance reporting with downloadable PDF files feat: add PDF output options for radar and bar plots; enhance reporting with downloadable PDF files feat: add PDF output options for CloneResidency script; enhance reporting with downloadable PDF files feat: add PDF output options for GSEA table and enrichment plots; enhance reporting with downloadable PDF files feat: add PDF output options for pie charts, heatmaps, Venn plots, and UpSet plots; enhance reporting with downloadable PDF files feat: add PDF output options for Enrichr plots; enhance reporting with downloadable PDF files feat: add PDF output options for estimated coefficients and distribution plots; enhance reporting with downloadable PDF files 0.32.3: chore: add descriptive summaries for fgsea and enrichr results 1.4.3 \u00b6 deps: update pipen-runinfo dependency to version 0.8.0 (pipen to 0.15.2) deps: update biopipen dependency to version 0.31.4 fix(scrna.SeuratMap2Ref): fix refnorm not detected for NormlizeData'ed reference 1.4.2 \u00b6 deps: add bioconductor-destiny dependency in docker environment files for ModuleScoreCalculator 1.4.1 \u00b6 docs: update tutorial dataset information and links 1.4.0 \u00b6 docs: update Singularity and Apptainer commands to include --writable-tmpfs flag docs: allow collapsing ns/choice items in the docs for processes docker: update Dockerfile to include npm cache configuration to allow the pipeline to run on read-only file system tests: update SeuratPreparing config to use DoubletFinder for doublet detection ci: use latest actions deps: add r-clustree as a dependency in docker environment files deps: update dependencies in docker environment files (python3.10, R4.3) deps: bump biopipen to 0.29.0 fix(tcr.TCRClusterStats): fix envs.shared_clusters.heatmap_meta being broken by envs.shared_clusters.sample_order (@ li.ying@mayo.edu ) choir(scrna.SeuratMap2Ref): present better error message when envs.use or values of envs.MapQuery.refdata not in reference (@ li.ying@mayo.edu ) fix(scrna.MarkersFinder): run PrepSCTFindMarkers when needed choir(scrna.SeuratClustering): use FindClusters to run for multiple resolutions choir(scrna.SeuratSubClustering): use FindClusters to run for multiple resolutions feat(scrna.SeuratClustering): add clustree plot (@ li.ying@mayo.edu ) feat(scrna.SeuratSubClustering): add clustree plot tests(scrna.SeuratClusterStats): add assertion for clustree plot generation deps: bump biopipen to 0.29.1 fix(delim.SampleInfo): fix numbers not split up when each is specified. enh(delim.SampleInfo): make sizes of pie charts proportional to number of samples when each is specified enh(scrna.MarkersFinder): run PrepSCTFindMarkers when necessary before calling FindMarkers feat(scrna.SeuratPreparing): add option to cache Seurat object at different steps feat(scrna.SeuratPreparing): allow doubletfinder to run with a different number of cores chore(scrna.SeuratClustering): record PrepSCTFindMarkers command in sobj@commands tests(scrna.SeuratClusterStats): use less stringent p-value cutoff for DEG/MarkersFinder tests(scrna.SeuratPreparing): add doubletfinder in tests deps: bump biopipen to 0.29.2 chore(scrna.SeuratClusterStats): use ident label length to adjust default height for feature plots fix(scrna.MetaMarkers): fix seurat object not updated when expanding cases and run PrepSCTFindMarkers when necessary before calling meta-markers fix(scrna.MarkersFinder): fix fetching command when composing the PrepSCTFindMarkers command fix(scrna_metabolic_landscape): handle null values in for loop in MetabolicFeatures and MetabolicFeaturesIntraSubset for report generation deps: bump biopipen to 0.30.0 BREAKING(scrna): move clustree plots from SeuratClustering/SeuratSubClustering to SeuratClusterStats feat(scrna.CellTypeAnnotation): allow to merge/not to merge (envs.merge) the clusters with the same labels predicted feat(scrna.SeuratPreparing): add scDblFinder to detect doublets feat(scrna.SeuratMap2Ref): add envs.skip_if_normalized option to skip normalization if query is already normalized using the same - method as the reference refactor(tcr.Immunarch): source the files for Immunarch scripts for better debugging refactor(scnra.SeuratClustering): refactor the script for better debugging refactor(scnra.SeuratPreparing): refactor the script for better debugging fix(scrna): fix resolution expansion for SeuratClustering and SeuratSubClustering fix(scrna): Fix generating PrepSCTFindMarkers command when no previous commands present tests(scrna.ScFGSEA): fix unavailable urls to GMT files chore(scrna.SeuratMap2Ref): optimize memory usage chore(scrna.MetaMarkers): remove plugin_opts.poplog_max chore(tcr.CloneResidency): improve logging when handling subjects deps: bump biopipen to 0.31.3 enh(scrna.SeuratMap2Ref): check if reference has SCTModel if SCTransform'ed (likely prepared by old Seurat) fix(tcr.CDR3AAPhyschem): use sequence from TRB chain only fix(tcr.CDR3AAPhyschem): fix when chain is not available fix(tcr.TCRClustering): fix for multi-chain TCRs, use TRB only if on_multi is false fix(tcr.TCRClustering): fix when chain is not available 1.3.9 \u00b6 docs: update docs for TCellSelection to avoid confusion deps: bump biopipen to 0.27.9 feat(tcr.TCRClusterStats): add sample_order to set sample order on heatmap and cluster_rows to switch row clustering on/off 1.3.8 \u00b6 docs: remove -w option for apptainer/singularity as no writing is necessary since pipen-board 0.15.1 deps: update biopipen to version 0.27.8 fix(scrna.SeuratClusterStats): fix selected columns not unique for stats feat(scrna.SeuratMap2Ref): allow non-SCTransform'ed reference feat(scrna.SeuratMap2Ref): allow splitting query object for mapping (pwwang/immunopipe#61) deps: update pipen-board to version 0.15.1 (allow configuration file path in the URL box on Web UI) 1.3.7 \u00b6 ci: fix docker images building when no essential changes made 1.3.6 \u00b6 ci: fix deploy workflow (#59) ci: add README.md to tests-output branch ci: fix test/test workflow tests: add make test tests: init test data preparation tests: add test for ImmunarchLoading tests: add tests for SeuratPreparing tests: Update configs for SeuratPreparing test to subset cells so tests can run on CI tests: update SeuratPreparing test to disable export tests: add tests for SeuratClusteringOfAllCells/SeuratClustering docs: update installation instructions (@ stein.mariam@mayo.edu ) deps: bump biopipen to version 0.27.7 (0.27.5-0.27.7) fix(scrna.SeuratClusterStats): fix color palette for ridge plots (@ stein.mariam@mayo.edu ) feat(scrna.SeuratPreparing): add envs.cell_qc_per_sample to filter cells before merging instead after fix(scrna_metabolic_landscape.MetabolicFeatures): fix return value of groups with less than 5 cells in do_one_group fix(scrna_metabolic_landscape): fix mutaters not working. fix(scrna_metabolic_landscape.MetabolicFeatures/MetabolicFeaturesIntraSubset): skip groups with less than 5 cells in do_one_group and save a warning file under the case chore: fix typo in class name ExprImpution to ExprImputation 1.3.5 \u00b6 ci/test: add tests in CI and deploy output in a different branch deps: bump biopipen to 0.27.4 choir(delim.SampleInfo): add alpha to the colors of the plots using biopipen color pallete docs(tcr/scrna/scrna_metabolic_landscape): update links of images in docs 1.3.4-post \u00b6 ci/test: init ci for tests docs: introduce versioning for docs 1.3.4 \u00b6 deps: bump biopipen to 0.27.3 deps: bump pipen-poplog to 0.1.2 (quick fix for populating logs when job fails) deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) choir(scrna.ScFGSEA): Skip cases when no cells found (#50) choir(scrna.MarkersFinder): Skip cases when no cells found (#50) choir(scrna.MetaMarkers): Skip cases when no cells found (#50) feat(scrna.SeuratPreparing): support DoubletFinder (#52) 1.3.3 \u00b6 deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) docs: update FAQ.md with instructions for running pipeline on a cluster deps: bump biopipen to 0.27.2 fix(scrna.RadarPlots): fix mutaters not working feat(tcr.CloneResidency): support envs.upset_ymax to set the max value of y axis in upset bar plot. 1.3.2 \u00b6 deps: bump pipen to 0.14.5 deps: add r-complexupset package to environment.yml and environment_full.yml for CloneResidency deps: pin tensorflow to 2.15 for TESSA deps: bump biopipen to 0.27.1 depr(scrna.MarkersFinder): remove envs.use_presto as it's used by Seurat v5 by default enh(tcr.CloneResidency): support log scale for y axis of upset bar plots enh(scrna.SeuratClusterStats): allow to rotate labels in circos plot (pwwang/immunopipe#48) @ li.ying@mayo.edu enh(scrna.SeuratClusterStats): use pal_biopipen for ident colors in circos plot fix(scrna.CellsDistribution): fix the row order of the heatmaps fix(scrna.SeuratClusterStats): fix when envs.split-by is specified feat(scrna.CellsDistribution): support envs.prefix_each feat(scrna.MarkersFinder): allow to set max number of genes to plot in dotplots feat(scrna.MarkersFinder): support setting detailed arguments for overlapping plots feat(scrna.MarkersFinder): support envs.prefix_group feat(scrna.ScFGSEA): support envs.prefix_each feat(scrna.RadarPlots): support envs.prefix_each and envs.subset choir(scrna.SeuratClusterStats): use logger instead of print for log messages choir(tcr.TCRClustering): print session info for clustcr script choir(scrna.MarkersFinder): flatten toc when no section and no ident-1 specified docs: add more detailed docs for envs.section for multiple processes BREAKING(scrna.SeuratMap2Ref): rename envs.name to envs.ident so envs.MapQuery.refdata is not - required anymore. It will be inferred from envs.ident and envs.use. @ li.ying@mayo.edu 1.3.1 \u00b6 deps: bump pipen to 0.14.3 deps: pin ggplot2 to 3.4 for docker due to breaking changes of 3.5 deps: bump biopipen to 0.26.2 deps: bump datar-pandas to 0.5.5 to dismiss deprecated warnings fix(utils.misc.R): replace latin and greek characters with closest ascii chars for slugify() feat(scrna.TopExpressingGenes): support subset fix(scrna.CellsDistribution): fix the row order of the heatmaps. enh(tcr.CloneResidency): add legend for multiplets in upset plots. feat(scrna.SeuratClusterStats): add circos plot for cell composition stats (#46). 1.3.0 \u00b6 deps: bump pipen to 0.14.1 deps: bump pipen-report to 0.18.2 deps: bump biopipen to 0.26.0 fix(scrna.CellTypeAnnotation): keep factor meta data when input and output are RDS for celltypist deps: bump datar to 0.15.4 (support pandas 2.2) fix(utils.single_cell.R): fix immdata_from_expanded missing other data columns fix(tcr.Immunarch): fix mutaters not working when no subset is set fix(scrna.CellsDistribution): fix hm_devpars not working fix(scrna.CellsDistribution): fix multiple cells_by columns and speed up plotting choir(tcr.CloneResidency): mark singletons in Venn diagrams more clear fix(scrna.RadarPlots): fix the order of groups on radar plots choir(scrna.RadarPlots): transpose the count/percentage table to save to files fix(scrna.MarkersFinder): fix generating report json file when no significant genes found choir(scrna.MarkersFinder): Plot maximum 20 genes in dotplots choir(scrna.MarkersFinder): Do not convert dashes in case names to dots see more at https://github.com/pwwang/biopipen/releases/tag/0.26.0 1.2.0 \u00b6 docs: update FAQs to align with Seurat v5 docs: add image from manuscript to README.md docs: center the flowchart image in README.md docs: mention celltypist model prep in preparing input data deps: bump pipen to 0.13.2 deps: bump biopipen to 0.25.2: scrna.MarkersFinder: allow to cache FindAllMarkers results scrna.CellTypeAnnotation: support celltypist (pwwang/biopipen#111) scrna.SeuratSubClustering: add envs_depth = 1 to replace whole envs.cases when new case assigned scrna_metabolic_landscape.MetabolicPathwayHeterogeneit): fix output directory path is not slugified tcr.Immunarch: change case filling log to debug level 1.1.1 \u00b6 deps: Bump biopipen to 0.24.2 chore: use internal slugify instead of slugify library tcr.Immunarch: fix spectratyping output file extension is not png scrna.SeuratPreparing: fix displaying filters in report scrna.SeuratPreparing: fix logging Seurat procedure arguments 1.1.0 \u00b6 docs: update table in gallery deps: use pipen-poplog to populate job logs to pipeline running log deps: bump biopipen to 0.24. Hights: scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112) @yuey11 scrna.SeuratClustering/SeuratSubClustering: cache Seurat procedures step by step (#40) @xyfqwlzoe tcr.Immunarch: add plot_type to support boxplots for diversity metrics see more at https://github.com/pwwang/biopipen/releases/tag/0.24.0 1.0.5 \u00b6 change: do not rescale gene expression in TCellSelection any more fix: fix column names of indicators not aligned with indicator_genes feat: add feature plots in TCellSelection deps: bump biopipen to 0.23.8 scrna.SeuratPreparing: log Seurat procedure arguments scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112) 1.0.4 \u00b6 deps: bump biopipen to 0.23.7 scrna.SeuratPreparing: update log message for transformation/scaling step scrna_metabolic_landscape.MetabolicPathwayHeterogeneity: add utils.gsea script source to support localizeGmtfile 1.0.3 \u00b6 deps: add r-seuratdisk dependency to conda env files. @yuey11 deps: pin r-matrixstats to 1.1.0 in conda env files to fix useNames = NA error. @yuey11 refactor: optimize configuration file validation deps: bump biopipen to 0.23.6 feat: support url for gmtfile wherever GSEA is performed (pwwang/biopipen#113) tcr.Immunarch: add error message for empty filtered/subset data in diversity scrna.SeuratPreparing: correct description of default assay in docstr scrna.SeuratPreparing: run also the normal normalization procedures when SCTransform is used (useful for visualization purposes on RNA assay) scrna.ModuleScoreCalculator: document the names added by cell cycle score (#34) scrna.SeuratPreparing: support sample names as reference for IntegrateLayers 1.0.2 \u00b6 deps: add bioconductor-glmgampoi to conda env files (#33) docs: correct the Seurat object assay description deps: bump biopipen to 0.23.5 fix: fix when no enriched items found for scrna.MarkersFinder , scrna.MetaMarkers and scrna.TopExpressingGenes scrna.SeuratClusterStats: fix when frac or frac_ofall is true and no group-by nor split-by is specified for stats utils.gsea.R: fix when no enriched items found for runEnrichr scrna_metabolic_landscript: fix adding report when ncores > 1 1.0.1 \u00b6 docs: add gallery section to README.md change: set default nstart of kmeans to 25 in TCellSelection deps: add r-hdf5r in conda env files to support Read_10x_h5 from Seurat. @yuey11 deps: bump biopipen to 0.23.4 scrna.TopExpressingGenes: fix colnames while pulling average expression scrna.CellsDistribution: fix when cells_by has multiple column names scrna.CellTypeAnnotation: fix the order of the clusters for direct method scrna.SeuratClusterStats: add position options for bar plots for stats scrna.RadarPlots: add colors to set the colors of the loops in radar and bar plots tcr.Immunarch: add split_by and split_order to put subplots together in one single plots 1.0.0 \u00b6 Highlights \u00b6 feat: support Seurat v5 (integration is now down by Seurat::IntegrateLayers ) feat: support supervised clustering (mapping cells to reference by Seurat ) feat: support dataset with scRNA-seq data only (no scTCR-seq data) feat: support diffusion map calculation (by ModuleScoreCalculator ) feat: support subclassing to cluster subsets of cells (by SeuratSubClustering ) feat: allow to ignore TCR data in TCellSelection and pass kmeans arguments feat: allow to set multiple resolutions ( envs.FindClusters.resolution ) in SeuratClustering / SeuratClusteringOfTCells change: change unsuperved cluster labels to c1 , c2 , ... in SeuratClustering by default docs: add gallery, which contains real-world examples of datasets from publications Breaking changes \u00b6 change: rename SeuratMetadataMutater to IntegratingTCR change: rename SeuratClusteringOfTCells to SeuratClustering change: rename TCRClusters2Seurat to IntegratingTCRClusters refactor: make SeuratClustering (instead of SeuratClusteringOfAllCells ) work for all cells when all are T cells change: move data preparation and integration from SeuratClustering to SeuratPreparing change: default mode of ImmunarchLoading to paired (instead of single ), which requires both alpha and beta chains (instead of beta chain only) to define a clonotype change: default dbs for enrichment analysis wherever applies to KEGG_2021_Human and MSigDB_Hallmark_2020 Changes \u00b6 feat: make TopExpressingGenes optional feat: add validate_config to validate configuration schematically Features \u00b6 feat(SeuratPreparing): allow to filter genes directly (by specifying envs.gene_qc.excludes ) feat(SeuratClusterStats): add ngenes to plot the number of genes expressed in each cluster feat(SeuratClusterStats): add barplot for features and allow aggregation of features feat(SeuratClusterStats): add envs.mutaters to mutate meta data feat(SeuratClusterStats): add histograms to plot number of cells against another variable feat(SeuratClusterStats): Add frac_ofall and transpose for stats to calculate fraction within group or against all cells, and transpose ident and group, respectively Dependencies \u00b6 deps: add r-presto to conda environment files to support using presto to fastly find markers deps: add bioconductor-destiny to conda environment file to support add diffusion map components in ModuleScoreCalculator deps: add r-harmony to support harmony integration by Seurat v5 in conda env file deps: add r-sf to conda env file deps: remove vdjtools from conda env files deps: bump pipen-report to 0.16.3 deps: bump biopipen to 0.23.3 . Hightlight changes: scrna.MarkersFinder: Add envs.use_presto to use presto to speed up finding markers scrna.SeuratPreparing: Set envs.gene_qc.min_cells to 0 by default (instead of 3) scrna.ScFGSEA: Allow to ignore small group when fgsea fails due to all NAs for pre-ranks scrna.CellsDistribution: Allow to order clusters by envs.cluster_orderby scrna.CellsDistribution: Add heatmaps tcr.CloneResidency: Make section works in report tcr.Immunarch: Support paired chain data for VJ conjuction plots tcr.TESSA: Change envs.assay to None to use default assay of Seurat object scrna.SeuratClusterStats: Add avgheatmap to plot more elegant heatmap for average gene expressions scrna.SeuratClusterStats: Fix ident not working for dimplots scrna.SeuratClusterStats: Add cluster_orderby to order clusters for features scrna.SeuratClusterStats: Add na_group to keep NA values in group-by utils.mutate_helpers: Change arguments id_col and compare_col of paired to id and compare , respectively utils.mutate_helpers: Fix that subset can't be an expression for expanded family utils.mutate_helpers: Add top to select top entities (e.g clones) scrna.RadarPlots: Add breakdown and test to break down the cell distribution and run statistic test on the fractions 0.11.2 \u00b6 docs: move Immunarch to the later position in process list docs: Use master tag in getting-started 0.11.1 \u00b6 chore: change line length to 88 for flake8 chore: dismissing warning about wasting columns for SeuratClusteringOfTCells docs: update CHANGELOG.md with missing changes of last version docs: add version of renaming envs.tcell_indicator to envs.tcell_selector docs: remove unused doc files docs: add metadata illustration deps: bump biopipen to 0.22.8. Highlights: deps: bump pipen-board to 0.13.10 (pipen-report to 0.16.2) CellsDistribution: Don't add rownames to the output table file MarkersFinder (ClusterMarkers/ClusterMarkersOfAllCells): Optimize to use FindAllMarkers if ident.1 is not specified SeuratClusterStats: Fix path of expression table file CellTypeAnnotation: Allow using NA to exclude clusters from output Seurat object utils.mutate_helpers: Return ids only when subset is true and group is not NA for uniq = TRUE in expanded , collapsed , emerged and vanished 0.11.0 \u00b6 deps: update biopipen to 0.22.1, highlights: add V-J junction circos plots to Immunarch process add cache option to cache the clustering results if nothing changed except ncores, to SeuratClustering process add dot plots to MarkersFinder ( ClusterMarkersOfAllCells , ClusterMarkers ) process save exported table with only necessary columns for CellsDistribution process add descr to describe cases cases in report for CellsDistribution process add subset for dimplots in SeuratClusterStats process use a new palette ( biopipen ) for related processes optimize report rendering (using render_job() filter from pipen-report ) change metacols to extracols so essential columns get exported for ImmunarchLoading process add cache option to cache the clustering results if nothing changed except ncores for SeuratClustering ( SeuratClusteringOfAllCells ) process see more at https://github.com/pwwang/biopipen/releases/tag/0.22.0 and https://github.com/pwwang/biopipen/releases/tag/0.22.1 deps: update pipen-report to 0.16, highlights: scroll anchor into view on the page build report page when each process is done, instead of the whole pipeline see more at https://github.com/pwwang/pipen-report/releases/tag/0.16.0 change: remove Immunarch2VDJtools and VJUsage processes (vj usage analysis can be done in Immunarch process) change: change tcell_indicator to tcell_selector in TCellSelection process enhance: provide better error message when none barcode matches from RNA and TCR data for TCRClustering process docs: add memory usage reduction tips in FAQ chore: dismiss warnings of wasted input columns for multiple processes 0.10.1 \u00b6 chore: update pipeline description to include version in the logs fix: add fc-cache command to Dockerfile to solve Fontconfig error docker: optimize building full image based off the base image 0.10.0 \u00b6 docker: lock r-matrix version to 1.6_1 for compatibility docs: adopt mkdocs-rtd 0.0.10 (add scrollbar to the table of contents) deps: bump biopipen to 0.21.1 use r-logger for logging in R scripts docs: fix internal references in API docs deps: bump pipen-board to 0.13.6 SampleInfo: refactor data subset logic using subset instead of distinct Immunarch: add in.metafile to allow other meta info (i.e. seurat clusters) for future subsetting (#22) Immunarch: fix empty groups in diversity plot after subsetting Immunarch: allow subset to subset cells for analyses Immunarch: allow separate_by also works on other diversity plots Immunarch: add ymin and ymax to align diversity plots by separate_by Immunarch: add ncol to specify # columns in the combined plots RadarPlots: fix envs.order not working MarkersFinder: add overlap to find overlapping markers between cases (#24) MarkersFinder: allow subset to subset cells for analyses MarkersFinder: add dot plots for significant markers CellsDistribution: allow multiple columns for cells_by CellsDistribution: allow subset to subset cells for analyses utils.mutate_helpers.R: add include_emerged for expanded() and include_vanished for collapsed() 0.9.3 \u00b6 deps: Bump biopipen to 0.20.7 deps: Bump pipen-board to 0.13.4 ClusterMarkers/ClusterMarkersOfAllCells: Choose avg_log2FC > 0 markers by default MarkersFinder: Allow to set assay and set assay to RNA by default CellsDistribution: Add venn/upset plot for overlapping cell groups in different cases SampleInfo: Add distinct to case to perform stats on distinct records 0.9.2 \u00b6 \u2795 Add r-ggnewscale as dependency for CDR3AAPhyschem in docker image \u2b06\ufe0f Bump biopipen to 0.20.5 \ud83e\uddf1 CloneResidency: Integrate RNA data to allow more flexible analysis (i.e. within specific seurat clusters) \ud83c\udfd7\ufe0f CloneResidency: Rename envs.sample_groups to envs.section to be consistent with other processes \ud83d\udcdd ScFGSEA: Remove the link in the summary of the docstring (since they are not transformed in the report) \ud83c\udfa8 CDR3AAPhyschem: Give better error message when wrong group items are given \u2b06\ufe0f Bump pipen-board to 0.13.3 Add items automatically when blurred for list options Add other sections to description on the UI for processes 0.9.1 \u00b6 \ud83d\udc1b Fix docstring for RadarPlots \u2795 Add pipen-diagram as dependency \u2795 Set pipen-runinfo as optional \u2b06\ufe0f Bump biopipen to 0.20.4 \ud83d\udcdd Update version in docs 0.9.0 \u00b6 Housekeeping and docs \u00b6 Bump biopipen to 0.20.3 (pipen to 0.12) Use pipen-cli-ref to generate API for processes (it uses docstring of the process class so that we don't need to maintain two copies of docs) Fixed/Enhanced \u00b6 Make /data directory in container, so it can be mounted Fix a bug when a single gene provided to indicator_genes in TCellSelection Move ModuleScoreCalculator before clustering so that the scores can be used in vars.to.regress of SCTransform while clustering Set default assay to RNA in case module scores only caculated using integrated features in ModuleScoreCalculator Improve QC plots in SeuratPreparing by marking the cells that are removed in the plots instead of doing before/after plots Fix type annotation for envs.features_defaults.ncol in docstring for SeuratPreparing (causing pipen-board not converting to int) Fix the cluster order in pie charts for CellsDistribution Fix the cluster order in pie charts for SeuratClusterStats Fix order in pie charts for SampleInfo Fix docstring for envs.div.args of Immunarch (more clear description of method) Allow mutiple columns in the file for envs.features_defaults.features in SeuratClusterStats Allow order to be optional for CloneResidency (errored when not provided) Add number of clusters at the end of log for SeuratClusteringOfAllCells / SeuratClusteringOfTCells Add stricter checker for input file (#13) Indicate the case name in logs when pie is enabled for group-by in SeuratClusterStats Allow to skip overlap and gene usage analyses by setting method to none for Immunoarch (#11, #12) Don't cluster on heatmap when there are only 2 samples for TCRClusterStats (#11) Import Seurat explictly to avoid satijalab/seurat#2853 in MetabolicFeatures Fix when NA values in data for heatmap in MetabolicPathwayActivity Fix error when no significant pathways selected in MetabolicPathwayHeterogeneity Give better error message in CellsDistribution if group value not found for CellsDistribution (#16) Try including more genes (even though insignificant) in volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells (#17) Add margins to volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells Fix when envs.cell_qc is None (not provided) for SeuratPreparing Fix ident in cases of envs.dimplots not working for SeuratClusterStats Added \u00b6 Add ClusterMarkersOfAllCells and TopExpressingGenesOfAllCells and set them as optional Add dim plots in SeuratClusterStats to overlay TCR presence/absence of cells (#14) Breaking changes-0.9.0 \u00b6 Rename TCRClusteringStats to TCRClusterStats (#15) 0.8.3 \u00b6 \ud83d\udcdd Fix typos in docs \ud83d\udcdd Add links to some optional input files (#9, 5) \ud83d\udd28 Add apptainer to docker entry.sh (#9, 6) \ud83d\udc84 Adjust process order in reports (#9, 1) \u2b06\ufe0f Bump pipen-report to 0.13.1 (#9, 2) 0.8.2 \u00b6 Bump biopipen to 0.18.3 to fix when either ident is empty for MarkersFinder 0.8.1 \u00b6 Bump biopipen to 0.18.2 to fix a bug when the min length of CDR3 seqs > 12 for CDR3AAphyschem 0.8.0 \u00b6 Housekeeping and docs updates \u00b6 Bump biopipen to 0.18.1 Mention function changes with versions in docs Add apptainer in board.toml so the command can be generated in pipen-board Make logo shorter in docs Add docker image with -full tags to include all dependencies Print command help message if run test failed in CI Add singularity/apptainer in FAQ for \"no space left\" question Add -w fro apptainer in docs (as we need to save pipen-board file in home directory) Added-0.8.0 \u00b6 Add TESSA process for tessa analysis Add volcano plot for MarkersFinder and ClusterMarkers Fixed \u00b6 Fix when Sample is the only column in meta for ImmunarchLoading Add clear message when k.weight is too large for IntegrateData in SeuratClustering Allow unique: prefix for on in SampleInfo Fix sample order in plots for SampleInfo Remove tidyseurat:: prefix for filter in scripts of MetaMarkers , ScFGSEA and SeuratClusterStats in case tidyseurat::filter is not exported when installed from conda (but it will make dplyr::filter work anyway on seurat object) Breaking changes-0.8.0 \u00b6 Redesign envs for SeuratClusteringStats to allow setting defaults for cases and switch identities for plots 0.7.0 \u00b6 Housekeeping and docs updates-0.7.0 \u00b6 Fix typos in docs/configurations TCRClustering should be TCRClusteringStats in Multi-case variable design section infile of [SampleInfo.in] should be samples.txt rather than sample.txt Remove unused scripts by deprecated processes Bump pipen-report to 0.12.8 Add master branch and master tag as stable tag for docker image Add pdf version of the flowchart (#4) Add warning for the results in getting started tutorial Bump pipen-board to 0.11.5 Add apptainer to the docs Added-0.7.0 \u00b6 Add ModuleScoreCalculator to calculate module scores or cell cycle scores See: https://pwwang.github.io/immunopipe/processes/ModuleScoreCalculator/ Allow SampleInfo to perform statistics on the sample information See: https://pwwang.github.io/immunopipe/processes/SampleInfo/ Add TCR_Cluster_Size and TCR_Cluster_Size1 from TCRClustering to metadata for further integrative analysis See: https://pwwang.github.io/immunopipe/processes/TCRClusters2Seurat/ Fixed-0.7.0 \u00b6 Fix default height and width for plots in SeuratClusterStats Fix cluster order not kept after annotation using hitype in CellTypeAnnotation Breaking changes-0.7.0 \u00b6 Change seurat_clusters_old to seurat_clusters_id to save old seurat_clusters in CellTypeAnnotation Remove MarkersForClustersOfAllCells and TopExpressingGenesOfAllCells processes Rename MarkersForClustersOfTCells to ClusterMarkers Rename TopExpressingGenesOfTCells to TopExpressingGenes Rename envs.exprs to envs.features for SeuratClusterStats envs.exprs.genes is also renamed to envs.features.features 0.6.0 \u00b6 \u2b06\ufe0f Bump biopipen to 0.16 \ud83d\udcdd Add documentation \ud83d\udc9a Fix docs building in CI \ud83d\udcdd Update README with flowchart 0.5.1 \u00b6 \u2728 Add TopExpressingGenes \ud83c\udfa8 Move RadarPlots to biopipen \u2b06\ufe0f Bump biopipen to 0.15.2 0.5.0 \u00b6 \u2b06\ufe0f Upgrade biopipen to 0.15.0 \ud83d\udc9a Use better strategy docker image building 0.4.0 \u00b6 \u2b06\ufe0f Bump biopipen to 0.6 \u2b06\ufe0f Upgrade other dependencies \ud83d\udc9a Use micromamba for docker image building \u2b06\ufe0f Add procps-ng for vdjtools for docker building 0.3.0 \u00b6 \ud83d\udc9a Use build 2 for genomeinfodbdata from bioconda (0.2.4) \ud83d\udc7d\ufe0f Use config from pipen_args \u2b06\ufe0f Pump biopipen to 0.5.3, pipen-args to 0.3.2 \u2b06\ufe0f Upgrade deps for docker \ud83d\udcdd Add flowchart in README.md \ud83d\udc1b Fix error when --config not passed 0.2.4 \u00b6 \ud83d\udc9a Use lastest miniconda3 for docker build \ud83d\udc9a Use conda channel pwwang for bioconductor-genomeinfodbdata for fix (bioconda/bioconda-recipes#31349) \u2b06\ufe0f Upgrade biopipen to 0.4.9 \ud83d\udcdd Add URL to example in README 0.2.3 \u00b6 \u2b06\ufe0f Upgrade biopipen to 0.4.8 0.2.2 \u00b6 \u2b06\ufe0f Upgrade biopipen to 0.4.7 to fix SeuratPreparing 0.2.1 \u00b6 \ud83d\udd25 Fix the bug of the wrong arguments in help page \u2b06\ufe0f Upgrade clustcr to 1.0.2 \ud83d\udcdd Fix docs for metabolic analysis 0.2.0 \u00b6 \u267b\ufe0f Move in-house processes out of processes.py \u267b\ufe0f Split up MARKERS_FINDER \u267b\ufe0f Refactor RadarPlots \u2728 Add an example config file \u26a1\ufe0f Add filter for RadarPlots \ud83d\udcdd Update docs \u2b06\ufe0f Upgrade deps \ud83d\udd27 Update docker/environment.yml \ud83d\udc1b Fix CloneHeterogeneity when only 1 row in continency table 0.1.1 \u00b6 \ud83d\udc9a Try fix pip in environment.yml \ud83d\udcdd Update readme for requirement checking \ud83d\udcdd Update docs to fix #1 \ud83d\udcdd Update CHANGELOG \u2b06\ufe0f Adopt biopipen 0.4.0 0.1.0 \u00b6 \ud83e\ude79 Disable force-caching for some procs \u2b06\ufe0f Upgrade datar to 0.8.* \u2728 Add dockerfile \u2b06\ufe0f Upgrade pipen to 0.3 \ud83d\udca5 Remove gene lists from start processes \u2b06\ufe0f Upgrade biopipen to 0.3 \u2b06\ufe0f Upgrade pipen to 0.3.5 0.0.7 \u00b6 Add CloneHeterogeneity Allow setting indicator_gene for TCellSelection Adopt latest datar and biopipen 0.0.6 \u00b6 \u2728 Allow dimplots with clonal information 0.0.5 \u00b6 \u2728 Allow more flexible dim plots 0.0.4 \u00b6 \u2728 Refactor markers finder module and add meta-marker analysis 0.0.3 \u00b6 -\u2728 Add metabolic pathway analysis 0.0.2 \u00b6 Adopt biopipen 0.1.3 0.0.1 \u00b6 First release","title":"Change log"},{"location":"CHANGELOG/#change-log","text":"","title":"Change Log"},{"location":"CHANGELOG/#232","text":"chore: update r-biopipen.utils version to 0.3.5=r43_6 in environment_rpkgs.yml chore: update r-scplotter version to 0.6.5=r43_3 in environment_rpkgs.yml chore: update blessed to version 1.26.0, pipen to 1.1.8, and pipen-runinfo to 1.1.1 chore: update r-hitype dependency in environment_base.yml to support sctype feat: add agent skills to construct configuration to run the pipeline chore: bump biopipen to 1.1.7 (support mutliple subset_by columns for metabolic landscape analysis)","title":"2.3.2"},{"location":"CHANGELOG/#231","text":"chore: chore: update Dockerfile to install numpy version 2.3 for compatibility with scanpy chore: add pwwang::r-sccatch to environment_base.yml chore: update r-plotthis dependency version to 0.9.4 chore: update r-scplotter dependency version to 0.6.5 feat: clone selectors gain a within option to select clones within a specific subset feat: clone selectors and / or support multiple selectors (more than 2) chore: update biopipen dependency version to 1.1.5 fix(scrna.MarkersFinder): update database handling in enrichment plots in case it is from gmt files fix(scrna.PseudoBulkDEG): update database handling in enrichment plots to use unique databases in case gmt files were used fix(scrna.CellTypeAnnotation): ensure at least 2 clusters for cell type annotation for scCATCH feat(tcr.ClonalStats): add caching functionality for plots feat(scrna.ScFGSEA): add caching functionality for GSEA results feat(scrna.CellTypeAnnotation): enhance cell type annotation functionality to support dict input for direct annotations","title":"2.3.1"},{"location":"CHANGELOG/#230","text":"chore: bump pipen to v1.1 so asynchronous path operations are supported refactor: convert synchronous methods to asynchronous in gbatch.py feat: add example configuration file fix: update header reading method in validate_config to use read_text docs: update process documentation with additional references and image links docs: update installation and running documentation to reflect dependency changes docs: add FAQ entry for mouse data support in the pipeline chore: update r-biopipen.utils version to 0.3.5 in environment_rpkgs.yml fix(RunSeuratDEAnalysis): handle +Inf/-Inf values in avg_log2FC to make visualization works chore: bump biopipen to 1.1.1 docs(tcr.ClonalStats): correct typo in documentation for ClonalStatsPlot reference","title":"2.3.0"},{"location":"CHANGELOG/#222","text":"chore: force conda to rebuild with biopipen.utils.R v0.3.4-7 make sure 'direct' method of CellTypeAnnotation keeps the order chore: update r-plotthis dependency version to 0.9.0=r43_3 chore: update biopipen dependency to version 1.0.0 fix(scrna.CellTypeAnnotation): handle NA values in cell type processing to prevent errors chore(scrna.SeuratPreparing): update min_cells parameter to require at least 3 cells for SCTransform fix: enhance seurat path resolution and error handling in check_genes function fix: improve seurat path resolution for containerized environments in check_dim function","title":"2.2.2"},{"location":"CHANGELOG/#221","text":"docs: add FAQ entries for process reruns after updating and skipping essential processes docs: add installation note for pipen-dry package in FAQ chore: add pipen-dry as an optional dependency and include it in extras ci(docker): use multi-staging building and make the packages relying numpy v1 to be merged to the base environment, which largely reduce the size of the image chore: bump pipen-cli-gbatch to 0.1.5 (make default running profile work) chore: update pipen-report version to 0.23.15 chore: update clustcr version in environment_base.yml to be compatible with numpy v2 chore: add .dockerignore file to exclude unnecessary files from Docker builds chore: update Python version to 3.12 and adjust biopipen.utils version in environment files chore: add Dockerhub descriptions for immunopipe, immunopipe-base, and immunopipe-rpkgs chore: update r-scplotter version to 0.6.4=r43_2 in environment_rpkgs.yml fix(ClonalDiversityPlot): fix calculating Gini coefficient fix(MarkersPlot): handle errors when subsetting object features fix(MarkersPlot): exclude groups that failed DE analysis from plotting chore: update r-plotthis version to 0.9.0=r43_1 in environment_rpkgs.yml fix(boxviolinplot): skip processing for data frames with less than 2 rows fix(network): update ggplot2 version check for link_type_by support fix(velocityplot): update ggplot2 version check for arrow length handling chore(heatmap): add warning for unknown arguments in HeatmapAtomic function feat: add list_fonts and import_font utilities chore: update r-biopipen.utils version in environment_rpkgs.yml to 0.3.4=r43_7 fix(RunSeuratDEAnalysis): improve error handling by returning empty data frame on logic error and adding traceback on stop feat: set default font to \"LiberationSans\" for plotthis plots fix: update RunUMAPArgs to use the correct reduction and improve dims handling fix(RunSeuratUMAP): avoid changing of identity when using features for RunUMAP chore(RunSeuratTransformation, RunSeuratMap2Ref): ensure return.only.var.genes defaults to FALSE when using SCTransform chore: update biopipen version to ^0.34.28 in pyproject.toml feat(tcr.ClonalStats): add save_data parameter to ClonalStats for saving plot data fix(scrna.PseudoBulkDEG): change default assay from \"RNA\" to None so that default assay can be used by default feat(scrna.ScFGSEA): add assay parameter to allow specification of assay in analysis fix(scrna.CellTypeAnnotation): correct assignment of identities in rename_idents function feat(tcr.CDR3Clustering): add verbose output option for GIANA command fix(scrna.CellTypeAnnotation): update package requirement from celltypist to celltypist2 (a version adopts numpy v2) fix(tcr.TESSA): add Keras model migration support for v2 and v3 fix(scrna.CellTypeAnnotation): improve handling of over_clustering assignment from Seurat object for celltypist","title":"2.2.1"},{"location":"CHANGELOG/#220","text":"BREAKING: restructure Docker workflows and update environment configurations using multiple-image/stage building, no \"-full\" suffix for image tags needed anymore. BREAKING: rename TCRClustering to CDR3Clustering across documentation and codebase to adopt for BCR data BREAKING: prevent export of RDS/qs files in SeuratPreparing and SeuratMap2Ref classes. NOTE that this may break reruning with cached SeuratPreparing and SeuratMap2Ref processes. The RDS/qs output files are no longer exported to output directory to reduce the report size. Instead, they are staying in the working directory for downstream processes to use. But the the figures will be still displayed in the report as before. fix: swap SeuratMap2Ref and SeuratClustering to make sure graph doesn't get overwritten fix: refactor VDJ configuration detection in validate_config when running with gbatch fix: default group_by to None for ClusterMarkers/ClusterMarkersOfAllCells so default ident will be used docs: update configuration options in getting started guide docs: update notes in Seurat processes to prevent overwriting cluster information docs: update column naming in SeuratClustering and CellTypeAnnotation documentation docs: update figures after CDR3Clustering renaming ci: add cache deletion step to save space in Docker workflow test: update configuration files and tests test: update assertions in test_route_sampleinfo_full for correct flow after refactoring test: reorder assertions in test_route_sampleinfo_full for correct flow due to the swapping of SeuratMap2Ref and SeuratClustering chore: bump biopipen version to 0.34.23 (related changes below) docs(scrna.SeuratPreparing): improve documentation for SeuratPreparing to make sure new lines in code blocks docs(scrna.SeuratClusterStats): enhance documentation for cluster statistics plots docs(tcr.ClonalStats): add exapmle configurations and plots docs(scrna.ScFGSEA): add examples and usage details for GSEA plots docs(CellCellCommunication): add example output for ligand-receptor interactions docs(CellCellCommunicationPlots): add examples for various plot types docs(scrna.MetabolicPathwayActivity): add merged heatmap example docs: improve documentation for SeuratPreparing to make sure new line\u2026 (#180) fix(scrna): update group_by assignment to use GetIdentityColumn feat(scrna.SeuratClustering): add envs.ident as shortcut for custom cluster name chore(scrna.SeuratClusterStats): set default group_by for dimplots to None docs(scrna): correct parameter names in docstring (ident-1 to ident_1, and ident-2 to ident-2) feat(scrna): add return option for identity column in convert_seurat_to_anndata function feat(scrna.CellCellCommunication): enhance groupby handling for Seurat objects feat(scrna.CellTypeAnnotation): add support for specifying identity column in CellTypeAnnotation for celltypist feat(scrna.CellTypeAnnotation): enhance identity column handling and add backup column support feat(scrna.CellTypeAnnotation): enhance classifier initialization and input handling for celltypist enh(scrna.MarkersFinder): add logging for plot processing in marker and enrichment functions feat(scrna.CellTypeAnnotation): require celltypist package with specified version and python interpreter docs(scrna): update dbs/gmtfile parameter description for enrichment analysis chore(scrna): update future.globals.maxSize to Inf for improved memory handling feat(tcr.CDR3Clustering): rename TCRClustering to CDR3Clustering and adopt BCR data docs(scrna.CellTypeAnnotation): clarify renaming of original identity column during cell type annotation see full changelog at https://pwwang.github.io/biopipen/CHANGELOG/ .","title":"2.2.0"},{"location":"CHANGELOG/#213","text":"docs: update docs for ClusterMarkers with examples ci: update biopipen dependency for tests feat: add new tests and configuration for ScRepLoading, ScRepCombiningExpression and SeuratClusterStats test: add test for clustermarkers test: add test for TOrBCellSelection docs: enhance documentation for PseudoBulkDEG and MarkersFinder test: add ClonalStats tests and configuration test: add ScFGSEA tests and configuration test: add CellCellCommunication and CellCellCommunicationPlots tests docs: update ScrnaMetabolicLandscape doc images chore: bump biopipen to 0.34.17 fix(scrna.MarkersFinder): enhance error handling in enrichment plotting and fix all-enrich plots when ident_1 is NULL fix(tcr.ClonalStats): replace deprecated ClonalDynamicsPlot with ClonalStatPlot","title":"2.1.3"},{"location":"CHANGELOG/#212","text":"test: update order of ScRepLoading and SeuratClustering in assertions in route tests docs: update configuration section name from cli-gbatch to gbatch docs: enhance installation and introduction documentation fix: better infer has_vdj when running by gbatch","title":"2.1.2"},{"location":"CHANGELOG/#211","text":"fix: correct order of input requirements for ScRepCombiningExpression","title":"2.1.1"},{"location":"CHANGELOG/#210","text":"BREAKING: rename process LoadRNAFromSeurat to LoadingRNAFromSeurat feat: enhance configuration validation logic feat: implement LoadRNAFromSeurat process to allow specifying sample column feat: allow SeuratClustering, SeuratMap2Ref and CellTypeAnnotation at the same time in a run feat: add \"help\" subcommand to show help for specific processes fix: make sure the routes of the pipeline work as expected (tests added) fix: ensure correct handling of kp_mount in main function docs: documentation and update processes for T/B cell selection and clustering ci: improve immunopipe installation check docs: update configurations and introduction for LoadingRNAFromSeurat process chore: bump xqute to 0.10.17 chore: bump pipen to 0.17.24 chore: bump pipen-cli-gbatch to v0.1.3 chore: bump pipen-args to v0.17.7 chore: bump pipen-report to 0.23.13 chore: update biopipen to version 0.34.16 feat(scrna.MarkersFinder): allow using other metadata columns from object for enrichment plot of all subcases","title":"2.1.0"},{"location":"CHANGELOG/#203","text":"feat: adopt pipen-cli-gbatch, allowing --mount-as-cwd to infer workdir and outdir fix: fix when running with a configuration file solely fix: fix gbatch deamon workdir not created inside the pipeline working folder for gbatch cli fix: fix outdir not following the pipeline name with gbatch cli docs: update volume mounting syntax in docker and singularity commands docs: update immunopipe gbatch options for running the pipeline on Google Cloud Batch Jobs chore: bump pipen-cli-gbatch to 0.0.7 and pipen-report to 0.23.12 chore: bump biopipen to 0.34.14 fix(scrna_metabolic_landscape): fix report paging issue docs(scrna.MarkersFinder): fix links in docs fix(scrna.SeuratClusterStats): improve error handling in feature plotting when save_code (due to upgrade to ggplot2 v4) feat(MarkersFinder): use scplotter::MarkersPlot (wrapped by biopipen.utils::VizDEGs to visualize marker fix(scrna.CellTypeAnnotation): update logging for celltypist command execution","title":"2.0.3"},{"location":"CHANGELOG/#202","text":"fix: fix immunopipe -h/--help not working as expected feat(gbatch): enhance validation and default handling in main function feat(gbatch): add --mount-as-cwd option to mount a cloudpath as working directory chore: bump biopipen to 0.34.10 docs(scrna.SeuratPreparing): enhance cell_qc parameter description in SeuratPreparing docs(scrna.ModuleScoreCalculator): update link format in ModuleScoreCalculator docstring","title":"2.0.2"},{"location":"CHANGELOG/#201","text":"feat: add utility cli for gene checking and dimension verification chore: make tests order work as expected chore: bump biopipen to 0.34.9 fix(scrna.CellCellCommunication): handle numpy product attribute error feat(scrna.ModuleScoreCalculator): add post mutaters functionality to allow compound modules based on added modules docs(scrna.MarkersFinder): correct URL in documentation feat(scrna.CellTypeAnnotation): add support for additional direct cell type annotations feat(scrna.MarkersFinder): enhance enrichment plot descriptions chore(scrna.CellCellCommunicationPlots): set default case to \"Cell-Cell Communication\" feat(scrna.CellCellCommunicationPlots): add table output option for ccc data chore: bump scplotter to 0.6.0 in docker image chore: optimize clonal_size_data feat(featurestatplot): add pos_only parameter to filter positive feature values chore(enrichmentplot) remove preset label_nudge parameter in BarPlot call feat: add downsample parameter to feature statistic plots feat(featurestatplot) default options to TRUE to show row and column names when plot_type is heatmap-alike","title":"2.0.1"},{"location":"CHANGELOG/#200-cloud-support-enhanced-visualization-new-analysesfeatures-and-more","text":"","title":"2.0.0 (Cloud support, enhanced visualization, new analyses/features, and more ...)"},{"location":"CHANGELOG/#cloud-support","text":"feat: immunopipe can now be run on Google Cloud Batch Jobs, allowing for scalable and efficient processing of larger datasets. You can either run the pipeline using the gbatch scheduler ; or run the entire pipeline on Gooble Batch Jobs using immunopipe gbatch command. See Run the pipeline using Google Cloud Batch Jobs\u00b6 for more details.","title":"Cloud support"},{"location":"CHANGELOG/#enhanced-visualization","text":"feat: scplotter and plotthis are now used for plotting, providing enhanced visualization capabilities and uniformity across different processes. feat: default descriptions/captions are now added to plots, making them more informative.","title":"Enhanced visualization"},{"location":"CHANGELOG/#enhanced-performance","text":"feat: the pipeline now uses qs2 for store the R objects, which speeds up the loading and saving of Seurat objects. feat: step-wise caching (in addition to process-wise) is now supported, especially for Seurat processes, allowing for faster re-running of the pipeline by caching intermediate results and improving results reproducibility. refactor: MetabolicLandscapeAnalysis is refactored for flexibility and performance improvement. BREAKING: enrichR is retired and replaced by enrichit for enrichment analysis, making it offline and more flexible. This enables the entire pipline to run without internet connection.","title":"Enhanced performance"},{"location":"CHANGELOG/#new-analysesfeatures","text":"feat: the pipeline now supports cell-cell communication analysis . feat: plots are supported for all cases for MarkersFinder and ScFGSEA , allowing plotting the markers (DEGs) and enriched pathways for all cases (e.g. all seurat clusters) in a single plot. BREAKING: the immunarch package is now replaced by scRepertoire for more features and allowing customized clonotype definition. feat: envs.mutaters is now supported for SeuratPreparing to allow create factor (categorical) columns in the metadata. feat: PseudoBulkDEG is added to perform pseudo-bulk differential expression analysis. feat: BCR-seq data is now supported, allowing users to analyze BCR-seq data paired with scRNA-seq data. feat: Now Seurat object (in RDS or qs2 format) is supported as input for scRNA-seq data. feat: Now loom format is supported for scRNA-seq data, allowing users to use loom files as input for the pipeline. feat: add mcp server functionality to launch mcp server to help compose the configuration file.","title":"New analyses/features"},{"location":"CHANGELOG/#house-keeping","text":"build: docker images are now built based on the biopipen base image. ci: the test workflow now caches the running intermediate files to speed up the tests. docs: the citation information is now added to the documentation, allowing users to easily cite the pipeline in their publications. chore(deps): biopipen is bumped to 0.34.8, which includes various bug fixes and enhancements. See the biopipen releases for more details.","title":"House keeping"},{"location":"CHANGELOG/#144","text":"chore(deps): add gcc_linux-64 to Docker environment dependencies docs: add input and output sections to multiple process documentation files feat: add PDF output for K-means and T cell plots, enhancing report generation deps: bump biopipen to 0.32.3 0.32.1: fix(scrna.ScFGSEA): fix case gmtfile not working fix(TopExpressingGenes): add InlineNotification component to TopExpressingGenes.svelte fix(scrna.SeuratClusterStats): fix kind not being added to the figure file name for plots of features feat(scrna.SeuratPreparing): support percent.mt, percent.ribo, percent.hb and percent.plat for mouse 0.32.2: feat: add PDF output option for SampleInfo plots feat: add PDF output options for violin and scatter plots in Seurat preparation scripts feat: add PDF output options for volcano, dotplot, venn, and upset plots feat: add PDF output option for Enrichr plots in TopExpressingGenes script feat: add PDF output options for UMAP plots in SeuratMap2Ref script; update image handling in misc.liq feat: add PDF output options for cluster size distribution, shared clusters, and sample diversity plots; update plotting functions to handle multiple output formats feat: add PDF output options for various Immunarch scripts; enhance reporting with downloadable PDF files feat: add PDF output options for cluster size distribution, dimension plots, and feature plots; enhance reporting with downloadable PDF files feat: add PDF output options for radar and bar plots; enhance reporting with downloadable PDF files feat: add PDF output options for CloneResidency script; enhance reporting with downloadable PDF files feat: add PDF output options for GSEA table and enrichment plots; enhance reporting with downloadable PDF files feat: add PDF output options for pie charts, heatmaps, Venn plots, and UpSet plots; enhance reporting with downloadable PDF files feat: add PDF output options for Enrichr plots; enhance reporting with downloadable PDF files feat: add PDF output options for estimated coefficients and distribution plots; enhance reporting with downloadable PDF files 0.32.3: chore: add descriptive summaries for fgsea and enrichr results","title":"1.4.4"},{"location":"CHANGELOG/#143","text":"deps: update pipen-runinfo dependency to version 0.8.0 (pipen to 0.15.2) deps: update biopipen dependency to version 0.31.4 fix(scrna.SeuratMap2Ref): fix refnorm not detected for NormlizeData'ed reference","title":"1.4.3"},{"location":"CHANGELOG/#142","text":"deps: add bioconductor-destiny dependency in docker environment files for ModuleScoreCalculator","title":"1.4.2"},{"location":"CHANGELOG/#141","text":"docs: update tutorial dataset information and links","title":"1.4.1"},{"location":"CHANGELOG/#140","text":"docs: update Singularity and Apptainer commands to include --writable-tmpfs flag docs: allow collapsing ns/choice items in the docs for processes docker: update Dockerfile to include npm cache configuration to allow the pipeline to run on read-only file system tests: update SeuratPreparing config to use DoubletFinder for doublet detection ci: use latest actions deps: add r-clustree as a dependency in docker environment files deps: update dependencies in docker environment files (python3.10, R4.3) deps: bump biopipen to 0.29.0 fix(tcr.TCRClusterStats): fix envs.shared_clusters.heatmap_meta being broken by envs.shared_clusters.sample_order (@ li.ying@mayo.edu ) choir(scrna.SeuratMap2Ref): present better error message when envs.use or values of envs.MapQuery.refdata not in reference (@ li.ying@mayo.edu ) fix(scrna.MarkersFinder): run PrepSCTFindMarkers when needed choir(scrna.SeuratClustering): use FindClusters to run for multiple resolutions choir(scrna.SeuratSubClustering): use FindClusters to run for multiple resolutions feat(scrna.SeuratClustering): add clustree plot (@ li.ying@mayo.edu ) feat(scrna.SeuratSubClustering): add clustree plot tests(scrna.SeuratClusterStats): add assertion for clustree plot generation deps: bump biopipen to 0.29.1 fix(delim.SampleInfo): fix numbers not split up when each is specified. enh(delim.SampleInfo): make sizes of pie charts proportional to number of samples when each is specified enh(scrna.MarkersFinder): run PrepSCTFindMarkers when necessary before calling FindMarkers feat(scrna.SeuratPreparing): add option to cache Seurat object at different steps feat(scrna.SeuratPreparing): allow doubletfinder to run with a different number of cores chore(scrna.SeuratClustering): record PrepSCTFindMarkers command in sobj@commands tests(scrna.SeuratClusterStats): use less stringent p-value cutoff for DEG/MarkersFinder tests(scrna.SeuratPreparing): add doubletfinder in tests deps: bump biopipen to 0.29.2 chore(scrna.SeuratClusterStats): use ident label length to adjust default height for feature plots fix(scrna.MetaMarkers): fix seurat object not updated when expanding cases and run PrepSCTFindMarkers when necessary before calling meta-markers fix(scrna.MarkersFinder): fix fetching command when composing the PrepSCTFindMarkers command fix(scrna_metabolic_landscape): handle null values in for loop in MetabolicFeatures and MetabolicFeaturesIntraSubset for report generation deps: bump biopipen to 0.30.0 BREAKING(scrna): move clustree plots from SeuratClustering/SeuratSubClustering to SeuratClusterStats feat(scrna.CellTypeAnnotation): allow to merge/not to merge (envs.merge) the clusters with the same labels predicted feat(scrna.SeuratPreparing): add scDblFinder to detect doublets feat(scrna.SeuratMap2Ref): add envs.skip_if_normalized option to skip normalization if query is already normalized using the same - method as the reference refactor(tcr.Immunarch): source the files for Immunarch scripts for better debugging refactor(scnra.SeuratClustering): refactor the script for better debugging refactor(scnra.SeuratPreparing): refactor the script for better debugging fix(scrna): fix resolution expansion for SeuratClustering and SeuratSubClustering fix(scrna): Fix generating PrepSCTFindMarkers command when no previous commands present tests(scrna.ScFGSEA): fix unavailable urls to GMT files chore(scrna.SeuratMap2Ref): optimize memory usage chore(scrna.MetaMarkers): remove plugin_opts.poplog_max chore(tcr.CloneResidency): improve logging when handling subjects deps: bump biopipen to 0.31.3 enh(scrna.SeuratMap2Ref): check if reference has SCTModel if SCTransform'ed (likely prepared by old Seurat) fix(tcr.CDR3AAPhyschem): use sequence from TRB chain only fix(tcr.CDR3AAPhyschem): fix when chain is not available fix(tcr.TCRClustering): fix for multi-chain TCRs, use TRB only if on_multi is false fix(tcr.TCRClustering): fix when chain is not available","title":"1.4.0"},{"location":"CHANGELOG/#139","text":"docs: update docs for TCellSelection to avoid confusion deps: bump biopipen to 0.27.9 feat(tcr.TCRClusterStats): add sample_order to set sample order on heatmap and cluster_rows to switch row clustering on/off","title":"1.3.9"},{"location":"CHANGELOG/#138","text":"docs: remove -w option for apptainer/singularity as no writing is necessary since pipen-board 0.15.1 deps: update biopipen to version 0.27.8 fix(scrna.SeuratClusterStats): fix selected columns not unique for stats feat(scrna.SeuratMap2Ref): allow non-SCTransform'ed reference feat(scrna.SeuratMap2Ref): allow splitting query object for mapping (pwwang/immunopipe#61) deps: update pipen-board to version 0.15.1 (allow configuration file path in the URL box on Web UI)","title":"1.3.8"},{"location":"CHANGELOG/#137","text":"ci: fix docker images building when no essential changes made","title":"1.3.7"},{"location":"CHANGELOG/#136","text":"ci: fix deploy workflow (#59) ci: add README.md to tests-output branch ci: fix test/test workflow tests: add make test tests: init test data preparation tests: add test for ImmunarchLoading tests: add tests for SeuratPreparing tests: Update configs for SeuratPreparing test to subset cells so tests can run on CI tests: update SeuratPreparing test to disable export tests: add tests for SeuratClusteringOfAllCells/SeuratClustering docs: update installation instructions (@ stein.mariam@mayo.edu ) deps: bump biopipen to version 0.27.7 (0.27.5-0.27.7) fix(scrna.SeuratClusterStats): fix color palette for ridge plots (@ stein.mariam@mayo.edu ) feat(scrna.SeuratPreparing): add envs.cell_qc_per_sample to filter cells before merging instead after fix(scrna_metabolic_landscape.MetabolicFeatures): fix return value of groups with less than 5 cells in do_one_group fix(scrna_metabolic_landscape): fix mutaters not working. fix(scrna_metabolic_landscape.MetabolicFeatures/MetabolicFeaturesIntraSubset): skip groups with less than 5 cells in do_one_group and save a warning file under the case chore: fix typo in class name ExprImpution to ExprImputation","title":"1.3.6"},{"location":"CHANGELOG/#135","text":"ci/test: add tests in CI and deploy output in a different branch deps: bump biopipen to 0.27.4 choir(delim.SampleInfo): add alpha to the colors of the plots using biopipen color pallete docs(tcr/scrna/scrna_metabolic_landscape): update links of images in docs","title":"1.3.5"},{"location":"CHANGELOG/#134-post","text":"ci/test: init ci for tests docs: introduce versioning for docs","title":"1.3.4-post"},{"location":"CHANGELOG/#134","text":"deps: bump biopipen to 0.27.3 deps: bump pipen-poplog to 0.1.2 (quick fix for populating logs when job fails) deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) choir(scrna.ScFGSEA): Skip cases when no cells found (#50) choir(scrna.MarkersFinder): Skip cases when no cells found (#50) choir(scrna.MetaMarkers): Skip cases when no cells found (#50) feat(scrna.SeuratPreparing): support DoubletFinder (#52)","title":"1.3.4"},{"location":"CHANGELOG/#133","text":"deps: temporary fix copier breaks with pyyaml-include v2 (copier-org/copier#1568) docs: update FAQ.md with instructions for running pipeline on a cluster deps: bump biopipen to 0.27.2 fix(scrna.RadarPlots): fix mutaters not working feat(tcr.CloneResidency): support envs.upset_ymax to set the max value of y axis in upset bar plot.","title":"1.3.3"},{"location":"CHANGELOG/#132","text":"deps: bump pipen to 0.14.5 deps: add r-complexupset package to environment.yml and environment_full.yml for CloneResidency deps: pin tensorflow to 2.15 for TESSA deps: bump biopipen to 0.27.1 depr(scrna.MarkersFinder): remove envs.use_presto as it's used by Seurat v5 by default enh(tcr.CloneResidency): support log scale for y axis of upset bar plots enh(scrna.SeuratClusterStats): allow to rotate labels in circos plot (pwwang/immunopipe#48) @ li.ying@mayo.edu enh(scrna.SeuratClusterStats): use pal_biopipen for ident colors in circos plot fix(scrna.CellsDistribution): fix the row order of the heatmaps fix(scrna.SeuratClusterStats): fix when envs.split-by is specified feat(scrna.CellsDistribution): support envs.prefix_each feat(scrna.MarkersFinder): allow to set max number of genes to plot in dotplots feat(scrna.MarkersFinder): support setting detailed arguments for overlapping plots feat(scrna.MarkersFinder): support envs.prefix_group feat(scrna.ScFGSEA): support envs.prefix_each feat(scrna.RadarPlots): support envs.prefix_each and envs.subset choir(scrna.SeuratClusterStats): use logger instead of print for log messages choir(tcr.TCRClustering): print session info for clustcr script choir(scrna.MarkersFinder): flatten toc when no section and no ident-1 specified docs: add more detailed docs for envs.section for multiple processes BREAKING(scrna.SeuratMap2Ref): rename envs.name to envs.ident so envs.MapQuery.refdata is not - required anymore. It will be inferred from envs.ident and envs.use. @ li.ying@mayo.edu","title":"1.3.2"},{"location":"CHANGELOG/#131","text":"deps: bump pipen to 0.14.3 deps: pin ggplot2 to 3.4 for docker due to breaking changes of 3.5 deps: bump biopipen to 0.26.2 deps: bump datar-pandas to 0.5.5 to dismiss deprecated warnings fix(utils.misc.R): replace latin and greek characters with closest ascii chars for slugify() feat(scrna.TopExpressingGenes): support subset fix(scrna.CellsDistribution): fix the row order of the heatmaps. enh(tcr.CloneResidency): add legend for multiplets in upset plots. feat(scrna.SeuratClusterStats): add circos plot for cell composition stats (#46).","title":"1.3.1"},{"location":"CHANGELOG/#130","text":"deps: bump pipen to 0.14.1 deps: bump pipen-report to 0.18.2 deps: bump biopipen to 0.26.0 fix(scrna.CellTypeAnnotation): keep factor meta data when input and output are RDS for celltypist deps: bump datar to 0.15.4 (support pandas 2.2) fix(utils.single_cell.R): fix immdata_from_expanded missing other data columns fix(tcr.Immunarch): fix mutaters not working when no subset is set fix(scrna.CellsDistribution): fix hm_devpars not working fix(scrna.CellsDistribution): fix multiple cells_by columns and speed up plotting choir(tcr.CloneResidency): mark singletons in Venn diagrams more clear fix(scrna.RadarPlots): fix the order of groups on radar plots choir(scrna.RadarPlots): transpose the count/percentage table to save to files fix(scrna.MarkersFinder): fix generating report json file when no significant genes found choir(scrna.MarkersFinder): Plot maximum 20 genes in dotplots choir(scrna.MarkersFinder): Do not convert dashes in case names to dots see more at https://github.com/pwwang/biopipen/releases/tag/0.26.0","title":"1.3.0"},{"location":"CHANGELOG/#120","text":"docs: update FAQs to align with Seurat v5 docs: add image from manuscript to README.md docs: center the flowchart image in README.md docs: mention celltypist model prep in preparing input data deps: bump pipen to 0.13.2 deps: bump biopipen to 0.25.2: scrna.MarkersFinder: allow to cache FindAllMarkers results scrna.CellTypeAnnotation: support celltypist (pwwang/biopipen#111) scrna.SeuratSubClustering: add envs_depth = 1 to replace whole envs.cases when new case assigned scrna_metabolic_landscape.MetabolicPathwayHeterogeneit): fix output directory path is not slugified tcr.Immunarch: change case filling log to debug level","title":"1.2.0"},{"location":"CHANGELOG/#111","text":"deps: Bump biopipen to 0.24.2 chore: use internal slugify instead of slugify library tcr.Immunarch: fix spectratyping output file extension is not png scrna.SeuratPreparing: fix displaying filters in report scrna.SeuratPreparing: fix logging Seurat procedure arguments","title":"1.1.1"},{"location":"CHANGELOG/#110","text":"docs: update table in gallery deps: use pipen-poplog to populate job logs to pipeline running log deps: bump biopipen to 0.24. Hights: scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112) @yuey11 scrna.SeuratClustering/SeuratSubClustering: cache Seurat procedures step by step (#40) @xyfqwlzoe tcr.Immunarch: add plot_type to support boxplots for diversity metrics see more at https://github.com/pwwang/biopipen/releases/tag/0.24.0","title":"1.1.0"},{"location":"CHANGELOG/#105","text":"change: do not rescale gene expression in TCellSelection any more fix: fix column names of indicators not aligned with indicator_genes feat: add feature plots in TCellSelection deps: bump biopipen to 0.23.8 scrna.SeuratPreparing: log Seurat procedure arguments scrna.ScFGSEA: add subset to filter cells (pwwang/biopipen#112)","title":"1.0.5"},{"location":"CHANGELOG/#104","text":"deps: bump biopipen to 0.23.7 scrna.SeuratPreparing: update log message for transformation/scaling step scrna_metabolic_landscape.MetabolicPathwayHeterogeneity: add utils.gsea script source to support localizeGmtfile","title":"1.0.4"},{"location":"CHANGELOG/#103","text":"deps: add r-seuratdisk dependency to conda env files. @yuey11 deps: pin r-matrixstats to 1.1.0 in conda env files to fix useNames = NA error. @yuey11 refactor: optimize configuration file validation deps: bump biopipen to 0.23.6 feat: support url for gmtfile wherever GSEA is performed (pwwang/biopipen#113) tcr.Immunarch: add error message for empty filtered/subset data in diversity scrna.SeuratPreparing: correct description of default assay in docstr scrna.SeuratPreparing: run also the normal normalization procedures when SCTransform is used (useful for visualization purposes on RNA assay) scrna.ModuleScoreCalculator: document the names added by cell cycle score (#34) scrna.SeuratPreparing: support sample names as reference for IntegrateLayers","title":"1.0.3"},{"location":"CHANGELOG/#102","text":"deps: add bioconductor-glmgampoi to conda env files (#33) docs: correct the Seurat object assay description deps: bump biopipen to 0.23.5 fix: fix when no enriched items found for scrna.MarkersFinder , scrna.MetaMarkers and scrna.TopExpressingGenes scrna.SeuratClusterStats: fix when frac or frac_ofall is true and no group-by nor split-by is specified for stats utils.gsea.R: fix when no enriched items found for runEnrichr scrna_metabolic_landscript: fix adding report when ncores > 1","title":"1.0.2"},{"location":"CHANGELOG/#101","text":"docs: add gallery section to README.md change: set default nstart of kmeans to 25 in TCellSelection deps: add r-hdf5r in conda env files to support Read_10x_h5 from Seurat. @yuey11 deps: bump biopipen to 0.23.4 scrna.TopExpressingGenes: fix colnames while pulling average expression scrna.CellsDistribution: fix when cells_by has multiple column names scrna.CellTypeAnnotation: fix the order of the clusters for direct method scrna.SeuratClusterStats: add position options for bar plots for stats scrna.RadarPlots: add colors to set the colors of the loops in radar and bar plots tcr.Immunarch: add split_by and split_order to put subplots together in one single plots","title":"1.0.1"},{"location":"CHANGELOG/#100","text":"","title":"1.0.0"},{"location":"CHANGELOG/#highlights","text":"feat: support Seurat v5 (integration is now down by Seurat::IntegrateLayers ) feat: support supervised clustering (mapping cells to reference by Seurat ) feat: support dataset with scRNA-seq data only (no scTCR-seq data) feat: support diffusion map calculation (by ModuleScoreCalculator ) feat: support subclassing to cluster subsets of cells (by SeuratSubClustering ) feat: allow to ignore TCR data in TCellSelection and pass kmeans arguments feat: allow to set multiple resolutions ( envs.FindClusters.resolution ) in SeuratClustering / SeuratClusteringOfTCells change: change unsuperved cluster labels to c1 , c2 , ... in SeuratClustering by default docs: add gallery, which contains real-world examples of datasets from publications","title":"Highlights"},{"location":"CHANGELOG/#breaking-changes","text":"change: rename SeuratMetadataMutater to IntegratingTCR change: rename SeuratClusteringOfTCells to SeuratClustering change: rename TCRClusters2Seurat to IntegratingTCRClusters refactor: make SeuratClustering (instead of SeuratClusteringOfAllCells ) work for all cells when all are T cells change: move data preparation and integration from SeuratClustering to SeuratPreparing change: default mode of ImmunarchLoading to paired (instead of single ), which requires both alpha and beta chains (instead of beta chain only) to define a clonotype change: default dbs for enrichment analysis wherever applies to KEGG_2021_Human and MSigDB_Hallmark_2020","title":"Breaking changes"},{"location":"CHANGELOG/#changes","text":"feat: make TopExpressingGenes optional feat: add validate_config to validate configuration schematically","title":"Changes"},{"location":"CHANGELOG/#features","text":"feat(SeuratPreparing): allow to filter genes directly (by specifying envs.gene_qc.excludes ) feat(SeuratClusterStats): add ngenes to plot the number of genes expressed in each cluster feat(SeuratClusterStats): add barplot for features and allow aggregation of features feat(SeuratClusterStats): add envs.mutaters to mutate meta data feat(SeuratClusterStats): add histograms to plot number of cells against another variable feat(SeuratClusterStats): Add frac_ofall and transpose for stats to calculate fraction within group or against all cells, and transpose ident and group, respectively","title":"Features"},{"location":"CHANGELOG/#dependencies","text":"deps: add r-presto to conda environment files to support using presto to fastly find markers deps: add bioconductor-destiny to conda environment file to support add diffusion map components in ModuleScoreCalculator deps: add r-harmony to support harmony integration by Seurat v5 in conda env file deps: add r-sf to conda env file deps: remove vdjtools from conda env files deps: bump pipen-report to 0.16.3 deps: bump biopipen to 0.23.3 . Hightlight changes: scrna.MarkersFinder: Add envs.use_presto to use presto to speed up finding markers scrna.SeuratPreparing: Set envs.gene_qc.min_cells to 0 by default (instead of 3) scrna.ScFGSEA: Allow to ignore small group when fgsea fails due to all NAs for pre-ranks scrna.CellsDistribution: Allow to order clusters by envs.cluster_orderby scrna.CellsDistribution: Add heatmaps tcr.CloneResidency: Make section works in report tcr.Immunarch: Support paired chain data for VJ conjuction plots tcr.TESSA: Change envs.assay to None to use default assay of Seurat object scrna.SeuratClusterStats: Add avgheatmap to plot more elegant heatmap for average gene expressions scrna.SeuratClusterStats: Fix ident not working for dimplots scrna.SeuratClusterStats: Add cluster_orderby to order clusters for features scrna.SeuratClusterStats: Add na_group to keep NA values in group-by utils.mutate_helpers: Change arguments id_col and compare_col of paired to id and compare , respectively utils.mutate_helpers: Fix that subset can't be an expression for expanded family utils.mutate_helpers: Add top to select top entities (e.g clones) scrna.RadarPlots: Add breakdown and test to break down the cell distribution and run statistic test on the fractions","title":"Dependencies"},{"location":"CHANGELOG/#0112","text":"docs: move Immunarch to the later position in process list docs: Use master tag in getting-started","title":"0.11.2"},{"location":"CHANGELOG/#0111","text":"chore: change line length to 88 for flake8 chore: dismissing warning about wasting columns for SeuratClusteringOfTCells docs: update CHANGELOG.md with missing changes of last version docs: add version of renaming envs.tcell_indicator to envs.tcell_selector docs: remove unused doc files docs: add metadata illustration deps: bump biopipen to 0.22.8. Highlights: deps: bump pipen-board to 0.13.10 (pipen-report to 0.16.2) CellsDistribution: Don't add rownames to the output table file MarkersFinder (ClusterMarkers/ClusterMarkersOfAllCells): Optimize to use FindAllMarkers if ident.1 is not specified SeuratClusterStats: Fix path of expression table file CellTypeAnnotation: Allow using NA to exclude clusters from output Seurat object utils.mutate_helpers: Return ids only when subset is true and group is not NA for uniq = TRUE in expanded , collapsed , emerged and vanished","title":"0.11.1"},{"location":"CHANGELOG/#0110","text":"deps: update biopipen to 0.22.1, highlights: add V-J junction circos plots to Immunarch process add cache option to cache the clustering results if nothing changed except ncores, to SeuratClustering process add dot plots to MarkersFinder ( ClusterMarkersOfAllCells , ClusterMarkers ) process save exported table with only necessary columns for CellsDistribution process add descr to describe cases cases in report for CellsDistribution process add subset for dimplots in SeuratClusterStats process use a new palette ( biopipen ) for related processes optimize report rendering (using render_job() filter from pipen-report ) change metacols to extracols so essential columns get exported for ImmunarchLoading process add cache option to cache the clustering results if nothing changed except ncores for SeuratClustering ( SeuratClusteringOfAllCells ) process see more at https://github.com/pwwang/biopipen/releases/tag/0.22.0 and https://github.com/pwwang/biopipen/releases/tag/0.22.1 deps: update pipen-report to 0.16, highlights: scroll anchor into view on the page build report page when each process is done, instead of the whole pipeline see more at https://github.com/pwwang/pipen-report/releases/tag/0.16.0 change: remove Immunarch2VDJtools and VJUsage processes (vj usage analysis can be done in Immunarch process) change: change tcell_indicator to tcell_selector in TCellSelection process enhance: provide better error message when none barcode matches from RNA and TCR data for TCRClustering process docs: add memory usage reduction tips in FAQ chore: dismiss warnings of wasted input columns for multiple processes","title":"0.11.0"},{"location":"CHANGELOG/#0101","text":"chore: update pipeline description to include version in the logs fix: add fc-cache command to Dockerfile to solve Fontconfig error docker: optimize building full image based off the base image","title":"0.10.1"},{"location":"CHANGELOG/#0100","text":"docker: lock r-matrix version to 1.6_1 for compatibility docs: adopt mkdocs-rtd 0.0.10 (add scrollbar to the table of contents) deps: bump biopipen to 0.21.1 use r-logger for logging in R scripts docs: fix internal references in API docs deps: bump pipen-board to 0.13.6 SampleInfo: refactor data subset logic using subset instead of distinct Immunarch: add in.metafile to allow other meta info (i.e. seurat clusters) for future subsetting (#22) Immunarch: fix empty groups in diversity plot after subsetting Immunarch: allow subset to subset cells for analyses Immunarch: allow separate_by also works on other diversity plots Immunarch: add ymin and ymax to align diversity plots by separate_by Immunarch: add ncol to specify # columns in the combined plots RadarPlots: fix envs.order not working MarkersFinder: add overlap to find overlapping markers between cases (#24) MarkersFinder: allow subset to subset cells for analyses MarkersFinder: add dot plots for significant markers CellsDistribution: allow multiple columns for cells_by CellsDistribution: allow subset to subset cells for analyses utils.mutate_helpers.R: add include_emerged for expanded() and include_vanished for collapsed()","title":"0.10.0"},{"location":"CHANGELOG/#093","text":"deps: Bump biopipen to 0.20.7 deps: Bump pipen-board to 0.13.4 ClusterMarkers/ClusterMarkersOfAllCells: Choose avg_log2FC > 0 markers by default MarkersFinder: Allow to set assay and set assay to RNA by default CellsDistribution: Add venn/upset plot for overlapping cell groups in different cases SampleInfo: Add distinct to case to perform stats on distinct records","title":"0.9.3"},{"location":"CHANGELOG/#092","text":"\u2795 Add r-ggnewscale as dependency for CDR3AAPhyschem in docker image \u2b06\ufe0f Bump biopipen to 0.20.5 \ud83e\uddf1 CloneResidency: Integrate RNA data to allow more flexible analysis (i.e. within specific seurat clusters) \ud83c\udfd7\ufe0f CloneResidency: Rename envs.sample_groups to envs.section to be consistent with other processes \ud83d\udcdd ScFGSEA: Remove the link in the summary of the docstring (since they are not transformed in the report) \ud83c\udfa8 CDR3AAPhyschem: Give better error message when wrong group items are given \u2b06\ufe0f Bump pipen-board to 0.13.3 Add items automatically when blurred for list options Add other sections to description on the UI for processes","title":"0.9.2"},{"location":"CHANGELOG/#091","text":"\ud83d\udc1b Fix docstring for RadarPlots \u2795 Add pipen-diagram as dependency \u2795 Set pipen-runinfo as optional \u2b06\ufe0f Bump biopipen to 0.20.4 \ud83d\udcdd Update version in docs","title":"0.9.1"},{"location":"CHANGELOG/#090","text":"","title":"0.9.0"},{"location":"CHANGELOG/#housekeeping-and-docs","text":"Bump biopipen to 0.20.3 (pipen to 0.12) Use pipen-cli-ref to generate API for processes (it uses docstring of the process class so that we don't need to maintain two copies of docs)","title":"Housekeeping and docs"},{"location":"CHANGELOG/#fixedenhanced","text":"Make /data directory in container, so it can be mounted Fix a bug when a single gene provided to indicator_genes in TCellSelection Move ModuleScoreCalculator before clustering so that the scores can be used in vars.to.regress of SCTransform while clustering Set default assay to RNA in case module scores only caculated using integrated features in ModuleScoreCalculator Improve QC plots in SeuratPreparing by marking the cells that are removed in the plots instead of doing before/after plots Fix type annotation for envs.features_defaults.ncol in docstring for SeuratPreparing (causing pipen-board not converting to int) Fix the cluster order in pie charts for CellsDistribution Fix the cluster order in pie charts for SeuratClusterStats Fix order in pie charts for SampleInfo Fix docstring for envs.div.args of Immunarch (more clear description of method) Allow mutiple columns in the file for envs.features_defaults.features in SeuratClusterStats Allow order to be optional for CloneResidency (errored when not provided) Add number of clusters at the end of log for SeuratClusteringOfAllCells / SeuratClusteringOfTCells Add stricter checker for input file (#13) Indicate the case name in logs when pie is enabled for group-by in SeuratClusterStats Allow to skip overlap and gene usage analyses by setting method to none for Immunoarch (#11, #12) Don't cluster on heatmap when there are only 2 samples for TCRClusterStats (#11) Import Seurat explictly to avoid satijalab/seurat#2853 in MetabolicFeatures Fix when NA values in data for heatmap in MetabolicPathwayActivity Fix error when no significant pathways selected in MetabolicPathwayHeterogeneity Give better error message in CellsDistribution if group value not found for CellsDistribution (#16) Try including more genes (even though insignificant) in volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells (#17) Add margins to volcano plot for MarkersFinder / ClusterMarkers / ClusterMarkersOfAllCells Fix when envs.cell_qc is None (not provided) for SeuratPreparing Fix ident in cases of envs.dimplots not working for SeuratClusterStats","title":"Fixed/Enhanced"},{"location":"CHANGELOG/#added","text":"Add ClusterMarkersOfAllCells and TopExpressingGenesOfAllCells and set them as optional Add dim plots in SeuratClusterStats to overlay TCR presence/absence of cells (#14)","title":"Added"},{"location":"CHANGELOG/#breaking-changes-090","text":"Rename TCRClusteringStats to TCRClusterStats (#15)","title":"Breaking changes-0.9.0"},{"location":"CHANGELOG/#083","text":"\ud83d\udcdd Fix typos in docs \ud83d\udcdd Add links to some optional input files (#9, 5) \ud83d\udd28 Add apptainer to docker entry.sh (#9, 6) \ud83d\udc84 Adjust process order in reports (#9, 1) \u2b06\ufe0f Bump pipen-report to 0.13.1 (#9, 2)","title":"0.8.3"},{"location":"CHANGELOG/#082","text":"Bump biopipen to 0.18.3 to fix when either ident is empty for MarkersFinder","title":"0.8.2"},{"location":"CHANGELOG/#081","text":"Bump biopipen to 0.18.2 to fix a bug when the min length of CDR3 seqs > 12 for CDR3AAphyschem","title":"0.8.1"},{"location":"CHANGELOG/#080","text":"","title":"0.8.0"},{"location":"CHANGELOG/#housekeeping-and-docs-updates","text":"Bump biopipen to 0.18.1 Mention function changes with versions in docs Add apptainer in board.toml so the command can be generated in pipen-board Make logo shorter in docs Add docker image with -full tags to include all dependencies Print command help message if run test failed in CI Add singularity/apptainer in FAQ for \"no space left\" question Add -w fro apptainer in docs (as we need to save pipen-board file in home directory)","title":"Housekeeping and docs updates"},{"location":"CHANGELOG/#added-080","text":"Add TESSA process for tessa analysis Add volcano plot for MarkersFinder and ClusterMarkers","title":"Added-0.8.0"},{"location":"CHANGELOG/#fixed","text":"Fix when Sample is the only column in meta for ImmunarchLoading Add clear message when k.weight is too large for IntegrateData in SeuratClustering Allow unique: prefix for on in SampleInfo Fix sample order in plots for SampleInfo Remove tidyseurat:: prefix for filter in scripts of MetaMarkers , ScFGSEA and SeuratClusterStats in case tidyseurat::filter is not exported when installed from conda (but it will make dplyr::filter work anyway on seurat object)","title":"Fixed"},{"location":"CHANGELOG/#breaking-changes-080","text":"Redesign envs for SeuratClusteringStats to allow setting defaults for cases and switch identities for plots","title":"Breaking changes-0.8.0"},{"location":"CHANGELOG/#070","text":"","title":"0.7.0"},{"location":"CHANGELOG/#housekeeping-and-docs-updates-070","text":"Fix typos in docs/configurations TCRClustering should be TCRClusteringStats in Multi-case variable design section infile of [SampleInfo.in] should be samples.txt rather than sample.txt Remove unused scripts by deprecated processes Bump pipen-report to 0.12.8 Add master branch and master tag as stable tag for docker image Add pdf version of the flowchart (#4) Add warning for the results in getting started tutorial Bump pipen-board to 0.11.5 Add apptainer to the docs","title":"Housekeeping and docs updates-0.7.0"},{"location":"CHANGELOG/#added-070","text":"Add ModuleScoreCalculator to calculate module scores or cell cycle scores See: https://pwwang.github.io/immunopipe/processes/ModuleScoreCalculator/ Allow SampleInfo to perform statistics on the sample information See: https://pwwang.github.io/immunopipe/processes/SampleInfo/ Add TCR_Cluster_Size and TCR_Cluster_Size1 from TCRClustering to metadata for further integrative analysis See: https://pwwang.github.io/immunopipe/processes/TCRClusters2Seurat/","title":"Added-0.7.0"},{"location":"CHANGELOG/#fixed-070","text":"Fix default height and width for plots in SeuratClusterStats Fix cluster order not kept after annotation using hitype in CellTypeAnnotation","title":"Fixed-0.7.0"},{"location":"CHANGELOG/#breaking-changes-070","text":"Change seurat_clusters_old to seurat_clusters_id to save old seurat_clusters in CellTypeAnnotation Remove MarkersForClustersOfAllCells and TopExpressingGenesOfAllCells processes Rename MarkersForClustersOfTCells to ClusterMarkers Rename TopExpressingGenesOfTCells to TopExpressingGenes Rename envs.exprs to envs.features for SeuratClusterStats envs.exprs.genes is also renamed to envs.features.features","title":"Breaking changes-0.7.0"},{"location":"CHANGELOG/#060","text":"\u2b06\ufe0f Bump biopipen to 0.16 \ud83d\udcdd Add documentation \ud83d\udc9a Fix docs building in CI \ud83d\udcdd Update README with flowchart","title":"0.6.0"},{"location":"CHANGELOG/#051","text":"\u2728 Add TopExpressingGenes \ud83c\udfa8 Move RadarPlots to biopipen \u2b06\ufe0f Bump biopipen to 0.15.2","title":"0.5.1"},{"location":"CHANGELOG/#050","text":"\u2b06\ufe0f Upgrade biopipen to 0.15.0 \ud83d\udc9a Use better strategy docker image building","title":"0.5.0"},{"location":"CHANGELOG/#040","text":"\u2b06\ufe0f Bump biopipen to 0.6 \u2b06\ufe0f Upgrade other dependencies \ud83d\udc9a Use micromamba for docker image building \u2b06\ufe0f Add procps-ng for vdjtools for docker building","title":"0.4.0"},{"location":"CHANGELOG/#030","text":"\ud83d\udc9a Use build 2 for genomeinfodbdata from bioconda (0.2.4) \ud83d\udc7d\ufe0f Use config from pipen_args \u2b06\ufe0f Pump biopipen to 0.5.3, pipen-args to 0.3.2 \u2b06\ufe0f Upgrade deps for docker \ud83d\udcdd Add flowchart in README.md \ud83d\udc1b Fix error when --config not passed","title":"0.3.0"},{"location":"CHANGELOG/#024","text":"\ud83d\udc9a Use lastest miniconda3 for docker build \ud83d\udc9a Use conda channel pwwang for bioconductor-genomeinfodbdata for fix (bioconda/bioconda-recipes#31349) \u2b06\ufe0f Upgrade biopipen to 0.4.9 \ud83d\udcdd Add URL to example in README","title":"0.2.4"},{"location":"CHANGELOG/#023","text":"\u2b06\ufe0f Upgrade biopipen to 0.4.8","title":"0.2.3"},{"location":"CHANGELOG/#022","text":"\u2b06\ufe0f Upgrade biopipen to 0.4.7 to fix SeuratPreparing","title":"0.2.2"},{"location":"CHANGELOG/#021","text":"\ud83d\udd25 Fix the bug of the wrong arguments in help page \u2b06\ufe0f Upgrade clustcr to 1.0.2 \ud83d\udcdd Fix docs for metabolic analysis","title":"0.2.1"},{"location":"CHANGELOG/#020","text":"\u267b\ufe0f Move in-house processes out of processes.py \u267b\ufe0f Split up MARKERS_FINDER \u267b\ufe0f Refactor RadarPlots \u2728 Add an example config file \u26a1\ufe0f Add filter for RadarPlots \ud83d\udcdd Update docs \u2b06\ufe0f Upgrade deps \ud83d\udd27 Update docker/environment.yml \ud83d\udc1b Fix CloneHeterogeneity when only 1 row in continency table","title":"0.2.0"},{"location":"CHANGELOG/#011","text":"\ud83d\udc9a Try fix pip in environment.yml \ud83d\udcdd Update readme for requirement checking \ud83d\udcdd Update docs to fix #1 \ud83d\udcdd Update CHANGELOG \u2b06\ufe0f Adopt biopipen 0.4.0","title":"0.1.1"},{"location":"CHANGELOG/#010","text":"\ud83e\ude79 Disable force-caching for some procs \u2b06\ufe0f Upgrade datar to 0.8.* \u2728 Add dockerfile \u2b06\ufe0f Upgrade pipen to 0.3 \ud83d\udca5 Remove gene lists from start processes \u2b06\ufe0f Upgrade biopipen to 0.3 \u2b06\ufe0f Upgrade pipen to 0.3.5","title":"0.1.0"},{"location":"CHANGELOG/#007","text":"Add CloneHeterogeneity Allow setting indicator_gene for TCellSelection Adopt latest datar and biopipen","title":"0.0.7"},{"location":"CHANGELOG/#006","text":"\u2728 Allow dimplots with clonal information","title":"0.0.6"},{"location":"CHANGELOG/#005","text":"\u2728 Allow more flexible dim plots","title":"0.0.5"},{"location":"CHANGELOG/#004","text":"\u2728 Refactor markers finder module and add meta-marker analysis","title":"0.0.4"},{"location":"CHANGELOG/#003","text":"-\u2728 Add metabolic pathway analysis","title":"0.0.3"},{"location":"CHANGELOG/#002","text":"Adopt biopipen 0.1.3","title":"0.0.2"},{"location":"CHANGELOG/#001","text":"First release","title":"0.0.1"},{"location":"agent-skills/","text":"Agent Skills \u00b6 Overview \u00b6 Agent Skills are AI-powered configuration assistants that help you create immunopipe configuration files through natural language. Instead of manually writing TOML configuration files, you can describe what you want to do in plain English, and AI agents use these skills to generate the correct configuration. What are Agent Skills? Agent Skills are a lightweight, open format for extending AI agent capabilities with specialized knowledge and workflows. Learn more at agentskills.io . Why Use Agent Skills? \u00b6 Problem : Immunopipe has 30+ processes with hundreds of configuration options. Understanding which processes to use, how to configure them, and how they interact requires deep pipeline knowledge. Solution : Agent Skills provide structured knowledge that AI agents can use to: - Recommend processes based on your analysis goals - Generate complete configurations with sensible defaults - Explain parameters and their effects - Validate configurations before running Available Skills \u00b6 Immunopipe provides two types of skills: 1. Main Pipeline Skill \u00b6 Location : skills/immunopipe-config/SKILL.md This is the entry point skill that helps AI agents: - Assess your data type (scRNA-seq only vs scRNA+scTCR/BCR-seq) - Determine analysis goals (QC, clustering, TCR analysis, metabolic profiling, etc.) - Route to appropriate process-specific skills - Generate pipeline-level configuration Example use : \"I have PBMC data with TCR-seq. I want to identify exhausted CD8+ T cells and analyze their clonality.\" 2. Process-Specific Skills \u00b6 Location : skills/{process-name}/SKILL.md (32 individual process skills) Each process has a dedicated skill documenting: - Purpose : What the process does - When to use : Conditions and requirements - Configuration structure : Complete TOML syntax - Parameters : All environment variables with types, defaults, and descriptions - Examples : Minimal, typical, and advanced configurations - Common patterns : Real-world usage scenarios - Troubleshooting : Common issues and solutions Categories : Core Workflow (8 processes) \u00b6 SampleInfo - Sample metadata entry point LoadingRNAFromSeurat - Load pre-processed Seurat objects ScRepLoading - Load TCR/BCR repertoire data SeuratPreparing - QC, normalization, integration SeuratClustering - Standard clustering workflow SeuratClusteringOfAllCells - Pre-selection clustering SeuratSubClustering - Sub-clustering specific populations SeuratClusterStats - Cluster visualization and QC TCR/BCR Analysis (7 processes) \u00b6 TOrBCellSelection - T or B cell selection ScRepCombiningExpression - Integrate TCR/BCR with RNA CDR3Clustering - CDR3 sequence clustering TESSA - TCR epitope-specific analysis CDR3AAPhyschem - Physicochemical properties ClonalStats - Clonality and diversity metrics Marker & Annotation (7 processes) \u00b6 ClusterMarkers - Differential expression per cluster ClusterMarkersOfAllCells - Markers before selection CellTypeAnnotation - Automated cell type annotation SeuratMap2Ref - Reference-based annotation MarkersFinder - Custom group comparisons TopExpressingGenes - Highly expressed genes TopExpressingGenesOfAllCells - Top genes before selection Advanced Analysis (10 processes) \u00b6 ModuleScoreCalculator - Gene signature scoring CellCellCommunication - Ligand-receptor interactions CellCellCommunicationPlots - Communication visualization ScFGSEA - Gene set enrichment analysis PseudoBulkDEG - Pseudo-bulk differential expression Metabolic processes (6): ScrnaMetabolicLandscape , MetabolicInput , MetabolicExprImputation , MetabolicFeatures , MetabolicPathwayActivity , MetabolicPathwayHeterogeneity How to Use Agent Skills \u00b6 Option 1: MCP Server (Recommended for Claude Desktop) \u00b6 Immunopipe includes a built-in Model Context Protocol (MCP) server that exposes skills to AI agents like Claude: # Start MCP server immunopipe mcp # Or configure in Claude Desktop settings # See docs/mcp-server.md for full setup The MCP server provides tools: - configure_immunopipe - Generate configurations via natural language - generate_full_config - Create complete pipeline configurations - suggest_processes - Recommend processes for your analysis - list_options - Browse available configuration options Example interaction : User: I have 5 PBMC samples with TCR-seq data. I want to: 1. QC and normalize the data 2. Cluster T cells 3. Identify exhausted T cells 4. Analyze TCR clonality by cluster Agent: I'll generate a configuration for your TCR-seq analysis workflow. Let me use the immunopipe configuration skill... [Agent generates complete TOML configuration with: - SampleInfo for your 5 samples - SeuratPreparing with appropriate QC thresholds - SeuratClustering for T cell clustering - ModuleScoreCalculator for exhaustion scoring - ScRepCombiningExpression to integrate TCR data - ClonalStats for clonality analysis] Here's your configuration. Would you like me to explain any section? Option 2: Direct Skill Access (For Other AI Agents) \u00b6 AI agents with file system access can directly read skill files: # Example: Agent reading skills main_skill = read ( \"skills/immunopipe-config/SKILL.md\" ) process_skill = read ( \"skills/seuratclustering/SKILL.md\" ) # Agent uses skill content to generate configuration config = generate_toml_from_user_request ( user_query , main_skill , process_skill ) Option 3: Manual Reference \u00b6 Even without AI agents, skills serve as comprehensive documentation: - Browse skill directories (e.g., skills/seuratclustering/ , skills/clustermarkers/ ) - Each SKILL.md file includes complete configuration examples - Copy-paste examples and adapt to your needs Skill Format \u00b6 Skills follow the Agent Skills specification : Directory Structure : skills/ \u251c\u2500\u2500 immunopipe-config/ \u2502 \u2514\u2500\u2500 SKILL.md # Main routing skill \u251c\u2500\u2500 sampleinfo/ \u2502 \u2514\u2500\u2500 SKILL.md # Process-specific skill \u251c\u2500\u2500 seuratclustering/ \u2502 \u2514\u2500\u2500 SKILL.md \u2514\u2500\u2500 ... # + 30 more process skills File Format ( SKILL.md ): --- name: process-name # Matches directory name description: When to use this process and what it does (max 1024 chars) --- # Process Name ## Purpose What this process does... ## Configuration Examples [Complete TOML examples] ## Troubleshooting [Common issues and solutions] Example Workflows \u00b6 Workflow 1: Basic TCR-seq Analysis \u00b6 User goal : \"Analyze PBMC TCR-seq data to identify clonally expanded T cells\" Skills used : 1. immunopipe-config/ - Routes to TCR workflow 2. sampleinfo/ - Configure sample metadata 3. seuratpreparing/ - QC and normalization 4. screploading/ - Load TCR data 5. seuratclustering/ - Cluster T cells 6. screpcombiningexpression/ - Integrate TCR + RNA 7. clonalstats/ - Calculate clonality metrics Output : Complete TOML configuration with all processes correctly wired Workflow 2: Cell-Cell Communication \u00b6 User goal : \"Analyze ligand-receptor interactions between T cells and myeloid cells\" Skills used : 1. immunopipe-config/ - Routes to non-TCR workflow 2. seuratclustering/ - Cluster all cells 3. celltypeannotation/ - Annotate T and myeloid cells 4. cellcellcommunication/ - Infer interactions 5. cellcellcommunicationplots/ - Visualize networks Output : Configuration focused on communication analysis Workflow 3: Metabolic Profiling \u00b6 User goal : \"Compare metabolic pathway activity between exhausted and effector T cells\" Skills used : 1. modulescorecalculator/ - Score exhaustion/effector signatures 2. scrnametaboliclandscape/ - Full metabolic analysis pipeline 3. seuratclusterstats/ - Visualize metabolic scores Output : Configuration with metabolic analysis modules Benefits for Different Users \u00b6 For Beginners \u00b6 Lower barrier : Describe goals in natural language instead of learning TOML syntax Guided selection : AI recommends appropriate processes Error prevention : Generated configs are validated Learning resource : Skills document all options with examples For Experienced Users \u00b6 Faster prototyping : Generate base configs quickly, then customize Parameter discovery : Find advanced options you didn't know existed Best practices : Learn common patterns from skill examples Troubleshooting : Quick reference for common issues For Workflow Developers \u00b6 Reproducibility : AI-generated configs are complete and documented Standardization : Consistent configuration patterns across projects Collaboration : Share natural language requirements, generate consistent configs Skill Development \u00b6 Immunopipe skills are actively maintained alongside the pipeline: Location : skills/ directory in repository Format : Agent Skills specification - directories with SKILL.md files Structure : One directory per skill with YAML frontmatter Updates : Skills are updated when processes change Contributions : Submit improvements via pull requests Each skill includes: - YAML frontmatter with name and description - Complete process documentation - All configuration parameters with types and defaults - Realistic usage examples (minimal, typical, advanced) - Common troubleshooting scenarios with solutions Related Documentation \u00b6 MCP Server : Set up the Model Context Protocol server for Claude Desktop Configurations : Manual TOML configuration reference Processes : Individual process documentation Getting Started : Quick start guide for immunopipe External Resources \u00b6 Agent Skills Specification - Official format documentation Agent Skills Examples - Example skills from Anthropic MCP Documentation - Model Context Protocol specification","title":"Agent Skills"},{"location":"agent-skills/#agent-skills","text":"","title":"Agent Skills"},{"location":"agent-skills/#overview","text":"Agent Skills are AI-powered configuration assistants that help you create immunopipe configuration files through natural language. Instead of manually writing TOML configuration files, you can describe what you want to do in plain English, and AI agents use these skills to generate the correct configuration. What are Agent Skills? Agent Skills are a lightweight, open format for extending AI agent capabilities with specialized knowledge and workflows. Learn more at agentskills.io .","title":"Overview"},{"location":"agent-skills/#why-use-agent-skills","text":"Problem : Immunopipe has 30+ processes with hundreds of configuration options. Understanding which processes to use, how to configure them, and how they interact requires deep pipeline knowledge. Solution : Agent Skills provide structured knowledge that AI agents can use to: - Recommend processes based on your analysis goals - Generate complete configurations with sensible defaults - Explain parameters and their effects - Validate configurations before running","title":"Why Use Agent Skills?"},{"location":"agent-skills/#available-skills","text":"Immunopipe provides two types of skills:","title":"Available Skills"},{"location":"agent-skills/#1-main-pipeline-skill","text":"Location : skills/immunopipe-config/SKILL.md This is the entry point skill that helps AI agents: - Assess your data type (scRNA-seq only vs scRNA+scTCR/BCR-seq) - Determine analysis goals (QC, clustering, TCR analysis, metabolic profiling, etc.) - Route to appropriate process-specific skills - Generate pipeline-level configuration Example use : \"I have PBMC data with TCR-seq. I want to identify exhausted CD8+ T cells and analyze their clonality.\"","title":"1. Main Pipeline Skill"},{"location":"agent-skills/#2-process-specific-skills","text":"Location : skills/{process-name}/SKILL.md (32 individual process skills) Each process has a dedicated skill documenting: - Purpose : What the process does - When to use : Conditions and requirements - Configuration structure : Complete TOML syntax - Parameters : All environment variables with types, defaults, and descriptions - Examples : Minimal, typical, and advanced configurations - Common patterns : Real-world usage scenarios - Troubleshooting : Common issues and solutions Categories :","title":"2. Process-Specific Skills"},{"location":"agent-skills/#core-workflow-8-processes","text":"SampleInfo - Sample metadata entry point LoadingRNAFromSeurat - Load pre-processed Seurat objects ScRepLoading - Load TCR/BCR repertoire data SeuratPreparing - QC, normalization, integration SeuratClustering - Standard clustering workflow SeuratClusteringOfAllCells - Pre-selection clustering SeuratSubClustering - Sub-clustering specific populations SeuratClusterStats - Cluster visualization and QC","title":"Core Workflow (8 processes)"},{"location":"agent-skills/#tcrbcr-analysis-7-processes","text":"TOrBCellSelection - T or B cell selection ScRepCombiningExpression - Integrate TCR/BCR with RNA CDR3Clustering - CDR3 sequence clustering TESSA - TCR epitope-specific analysis CDR3AAPhyschem - Physicochemical properties ClonalStats - Clonality and diversity metrics","title":"TCR/BCR Analysis (7 processes)"},{"location":"agent-skills/#marker-annotation-7-processes","text":"ClusterMarkers - Differential expression per cluster ClusterMarkersOfAllCells - Markers before selection CellTypeAnnotation - Automated cell type annotation SeuratMap2Ref - Reference-based annotation MarkersFinder - Custom group comparisons TopExpressingGenes - Highly expressed genes TopExpressingGenesOfAllCells - Top genes before selection","title":"Marker &amp; Annotation (7 processes)"},{"location":"agent-skills/#advanced-analysis-10-processes","text":"ModuleScoreCalculator - Gene signature scoring CellCellCommunication - Ligand-receptor interactions CellCellCommunicationPlots - Communication visualization ScFGSEA - Gene set enrichment analysis PseudoBulkDEG - Pseudo-bulk differential expression Metabolic processes (6): ScrnaMetabolicLandscape , MetabolicInput , MetabolicExprImputation , MetabolicFeatures , MetabolicPathwayActivity , MetabolicPathwayHeterogeneity","title":"Advanced Analysis (10 processes)"},{"location":"agent-skills/#how-to-use-agent-skills","text":"","title":"How to Use Agent Skills"},{"location":"agent-skills/#option-1-mcp-server-recommended-for-claude-desktop","text":"Immunopipe includes a built-in Model Context Protocol (MCP) server that exposes skills to AI agents like Claude: # Start MCP server immunopipe mcp # Or configure in Claude Desktop settings # See docs/mcp-server.md for full setup The MCP server provides tools: - configure_immunopipe - Generate configurations via natural language - generate_full_config - Create complete pipeline configurations - suggest_processes - Recommend processes for your analysis - list_options - Browse available configuration options Example interaction : User: I have 5 PBMC samples with TCR-seq data. I want to: 1. QC and normalize the data 2. Cluster T cells 3. Identify exhausted T cells 4. Analyze TCR clonality by cluster Agent: I'll generate a configuration for your TCR-seq analysis workflow. Let me use the immunopipe configuration skill... [Agent generates complete TOML configuration with: - SampleInfo for your 5 samples - SeuratPreparing with appropriate QC thresholds - SeuratClustering for T cell clustering - ModuleScoreCalculator for exhaustion scoring - ScRepCombiningExpression to integrate TCR data - ClonalStats for clonality analysis] Here's your configuration. Would you like me to explain any section?","title":"Option 1: MCP Server (Recommended for Claude Desktop)"},{"location":"agent-skills/#option-2-direct-skill-access-for-other-ai-agents","text":"AI agents with file system access can directly read skill files: # Example: Agent reading skills main_skill = read ( \"skills/immunopipe-config/SKILL.md\" ) process_skill = read ( \"skills/seuratclustering/SKILL.md\" ) # Agent uses skill content to generate configuration config = generate_toml_from_user_request ( user_query , main_skill , process_skill )","title":"Option 2: Direct Skill Access (For Other AI Agents)"},{"location":"agent-skills/#option-3-manual-reference","text":"Even without AI agents, skills serve as comprehensive documentation: - Browse skill directories (e.g., skills/seuratclustering/ , skills/clustermarkers/ ) - Each SKILL.md file includes complete configuration examples - Copy-paste examples and adapt to your needs","title":"Option 3: Manual Reference"},{"location":"agent-skills/#skill-format","text":"Skills follow the Agent Skills specification : Directory Structure : skills/ \u251c\u2500\u2500 immunopipe-config/ \u2502 \u2514\u2500\u2500 SKILL.md # Main routing skill \u251c\u2500\u2500 sampleinfo/ \u2502 \u2514\u2500\u2500 SKILL.md # Process-specific skill \u251c\u2500\u2500 seuratclustering/ \u2502 \u2514\u2500\u2500 SKILL.md \u2514\u2500\u2500 ... # + 30 more process skills File Format ( SKILL.md ): --- name: process-name # Matches directory name description: When to use this process and what it does (max 1024 chars) --- # Process Name ## Purpose What this process does... ## Configuration Examples [Complete TOML examples] ## Troubleshooting [Common issues and solutions]","title":"Skill Format"},{"location":"agent-skills/#example-workflows","text":"","title":"Example Workflows"},{"location":"agent-skills/#workflow-1-basic-tcr-seq-analysis","text":"User goal : \"Analyze PBMC TCR-seq data to identify clonally expanded T cells\" Skills used : 1. immunopipe-config/ - Routes to TCR workflow 2. sampleinfo/ - Configure sample metadata 3. seuratpreparing/ - QC and normalization 4. screploading/ - Load TCR data 5. seuratclustering/ - Cluster T cells 6. screpcombiningexpression/ - Integrate TCR + RNA 7. clonalstats/ - Calculate clonality metrics Output : Complete TOML configuration with all processes correctly wired","title":"Workflow 1: Basic TCR-seq Analysis"},{"location":"agent-skills/#workflow-2-cell-cell-communication","text":"User goal : \"Analyze ligand-receptor interactions between T cells and myeloid cells\" Skills used : 1. immunopipe-config/ - Routes to non-TCR workflow 2. seuratclustering/ - Cluster all cells 3. celltypeannotation/ - Annotate T and myeloid cells 4. cellcellcommunication/ - Infer interactions 5. cellcellcommunicationplots/ - Visualize networks Output : Configuration focused on communication analysis","title":"Workflow 2: Cell-Cell Communication"},{"location":"agent-skills/#workflow-3-metabolic-profiling","text":"User goal : \"Compare metabolic pathway activity between exhausted and effector T cells\" Skills used : 1. modulescorecalculator/ - Score exhaustion/effector signatures 2. scrnametaboliclandscape/ - Full metabolic analysis pipeline 3. seuratclusterstats/ - Visualize metabolic scores Output : Configuration with metabolic analysis modules","title":"Workflow 3: Metabolic Profiling"},{"location":"agent-skills/#benefits-for-different-users","text":"","title":"Benefits for Different Users"},{"location":"agent-skills/#for-beginners","text":"Lower barrier : Describe goals in natural language instead of learning TOML syntax Guided selection : AI recommends appropriate processes Error prevention : Generated configs are validated Learning resource : Skills document all options with examples","title":"For Beginners"},{"location":"agent-skills/#for-experienced-users","text":"Faster prototyping : Generate base configs quickly, then customize Parameter discovery : Find advanced options you didn't know existed Best practices : Learn common patterns from skill examples Troubleshooting : Quick reference for common issues","title":"For Experienced Users"},{"location":"agent-skills/#for-workflow-developers","text":"Reproducibility : AI-generated configs are complete and documented Standardization : Consistent configuration patterns across projects Collaboration : Share natural language requirements, generate consistent configs","title":"For Workflow Developers"},{"location":"agent-skills/#skill-development","text":"Immunopipe skills are actively maintained alongside the pipeline: Location : skills/ directory in repository Format : Agent Skills specification - directories with SKILL.md files Structure : One directory per skill with YAML frontmatter Updates : Skills are updated when processes change Contributions : Submit improvements via pull requests Each skill includes: - YAML frontmatter with name and description - Complete process documentation - All configuration parameters with types and defaults - Realistic usage examples (minimal, typical, advanced) - Common troubleshooting scenarios with solutions","title":"Skill Development"},{"location":"agent-skills/#related-documentation","text":"MCP Server : Set up the Model Context Protocol server for Claude Desktop Configurations : Manual TOML configuration reference Processes : Individual process documentation Getting Started : Quick start guide for immunopipe","title":"Related Documentation"},{"location":"agent-skills/#external-resources","text":"Agent Skills Specification - Official format documentation Agent Skills Examples - Example skills from Anthropic MCP Documentation - Model Context Protocol specification","title":"External Resources"},{"location":"configurations/","text":"Configurations \u00b6 In this section, we are discussing how to configure the pipeline itself and some common issues we may encounter or need to be aware of to configure individual processes. For the configurations of each process in details, please refer to the individual process pages. As mentioned in pipen 's docs , the configurations to control the pipeline can be ~/.pipen.toml and/or ./.pipen.toml . You can set the default values in those files. Additionally, you can also pass a configuration file from command line, as described in Running the pipeline section. You can override the default values in the configuration files by passing arguments from command line. The configuration file is in toml format. A schematic example is shown below: forks = 4 # Other pipeline configurations # process configurations [TOrBCellSelection] forks = 2 # override the default value # envs of the process # e.g [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] # other processes # [ProcessName] # ... Tip In the individual process pages, we will list the envs of the process. For example, indicator_genes (list) : The genes to be used to select T cells. This means that the environment variable indicator_genes should be set as follows: [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] Tip An example configuration file with possible configuration items is provided in the repository as immunopipe.config.example.toml . You can refer to it when creating your own configuration file. Attention With pipen-args plugin, the arguments can also be passed from command line directly. For example, you can pass --TESSA.envs.python python_np1 from command line to set the python with dependencies installed for TESSA process. We know that when a process name appears in the configuration file, the process will be enabled. However, this won't work for the arguments passed from command line. You need to make sure that the process is enabled in the configuration file first. Then you can override the environment variables from command line. Pipeline configurations \u00b6 There are pipeline level configurations and process level configurations. The pipeline level configurations are used to control the pipeline itself. The process level configurations set here are the default values for all the processes. You can override the default values for each process in the process level configurations. You can check all available configuration items and more details here . Here we only list some of the most important ones. The rest ones are not recommended to change unless you know what you are doing. Pipeline level configurations \u00b6 name : The name of the pipeline (Default: \"Immunopipe\" ) It will change the working directory to ./.pipen/<name> , where the pipeline information and intermediate files will be stored. It will also change the default output directory to ./<name>-output . outdir : The output directory (Default: \"./<name>-output\" ) The output directory is where the final results and reports are stored. loglevel : The logging level for the logger (Default: \"info\" ) plugin_opts : The options for the plugins. Following pipen plugins are installed with immunopipe . You may check the links for more details. pipen-board : Visualizing configuration and running of pipen pipelines on the web. pipen-verbose : Adding verbosal information in logs for pipen. pipen-runinfo : Generating running information for jobs in pipen pipelines. pipen-filters : Adding a set of useful filters for pipen templates. pipen-args : Command line argument parser for pipen pipen-annotate : Using docstring to annotate pipen processes. pipen-report : Generating reports for pipen pipelines. pipen-log2file : Logging to files for pipen pipelines. pipen-cli-run : Running pipen processes/process groups from command line. scheduler : The scheduler to use (Default: \"local\" ) scheduler_opts : The options for the scheduler. immunopipe is implemented using pipen , which is backended by xqute . Supported schedulers and options are listed here . See also How to run the pipeline on a cluster? for more details. Output and working directory \u00b6 The output directory is the directory where the final results are stored. The working directory is the directory where the pipeline information and intermediate files are stored. By default, the output directory is ./<name>-output and the working directory is ./.pipen/<name> . The output of processes with final results will be stored in the output directory in sub-directories named after the processes. For example, the output of SeuratClusteringOfAllCells will be stored in ./<outdir>/SeuratClusteringOfAllCells . This is also a special subdirectory named REPORTS that contains the reports of the pipeline. By visiting the <outdir>/REPORTS/index.html with a web browser, you can check the reports of the pipeline. You can change the output directory by setting outdir or name in the configuration file. For example, if you want to change the output directory to ./output , you can set the configurations as follows: outdir = \"./output\" If you change the pipeline name: name = \"my-pipeline\" Then the output directory will be changed to ./my-pipeline-output . Note If both outdir and name are set, outdir will be used. You can do the similar thing to change the working directory. However, you are NOT recommended to change the working directory, especially if you are using pipen-board . This is because that the plugin scans ./.pipen/<name> to get the information for the previous run of the pipeline. If you change the working directory, the plugin will not be able to find the information for the previous run. Tip What if you want to change the working directory anyway? The recommended way is to create a symbolic link to the working directory. For example, if you want to change the working directory to /path/to/the/real/working/directory , you can do: ln -s /path/to/the/real/working/directory ./.pipen Tip You can also then debug the pipeline by inspecting the real scripts in the working directory that run for the jobs of each process at ./.pipen/<name>/<process-name>/<job-index>/job.script . You can also find the other information for the jobs at ./.pipen/<name>/<process-name>/<job-index>/ , including the stdout ( job.stdout ) and stderr ( job.stderr ) of the jobs, the exit code of the jobs ( job.rc ), etc. Process level configurations \u00b6 cache : Should we detect whether the jobs are cached. If true , the jobs will be skipped if the output files exist and newer than the input files. (Default: true ) error_strategy : The strategy to handle the errors. halt : Any failure will just halt the entire pipeline (default) ignore : Ignore the error and keep running (assuming the job runs successfully anyway) retry : Retry to job running. After num_retries times of retrying, if the job is still failing, halt the pipeline. num_retries : The number of retries for the jobs. (Default: 3 ) forks : How many jobs to run simultaneously? (Default: 1 ) scheduler : The scheduler to use. If not specified, the scheduler specified in the pipeline level configurations will be used. scheduler_opts : The options for the scheduler. If not specified, the scheduler options specified in the pipeline level configurations will be used. See also How to run the pipeline on a cluster? for more details. To know more about the configuration items for the pipeline, you can also read the pipen docs . Enabling/disabling processes \u00b6 By default, only the essential processes are enabled. If scTCR-/scBCR-seq data is avaiable, these processes include: SampleInfo ScRepLoading SeuratPreparing SeuratClustering ScRepCombiningExpression ClusterMarkers SeuratClusterStats ClonalStats If only scRNA-seq data is available, these processes include: SampleInfo (or LoadingRNAFromSeurat if loading from existing Seurat objects) SeuratPreparing (or skipped if loading from existing Seurat objects with LoadingRNAFromSeurat.envs.prepared or LoadingRNAFromSeurat.envs.prepared.clustered set to true ) SeuratClustering (or skipped if loading from existing Seurat objects with LoadingRNAFromSeurat.envs.clustered set to true ) ClusterMarkers SeuratClusterStats See also Routes of the pipeline for more details. To enable optional processes, you just need to add the corresponding sections for the processes in the configuration file. As long as the process name appears in the configuration file, the process will be enabled. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you can add the following lines to the configuration file: [ModuleScoreCalulator.envs.modules.TCell_Terminal_Differentiation] features = [ \"TIGIT\" , \"PDCD1\" , \"CD274\" , \"CTLA4\" , \"LAG3\" , \"HAVCR2\" , \"CD244\" , \"CD160\" ] Tip You may find out that for some processes, the default configurations are good enough for you to run. For example, CDR3Clustering is not enabled by default. If you don't change any configurations (by not putting in the configuration file nor changing any items on the web interface of pipen-board ) for the process, it will not be triggered. However, the default configurations are good enough for you to run the process. To enable it, you can either add this process manually in the configuration file: # ... other configurations [CDR3Clustering] or if you are using pipen-board , you can change a configuration item that does not actually affect the process. For example, you can change the forks of the process to 2 , instead of the default 1 , since the process is a single-job process. Then the process will be put in the configuration file and will be enabled. [CDR3Clustering] forks = 2 Caching mechanism \u00b6 There are two levels of caching mechanism in the pipeline: the process level and step level. The process level caching is controlled by the cache configuration item of each process (either passed from CLI --cache value or in the configuration file [Process] cache = value ). This level of caching is powered by the underlying pipen framework. The value can be one of true / false / \"force\" . true : normal cache relying on options/script/input (any changes will uncache a process) false : do not use the cache anyway (always run the process, but the signature will still be saved) force : skip running the processes even when there are changes (only when the previous run is sucessful) The step level caching is implemented using the Cache class from the biopipen.utils.R package. A step is usually a function call. A signature is generated for the step based on the function name and the arguments passed to the function. When a function is about to be called, the result with the signature in the caching directory will be checked. If the result exists, the result will be loaded from the caching directory instead of calling the function again. Otherwise, the function will be called and the result will be saved to the caching directory with the signature. The caching directory is controlled by the --process.envs.cache or [process.envs] cache = value The value can be one of true / false / <path> . true : will use the job outdir (.pipen/ / /0/output) as cache directory false : don't use cache (always run the step) <path> : use the to check/save the cached results Minimal configurations \u00b6 The minimal configurations are just the configurations with the input file: [SampleInfo.in] infile = [ \"samples.txt\" ] The input file is the metadata file mentioned in Preparing the input . With the minimal configurations, the pipeline will have the essential processes enabled, depending on whether scTCR-/scBCR-seq data is available or not. You can also check the example report here to see what you will get with the minimal configurations, with scTCR-/scBCR-seq data available. Environment variable types \u00b6 The types of environment variables are annotated in the brackets next the name of the environment variables. For example, the type of envs.indicator_genes of TOrBCellSelection is list , and it's annotated as: - indicator_genes (list): The genes to be used to select T cells. By default, the type of environment variables is string . The annotated types are helpful for the environment variables to be passed from the command line. It defines the argument and helps parse the argument from the command line. It is also useful to define the input elements from the pipen-board web interface and parse the values passed from the web interface as desired types. The following types are supported: string : The default type, the values will be used as strings. int : The values will be parsed as integers. float : The values will be parsed as floats. flag : The values will be parsed as boolean values. list / array : The values will be parsed as lists. You can also see the itype of some environment variables, that specifies the type of the elements in the list. It must be atomatic types, such as int , float , string , and flag . json : The values will be reciived as JSON strings and parsed as dictionaries (in python). choice / choices : The value should be chosen from one of the choices listed as sub-items. mchoice / mchoices : The value should be chosen from one or more of the choices listed as sub-items. ns / namespace : There are sub-items for the value. The sub-items will be parsed as key-value pairs. Understanding the data \u00b6 Understanding how the data is presented in the pipeline is helpful for the configuration, especially for the processes, such as SeuratClusterStats and ClonalStats . The configurations of this kind of processes are relying on the metadata. You can refer to the individual process pages for more details. Here we just give an introduction of how it works to set the configurations. The assay of the Seurat object \u00b6 The Seurat object is the main object used in the pipeline. You can have multiple assays in the Seurat object. While preparing the Seurat object at SeuratPreparing process, the default assay is determined. If envs.use_sct is true, meaning SCTransform is used, the default assay will be SCT . If you are using cca or rpca integration, integrated will be used as the default assay. Otherwise, the default assay will be RNA . For downstream processes using the expression values, we provide an option to specify the assay to use. However, the default assay is used. Unless you know what you are doing, you are not recommended to change the default assay. Using existing columns in the metadata \u00b6 In most cases, you can use the existing columns in the metadata to set the configurations. For example, if you want to plot the clone residency for each patient/subject, you need to specify the column name of the sample ID, as well as the column with the paired sample information (i.e. tumor vs blood ). Suppose the metadata (sitting in seurat_obj@meta in R for example) is as follows (showing sample-level information only): Subject Source MM003-Eariler BM MM003-Eariler PB MM005-Eariler BM MM005-Eariler PB Then you can set the configurations as follows: [SeuratClusterStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Subject\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] And you will get the following plots: Mutating the metadata \u00b6 Sometimes, you may want to mutate the metadata to get the desired information. Of course, you can have them prepared in the input file, as those extra columns with meta information will be attached to the object automatically. See Preparing the input for more details. However, sometimes the metadata is specific to some processes, you may not want to have them prepared in the input file to get all processes contaminated. Moreover, those derived columns are usually based on the existing columns, so that is also helpful to create them on the fly to keep the input file clean. In such case, for example, if you want to plot the clone residency for two groups (e.g. BM-Pre vs. BM-Post ) of samples for the same group (e.g. A ). However, the Source and Timepoint information are not in a single column of metadata. Here is when mutaters come in place. Suppose the metadata is as follows: Sample Group Source Timepoint MM003 A BM Pre MM003 A BM Pre MM005 A BM Post MM005 A BM Post ... ... ... ... Then you can set the configurations as follows: [ClonalStats.envs.mutaters] SampleGroup = \"paste0(Sample, '-', Timepoint)\" [ClonalStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Group\" group_by = \"SampleGroup\" groups = [ \"BM-Pre\" , \"BM-Post\" ] Then you will get a clone residency plot for group A with BM-Pre as x-axis and BM-Post as y-axis. The key-value pairs of mutaters are passed to dplyr::mutate() function. The actual code to mutate the metadata is as follows: df %>% mutate ( SampleGroup = paste0 ( Sample , '-' , Timepoint )) So, for this kind of advanced configurations, you need to have some knowledge of dplyr in R . You also need to pay attention to the keys of mutaters . Basically, the keys are the column names you want to create. So you need to make sure that the column names are not in the metadata already. Otherwise, the existing columns will be overwritten. For scRNA-seq data, the existing column names of the metadata are: orig.ident nCount_RNA nFeature_RNA and the meta columns in the input file. See also Preparing the input for more details. There could also be some other columns, depending on the previous processes. For example, if you have the cells clustered, there will be a column named seurat_clusters in the metadata. For scTCR-/scBCR-seq data, Sample is the only existing column in the metadata after loaded. Then the meta columns from the input file will be attached to the metadata. The best practice is to use a prefix for the column names you want to create. For example, if you want to create a column named Sample , you can use my_Sample instead. Then you can make sure that the column names are not in the metadata already. The other thing you need to pay attention to is that you should try to avoid . or - in the column names. For example, if you want to create a column named Sample-Source , you can use Sample_Source instead. This is because that the column names will be used as the keys of the environment variables, and some processes will translate - into . . See also Namespace environment variables for more details. Filtering/Subsetting the data \u00b6 In most processes where we need to filter the data, we don't provide an option for you to set the expression for dplyr::filter() . Instead, you can make use of the mutaters to create a column for filtering. For example, if you only want to plot clone residency for only one patient/subject (e.g. MM003-Eariler ) in ClonalStats , you can set the configurations as follows (suppose we have Sample and Source columns in the metadata): [SeuratClusterStats.envs.mutaters] SingleSample = \"if_else(Sample == 'MM003-Eariler', Sample, NA)\" [SeuratClusterStats.envs.stats.CloneResidency] split_by = \"SingleSample\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] Then you will get only one plot for MM003-Eariler , but not for MM005-Eariler . The NA s will be filtered out automatically. Namespace environment variables \u00b6 There are some enviroment variables marked as namespace , which means that you can have sub-keys for them. For example, the envs.SCTransform of SeuratClusteringOfAllCells process is a namespace environment variable. It takes the arguments of Seurat::SCTransform() function. The names of arguments have dot ( . ) in them, such as do.scale , do.center , seed.use , etc. In the configuration file, we need to use dash ( - ) instead of dot ( . ) to set the values for these arguments. For example, if we want to set do.scale to TRUE , we need to set do-scale to true in the configuration file. [SeuratClusteringOfAllCells.envs.SCTransform] do-scale = true This is because that we use pipen-args plugin backended by argx to parse the command line arguments, including the configuration file. If we use . directly in the configuration file: [SeuratClusteringOfAllCells.envs.SCTransform] do . scale = true Then the pipen-args will parse it as do is the key and scale is the sub-key, and the above configuration will be parsed as: [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } which is not what we want. The reason why . is parsed as sub-key is that we want the argument to be able to be passed from command line. For example, if we want to set do.scale to TRUE from command line, we can do: > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do-scale true If we use . instead of - : > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do.scale true Then the pipen-args will parse it as [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } again. Tip You don't need to worry about which environment variables are namespace ones. We will mention it in the individual process pages and the description of the environment variables in pipen-board configuration descriptions. Multi-casing design \u00b6 Some environment variables are designed to support multiple cases. However, in most cases, we only need to set the values for the default case. In such cases, the environment variable is usually a namespace environment variable with the sub-keys needed for the default case. In order to support multiple cases, a sub-key cases is added to the namespace environment variable. The cases is a dictionary (key-value pairs), where the keys are the names of the cases, and the values are the sub-keys for the corresponding cases. For example, the envs.group_by of ScFGSEA process: [ScFGSEA.envs] group_by = \"Group\" cases = {} If cases is empty, the default case will be added automatically. The name of the default case is GSEA . So the above configuration is equivalent to: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {} } If you want to add more cases, you can add them to the cases dictionary. For example, if you want to add a case named CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {}, CASE1 = {} } Then you can set the values for the default case and CASE1 case. For example, if you want to set the ident_2 to g3 for the default case and g4 for CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" ident_1 = \"g1\" cases = { GSEA = { ident_2 = \"g3\" }, CASE1 = { ident_2 = \"g4\" } } If a key in a case is not specified, the value in [ScFGSEA.envs] case will be used. In the above example, group_by = \"Group\" and ident_1 = \"g1\" will be used for both GSEA and CASE1 cases. Security alert \u00b6 Danger Note that some configuration items will be evaluated in the scripts directly. For example, the mutaters will be passed to R scripts, parsed and evaluated so that they can be used in dplyr::mutate() . Even though some were evaluated by rlang , not all of them are safe. Some of them are evaluated directly. For example, one could inject malicious code in the expressions passed by dplyr::filter() . For example, in the script: df %>% filter ({{ expression }}) The expected expression is something like Sample == \"Sample001\" . However, one could pass Sample == \"Sample001\"); system(\"cat /etc/passwd\") to the expression , which will be evaluated as: df %>% filter ( Sample == \"Sample001\" ); system ( \"cat /etc/passwd\" ) This will cause the pipeline to run the command cat /etc/passwd in the shell. This is just an example. One could do more harm by injecting malicious code. When you give acess of composing the configuration file to others or the public (not recommended), either via the command line or the web interface by pipen-board , you need to be careful about the security issues.","title":"Configurations"},{"location":"configurations/#configurations","text":"In this section, we are discussing how to configure the pipeline itself and some common issues we may encounter or need to be aware of to configure individual processes. For the configurations of each process in details, please refer to the individual process pages. As mentioned in pipen 's docs , the configurations to control the pipeline can be ~/.pipen.toml and/or ./.pipen.toml . You can set the default values in those files. Additionally, you can also pass a configuration file from command line, as described in Running the pipeline section. You can override the default values in the configuration files by passing arguments from command line. The configuration file is in toml format. A schematic example is shown below: forks = 4 # Other pipeline configurations # process configurations [TOrBCellSelection] forks = 2 # override the default value # envs of the process # e.g [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] # other processes # [ProcessName] # ... Tip In the individual process pages, we will list the envs of the process. For example, indicator_genes (list) : The genes to be used to select T cells. This means that the environment variable indicator_genes should be set as follows: [TOrBCellSelection.envs] indicator_genes = [ \"CD3D\" , \"CD3E\" , \"CD3G\" ] Tip An example configuration file with possible configuration items is provided in the repository as immunopipe.config.example.toml . You can refer to it when creating your own configuration file. Attention With pipen-args plugin, the arguments can also be passed from command line directly. For example, you can pass --TESSA.envs.python python_np1 from command line to set the python with dependencies installed for TESSA process. We know that when a process name appears in the configuration file, the process will be enabled. However, this won't work for the arguments passed from command line. You need to make sure that the process is enabled in the configuration file first. Then you can override the environment variables from command line.","title":"Configurations"},{"location":"configurations/#pipeline-configurations","text":"There are pipeline level configurations and process level configurations. The pipeline level configurations are used to control the pipeline itself. The process level configurations set here are the default values for all the processes. You can override the default values for each process in the process level configurations. You can check all available configuration items and more details here . Here we only list some of the most important ones. The rest ones are not recommended to change unless you know what you are doing.","title":"Pipeline configurations"},{"location":"configurations/#pipeline-level-configurations","text":"name : The name of the pipeline (Default: \"Immunopipe\" ) It will change the working directory to ./.pipen/<name> , where the pipeline information and intermediate files will be stored. It will also change the default output directory to ./<name>-output . outdir : The output directory (Default: \"./<name>-output\" ) The output directory is where the final results and reports are stored. loglevel : The logging level for the logger (Default: \"info\" ) plugin_opts : The options for the plugins. Following pipen plugins are installed with immunopipe . You may check the links for more details. pipen-board : Visualizing configuration and running of pipen pipelines on the web. pipen-verbose : Adding verbosal information in logs for pipen. pipen-runinfo : Generating running information for jobs in pipen pipelines. pipen-filters : Adding a set of useful filters for pipen templates. pipen-args : Command line argument parser for pipen pipen-annotate : Using docstring to annotate pipen processes. pipen-report : Generating reports for pipen pipelines. pipen-log2file : Logging to files for pipen pipelines. pipen-cli-run : Running pipen processes/process groups from command line. scheduler : The scheduler to use (Default: \"local\" ) scheduler_opts : The options for the scheduler. immunopipe is implemented using pipen , which is backended by xqute . Supported schedulers and options are listed here . See also How to run the pipeline on a cluster? for more details.","title":"Pipeline level configurations"},{"location":"configurations/#output-and-working-directory","text":"The output directory is the directory where the final results are stored. The working directory is the directory where the pipeline information and intermediate files are stored. By default, the output directory is ./<name>-output and the working directory is ./.pipen/<name> . The output of processes with final results will be stored in the output directory in sub-directories named after the processes. For example, the output of SeuratClusteringOfAllCells will be stored in ./<outdir>/SeuratClusteringOfAllCells . This is also a special subdirectory named REPORTS that contains the reports of the pipeline. By visiting the <outdir>/REPORTS/index.html with a web browser, you can check the reports of the pipeline. You can change the output directory by setting outdir or name in the configuration file. For example, if you want to change the output directory to ./output , you can set the configurations as follows: outdir = \"./output\" If you change the pipeline name: name = \"my-pipeline\" Then the output directory will be changed to ./my-pipeline-output . Note If both outdir and name are set, outdir will be used. You can do the similar thing to change the working directory. However, you are NOT recommended to change the working directory, especially if you are using pipen-board . This is because that the plugin scans ./.pipen/<name> to get the information for the previous run of the pipeline. If you change the working directory, the plugin will not be able to find the information for the previous run. Tip What if you want to change the working directory anyway? The recommended way is to create a symbolic link to the working directory. For example, if you want to change the working directory to /path/to/the/real/working/directory , you can do: ln -s /path/to/the/real/working/directory ./.pipen Tip You can also then debug the pipeline by inspecting the real scripts in the working directory that run for the jobs of each process at ./.pipen/<name>/<process-name>/<job-index>/job.script . You can also find the other information for the jobs at ./.pipen/<name>/<process-name>/<job-index>/ , including the stdout ( job.stdout ) and stderr ( job.stderr ) of the jobs, the exit code of the jobs ( job.rc ), etc.","title":"Output and working directory"},{"location":"configurations/#process-level-configurations","text":"cache : Should we detect whether the jobs are cached. If true , the jobs will be skipped if the output files exist and newer than the input files. (Default: true ) error_strategy : The strategy to handle the errors. halt : Any failure will just halt the entire pipeline (default) ignore : Ignore the error and keep running (assuming the job runs successfully anyway) retry : Retry to job running. After num_retries times of retrying, if the job is still failing, halt the pipeline. num_retries : The number of retries for the jobs. (Default: 3 ) forks : How many jobs to run simultaneously? (Default: 1 ) scheduler : The scheduler to use. If not specified, the scheduler specified in the pipeline level configurations will be used. scheduler_opts : The options for the scheduler. If not specified, the scheduler options specified in the pipeline level configurations will be used. See also How to run the pipeline on a cluster? for more details. To know more about the configuration items for the pipeline, you can also read the pipen docs .","title":"Process level configurations"},{"location":"configurations/#enablingdisabling-processes","text":"By default, only the essential processes are enabled. If scTCR-/scBCR-seq data is avaiable, these processes include: SampleInfo ScRepLoading SeuratPreparing SeuratClustering ScRepCombiningExpression ClusterMarkers SeuratClusterStats ClonalStats If only scRNA-seq data is available, these processes include: SampleInfo (or LoadingRNAFromSeurat if loading from existing Seurat objects) SeuratPreparing (or skipped if loading from existing Seurat objects with LoadingRNAFromSeurat.envs.prepared or LoadingRNAFromSeurat.envs.prepared.clustered set to true ) SeuratClustering (or skipped if loading from existing Seurat objects with LoadingRNAFromSeurat.envs.clustered set to true ) ClusterMarkers SeuratClusterStats See also Routes of the pipeline for more details. To enable optional processes, you just need to add the corresponding sections for the processes in the configuration file. As long as the process name appears in the configuration file, the process will be enabled. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you can add the following lines to the configuration file: [ModuleScoreCalulator.envs.modules.TCell_Terminal_Differentiation] features = [ \"TIGIT\" , \"PDCD1\" , \"CD274\" , \"CTLA4\" , \"LAG3\" , \"HAVCR2\" , \"CD244\" , \"CD160\" ] Tip You may find out that for some processes, the default configurations are good enough for you to run. For example, CDR3Clustering is not enabled by default. If you don't change any configurations (by not putting in the configuration file nor changing any items on the web interface of pipen-board ) for the process, it will not be triggered. However, the default configurations are good enough for you to run the process. To enable it, you can either add this process manually in the configuration file: # ... other configurations [CDR3Clustering] or if you are using pipen-board , you can change a configuration item that does not actually affect the process. For example, you can change the forks of the process to 2 , instead of the default 1 , since the process is a single-job process. Then the process will be put in the configuration file and will be enabled. [CDR3Clustering] forks = 2","title":"Enabling/disabling processes"},{"location":"configurations/#caching-mechanism","text":"There are two levels of caching mechanism in the pipeline: the process level and step level. The process level caching is controlled by the cache configuration item of each process (either passed from CLI --cache value or in the configuration file [Process] cache = value ). This level of caching is powered by the underlying pipen framework. The value can be one of true / false / \"force\" . true : normal cache relying on options/script/input (any changes will uncache a process) false : do not use the cache anyway (always run the process, but the signature will still be saved) force : skip running the processes even when there are changes (only when the previous run is sucessful) The step level caching is implemented using the Cache class from the biopipen.utils.R package. A step is usually a function call. A signature is generated for the step based on the function name and the arguments passed to the function. When a function is about to be called, the result with the signature in the caching directory will be checked. If the result exists, the result will be loaded from the caching directory instead of calling the function again. Otherwise, the function will be called and the result will be saved to the caching directory with the signature. The caching directory is controlled by the --process.envs.cache or [process.envs] cache = value The value can be one of true / false / <path> . true : will use the job outdir (.pipen/ / /0/output) as cache directory false : don't use cache (always run the step) <path> : use the to check/save the cached results","title":"Caching mechanism"},{"location":"configurations/#minimal-configurations","text":"The minimal configurations are just the configurations with the input file: [SampleInfo.in] infile = [ \"samples.txt\" ] The input file is the metadata file mentioned in Preparing the input . With the minimal configurations, the pipeline will have the essential processes enabled, depending on whether scTCR-/scBCR-seq data is available or not. You can also check the example report here to see what you will get with the minimal configurations, with scTCR-/scBCR-seq data available.","title":"Minimal configurations"},{"location":"configurations/#environment-variable-types","text":"The types of environment variables are annotated in the brackets next the name of the environment variables. For example, the type of envs.indicator_genes of TOrBCellSelection is list , and it's annotated as: - indicator_genes (list): The genes to be used to select T cells. By default, the type of environment variables is string . The annotated types are helpful for the environment variables to be passed from the command line. It defines the argument and helps parse the argument from the command line. It is also useful to define the input elements from the pipen-board web interface and parse the values passed from the web interface as desired types. The following types are supported: string : The default type, the values will be used as strings. int : The values will be parsed as integers. float : The values will be parsed as floats. flag : The values will be parsed as boolean values. list / array : The values will be parsed as lists. You can also see the itype of some environment variables, that specifies the type of the elements in the list. It must be atomatic types, such as int , float , string , and flag . json : The values will be reciived as JSON strings and parsed as dictionaries (in python). choice / choices : The value should be chosen from one of the choices listed as sub-items. mchoice / mchoices : The value should be chosen from one or more of the choices listed as sub-items. ns / namespace : There are sub-items for the value. The sub-items will be parsed as key-value pairs.","title":"Environment variable types"},{"location":"configurations/#understanding-the-data","text":"Understanding how the data is presented in the pipeline is helpful for the configuration, especially for the processes, such as SeuratClusterStats and ClonalStats . The configurations of this kind of processes are relying on the metadata. You can refer to the individual process pages for more details. Here we just give an introduction of how it works to set the configurations.","title":"Understanding the data"},{"location":"configurations/#the-assay-of-the-seurat-object","text":"The Seurat object is the main object used in the pipeline. You can have multiple assays in the Seurat object. While preparing the Seurat object at SeuratPreparing process, the default assay is determined. If envs.use_sct is true, meaning SCTransform is used, the default assay will be SCT . If you are using cca or rpca integration, integrated will be used as the default assay. Otherwise, the default assay will be RNA . For downstream processes using the expression values, we provide an option to specify the assay to use. However, the default assay is used. Unless you know what you are doing, you are not recommended to change the default assay.","title":"The assay of the Seurat object"},{"location":"configurations/#using-existing-columns-in-the-metadata","text":"In most cases, you can use the existing columns in the metadata to set the configurations. For example, if you want to plot the clone residency for each patient/subject, you need to specify the column name of the sample ID, as well as the column with the paired sample information (i.e. tumor vs blood ). Suppose the metadata (sitting in seurat_obj@meta in R for example) is as follows (showing sample-level information only): Subject Source MM003-Eariler BM MM003-Eariler PB MM005-Eariler BM MM005-Eariler PB Then you can set the configurations as follows: [SeuratClusterStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Subject\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] And you will get the following plots:","title":"Using existing columns in the metadata"},{"location":"configurations/#mutating-the-metadata","text":"Sometimes, you may want to mutate the metadata to get the desired information. Of course, you can have them prepared in the input file, as those extra columns with meta information will be attached to the object automatically. See Preparing the input for more details. However, sometimes the metadata is specific to some processes, you may not want to have them prepared in the input file to get all processes contaminated. Moreover, those derived columns are usually based on the existing columns, so that is also helpful to create them on the fly to keep the input file clean. In such case, for example, if you want to plot the clone residency for two groups (e.g. BM-Pre vs. BM-Post ) of samples for the same group (e.g. A ). However, the Source and Timepoint information are not in a single column of metadata. Here is when mutaters come in place. Suppose the metadata is as follows: Sample Group Source Timepoint MM003 A BM Pre MM003 A BM Pre MM005 A BM Post MM005 A BM Post ... ... ... ... Then you can set the configurations as follows: [ClonalStats.envs.mutaters] SampleGroup = \"paste0(Sample, '-', Timepoint)\" [ClonalStats.envs.cases.CloneResidency] viz_type = \"residency\" split_by = \"Group\" group_by = \"SampleGroup\" groups = [ \"BM-Pre\" , \"BM-Post\" ] Then you will get a clone residency plot for group A with BM-Pre as x-axis and BM-Post as y-axis. The key-value pairs of mutaters are passed to dplyr::mutate() function. The actual code to mutate the metadata is as follows: df %>% mutate ( SampleGroup = paste0 ( Sample , '-' , Timepoint )) So, for this kind of advanced configurations, you need to have some knowledge of dplyr in R . You also need to pay attention to the keys of mutaters . Basically, the keys are the column names you want to create. So you need to make sure that the column names are not in the metadata already. Otherwise, the existing columns will be overwritten. For scRNA-seq data, the existing column names of the metadata are: orig.ident nCount_RNA nFeature_RNA and the meta columns in the input file. See also Preparing the input for more details. There could also be some other columns, depending on the previous processes. For example, if you have the cells clustered, there will be a column named seurat_clusters in the metadata. For scTCR-/scBCR-seq data, Sample is the only existing column in the metadata after loaded. Then the meta columns from the input file will be attached to the metadata. The best practice is to use a prefix for the column names you want to create. For example, if you want to create a column named Sample , you can use my_Sample instead. Then you can make sure that the column names are not in the metadata already. The other thing you need to pay attention to is that you should try to avoid . or - in the column names. For example, if you want to create a column named Sample-Source , you can use Sample_Source instead. This is because that the column names will be used as the keys of the environment variables, and some processes will translate - into . . See also Namespace environment variables for more details.","title":"Mutating the metadata"},{"location":"configurations/#filteringsubsetting-the-data","text":"In most processes where we need to filter the data, we don't provide an option for you to set the expression for dplyr::filter() . Instead, you can make use of the mutaters to create a column for filtering. For example, if you only want to plot clone residency for only one patient/subject (e.g. MM003-Eariler ) in ClonalStats , you can set the configurations as follows (suppose we have Sample and Source columns in the metadata): [SeuratClusterStats.envs.mutaters] SingleSample = \"if_else(Sample == 'MM003-Eariler', Sample, NA)\" [SeuratClusterStats.envs.stats.CloneResidency] split_by = \"SingleSample\" group_by = \"Source\" groups = [ \"BM\" , \"PB\" ] Then you will get only one plot for MM003-Eariler , but not for MM005-Eariler . The NA s will be filtered out automatically.","title":"Filtering/Subsetting the data"},{"location":"configurations/#namespace-environment-variables","text":"There are some enviroment variables marked as namespace , which means that you can have sub-keys for them. For example, the envs.SCTransform of SeuratClusteringOfAllCells process is a namespace environment variable. It takes the arguments of Seurat::SCTransform() function. The names of arguments have dot ( . ) in them, such as do.scale , do.center , seed.use , etc. In the configuration file, we need to use dash ( - ) instead of dot ( . ) to set the values for these arguments. For example, if we want to set do.scale to TRUE , we need to set do-scale to true in the configuration file. [SeuratClusteringOfAllCells.envs.SCTransform] do-scale = true This is because that we use pipen-args plugin backended by argx to parse the command line arguments, including the configuration file. If we use . directly in the configuration file: [SeuratClusteringOfAllCells.envs.SCTransform] do . scale = true Then the pipen-args will parse it as do is the key and scale is the sub-key, and the above configuration will be parsed as: [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } which is not what we want. The reason why . is parsed as sub-key is that we want the argument to be able to be passed from command line. For example, if we want to set do.scale to TRUE from command line, we can do: > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do-scale true If we use . instead of - : > immunopipe --SeuratClusteringOfAllCells.envs.SCTransform.do.scale true Then the pipen-args will parse it as [SeuratClusteringOfAllCells.envs.SCTransform] do = { scale = true } again. Tip You don't need to worry about which environment variables are namespace ones. We will mention it in the individual process pages and the description of the environment variables in pipen-board configuration descriptions.","title":"Namespace environment variables"},{"location":"configurations/#multi-casing-design","text":"Some environment variables are designed to support multiple cases. However, in most cases, we only need to set the values for the default case. In such cases, the environment variable is usually a namespace environment variable with the sub-keys needed for the default case. In order to support multiple cases, a sub-key cases is added to the namespace environment variable. The cases is a dictionary (key-value pairs), where the keys are the names of the cases, and the values are the sub-keys for the corresponding cases. For example, the envs.group_by of ScFGSEA process: [ScFGSEA.envs] group_by = \"Group\" cases = {} If cases is empty, the default case will be added automatically. The name of the default case is GSEA . So the above configuration is equivalent to: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {} } If you want to add more cases, you can add them to the cases dictionary. For example, if you want to add a case named CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" cases = { GSEA = {}, CASE1 = {} } Then you can set the values for the default case and CASE1 case. For example, if you want to set the ident_2 to g3 for the default case and g4 for CASE1 , you can do: [ScFGSEA.envs] group_by = \"Group\" ident_1 = \"g1\" cases = { GSEA = { ident_2 = \"g3\" }, CASE1 = { ident_2 = \"g4\" } } If a key in a case is not specified, the value in [ScFGSEA.envs] case will be used. In the above example, group_by = \"Group\" and ident_1 = \"g1\" will be used for both GSEA and CASE1 cases.","title":"Multi-casing design"},{"location":"configurations/#security-alert","text":"Danger Note that some configuration items will be evaluated in the scripts directly. For example, the mutaters will be passed to R scripts, parsed and evaluated so that they can be used in dplyr::mutate() . Even though some were evaluated by rlang , not all of them are safe. Some of them are evaluated directly. For example, one could inject malicious code in the expressions passed by dplyr::filter() . For example, in the script: df %>% filter ({{ expression }}) The expected expression is something like Sample == \"Sample001\" . However, one could pass Sample == \"Sample001\"); system(\"cat /etc/passwd\") to the expression , which will be evaluated as: df %>% filter ( Sample == \"Sample001\" ); system ( \"cat /etc/passwd\" ) This will cause the pipeline to run the command cat /etc/passwd in the shell. This is just an example. One could do more harm by injecting malicious code. When you give acess of composing the configuration file to others or the public (not recommended), either via the command line or the web interface by pipen-board , you need to be careful about the security issues.","title":"Security alert"},{"location":"faq/","text":"FAQ \u00b6 immunopipe command not found? Please make sure if you have installed immunopipe on the right python . If you have used pip to install immunopipe , make sure the pip is associated with the right python . You may try /path/to/python -m pip install -U immunopipe to ensure immunopipe is installed with the python you wanted. If immunopipe still can't be found from command line, try /path/to/python -m immunopipe . Why I am getting \"Error writing to connection: No space left on device\"? If you are running the pipeline and it complains about \"No space left on device\", and you are pretty sure that your working directory is way from full, it is likely that your temporary directory does not have enough space. This is because that the pipeline will create a temporary directory to store the intermediate files, and the default temporary directory is /tmp . Make sure that you have enough space in /tmp or you can change the temporary directory by setting the environment variable of the process: envs.tmpdir . It is also likely that you are running the pipeline in a docker container and the docker container does not have enough space in /tmp . In such case, you can try to run the pipeline with the -v option of docker to local directory to /tmp in the container. For example: docker run --rm -w /workdir -v .:/workdir -v path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ justold/immunopipe:<tag> @config.toml If you are using singularity / apptainer , you can try to use the -B option to bind the local directory to /tmp in the container. Singularity Apptainer singularity run \\ --pwd /workdir -B .:/workdir -c -e --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml apptainer run \\ --pwd /workdir -B .:/workdir -c -e --unsquash --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml Why does the pipeline stop at SeuratClusteringOfAllCells and family without a clear error message? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. Please see the following issues for more details: https://github.com/satijalab/seurat/issues/3326 https://github.com/satijalab/seurat/issues/1720 https://github.com/satijalab/seurat/issues/2828 https://github.com/satijalab/seurat/issues/1254 https://github.com/satijalab/seurat/issues/7027 Also check out the tips by the Seurat team: https://satijalab.org/seurat/articles/integration_large_datasets Two possible solutions are: Use reduction = \"rpca\" for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . Use Reference-based integration reference = [1, 2] for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . For Seurat v5, use corresponding parameters for IntegrateLayers . Tip You can also pass a list of sample names instead of the sample indices. For example, reference = [\"sample1\", \"sample2\"] under [SeuratPreparing.envs.IntegrateLayers] to use sample1 and sample2 as the reference samples. See also description about IntegrateLayers here . Can I run one of the processes from the pipeline separately if I have the input files prepared? Only for some of the processes. immunopipe depends on biopipen . Most of the processes in immunopipe are subclasses of processes in biopipen . You can run the processes in biopipen separately by: pipen run scrna SeuratClustering [ options ] Note that only the processes from biopipen can be run separately. The processes in immunopipe are not designed to be run separately. For example, the SeuratClusteringOfAllCells process in immunopipe is a subclass of the SeuratClustering process in biopipen . It's specialized for the immunopipe pipeline. If you want to run a similar process separately, you should use the SeuratClustering process in biopipen instead. Like immunopipe , you can also either provide a configuration file: pipen run scrna SeuratClustering @config.toml or specify the options in the command line: pipen run scrna SeuratClustering --in.srtobj path/to/srtobj.RDS ... You can also use the -h / --help option to see the brief options of the process, or use -h+ / --help+ to see the full options of the process. How to run the pipeline on a cluster? To run the pipeline on a cluster, it's recommended to install the pipeline locally so that the cluster nodes can access the pipeline. immunopipe is built on top of pipen and xqute . A set of schedulers are supported by default. These schedulers are: local : Run the pipeline locally. slurm : Run the pipeline on a slurm cluster. sge : Run the pipeline on a sge cluster. ssh : Run the pipeline on a remote host via ssh. The scheduler can be specified via scheduler_opts for the whole pipeline or for a specific process. For example, to run the whole pipeline on a slurm cluster, you can use the following configuration file: scheduler = \"slurm\" [scheduler_opts] sbatch_partition = \"1-day\" To run a specific process on a slurm cluster, you can use the following configuration file: [ < Process > ] scheduler = \"slurm\" [ < Process > .scheduler_opts] sbatch_partition = \"1-day\" You can also use profiles to switch between different schedulers. See also https://pwwang.github.io/pipen/configurations/#profiles Unlike the pipeline installed locally, using a doker image to run the pipeline on a cluster, we need to run the whole pipeline as a job. For example, to run the pipeline on a slurm cluster using apptainer , you can use slurm to submit the job: srun <srun options> \\ apptainer run --pwd /workdir -B /path/to/workdir:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ -B /path/to/tmp:/tmp \\ docker://justold/immunopipe:<tag> \\ @config.toml If you are using docker and its alternatives, please also refer to: https://slurm.schedmd.com/containers.html Do I have to re-run the entire pipeline if I want to change some parameters? If you want to change some parameters for a specific process, you just modify the configuration file and re-run the pipeline. The pipeline will detect the changes and re-run the necessary processes. For example, if you are changing some environment variables for ScFGSEA , the prior processes, such as the ones for clustering and differential expression analysis, will be cached and will not be re-run. Why I am getting this error when running with apptainer : FATAL: no SIF writable overlay partition found in /tmp/apptainer_cache_xxx/... ? You may need to add --unsquash option for apptainer run . How can I use data with soft links while using docker image to run the pipeline? The container does not have access to the host filesystem directly. You need to mount the directory containing the data to the container. For example, if your real data is under /path/to/data , you can mount it to /data in the container (using -v /path/to/data:/data option for docker or -B /path/to/data:/data option for singularity or apptainer ). Then you can use /data in the container to access the data under /path/to/data on the host. Also remember to change the path of RNAData and TCRData / BCRData in the file (e.g. samples.txt ) that is passed to SampleInfo process. Other than /data , there are other directories that you can use for mounting inside the container, including /mnt and /tmp , in case your want to mount multiple directories. See also The directory structure in the container . Why I am getting disk quota exceeded error while pulling the docker image using apptainer with still plenty of space on the disk? It's probably because that the cache directory of apptainer is full. You can try to use a different cache directory by setting the environment variable APPTAINER_CACHEDIR to a different directory. For example: export APPTAINER_CACHEDIR = /path/to/cache apptainer pull justold/immunopipe:<tag> See also: https://apptainer.org/docs/user/main/build_env.html#cache-folders Unable to fork: Cannot allocate memory or long vectors not supported yet during clustering using Seurat? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. You can try to set envs.ncores to a smaller number to reduce the memory usage. For example: [SeuratClusteringOfAllCells.envs] ncores = 4 # instead of 16 The other strategy is to use Reference-based integration reference = [1, 2] for IntegrateLayers with method rpca or cca . See also description about IntegrateLayers here . For example: [SeuratPreparing.envs.IntegrateLayers] method = \"rpca\" reference = [ 1 , 2 ] # You can also use sample names instead of indices See also these issues for more details: https://github.com/satijalab/seurat/issues/1029 https://github.com/satijalab/seurat/issues/7419 Got error Not all stats values are finite numbers while running ScFGSEA ? It's probably because that there are too many missing values in the expression matrix and signal_to_noise is not able to detect the rank of the genes. You can try a different method for gene preranking. For example: [ScFGSEA.envs] method = \"diff_of_classes\" Why some of the processes rerun even if I didn't change anything after updating immunopipe to a new version? This is likely because that the process has changed in the new version of immunopipe . The pipeline will detect the changes and re-run the necessary processes to ensure that the results are consistent with the new version of the pipeline. If you want to avoid re-running the processes, you can try to use the --<proc>.cache force option when running the pipeline. This will force the pipeline to use the cached results from the previous run. How can I skip certain processes even if they are essential for the pipeline? For optional processes, you can just remove them from the configuration file or comment them out. For example, to skip the ScFGSEA process, you can remove the [ScFGSEA] section from the configuration file or comment it out. You can't skip some processes that are depended by other processes, if other processes are not skipped. However, you can skip some processes even they belong to the minimal set of processes required for the pipeline, by using the dry scheduler (runner). For example, to skip the ClusterMarkers process, you can use the following configuration file: [ClusterMarkers.scheduler_opts] scheduler = \"dry\" You need to install the pipen-dry package to use the dry scheduler. If you are using the docker image to run the pipeline, it is already included in the image. ```shell Can I change the font used in the plots generated by the pipeline? Yes, most of the plots are generated using R scplotter package, which uses plotthis package for underlying plotting. You can change the font by setting the argument theme_args = list(font_family = \"YourFontFamily\") of the plotting functions. Note that the eme you are using must be theme_this . If you are using other themes, such as ggplot2::theme_minimal , you may set the font family using theme_args = list(base_family = \"YourFontFamily\") . You can use unique(systemfonts::system_fonts()$family) in R to see the available font families on your system. With the docker image, in additional to the default system fonts, we also have installed mscorefonts package to provide more font options. The available fonts include: \"Georgia\" \"Andale Mono\" \"Source Code Pro\" \"Times New Roman\" \"Ubuntu\" \"Inconsolata\" \"Ubuntu Mono\" \"Courier New\" \"Trebuchet MS\" \"DejaVu Sans\" \"Impact\" \"Arial\" \"Comic Sans MS\" \"Ubuntu Condensed\" \"Verdana\" \"Webdings\" \"Arial Black\" Does the pipeline work for mouse data? Yes, the pipeline fully supports mouse data. To analyze mouse samples, specify the relevant mouse reference datasets in your configuration file. For example, set the appropriate mouse reference in the SeuratMap2Ref process. For pathway enrichment or GSEA analyses, provide mouse-specific gene sets from MSigDB or other compatible sources. Ensure all reference files and gene sets correspond to the mouse genome to achieve accurate results.","title":"FAQ"},{"location":"faq/#faq","text":"immunopipe command not found? Please make sure if you have installed immunopipe on the right python . If you have used pip to install immunopipe , make sure the pip is associated with the right python . You may try /path/to/python -m pip install -U immunopipe to ensure immunopipe is installed with the python you wanted. If immunopipe still can't be found from command line, try /path/to/python -m immunopipe . Why I am getting \"Error writing to connection: No space left on device\"? If you are running the pipeline and it complains about \"No space left on device\", and you are pretty sure that your working directory is way from full, it is likely that your temporary directory does not have enough space. This is because that the pipeline will create a temporary directory to store the intermediate files, and the default temporary directory is /tmp . Make sure that you have enough space in /tmp or you can change the temporary directory by setting the environment variable of the process: envs.tmpdir . It is also likely that you are running the pipeline in a docker container and the docker container does not have enough space in /tmp . In such case, you can try to run the pipeline with the -v option of docker to local directory to /tmp in the container. For example: docker run --rm -w /workdir -v .:/workdir -v path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ justold/immunopipe:<tag> @config.toml If you are using singularity / apptainer , you can try to use the -B option to bind the local directory to /tmp in the container. Singularity Apptainer singularity run \\ --pwd /workdir -B .:/workdir -c -e --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml apptainer run \\ --pwd /workdir -B .:/workdir -c -e --unsquash --writable-tmpfs \\ -B path/to/tmp:/tmp \\ # ^^^^^^^^^^^^^^^^^^^ docker://justold/immunopipe:<tag> \\ @config.toml Why does the pipeline stop at SeuratClusteringOfAllCells and family without a clear error message? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. Please see the following issues for more details: https://github.com/satijalab/seurat/issues/3326 https://github.com/satijalab/seurat/issues/1720 https://github.com/satijalab/seurat/issues/2828 https://github.com/satijalab/seurat/issues/1254 https://github.com/satijalab/seurat/issues/7027 Also check out the tips by the Seurat team: https://satijalab.org/seurat/articles/integration_large_datasets Two possible solutions are: Use reduction = \"rpca\" for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . Use Reference-based integration reference = [1, 2] for FindIntegrationAnchors under [SeuratClusteringOfAllCells.envs.FindIntegrationAnchors] . For Seurat v5, use corresponding parameters for IntegrateLayers . Tip You can also pass a list of sample names instead of the sample indices. For example, reference = [\"sample1\", \"sample2\"] under [SeuratPreparing.envs.IntegrateLayers] to use sample1 and sample2 as the reference samples. See also description about IntegrateLayers here . Can I run one of the processes from the pipeline separately if I have the input files prepared? Only for some of the processes. immunopipe depends on biopipen . Most of the processes in immunopipe are subclasses of processes in biopipen . You can run the processes in biopipen separately by: pipen run scrna SeuratClustering [ options ] Note that only the processes from biopipen can be run separately. The processes in immunopipe are not designed to be run separately. For example, the SeuratClusteringOfAllCells process in immunopipe is a subclass of the SeuratClustering process in biopipen . It's specialized for the immunopipe pipeline. If you want to run a similar process separately, you should use the SeuratClustering process in biopipen instead. Like immunopipe , you can also either provide a configuration file: pipen run scrna SeuratClustering @config.toml or specify the options in the command line: pipen run scrna SeuratClustering --in.srtobj path/to/srtobj.RDS ... You can also use the -h / --help option to see the brief options of the process, or use -h+ / --help+ to see the full options of the process. How to run the pipeline on a cluster? To run the pipeline on a cluster, it's recommended to install the pipeline locally so that the cluster nodes can access the pipeline. immunopipe is built on top of pipen and xqute . A set of schedulers are supported by default. These schedulers are: local : Run the pipeline locally. slurm : Run the pipeline on a slurm cluster. sge : Run the pipeline on a sge cluster. ssh : Run the pipeline on a remote host via ssh. The scheduler can be specified via scheduler_opts for the whole pipeline or for a specific process. For example, to run the whole pipeline on a slurm cluster, you can use the following configuration file: scheduler = \"slurm\" [scheduler_opts] sbatch_partition = \"1-day\" To run a specific process on a slurm cluster, you can use the following configuration file: [ < Process > ] scheduler = \"slurm\" [ < Process > .scheduler_opts] sbatch_partition = \"1-day\" You can also use profiles to switch between different schedulers. See also https://pwwang.github.io/pipen/configurations/#profiles Unlike the pipeline installed locally, using a doker image to run the pipeline on a cluster, we need to run the whole pipeline as a job. For example, to run the pipeline on a slurm cluster using apptainer , you can use slurm to submit the job: srun <srun options> \\ apptainer run --pwd /workdir -B /path/to/workdir:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ -B /path/to/tmp:/tmp \\ docker://justold/immunopipe:<tag> \\ @config.toml If you are using docker and its alternatives, please also refer to: https://slurm.schedmd.com/containers.html Do I have to re-run the entire pipeline if I want to change some parameters? If you want to change some parameters for a specific process, you just modify the configuration file and re-run the pipeline. The pipeline will detect the changes and re-run the necessary processes. For example, if you are changing some environment variables for ScFGSEA , the prior processes, such as the ones for clustering and differential expression analysis, will be cached and will not be re-run. Why I am getting this error when running with apptainer : FATAL: no SIF writable overlay partition found in /tmp/apptainer_cache_xxx/... ? You may need to add --unsquash option for apptainer run . How can I use data with soft links while using docker image to run the pipeline? The container does not have access to the host filesystem directly. You need to mount the directory containing the data to the container. For example, if your real data is under /path/to/data , you can mount it to /data in the container (using -v /path/to/data:/data option for docker or -B /path/to/data:/data option for singularity or apptainer ). Then you can use /data in the container to access the data under /path/to/data on the host. Also remember to change the path of RNAData and TCRData / BCRData in the file (e.g. samples.txt ) that is passed to SampleInfo process. Other than /data , there are other directories that you can use for mounting inside the container, including /mnt and /tmp , in case your want to mount multiple directories. See also The directory structure in the container . Why I am getting disk quota exceeded error while pulling the docker image using apptainer with still plenty of space on the disk? It's probably because that the cache directory of apptainer is full. You can try to use a different cache directory by setting the environment variable APPTAINER_CACHEDIR to a different directory. For example: export APPTAINER_CACHEDIR = /path/to/cache apptainer pull justold/immunopipe:<tag> See also: https://apptainer.org/docs/user/main/build_env.html#cache-folders Unable to fork: Cannot allocate memory or long vectors not supported yet during clustering using Seurat? This is likely because that the pipeline is running out of memory. The SeuratClusteringOfAllCells and family processes (e.g. SeuratClustering ) will run the a series of Seurat functions to perform the clustering, especially the IntegrateData and FindIntegrationAnchors functions, and IntegrateLayers with Seurat v5. You can try to set envs.ncores to a smaller number to reduce the memory usage. For example: [SeuratClusteringOfAllCells.envs] ncores = 4 # instead of 16 The other strategy is to use Reference-based integration reference = [1, 2] for IntegrateLayers with method rpca or cca . See also description about IntegrateLayers here . For example: [SeuratPreparing.envs.IntegrateLayers] method = \"rpca\" reference = [ 1 , 2 ] # You can also use sample names instead of indices See also these issues for more details: https://github.com/satijalab/seurat/issues/1029 https://github.com/satijalab/seurat/issues/7419 Got error Not all stats values are finite numbers while running ScFGSEA ? It's probably because that there are too many missing values in the expression matrix and signal_to_noise is not able to detect the rank of the genes. You can try a different method for gene preranking. For example: [ScFGSEA.envs] method = \"diff_of_classes\" Why some of the processes rerun even if I didn't change anything after updating immunopipe to a new version? This is likely because that the process has changed in the new version of immunopipe . The pipeline will detect the changes and re-run the necessary processes to ensure that the results are consistent with the new version of the pipeline. If you want to avoid re-running the processes, you can try to use the --<proc>.cache force option when running the pipeline. This will force the pipeline to use the cached results from the previous run. How can I skip certain processes even if they are essential for the pipeline? For optional processes, you can just remove them from the configuration file or comment them out. For example, to skip the ScFGSEA process, you can remove the [ScFGSEA] section from the configuration file or comment it out. You can't skip some processes that are depended by other processes, if other processes are not skipped. However, you can skip some processes even they belong to the minimal set of processes required for the pipeline, by using the dry scheduler (runner). For example, to skip the ClusterMarkers process, you can use the following configuration file: [ClusterMarkers.scheduler_opts] scheduler = \"dry\" You need to install the pipen-dry package to use the dry scheduler. If you are using the docker image to run the pipeline, it is already included in the image. ```shell Can I change the font used in the plots generated by the pipeline? Yes, most of the plots are generated using R scplotter package, which uses plotthis package for underlying plotting. You can change the font by setting the argument theme_args = list(font_family = \"YourFontFamily\") of the plotting functions. Note that the eme you are using must be theme_this . If you are using other themes, such as ggplot2::theme_minimal , you may set the font family using theme_args = list(base_family = \"YourFontFamily\") . You can use unique(systemfonts::system_fonts()$family) in R to see the available font families on your system. With the docker image, in additional to the default system fonts, we also have installed mscorefonts package to provide more font options. The available fonts include: \"Georgia\" \"Andale Mono\" \"Source Code Pro\" \"Times New Roman\" \"Ubuntu\" \"Inconsolata\" \"Ubuntu Mono\" \"Courier New\" \"Trebuchet MS\" \"DejaVu Sans\" \"Impact\" \"Arial\" \"Comic Sans MS\" \"Ubuntu Condensed\" \"Verdana\" \"Webdings\" \"Arial Black\" Does the pipeline work for mouse data? Yes, the pipeline fully supports mouse data. To analyze mouse samples, specify the relevant mouse reference datasets in your configuration file. For example, set the appropriate mouse reference in the SeuratMap2Ref process. For pathway enrichment or GSEA analyses, provide mouse-specific gene sets from MSigDB or other compatible sources. Ensure all reference files and gene sets correspond to the mouse genome to achieve accurate results.","title":"FAQ"},{"location":"gallery/","text":"Gallery \u00b6 The following are some datasets with both scRNA-seq and scTCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. In the README file of each repository, you can find the links to the original publications and the reports generated by immunopipe . ID GEO Repository Condition 1 GSE144469 immunopipe-AdrienneML-2020 Melanoma and therapy 2 GSE176201 immunopipe-CheonIS-2021 COVID-19 lung tissue 3 GSE180268 immunopipe-EberhardtCS-2021 HPV and Head and Neck cancer 4 GSE114724 immunopipe-ElhamA-2018 Breast Cancer 5 GSE161192 immunopipe-GateD-2021 LB dementia 6 GSE179994 immunopipe-LiuB-2022 anti-PD-1 therapy in lung cancer 7 GSE148190 immunopipe-MahuronKM-2020 Skin cancer 8 GSE139555 immunopipe-ThomasW-2020 Anti-PD1 therapy 9 GSE145370 immunopipe-ZhengY-2020 Oesophageal cancer ID # Individuals # Samples # Cells # matched TCR seqs 1 22 22 75,569 68,760 2 5 6 34,781 23,081 3 6 6 53,303 26,844 4 3 5 28,341 24,039 5 2 4 6,438 5,642 6 38 47 150,849 77,030 7 1 2 8,794 4,904 8 14 32 194,519 67,700 9 7 14 108,226 35,449 ID Reference 1 Luoma, Adrienne M., et al. 2020 2 Cheon, I. S., et al. 2021 3 Eberhardt, Christian S., et al. 2021 4 Alizadeh, Elham, et al. 2018 5 Gate, David, et al. 2021 6 Liu, B., et al. 2022 7 Mahuron, Kelly M., et al. 2020 8 Wu, Thomas D., et al. 2020 9 Zheng, Y., et al. 2020","title":"Gallery"},{"location":"gallery/#gallery","text":"The following are some datasets with both scRNA-seq and scTCR-seq data available in the publications. The data were reanalyzed using immunopipe with the configurations provided in each repository, where the results are also available. In the README file of each repository, you can find the links to the original publications and the reports generated by immunopipe . ID GEO Repository Condition 1 GSE144469 immunopipe-AdrienneML-2020 Melanoma and therapy 2 GSE176201 immunopipe-CheonIS-2021 COVID-19 lung tissue 3 GSE180268 immunopipe-EberhardtCS-2021 HPV and Head and Neck cancer 4 GSE114724 immunopipe-ElhamA-2018 Breast Cancer 5 GSE161192 immunopipe-GateD-2021 LB dementia 6 GSE179994 immunopipe-LiuB-2022 anti-PD-1 therapy in lung cancer 7 GSE148190 immunopipe-MahuronKM-2020 Skin cancer 8 GSE139555 immunopipe-ThomasW-2020 Anti-PD1 therapy 9 GSE145370 immunopipe-ZhengY-2020 Oesophageal cancer ID # Individuals # Samples # Cells # matched TCR seqs 1 22 22 75,569 68,760 2 5 6 34,781 23,081 3 6 6 53,303 26,844 4 3 5 28,341 24,039 5 2 4 6,438 5,642 6 38 47 150,849 77,030 7 1 2 8,794 4,904 8 14 32 194,519 67,700 9 7 14 108,226 35,449 ID Reference 1 Luoma, Adrienne M., et al. 2020 2 Cheon, I. S., et al. 2021 3 Eberhardt, Christian S., et al. 2021 4 Alizadeh, Elham, et al. 2018 5 Gate, David, et al. 2021 6 Liu, B., et al. 2022 7 Mahuron, Kelly M., et al. 2020 8 Wu, Thomas D., et al. 2020 9 Zheng, Y., et al. 2020","title":"Gallery"},{"location":"getting-started/","text":"Getting started \u00b6 You can find the nessary files and source code of this tutorial in the example repository . In this tutorial we will show you how to run the immunopipe pipeline on a small dataset of 6 patients from 3 groups: colitis (n=2), non-colitis(n=2) and control(n=2). The dataset is part of the data used in the publication below: Luoma, Adrienne M., et al. \"Molecular pathways of colon inflammation induced by cancer immunotherapy.\" Cell 182.3 (2020): 655-671. We are using a small subset of the data to make the tutorial run faster. The full dataset can be downloaded from Gene Expression Omnibus (GEO) GSE144469 . Download and prepare the data \u00b6 The data can be downloaded and prepared by running the following commands: # Clone the example repository git clone https://github.com/pwwang/immunopipe-example.git # Enter the example directory cd immunopipe-example # Download and prepare the data bash prepare-data.sh # The data from GSE144469 (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE144469) # will be downloaded and extracted into: # # ./prepared-data/C1 # ./prepared-data/C2 # ... # You may also check other files in the data/ directory, especially the samples.txt file, which contains the sample information for the dataset we prepared above. Prepare the configuration file \u00b6 To run the pipeline, we need to prepare a configuration file (recommended) or pass the arguments directly via command line. Here we will use the configuration file. See also Configurations for more details. As explained in the Configurations page, we can provide a configuration file with a minimal set of configuration items to get the pipeline running. The only required configuration item is the input file for the SampleInfo process. However, here we want to give the pipeline a different name and output directory to distinguish it from other runs with a different set of configurations. The configuration file shall be in the TOML format. We can create a file named ImmunopipeMinimal.config.toml with the following content: name = \"ImmunopipeMinimal\" outdir = \"minimal\" [SampleInfo.in] infile = [ \"data/samples.txt\" ] Run the pipeline \u00b6 The easiest way to run the pipeline is to run it within the docker container. We can use the following command to run the pipeline with the configuration file we just created: Using docker Using singularity Using apptainer docker run \\ --rm -w /workdir -v .:/workdir \\ justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml singularity run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml apptainer run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml Tip docker , singularity and apptainer commands map the current directory ( . ) to the /workdir directory in the container. To get the detailed directory structure in the container, please refer to the The directory structure in the container . Tip If you want to install and run the pipeline without docker, please refer to the Installation and Running the pipeline pages for more details. Note You need at least 16GB of memory to run the pipeline with the example dataset and minimal configuration. You may also need to decrease ncores of some processes to avoid running out of memory. For example: [SeuratClusteringOfAllCells.envs] - ncores = 8 + ncores = 4 Check the results \u00b6 With that \"minimal\" configuration file, only a subset of the processes will be run. See also Enabling/Disabling processes . The results will be saved in the minimal directory. You can also check the reports at minimal/REPORTS/index.html with a web browser. You can also visit the following link to see the reports of the pipeline we just ran: http://imp.pwwang.com/minimal/REPORTS/index.html Next steps \u00b6 You may read through this documentation to learn more about the pipeline and how to configure it. There is also a configuration file, named Immunopipe.config.toml in the example repository, with more processes enabled. You can use it to run the pipeline with the dataset prepared above. Check out the following link for the reports: http://imp.pwwang.com/output/REPORTS/index.html Note The results provided by this example configuration files are for demonstration purpose only. They are not intended to be used for any scientific analysis. You may also want to try other routes of the pipeline with the prepared data. These routes are defined in: ImmunopipeMinimalNoTCR.config.toml : The configuration for minimal analyses without scTCR-/scBCR-seq data. ImmunopipeWSNoTCR.config.toml : The configuration for analyses without scTCR-/scBCR-seq data, but with selection of T cells. ImmunopipeRNAFromSeurat.config.toml : The configuration for analyses starting from a Seurat object. Also check out the gallery for more real-world examples. You can also check the example configuration file to check the possible configuration items: immunopipe.config.example.toml","title":"Geting started"},{"location":"getting-started/#getting-started","text":"You can find the nessary files and source code of this tutorial in the example repository . In this tutorial we will show you how to run the immunopipe pipeline on a small dataset of 6 patients from 3 groups: colitis (n=2), non-colitis(n=2) and control(n=2). The dataset is part of the data used in the publication below: Luoma, Adrienne M., et al. \"Molecular pathways of colon inflammation induced by cancer immunotherapy.\" Cell 182.3 (2020): 655-671. We are using a small subset of the data to make the tutorial run faster. The full dataset can be downloaded from Gene Expression Omnibus (GEO) GSE144469 .","title":"Getting started"},{"location":"getting-started/#download-and-prepare-the-data","text":"The data can be downloaded and prepared by running the following commands: # Clone the example repository git clone https://github.com/pwwang/immunopipe-example.git # Enter the example directory cd immunopipe-example # Download and prepare the data bash prepare-data.sh # The data from GSE144469 (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE144469) # will be downloaded and extracted into: # # ./prepared-data/C1 # ./prepared-data/C2 # ... # You may also check other files in the data/ directory, especially the samples.txt file, which contains the sample information for the dataset we prepared above.","title":"Download and prepare the data"},{"location":"getting-started/#prepare-the-configuration-file","text":"To run the pipeline, we need to prepare a configuration file (recommended) or pass the arguments directly via command line. Here we will use the configuration file. See also Configurations for more details. As explained in the Configurations page, we can provide a configuration file with a minimal set of configuration items to get the pipeline running. The only required configuration item is the input file for the SampleInfo process. However, here we want to give the pipeline a different name and output directory to distinguish it from other runs with a different set of configurations. The configuration file shall be in the TOML format. We can create a file named ImmunopipeMinimal.config.toml with the following content: name = \"ImmunopipeMinimal\" outdir = \"minimal\" [SampleInfo.in] infile = [ \"data/samples.txt\" ]","title":"Prepare the configuration file"},{"location":"getting-started/#run-the-pipeline","text":"The easiest way to run the pipeline is to run it within the docker container. We can use the following command to run the pipeline with the configuration file we just created: Using docker Using singularity Using apptainer docker run \\ --rm -w /workdir -v .:/workdir \\ justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml singularity run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml apptainer run \\ --pwd /workdir -B .:/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:master \\ @ImmunopipeMinimal.config.toml Tip docker , singularity and apptainer commands map the current directory ( . ) to the /workdir directory in the container. To get the detailed directory structure in the container, please refer to the The directory structure in the container . Tip If you want to install and run the pipeline without docker, please refer to the Installation and Running the pipeline pages for more details. Note You need at least 16GB of memory to run the pipeline with the example dataset and minimal configuration. You may also need to decrease ncores of some processes to avoid running out of memory. For example: [SeuratClusteringOfAllCells.envs] - ncores = 8 + ncores = 4","title":"Run the pipeline"},{"location":"getting-started/#check-the-results","text":"With that \"minimal\" configuration file, only a subset of the processes will be run. See also Enabling/Disabling processes . The results will be saved in the minimal directory. You can also check the reports at minimal/REPORTS/index.html with a web browser. You can also visit the following link to see the reports of the pipeline we just ran: http://imp.pwwang.com/minimal/REPORTS/index.html","title":"Check the results"},{"location":"getting-started/#next-steps","text":"You may read through this documentation to learn more about the pipeline and how to configure it. There is also a configuration file, named Immunopipe.config.toml in the example repository, with more processes enabled. You can use it to run the pipeline with the dataset prepared above. Check out the following link for the reports: http://imp.pwwang.com/output/REPORTS/index.html Note The results provided by this example configuration files are for demonstration purpose only. They are not intended to be used for any scientific analysis. You may also want to try other routes of the pipeline with the prepared data. These routes are defined in: ImmunopipeMinimalNoTCR.config.toml : The configuration for minimal analyses without scTCR-/scBCR-seq data. ImmunopipeWSNoTCR.config.toml : The configuration for analyses without scTCR-/scBCR-seq data, but with selection of T cells. ImmunopipeRNAFromSeurat.config.toml : The configuration for analyses starting from a Seurat object. Also check out the gallery for more real-world examples. You can also check the example configuration file to check the possible configuration items: immunopipe.config.example.toml","title":"Next steps"},{"location":"installation/","text":"Installation \u00b6 Install the pipline and the dependencies using conda \u00b6 Tip If you plan to use the docker image to run the pipeline locally, you can skip this section. immunopipe is built upon pipen framework, and a number of packages written in R and python . It's not recommended to install the packages manually. Instead, you can use the provided environment_base.yml to create a conda environment. $ conda env create \\ -n immunopipe \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_base.yml Then update the environment with essential R packages: $ conda env update \\ -n immunopipe \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_rpkgs.yml If the URL doesn't work, you can download the file and create the environment locally. For more detailed instructions of conda env create , please refer to conda docs . Note If you are using celltypist for cell type annotation: [CellTypeAnnotation.envs] tool = \"celltypist\" Or if you are enabling TESSA and CDR3Clustering processes, you need to install additional dependencies, including numpy v1 , which is not compatible with some other packages in the base environment. You can create a separate conda environment for these processes. $ conda env create \\ -n python_np1 \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_np1.yml Then in your pipeline configuration file, specify the conda environment for these processes: [CellTypeAnnotation.envs] tool = \"celltypist\" [CellTypeAnnotation.envs.celltypist_args] model = \"data/Immune_All_Low.pkl\" python = \"/path/to/conda/envs/python_np1/bin/python\" [CDR3Clustering] python = \"/path/to/conda/envs/python_np1/bin/python\" [TESSA.envs] predefined_b = true python = \"/path/to/conda/envs/python_np1/bin/python\" Attention The pipeline itself is NOT included in the conda environment. You need to install it separately. $ conda activate immunopipe $ pip install -U immunopipe $ # If you want to create diagram and generate running information $ # or use the dry run scheduler, install with the extras $ pip install -U immunopipe [ diagram,runinfo,dry ] $ # You also need to install the frontend dependencies to generate reports $ pipen report update Use the docker image \u00b6 You can also use the docker image to run the pipeline. The image is built upon miniconda3 and micromamba is used as the package manager. The image is available at Docker Hub . To pull the image: Using docker Using singularity Using apptainer $ docker pull justold/immunopipe:<tag> If you are using singularity , you can pull and convert the image to sif format: $ singularity pull docker://justold/immunopipe:<tag> $ apptainer pull docker://justold/immunopipe:<tag> To run the pipeline use the image, please refer to Running the pipeline . The directory structure in the container \u00b6 The docker image is build upon mambaorg/micromamba:2.3.0 . The OS is linux/amd64. Other than the default directories, the following directories are also created or should be mapped during the run: /immunopipe : The directory where the source code of the pipeline is. It is general a clone of the repository . The pipeline is also installed from this directory. /workdir : The working directory. It is the directory where the pipeline is run. It is recommended to map the current directory ( . ) to this directory. Prepare to run the pipeline via Google Batch Jobs \u00b6 There are two ways of running the pipeline via Google Batch Jobs: using the gbatch scheduler (provided by xqute ) or using pipen-cli-gbatch . See more details in Running the pipeline via Google Batch Jobs . In addition to prepare the docker image in the artifact registry (or docker hub if your google cloud project allows pulling from docker hub), you also need to install some dependencies locally. If you choose to use the gbatch scheduler, in addition to installing the pipeline: $ pip install -U immunopipe # install cloud dependencies $ pip install -U panpath [ gs,async-gs ] You still have to install the following dependencies to generate reports: nodejs : Follow the instructions at https://nodejs.org/en/download/package-manager/ to install nodejs for your system (v20+ is required); or bunjs : Follow the instructions at https://bun.sh/docs/install to install bunjs for your system. Then you need to install frontend dependencies for report generation: $ pipen report update If you choose to use pipen-cli-gbatch (running the pipeline via immunopipe gbatch ), you just need to install the pipeline with the cli-gbatch extra: $ pip install -U immunopipe [ cli-gbatch ]","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#install-the-pipline-and-the-dependencies-using-conda","text":"Tip If you plan to use the docker image to run the pipeline locally, you can skip this section. immunopipe is built upon pipen framework, and a number of packages written in R and python . It's not recommended to install the packages manually. Instead, you can use the provided environment_base.yml to create a conda environment. $ conda env create \\ -n immunopipe \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_base.yml Then update the environment with essential R packages: $ conda env update \\ -n immunopipe \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_rpkgs.yml If the URL doesn't work, you can download the file and create the environment locally. For more detailed instructions of conda env create , please refer to conda docs . Note If you are using celltypist for cell type annotation: [CellTypeAnnotation.envs] tool = \"celltypist\" Or if you are enabling TESSA and CDR3Clustering processes, you need to install additional dependencies, including numpy v1 , which is not compatible with some other packages in the base environment. You can create a separate conda environment for these processes. $ conda env create \\ -n python_np1 \\ -f https://raw.githubusercontent.com/pwwang/immunopipe/master/docker/environment_np1.yml Then in your pipeline configuration file, specify the conda environment for these processes: [CellTypeAnnotation.envs] tool = \"celltypist\" [CellTypeAnnotation.envs.celltypist_args] model = \"data/Immune_All_Low.pkl\" python = \"/path/to/conda/envs/python_np1/bin/python\" [CDR3Clustering] python = \"/path/to/conda/envs/python_np1/bin/python\" [TESSA.envs] predefined_b = true python = \"/path/to/conda/envs/python_np1/bin/python\" Attention The pipeline itself is NOT included in the conda environment. You need to install it separately. $ conda activate immunopipe $ pip install -U immunopipe $ # If you want to create diagram and generate running information $ # or use the dry run scheduler, install with the extras $ pip install -U immunopipe [ diagram,runinfo,dry ] $ # You also need to install the frontend dependencies to generate reports $ pipen report update","title":"Install the pipline and the dependencies using conda"},{"location":"installation/#use-the-docker-image","text":"You can also use the docker image to run the pipeline. The image is built upon miniconda3 and micromamba is used as the package manager. The image is available at Docker Hub . To pull the image: Using docker Using singularity Using apptainer $ docker pull justold/immunopipe:<tag> If you are using singularity , you can pull and convert the image to sif format: $ singularity pull docker://justold/immunopipe:<tag> $ apptainer pull docker://justold/immunopipe:<tag> To run the pipeline use the image, please refer to Running the pipeline .","title":"Use the docker image"},{"location":"installation/#the-directory-structure-in-the-container","text":"The docker image is build upon mambaorg/micromamba:2.3.0 . The OS is linux/amd64. Other than the default directories, the following directories are also created or should be mapped during the run: /immunopipe : The directory where the source code of the pipeline is. It is general a clone of the repository . The pipeline is also installed from this directory. /workdir : The working directory. It is the directory where the pipeline is run. It is recommended to map the current directory ( . ) to this directory.","title":"The directory structure in the container"},{"location":"installation/#prepare-to-run-the-pipeline-via-google-batch-jobs","text":"There are two ways of running the pipeline via Google Batch Jobs: using the gbatch scheduler (provided by xqute ) or using pipen-cli-gbatch . See more details in Running the pipeline via Google Batch Jobs . In addition to prepare the docker image in the artifact registry (or docker hub if your google cloud project allows pulling from docker hub), you also need to install some dependencies locally. If you choose to use the gbatch scheduler, in addition to installing the pipeline: $ pip install -U immunopipe # install cloud dependencies $ pip install -U panpath [ gs,async-gs ] You still have to install the following dependencies to generate reports: nodejs : Follow the instructions at https://nodejs.org/en/download/package-manager/ to install nodejs for your system (v20+ is required); or bunjs : Follow the instructions at https://bun.sh/docs/install to install bunjs for your system. Then you need to install frontend dependencies for report generation: $ pipen report update If you choose to use pipen-cli-gbatch (running the pipeline via immunopipe gbatch ), you just need to install the pipeline with the cli-gbatch extra: $ pip install -U immunopipe [ cli-gbatch ]","title":"Prepare to run the pipeline via Google Batch Jobs"},{"location":"introduction/","text":"Introduction \u00b6 The pipeline architecture \u00b6 immunopipe is built upon pipen . It is recommended to read the pipen docs first to get a better understanding of the pipeline. Here, we just want to highlight some concepts that are helpful to use the pipeline as a user. A process is a unit of work in the pipeline. immunopipe includes a set of processes. Some of them are reused from biopipen and some are written specifically for immunopipe . The input of a process is typically a pandas DataFrame , which serves as the channel passing data between processes. The rows of the data frame are distributed to the jobs of the process, and columns are spreaded to the input variables of the job s. See more illustration here . In our case, most processes are just single-job processes. Other than the start processes, the input of a process is the output of other process(es). So users don't need to worry about the input of the processes in the configurations. envs of a process is the most important part of immunopipe that a user needs to configure. It defines the environment variables of the process. The environment variables are shared by all the jobs of the process. Attention These environment variables are not the same as the environment variables of the system. They are just variables that are used in the process across its jobs. See individual process pages for more details about the envs of each process. Analyses and processes \u00b6 As shown in the figure above, immunopipe includes a set of processes for scRNA-seq and scTCR-/scBCR-seq data analysis. The processes are grouped into categories below: Data input and QC \u00b6 SampleInfo : Read sample information from a CSV file and list the sample information in the report. LoadingRNAFromSeurat : Load the scRNA-seq data from existing Seurat objects. ScRepLoading : Load the VDJ data into ScRepertoire objects. SeuratPreparing : Read the data into Seurat objects and perform QC. T cell selection \u00b6 SeuratClusteringOfAllCells : Perform clustering on all cells if non-T cells are present in the data. ClusterMarkersOfAllCells : Find markers for each cluster of all the cells and perform enrichment analysis. TopExpressingGenesOfAllCells : Find top expressing genes for each cluster of all the cells and perform enrichment analysis. TOrBCellSelection : Select T cells from all cells. Clustering of T cells \u00b6 SeuratClustering : Perform clustering on all or T cells selected above. SeuratMap2Ref : Map the cells to a reference dataset. CellTypeAnnotation : Annotate cell types for each T-cell cluster. SeuratSubClustering : Perform sub-clustering on subsets of cells. ClusterMarkers : Find markers for each T-cell cluster and perform enrichment analysis. TopExpressingGenes : Find top expressing genes for each T-cell cluster and perform enrichment analysis. ModuleScoreCalculator : Calculate module scores or cell cycle scores for each cell. Note You can have multiple annotation processes, including SeuratClustering , SeuratMap2Ref , CellTypeAnnotation enabled in the same run. Make sure you use a different name for each annotation. By default, the name all default to seurat_clusters . For SeuratMap2Ref , you can use envs.ident to specify a new column name to store the mapped cluster information. For SeuratClustering , you can use envs.FindClusters.cluster-name to specify a new column name. For CellTypeAnnotation , you can use envs.newcol to specify a new column name. See the Environment Variables of each process for more details. Clonotype refinement \u00b6 CDR3Clustering : Perform clustering on TCR clones based on CDR3 amino acid sequences. TESSA : Perform integrative analyses using Tessa . Integration of scRNA-seq and scTCR-/scBCR-seq data \u00b6 ScRepCombiningExpression : Combine the VDJ data with the expression data (into a Seurat object). Downstream analyses \u00b6 SeuratClusterStats : Investigate statistics for each T-cell cluster (i.e. the number of cells in each cluster, the number of cells in each sample for each cluster, feature/gene expression visualization, dimension reduction plots, etc.). It's also possible to perform stats on TCR/BCR clones/clusters for each T-cell cluster. ClonalStats : Investigate statistics for clones. MarkersFinder : Find markers (differentially expressed genes) for any two groups, including clones or clone groups. PseudoBulkDEG : Perform pseudo-bulk differential expression analysis. CDR3AAPhyschem : Investigate the physicochemical properties of CDR3 amino acid sequences of one cell type over another (i.e. Treg vs Tconv ). ScFGSEA : Perform GSEA analysis for comparisons between two groups of cells. For example, between two cell types, clone groups, TCR/BCR clusters or clinical groups. CellCellCommunication : Perform cell-cell communication analysis. CellCellCommunicationPlots : Generate plots for cell-cell communication analysis. Metabolic landscape analyses \u00b6 ScrnaMetabolicLandscape : A group of folowwing processes to perform metabolic landscape analyses. MetabolicInput : Prepare the input files for metabolic landscape analyses. MetabolicExprImputation : Impute the dropout values in the expression matrix. MetabolicPathwayActivity : Investigate the metabolic pathways of the cells in different groups and subsets. MetabolicPathwayHeterogeneity : Show metabolic pathways enriched in genes with highest contribution to the metabolic heterogeneities. MetabolicFeatures : Perform gene set enrichment analysis against the metabolic pathways for groups in different subsets. Routes of the pipeline \u00b6 immunopipe is designed to be flexible. It can be used in different ways. Here we list some common routes of the pipeline: Both scRNA-seq and scTCR-/scBCR-seq data avaiable \u00b6 To enable this route, you need to: tell the pipeline that scTCR-seq data is available by adding a column named TCRData / BCRData in the sample information file. put the path of the sample information file in the configuration file [SampleInfo.in.infile] , instead of passing it as a command line argument ( --Sample.in.infile ). Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. You can also assign cell types to clusters using [CellTypeAnnotation] . If you need to select T/B cells from all cells available for later analyses, you need to add [TOrBCellSelection] in the configuration file. If so, the processes annotated as something like For selected cells will be added to the pipeline. This is the most common route of the pipeline: The optional processes are enabled only when the corresponding sections are added in the configuration file. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you need to add [ModuleScoreCalculator] in the configuration file. When you have a processed Seurat object with scRNA-seq data, you can use LoadingRNAFromSeurat to load the data into the pipeline directly, which will take the place of [SampleInfo] . When LoadingRNAFromSeurat.envs.prepared is set to true , SeuratPreparing will be skipped. When LoadingRNAFromSeurat.envs.clustered is set to true , both SeuratPreparing and SeuratClusteringOfAllCells / SeuratClustering will be skipped. See LoadingRNAFromSeurat for more details. Only scRNA-seq data avaiable \u00b6 When you have only scRNA-seq data, you just don't need to add the TCRData / BCRData column in the sample information file. The pipeline will automatically skip the processes related to scTCR-/scBCR-seq data analysis. Attention You need to specify the sample information file in the configuration file [SampleInfo.in.infile] to enable this route. Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger this route if you don't have SampleInfo defined in your configuration file. Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. Similar to the previous route, you can also load a processed Seurat object with scRNA-seq data using LoadingRNAFromSeurat .","title":"Introduction"},{"location":"introduction/#introduction","text":"","title":"Introduction"},{"location":"introduction/#the-pipeline-architecture","text":"immunopipe is built upon pipen . It is recommended to read the pipen docs first to get a better understanding of the pipeline. Here, we just want to highlight some concepts that are helpful to use the pipeline as a user. A process is a unit of work in the pipeline. immunopipe includes a set of processes. Some of them are reused from biopipen and some are written specifically for immunopipe . The input of a process is typically a pandas DataFrame , which serves as the channel passing data between processes. The rows of the data frame are distributed to the jobs of the process, and columns are spreaded to the input variables of the job s. See more illustration here . In our case, most processes are just single-job processes. Other than the start processes, the input of a process is the output of other process(es). So users don't need to worry about the input of the processes in the configurations. envs of a process is the most important part of immunopipe that a user needs to configure. It defines the environment variables of the process. The environment variables are shared by all the jobs of the process. Attention These environment variables are not the same as the environment variables of the system. They are just variables that are used in the process across its jobs. See individual process pages for more details about the envs of each process.","title":"The pipeline architecture"},{"location":"introduction/#analyses-and-processes","text":"As shown in the figure above, immunopipe includes a set of processes for scRNA-seq and scTCR-/scBCR-seq data analysis. The processes are grouped into categories below:","title":"Analyses and processes"},{"location":"introduction/#data-input-and-qc","text":"SampleInfo : Read sample information from a CSV file and list the sample information in the report. LoadingRNAFromSeurat : Load the scRNA-seq data from existing Seurat objects. ScRepLoading : Load the VDJ data into ScRepertoire objects. SeuratPreparing : Read the data into Seurat objects and perform QC.","title":"Data input and QC"},{"location":"introduction/#t-cell-selection","text":"SeuratClusteringOfAllCells : Perform clustering on all cells if non-T cells are present in the data. ClusterMarkersOfAllCells : Find markers for each cluster of all the cells and perform enrichment analysis. TopExpressingGenesOfAllCells : Find top expressing genes for each cluster of all the cells and perform enrichment analysis. TOrBCellSelection : Select T cells from all cells.","title":"T cell selection"},{"location":"introduction/#clustering-of-t-cells","text":"SeuratClustering : Perform clustering on all or T cells selected above. SeuratMap2Ref : Map the cells to a reference dataset. CellTypeAnnotation : Annotate cell types for each T-cell cluster. SeuratSubClustering : Perform sub-clustering on subsets of cells. ClusterMarkers : Find markers for each T-cell cluster and perform enrichment analysis. TopExpressingGenes : Find top expressing genes for each T-cell cluster and perform enrichment analysis. ModuleScoreCalculator : Calculate module scores or cell cycle scores for each cell. Note You can have multiple annotation processes, including SeuratClustering , SeuratMap2Ref , CellTypeAnnotation enabled in the same run. Make sure you use a different name for each annotation. By default, the name all default to seurat_clusters . For SeuratMap2Ref , you can use envs.ident to specify a new column name to store the mapped cluster information. For SeuratClustering , you can use envs.FindClusters.cluster-name to specify a new column name. For CellTypeAnnotation , you can use envs.newcol to specify a new column name. See the Environment Variables of each process for more details.","title":"Clustering of T cells"},{"location":"introduction/#clonotype-refinement","text":"CDR3Clustering : Perform clustering on TCR clones based on CDR3 amino acid sequences. TESSA : Perform integrative analyses using Tessa .","title":"Clonotype refinement"},{"location":"introduction/#integration-of-scrna-seq-and-sctcr-scbcr-seq-data","text":"ScRepCombiningExpression : Combine the VDJ data with the expression data (into a Seurat object).","title":"Integration of scRNA-seq and scTCR-/scBCR-seq data"},{"location":"introduction/#downstream-analyses","text":"SeuratClusterStats : Investigate statistics for each T-cell cluster (i.e. the number of cells in each cluster, the number of cells in each sample for each cluster, feature/gene expression visualization, dimension reduction plots, etc.). It's also possible to perform stats on TCR/BCR clones/clusters for each T-cell cluster. ClonalStats : Investigate statistics for clones. MarkersFinder : Find markers (differentially expressed genes) for any two groups, including clones or clone groups. PseudoBulkDEG : Perform pseudo-bulk differential expression analysis. CDR3AAPhyschem : Investigate the physicochemical properties of CDR3 amino acid sequences of one cell type over another (i.e. Treg vs Tconv ). ScFGSEA : Perform GSEA analysis for comparisons between two groups of cells. For example, between two cell types, clone groups, TCR/BCR clusters or clinical groups. CellCellCommunication : Perform cell-cell communication analysis. CellCellCommunicationPlots : Generate plots for cell-cell communication analysis.","title":"Downstream analyses"},{"location":"introduction/#metabolic-landscape-analyses","text":"ScrnaMetabolicLandscape : A group of folowwing processes to perform metabolic landscape analyses. MetabolicInput : Prepare the input files for metabolic landscape analyses. MetabolicExprImputation : Impute the dropout values in the expression matrix. MetabolicPathwayActivity : Investigate the metabolic pathways of the cells in different groups and subsets. MetabolicPathwayHeterogeneity : Show metabolic pathways enriched in genes with highest contribution to the metabolic heterogeneities. MetabolicFeatures : Perform gene set enrichment analysis against the metabolic pathways for groups in different subsets.","title":"Metabolic landscape analyses"},{"location":"introduction/#routes-of-the-pipeline","text":"immunopipe is designed to be flexible. It can be used in different ways. Here we list some common routes of the pipeline:","title":"Routes of the pipeline"},{"location":"introduction/#both-scrna-seq-and-sctcr-scbcr-seq-data-avaiable","text":"To enable this route, you need to: tell the pipeline that scTCR-seq data is available by adding a column named TCRData / BCRData in the sample information file. put the path of the sample information file in the configuration file [SampleInfo.in.infile] , instead of passing it as a command line argument ( --Sample.in.infile ). Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. You can also assign cell types to clusters using [CellTypeAnnotation] . If you need to select T/B cells from all cells available for later analyses, you need to add [TOrBCellSelection] in the configuration file. If so, the processes annotated as something like For selected cells will be added to the pipeline. This is the most common route of the pipeline: The optional processes are enabled only when the corresponding sections are added in the configuration file. For example, if you want to add module scores (e.g. cell activation score) to the Seurat object, you need to add [ModuleScoreCalculator] in the configuration file. When you have a processed Seurat object with scRNA-seq data, you can use LoadingRNAFromSeurat to load the data into the pipeline directly, which will take the place of [SampleInfo] . When LoadingRNAFromSeurat.envs.prepared is set to true , SeuratPreparing will be skipped. When LoadingRNAFromSeurat.envs.clustered is set to true , both SeuratPreparing and SeuratClusteringOfAllCells / SeuratClustering will be skipped. See LoadingRNAFromSeurat for more details.","title":"Both scRNA-seq and scTCR-/scBCR-seq data avaiable"},{"location":"introduction/#only-scrna-seq-data-avaiable","text":"When you have only scRNA-seq data, you just don't need to add the TCRData / BCRData column in the sample information file. The pipeline will automatically skip the processes related to scTCR-/scBCR-seq data analysis. Attention You need to specify the sample information file in the configuration file [SampleInfo.in.infile] to enable this route. Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger this route if you don't have SampleInfo defined in your configuration file. Unsupervised clustering [SeuratClustering] on selected T cells is the default setting. If you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. Similar to the previous route, you can also load a processed Seurat object with scRNA-seq data using LoadingRNAFromSeurat .","title":"Only scRNA-seq data avaiable"},{"location":"mcp-server/","text":"MCP Server \u00b6 The Immunopipe MCP Server is a Model Context Protocol (MCP) server that provides intelligent configuration generation for immunopipe pipelines. It allows AI assistants like Claude to understand and generate complex TOML configuration files for single-cell RNA-seq and TCR/BCR analysis workflows. Overview \u00b6 The MCP server exposes a comprehensive set of tools for: Discovery : List available pipeline options, processes, and Google Batch configurations Generation : Create TOML configuration files, templates, and process-specific configs Manipulation : Merge, validate, and format configuration files AI-Assisted Configuration : Generate configurations from natural language descriptions Installation \u00b6 The MCP server is included with immunopipe. You can run it directly using: # Run with stdio transport (for VSCode/Claude integration) immunopipe mcp --transport stdio # Run with HTTP transport (for testing) immunopipe mcp --transport http --port 8000 VSCode Integration \u00b6 To integrate with VSCode and Claude, add the following to your VSCode settings: { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe.mcp\" , \"--transport\" , \"stdio\" ] } } } } Available Tools \u00b6 Discovery Tools \u00b6 list_pipeline_options \u00b6 Lists all available pipeline-level configuration options. Parameters : None Returns : Dictionary of pipeline options with descriptions, types, defaults, and requirements. list_processes \u00b6 Lists all available immunopipe processes. Parameters : None Returns : Dictionary of processes with descriptions, environment variables, and requirements. list_gbatch_options \u00b6 Lists all Google Batch configuration options. Parameters : None Returns : Dictionary of Google Batch options with descriptions, types, and defaults. get_process_details \u00b6 Gets detailed information about a specific process. Parameters : - process_name (string): Name of the process to get details for Returns : Detailed process information including configuration options. Generation Tools \u00b6 generate_full_config \u00b6 Generates a complete immunopipe TOML configuration file. Parameters : - pipeline_options (object, optional): Pipeline-level options - processes (object, optional): Process configurations - gbatch_options (object, optional): Google Batch options - description (string, optional): Description for the configuration file Returns : Complete TOML configuration as a string. generate_pipeline_config \u00b6 Generates pipeline-level configuration section. Parameters : - options (object): Pipeline options to include Returns : Pipeline configuration TOML section. generate_process_config \u00b6 Generates configuration for a specific process. Parameters : - process_name (string): Name of the process - config (object): Process configuration options Returns : Process configuration TOML section. generate_gbatch_config \u00b6 Generates Google Batch configuration section. Parameters : - options (object): Google Batch options Returns : Google Batch configuration TOML section. Template Tools \u00b6 generate_basic_template \u00b6 Generates a basic immunopipe configuration template. Parameters : None Returns : Basic TOML template suitable for standard scRNA-seq analysis. generate_tcr_template \u00b6 Generates a template optimized for TCR analysis. Parameters : None Returns : TOML template configured for single-cell TCR/BCR analysis. generate_gbatch_template \u00b6 Generates a template for Google Batch execution. Parameters : None Returns : TOML template configured for cloud execution via Google Batch. Manipulation Tools \u00b6 merge_configs \u00b6 Merges two TOML configuration files or strings. Parameters : - base_config (string): Base configuration (TOML string) - new_config (string): New configuration to merge (TOML string) Returns : Merged TOML configuration. validate_config \u00b6 Validates a TOML configuration file. Parameters : - config_content (string): TOML configuration content to validate Returns : Validation results with success status and error messages. format_config \u00b6 Formats and enhances a TOML configuration. Parameters : - config_content (string): TOML configuration content to format - add_comments (boolean, optional): Whether to add helpful comments Returns : Formatted TOML configuration with optional comments. AI-Assisted Tools \u00b6 configure_immunopipe \u00b6 Generates immunopipe configuration from natural language requirements. This is the most intelligent tool that can understand complex analysis requirements and automatically select appropriate processes. Parameters : - requirements (string): Natural language description of analysis needs - specific_processes (array, optional): Specific process names to configure - parameters (object, optional): Specific parameter values to set Examples : - \"clustering with resolution 0.5\" - \"TCR analysis with clustering\" - \"set SeuratPreparing QC parameters\" Returns : Complete TOML configuration tailored to the requirements. help_generate_config \u00b6 Provides configuration suggestions based on natural language descriptions. Parameters : - description (string): Natural language description of analysis goals Returns : Suggestions and recommended tools for the analysis. suggest_processes \u00b6 Suggests processes based on analysis type. Parameters : - analysis_type (string): Type of analysis (e.g., 'tcr', 'bcr', 'clustering', 'differential') Returns : List of recommended processes for the analysis type. Usage Examples \u00b6 Basic Usage \u00b6 from immunopipe.mcp.tools import ImmunopipeConfigTools # Initialize the tools tools = ImmunopipeConfigTools () # Generate a basic template result = await tools . generate_basic_template () print ( result . content ) Natural Language Configuration \u00b6 # Configure immunopipe using natural language result = await tools . configure_immunopipe ( requirements = \"I want to analyze single-cell TCR data with clustering resolution 0.8\" ) print ( result . content ) # Complete TOML configuration Process Discovery \u00b6 # List available processes processes = await tools . list_processes () print ( f \"Found { len ( processes . content ) } processes\" ) # Get details for a specific process details = await tools . get_process_details ( \"SeuratClustering\" ) print ( details . content ) Configuration Manipulation \u00b6 # Generate base config base = await tools . generate_basic_template () # Generate TCR-specific additions tcr_config = await tools . generate_tcr_template () # Merge configurations merged = await tools . merge_configs ( base . content , tcr_config . content ) print ( merged . content ) Integration with Claude/AI Assistants \u00b6 The MCP server is designed to work seamlessly with AI assistants. With immunopipe installed, you can add the MCP server to your Claude or VSCode setup to enable intelligent configuration generation: claude mcp add --transport http immunopipe-mcp http://localhost:80000 { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe\" , \"mcp\" , \"--transport\" , \"stdio\" ] } } } Here are some example prompts that work well: Configuration Generation \u00b6 \"Generate an immunopipe configuration for TCR analysis\" \"Create a config for single-cell clustering with resolution 0.5\" \"Set up immunopipe for differential expression analysis\" Process Selection \u00b6 \"What processes do I need for BCR analysis?\" \"Suggest processes for clustering analysis\" \"Show me options for Google Batch execution\" Configuration Management \u00b6 \"Validate this immunopipe configuration\" \"Format and add comments to my config file\" \"Merge these two immunopipe configurations\" Architecture \u00b6 The MCP server consists of several key components: McpServer : Main server implementation with JSON-RPC over HTTP MCPServer : Standards-compliant MCP server for VSCode integration ImmunopipeConfigTools : Core tool collection with hierarchical capabilities OptionsDiscovery : Discovers available configuration options and processes TOMLGenerator : Generates and manipulates TOML configuration files ProcessDocumentationExtractor : Extracts process documentation for intelligent configuration Error Handling \u00b6 The MCP server provides comprehensive error handling: Tool Validation : Validates tool parameters and provides helpful error messages Configuration Validation : Checks TOML syntax and immunopipe-specific requirements Process Discovery : Handles missing or unavailable processes gracefully Natural Language Processing : Provides fallback configurations when analysis fails Development and Testing \u00b6 To test the MCP server locally: # Run the example demonstration python -m immunopipe.mcp.example # Run interactive demo python -m immunopipe.mcp.example interactive # Test with HTTP transport immunopipe mcp --transport http --port 8000 The server includes comprehensive test coverage and example usage patterns to help with development and integration. Performance \u00b6 The MCP server is optimized for: Fast Discovery : Efficient caching of process and option information Incremental Configuration : Tools can be chained for complex configurations Memory Efficiency : Lazy loading of process documentation Scalability : Async/await support for concurrent tool execution Support and Troubleshooting \u00b6 Common issues and solutions: Process Not Found : Ensure immunopipe is properly installed and processes are available Configuration Validation Errors : Check TOML syntax and parameter validity Natural Language Analysis Failures : Use more specific descriptions or explicit process names VSCode Integration Issues : Verify MCP server configuration in VSCode settings For additional help, open an issue on the GitHub repository .","title":"MCP Sever"},{"location":"mcp-server/#mcp-server","text":"The Immunopipe MCP Server is a Model Context Protocol (MCP) server that provides intelligent configuration generation for immunopipe pipelines. It allows AI assistants like Claude to understand and generate complex TOML configuration files for single-cell RNA-seq and TCR/BCR analysis workflows.","title":"MCP Server"},{"location":"mcp-server/#overview","text":"The MCP server exposes a comprehensive set of tools for: Discovery : List available pipeline options, processes, and Google Batch configurations Generation : Create TOML configuration files, templates, and process-specific configs Manipulation : Merge, validate, and format configuration files AI-Assisted Configuration : Generate configurations from natural language descriptions","title":"Overview"},{"location":"mcp-server/#installation","text":"The MCP server is included with immunopipe. You can run it directly using: # Run with stdio transport (for VSCode/Claude integration) immunopipe mcp --transport stdio # Run with HTTP transport (for testing) immunopipe mcp --transport http --port 8000","title":"Installation"},{"location":"mcp-server/#vscode-integration","text":"To integrate with VSCode and Claude, add the following to your VSCode settings: { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe.mcp\" , \"--transport\" , \"stdio\" ] } } } }","title":"VSCode Integration"},{"location":"mcp-server/#available-tools","text":"","title":"Available Tools"},{"location":"mcp-server/#discovery-tools","text":"","title":"Discovery Tools"},{"location":"mcp-server/#list_pipeline_options","text":"Lists all available pipeline-level configuration options. Parameters : None Returns : Dictionary of pipeline options with descriptions, types, defaults, and requirements.","title":"list_pipeline_options"},{"location":"mcp-server/#list_processes","text":"Lists all available immunopipe processes. Parameters : None Returns : Dictionary of processes with descriptions, environment variables, and requirements.","title":"list_processes"},{"location":"mcp-server/#list_gbatch_options","text":"Lists all Google Batch configuration options. Parameters : None Returns : Dictionary of Google Batch options with descriptions, types, and defaults.","title":"list_gbatch_options"},{"location":"mcp-server/#get_process_details","text":"Gets detailed information about a specific process. Parameters : - process_name (string): Name of the process to get details for Returns : Detailed process information including configuration options.","title":"get_process_details"},{"location":"mcp-server/#generation-tools","text":"","title":"Generation Tools"},{"location":"mcp-server/#generate_full_config","text":"Generates a complete immunopipe TOML configuration file. Parameters : - pipeline_options (object, optional): Pipeline-level options - processes (object, optional): Process configurations - gbatch_options (object, optional): Google Batch options - description (string, optional): Description for the configuration file Returns : Complete TOML configuration as a string.","title":"generate_full_config"},{"location":"mcp-server/#generate_pipeline_config","text":"Generates pipeline-level configuration section. Parameters : - options (object): Pipeline options to include Returns : Pipeline configuration TOML section.","title":"generate_pipeline_config"},{"location":"mcp-server/#generate_process_config","text":"Generates configuration for a specific process. Parameters : - process_name (string): Name of the process - config (object): Process configuration options Returns : Process configuration TOML section.","title":"generate_process_config"},{"location":"mcp-server/#generate_gbatch_config","text":"Generates Google Batch configuration section. Parameters : - options (object): Google Batch options Returns : Google Batch configuration TOML section.","title":"generate_gbatch_config"},{"location":"mcp-server/#template-tools","text":"","title":"Template Tools"},{"location":"mcp-server/#generate_basic_template","text":"Generates a basic immunopipe configuration template. Parameters : None Returns : Basic TOML template suitable for standard scRNA-seq analysis.","title":"generate_basic_template"},{"location":"mcp-server/#generate_tcr_template","text":"Generates a template optimized for TCR analysis. Parameters : None Returns : TOML template configured for single-cell TCR/BCR analysis.","title":"generate_tcr_template"},{"location":"mcp-server/#generate_gbatch_template","text":"Generates a template for Google Batch execution. Parameters : None Returns : TOML template configured for cloud execution via Google Batch.","title":"generate_gbatch_template"},{"location":"mcp-server/#manipulation-tools","text":"","title":"Manipulation Tools"},{"location":"mcp-server/#merge_configs","text":"Merges two TOML configuration files or strings. Parameters : - base_config (string): Base configuration (TOML string) - new_config (string): New configuration to merge (TOML string) Returns : Merged TOML configuration.","title":"merge_configs"},{"location":"mcp-server/#validate_config","text":"Validates a TOML configuration file. Parameters : - config_content (string): TOML configuration content to validate Returns : Validation results with success status and error messages.","title":"validate_config"},{"location":"mcp-server/#format_config","text":"Formats and enhances a TOML configuration. Parameters : - config_content (string): TOML configuration content to format - add_comments (boolean, optional): Whether to add helpful comments Returns : Formatted TOML configuration with optional comments.","title":"format_config"},{"location":"mcp-server/#ai-assisted-tools","text":"","title":"AI-Assisted Tools"},{"location":"mcp-server/#configure_immunopipe","text":"Generates immunopipe configuration from natural language requirements. This is the most intelligent tool that can understand complex analysis requirements and automatically select appropriate processes. Parameters : - requirements (string): Natural language description of analysis needs - specific_processes (array, optional): Specific process names to configure - parameters (object, optional): Specific parameter values to set Examples : - \"clustering with resolution 0.5\" - \"TCR analysis with clustering\" - \"set SeuratPreparing QC parameters\" Returns : Complete TOML configuration tailored to the requirements.","title":"configure_immunopipe"},{"location":"mcp-server/#help_generate_config","text":"Provides configuration suggestions based on natural language descriptions. Parameters : - description (string): Natural language description of analysis goals Returns : Suggestions and recommended tools for the analysis.","title":"help_generate_config"},{"location":"mcp-server/#suggest_processes","text":"Suggests processes based on analysis type. Parameters : - analysis_type (string): Type of analysis (e.g., 'tcr', 'bcr', 'clustering', 'differential') Returns : List of recommended processes for the analysis type.","title":"suggest_processes"},{"location":"mcp-server/#usage-examples","text":"","title":"Usage Examples"},{"location":"mcp-server/#basic-usage","text":"from immunopipe.mcp.tools import ImmunopipeConfigTools # Initialize the tools tools = ImmunopipeConfigTools () # Generate a basic template result = await tools . generate_basic_template () print ( result . content )","title":"Basic Usage"},{"location":"mcp-server/#natural-language-configuration","text":"# Configure immunopipe using natural language result = await tools . configure_immunopipe ( requirements = \"I want to analyze single-cell TCR data with clustering resolution 0.8\" ) print ( result . content ) # Complete TOML configuration","title":"Natural Language Configuration"},{"location":"mcp-server/#process-discovery","text":"# List available processes processes = await tools . list_processes () print ( f \"Found { len ( processes . content ) } processes\" ) # Get details for a specific process details = await tools . get_process_details ( \"SeuratClustering\" ) print ( details . content )","title":"Process Discovery"},{"location":"mcp-server/#configuration-manipulation","text":"# Generate base config base = await tools . generate_basic_template () # Generate TCR-specific additions tcr_config = await tools . generate_tcr_template () # Merge configurations merged = await tools . merge_configs ( base . content , tcr_config . content ) print ( merged . content )","title":"Configuration Manipulation"},{"location":"mcp-server/#integration-with-claudeai-assistants","text":"The MCP server is designed to work seamlessly with AI assistants. With immunopipe installed, you can add the MCP server to your Claude or VSCode setup to enable intelligent configuration generation: claude mcp add --transport http immunopipe-mcp http://localhost:80000 { \"mcp\" : { \"servers\" : { \"immunopipe\" : { \"command\" : \"python\" , \"args\" : [ \"-m\" , \"immunopipe\" , \"mcp\" , \"--transport\" , \"stdio\" ] } } } Here are some example prompts that work well:","title":"Integration with Claude/AI Assistants"},{"location":"mcp-server/#configuration-generation","text":"\"Generate an immunopipe configuration for TCR analysis\" \"Create a config for single-cell clustering with resolution 0.5\" \"Set up immunopipe for differential expression analysis\"","title":"Configuration Generation"},{"location":"mcp-server/#process-selection","text":"\"What processes do I need for BCR analysis?\" \"Suggest processes for clustering analysis\" \"Show me options for Google Batch execution\"","title":"Process Selection"},{"location":"mcp-server/#configuration-management","text":"\"Validate this immunopipe configuration\" \"Format and add comments to my config file\" \"Merge these two immunopipe configurations\"","title":"Configuration Management"},{"location":"mcp-server/#architecture","text":"The MCP server consists of several key components: McpServer : Main server implementation with JSON-RPC over HTTP MCPServer : Standards-compliant MCP server for VSCode integration ImmunopipeConfigTools : Core tool collection with hierarchical capabilities OptionsDiscovery : Discovers available configuration options and processes TOMLGenerator : Generates and manipulates TOML configuration files ProcessDocumentationExtractor : Extracts process documentation for intelligent configuration","title":"Architecture"},{"location":"mcp-server/#error-handling","text":"The MCP server provides comprehensive error handling: Tool Validation : Validates tool parameters and provides helpful error messages Configuration Validation : Checks TOML syntax and immunopipe-specific requirements Process Discovery : Handles missing or unavailable processes gracefully Natural Language Processing : Provides fallback configurations when analysis fails","title":"Error Handling"},{"location":"mcp-server/#development-and-testing","text":"To test the MCP server locally: # Run the example demonstration python -m immunopipe.mcp.example # Run interactive demo python -m immunopipe.mcp.example interactive # Test with HTTP transport immunopipe mcp --transport http --port 8000 The server includes comprehensive test coverage and example usage patterns to help with development and integration.","title":"Development and Testing"},{"location":"mcp-server/#performance","text":"The MCP server is optimized for: Fast Discovery : Efficient caching of process and option information Incremental Configuration : Tools can be chained for complex configurations Memory Efficiency : Lazy loading of process documentation Scalability : Async/await support for concurrent tool execution","title":"Performance"},{"location":"mcp-server/#support-and-troubleshooting","text":"Common issues and solutions: Process Not Found : Ensure immunopipe is properly installed and processes are available Configuration Validation Errors : Check TOML syntax and parameter validity Natural Language Analysis Failures : Use more specific descriptions or explicit process names VSCode Integration Issues : Verify MCP server configuration in VSCode settings For additional help, open an issue on the GitHub repository .","title":"Support and Troubleshooting"},{"location":"preparing-input/","text":"Preparing the input data \u00b6 Single-cell RNA-seq (scRNA-seq) data \u00b6 Currently supported data formats: 10X Genomics by CellRanger loom For each sample, you need to provide the path to the data file or a directory containing the files. Specifically, the directory should be able to be read by Seurat::Read_10X() . For example, the directory should contain matrix.mtx , barcodes.tsv and features.tsv . These files can also be gzipped. For 10X Genomics data, you can also provide the h5 file generated by CellRanger . With v2+, we also support loading expression data directly from a Seurat object in RDS or qs/qs2 file. To do so, you need to enable the LoadingRNAFromSeurat process in the configuration file, and provide the path to the RDS or qs2 file: [LoadingRNAFromSeurat.in] infile = \"path/to/seurat_object.rds\" [LoadingRNAFromSeurat.envs] # When true, SeuratPreparing will be skipped # Suppose the Seurat object is already prepared prepared = false # When true (assuming prepared is also true), SeuratClusteringOfAllCells/SeuratClustering will be skipped # Suppose the Seurat object already contains the clustering information clustered = false # The column name in meta.data to use for sample identity sample = \"Sample\" Single-cell TCR-/BCR-seq (scTCR-seq/scBCR-seq) data \u00b6 The scTCR-/scBCR-seq data is optional for the pipeline. However, the scRNA-seq data is required for the pipeline. The scTCR-/scBCR-seq data, if available, should be paired with the scRNA-seq data. Theoratically, as long as the data can be loaded by scRepertoire::loadContigs() , it should be fine. Following formats are supported: 10X: 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR: AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD: Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion: Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation: Immcantation data, which is usually in a file with data.tsv file. JSON: JSON format, which is usually in a file with .json extension. ParseBio: ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR: MiXCR data, which is usually in a file with clones.tsv file. Omniscope: Omniscope data, which is usually in a file with .csv extension. TRUST4: TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R: WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html Metadata \u00b6 A metadata file is required as an input file for the pipeline. It should be a TAB delimited file with 2 required columns: Sample : A unique id for each sample RNAData : The directory or h5 file for single-cell RNA data for this sample, as described above. TCRData (optional): The directory for single-cell TCR data for this sample as described above. BCRData (optional): The directory for single-cell BCR data for this sample as described above. When TCRData / BCRData is not provided, the pipeline will skip the processes related to scTCR-/scBCR-seq data (see Routes of the pipeline for more details). You can also add other columns to the metadata file. The columns will be added the Seurat object as metadata, and can be used for downstream analysis. For example, you can add a column Condition to indicate the condition of each sample, or Batch to indicate the batch effect. This file should be provided to SampleInfo process. See SampleInfo for more details. An example metadata file can be found here . You can also use SampleInfo with envs.save_mutated = true and/or SeuratPreparing to add columns to metadata by configuration. These columns are persisted for downstream analysis. The difference is that SampleInfo can not pass along the factor (categorical) columns, while you are able to do so with SeuratPreparing . Other optional files \u00b6 Genes/Features to visualize for Seurat object \u00b6 If you have a set of genes/features of interest, you can provide a file with those genes, one gene per line, to SeuratClusterStats.envs.features.features for visualization the feature values, which finally is implemented by scplotter::FeatureStatPlot() . Note The genes should exist in the RNA-seq data (i.e features.tsv or the h5 file from cellranger). See SeuratClusterStats for more details. Pathways for Gene Set Enrichment Analysis (GSEA) \u00b6 If you want to perform GSEA, you need to provide a file containing the pathways. The file should be in the GMT format . You can provide the file to ScFGSEA.envs.gmtfile . Similarly, the genes should exist (be in the same format) in the features.tsv file. See ScFGSEA for more details. You can also find an example here: https://github.com/pwwang/immunopipe-example/blob/master/data/MSigDB_Hallmark_v7.5.1.gmt Cell type database for cell type annotation by sctype or hitype \u00b6 If you want to perform cell type annotation, you need to provide a file containing the cell type database if you are using sctype or hitype . The database file should be fed to CellTypeAnnotation.envs.sctype_db if you are using sctype , or CellTypeAnnotation.envs.hitype_db if you are using hitype . Again, the markers in the database should exist (be in the same format) in the features.tsv file or the h5 file. See CellTypeAnnotation for more details. Examples can be found here: ScTypeDB_short.xlsx and ScTypeDB_full.xlsx . Model for cell type annotation by celltypist \u00b6 If you want to perform cell type annotation by celltypist , you need to provide a model file. The model file should be fed to CellTypeAnnotation.envs.celltypist_args.model . The information of models can be found here . Download the one you want to use and provide the path to the file. Metabolic pathway for Metabolic Landscape Analysis \u00b6 Similarly, if you want to perform metabolic landscape analysis, you need to provide a file containing the metabolic pathways. The file should be in the GMT format . You can provide the file to ScMetabolicLandscape.envs.gmtfile . This file can also be used for GSEA. A pathway file for KEGG metabolism is provided here . See ScrnaMetabolicLandscape for more details. Reference for Seurat mapping if you want to perform supervised clustering \u00b6 If you want to perform supervised clustering, you need to provide a reference for SeuratMap2Ref . The reference should be a Seurat object in RDS or h5seurat file. You can provide the reference to SeuratMap2Ref.envs.ref . See SeuratMap2Ref for more details.","title":"Preparing the input"},{"location":"preparing-input/#preparing-the-input-data","text":"","title":"Preparing the input data"},{"location":"preparing-input/#single-cell-rna-seq-scrna-seq-data","text":"Currently supported data formats: 10X Genomics by CellRanger loom For each sample, you need to provide the path to the data file or a directory containing the files. Specifically, the directory should be able to be read by Seurat::Read_10X() . For example, the directory should contain matrix.mtx , barcodes.tsv and features.tsv . These files can also be gzipped. For 10X Genomics data, you can also provide the h5 file generated by CellRanger . With v2+, we also support loading expression data directly from a Seurat object in RDS or qs/qs2 file. To do so, you need to enable the LoadingRNAFromSeurat process in the configuration file, and provide the path to the RDS or qs2 file: [LoadingRNAFromSeurat.in] infile = \"path/to/seurat_object.rds\" [LoadingRNAFromSeurat.envs] # When true, SeuratPreparing will be skipped # Suppose the Seurat object is already prepared prepared = false # When true (assuming prepared is also true), SeuratClusteringOfAllCells/SeuratClustering will be skipped # Suppose the Seurat object already contains the clustering information clustered = false # The column name in meta.data to use for sample identity sample = \"Sample\"","title":"Single-cell RNA-seq (scRNA-seq) data"},{"location":"preparing-input/#single-cell-tcr-bcr-seq-sctcr-seqscbcr-seq-data","text":"The scTCR-/scBCR-seq data is optional for the pipeline. However, the scRNA-seq data is required for the pipeline. The scTCR-/scBCR-seq data, if available, should be paired with the scRNA-seq data. Theoratically, as long as the data can be loaded by scRepertoire::loadContigs() , it should be fine. Following formats are supported: 10X: 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR: AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD: Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion: Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation: Immcantation data, which is usually in a file with data.tsv file. JSON: JSON format, which is usually in a file with .json extension. ParseBio: ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR: MiXCR data, which is usually in a file with clones.tsv file. Omniscope: Omniscope data, which is usually in a file with .csv extension. TRUST4: TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R: WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html","title":"Single-cell TCR-/BCR-seq (scTCR-seq/scBCR-seq) data"},{"location":"preparing-input/#metadata","text":"A metadata file is required as an input file for the pipeline. It should be a TAB delimited file with 2 required columns: Sample : A unique id for each sample RNAData : The directory or h5 file for single-cell RNA data for this sample, as described above. TCRData (optional): The directory for single-cell TCR data for this sample as described above. BCRData (optional): The directory for single-cell BCR data for this sample as described above. When TCRData / BCRData is not provided, the pipeline will skip the processes related to scTCR-/scBCR-seq data (see Routes of the pipeline for more details). You can also add other columns to the metadata file. The columns will be added the Seurat object as metadata, and can be used for downstream analysis. For example, you can add a column Condition to indicate the condition of each sample, or Batch to indicate the batch effect. This file should be provided to SampleInfo process. See SampleInfo for more details. An example metadata file can be found here . You can also use SampleInfo with envs.save_mutated = true and/or SeuratPreparing to add columns to metadata by configuration. These columns are persisted for downstream analysis. The difference is that SampleInfo can not pass along the factor (categorical) columns, while you are able to do so with SeuratPreparing .","title":"Metadata"},{"location":"preparing-input/#other-optional-files","text":"","title":"Other optional files"},{"location":"preparing-input/#genesfeatures-to-visualize-for-seurat-object","text":"If you have a set of genes/features of interest, you can provide a file with those genes, one gene per line, to SeuratClusterStats.envs.features.features for visualization the feature values, which finally is implemented by scplotter::FeatureStatPlot() . Note The genes should exist in the RNA-seq data (i.e features.tsv or the h5 file from cellranger). See SeuratClusterStats for more details.","title":"Genes/Features to visualize for Seurat object"},{"location":"preparing-input/#pathways-for-gene-set-enrichment-analysis-gsea","text":"If you want to perform GSEA, you need to provide a file containing the pathways. The file should be in the GMT format . You can provide the file to ScFGSEA.envs.gmtfile . Similarly, the genes should exist (be in the same format) in the features.tsv file. See ScFGSEA for more details. You can also find an example here: https://github.com/pwwang/immunopipe-example/blob/master/data/MSigDB_Hallmark_v7.5.1.gmt","title":"Pathways for Gene Set Enrichment Analysis (GSEA)"},{"location":"preparing-input/#cell-type-database-for-cell-type-annotation-by-sctype-or-hitype","text":"If you want to perform cell type annotation, you need to provide a file containing the cell type database if you are using sctype or hitype . The database file should be fed to CellTypeAnnotation.envs.sctype_db if you are using sctype , or CellTypeAnnotation.envs.hitype_db if you are using hitype . Again, the markers in the database should exist (be in the same format) in the features.tsv file or the h5 file. See CellTypeAnnotation for more details. Examples can be found here: ScTypeDB_short.xlsx and ScTypeDB_full.xlsx .","title":"Cell type database for cell type annotation by sctype or hitype"},{"location":"preparing-input/#model-for-cell-type-annotation-by-celltypist","text":"If you want to perform cell type annotation by celltypist , you need to provide a model file. The model file should be fed to CellTypeAnnotation.envs.celltypist_args.model . The information of models can be found here . Download the one you want to use and provide the path to the file.","title":"Model for cell type annotation by celltypist"},{"location":"preparing-input/#metabolic-pathway-for-metabolic-landscape-analysis","text":"Similarly, if you want to perform metabolic landscape analysis, you need to provide a file containing the metabolic pathways. The file should be in the GMT format . You can provide the file to ScMetabolicLandscape.envs.gmtfile . This file can also be used for GSEA. A pathway file for KEGG metabolism is provided here . See ScrnaMetabolicLandscape for more details.","title":"Metabolic pathway for Metabolic Landscape Analysis"},{"location":"preparing-input/#reference-for-seurat-mapping-if-you-want-to-perform-supervised-clustering","text":"If you want to perform supervised clustering, you need to provide a reference for SeuratMap2Ref . The reference should be a Seurat object in RDS or h5seurat file. You can provide the reference to SeuratMap2Ref.envs.ref . See SeuratMap2Ref for more details.","title":"Reference for Seurat mapping if you want to perform supervised clustering"},{"location":"running/","text":"Running the pipeline \u00b6 Run the pipeline locally via CLI \u00b6 Once the pipeline is installed, you can run it via CLI: $ immunopipe --help You can specify the options directly in the CLI. For example: $ immunopipe --forks 4 --TopExpressingGenes.envs.n 100 ... It's recommended to use a configuration file to specify all the options. For example: $ immunopipe @config.toml You can also use both ways together. The options specified in the CLI will override the ones in the configuration file. $ immunopipe @config.toml --forks 4 --TopExpressingGenes.envs.n 100 ... For configuration items, see configurations for more details. Tip If you want to run the pipeline on a cluster, see How to run the pipeline on a cluster? for more details. Attention For settings that determine the routes (a set of processes) of the pipeline, you should define them in the configuration file. For example, if you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If you just pass the section as a command line argument ( --SeuratMap2Ref ), it will not trigger the corresponding processes. To indicate whether the scTCR-/scBCR-seq data is available or not, you also need to specify the sample information file in the configuration file [SampleInfo.in.infile] . Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger the corresponding processes. See Routes of the pipeline for more details. Run the pipeline via pipen-board \u00b6 pipen-board is a web-based dashboard for pipen . It provides a user-friendly interface to configure and run the pipeline. It also provides a way to monitor the running progress of the pipeline. pipen-board is installed by default with immunopipe . You can run it via CLI: $ pipen board immunopipe:Immunopipe * * __ __ __. . __ __ + __ __ * | __ )|| __ ) | _ | \\ | __ | __ ) / \\ / \\ | __ ) | \\ * | || | __ | \\| | __ ) \\_ _//-- \\| \\ | __/ * * version: 0 .11.1 * * Configure and run pipen pipelines from the web * * Serving Quart app 'pipen_board' * Environment: development * Debug mode: True * Running on http://0.0.0.0:18521 ( CTRL + C to quit ) [ 07 /31/23 21 :23:27 ] INFO Running on http://0.0.0.0:18521 ( CTRL + C to quit ) Then you can open the dashboard in your browser at http://localhost:18521 . In the Configuration tab, you can configure the pipeline and the processes. Then you can use the Generate Configuration button to generate the configuration file and then use the generated configuration file to run the pipeline via CLI. If you want to run the pipeline via pipen-board , you need an additional configuration file to tell pipen-board how to run the pipeline: $ pipen board immunopipe:Immunopipe -a gh:pwwang/immunopipe/board.toml@dev The additional file is available at immunopipe 's GitHub repo. You can also download it and modify it to fit your needs, but in most cases, you don't have to. With the additional file, you can find four running options , LOCAL , DOCKER , SINGULARITY and APPTAINER , on the left side of the Configuration tab. You can choose one of them to run the pipeline. Take LOCAL as an example. When clicking the Run the command button, a configuration file specified by configfile is saved and used to run the pipeline via CLI. Then the Previous Run tab is replaced by the Running tab to track the progress of the pipeline. Run the pipeline using docker image \u00b6 Choose the right tag of the docker image \u00b6 The docker image is tagged with the version of immunopipe , together with master and dev . They are listed here: https://hub.docker.com/repository/docker/justold/immunopipe/tags . dev is the latest development version of immunopipe . It may have unstable features. If you want to use a more stable version, please try master , or a specific semantic version. You can pull the images in advance using docker , singularity or apptainer . See help options of docker pull , singularity pull or apptainer pull for more details. You can also specify the tag when running the pipeline. See the following sections for more details. Using docker Using singularity Using apptainer To run the pipeline using the docker image with docker , you need to mount the current working directory to the /workdir directory in the container. You also need to specify the configuration file via @<configfile> option. For example: $ docker run \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using singularity . You also need to specify the configuration file via @<configfile> option. For example: $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using apptainer . You also need to specify the configuration file via @<configfile> option. For example: $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml Run the pipeline via pipen-board using docker image \u00b6 Using docker Using singularity Using apptainer You can also run the pipeline via pipen-board using the docker image with docker : $ docker run -p 18521 :18521 \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Note You should use LOCAL instead of DOCKER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the docker container. You can also run the pipeline via pipen-board using the docker image with singularity : $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Similarly, you should use LOCAL instead of SINGULARITY to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. You can also run the pipeline via pipen-board using the docker image with apptainer : $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml Also similarly, you should use LOCAL instead of APPTAINER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. When the command is running, you will see the following message: Then, You can open the dashboard in your browser at http://localhost:18521 . Run the pipeline using Google Cloud Batch Jobs \u00b6 There are two ways to run the pipeline using Google Cloud Batch Jobs: Use the gbatch scheduler of pipen \u00b6 When using the gbatch , the metadata of the processes (job status, job output, etc) are managed locally. Even though they are on the cloud, they are manipuated locally (using the API provided by panpath ). The processes are submitted to Google Cloud Batch Jobs using gcloud batch jobs submit . And the processes are run on Google Cloud Compute Engine VMs, and they need to be sumbitted one after another. See the documentation of cloud support of pipen . Use pipen-cli-gbatch \u00b6 You need install the dependencies via pip install -U immunopipe[cli-gbatch] to use this feature. immunopipe has integrated with pipen-cli-gbatch to provide a seamless way to run the pipeline using Google Cloud Batch Jobs. The entire pipeline is wrapped (like it is running locally) and submitted as a single job to Google Cloud Batch Jobs. You just need to run the following: > immunopipe gbatch @config.toml To provide the scheduler options to run the wrapped job (daemon) on Google Cloud Batch Jobs, you can specify them by --gbatch.machine-type , --gbatch.provisioning-model , --gbatch.disk-size-gb , etc. See the help message of immunopipe gbatch --help for more details. > immunopipe gbatch --help # pipeline options Options For Pipen-cli-gbatch ( extra Options ) : --gbatch.profile PROFILE Use the ` scheduler_opts ` as the Scheduler Options of a given profile from pipen configuration files, including ~/.pipen.toml and ./pipen.toml. Note that if not provided, nothing will be loaded from the configuration files. --gbatch.loglevel { DEBUG,INFO,WARNING,ERROR,CRITICAL,debug,info,warning,error,critical } Set the logging level for the daemon process. [ default: INFO ] --gbatch.error-strategy { retry,halt } The strategy when there is error happened [ default: halt ] --gbatch.num-retries NUM_RETRIES The number of retries when there is error happened. Only valid when --error-strategy is 'retry' . [ default: 0 ] --gbatch.prescript PRESCRIPT The prescript to run before the main command. --gbatch.postscript POSTSCRIPT The postscript to run after the main command. --gbatch.recheck-interval RECHECK_INTERVAL The interval to recheck the job status, each takes about 0 .1 seconds. [ default: 600 ] --gbatch.cwd CWD The working directory to run the command. If not provided, the current directory is used. You can pass either a mounted path ( inside the VM ) or a Google Storage Bucket path ( gs://... ) . If a Google Storage Bucket path is provided, the mounted path will be inferred from the mounted paths of the VM. --gbatch.project PROJECT The Google Cloud project to run the job. --gbatch.location LOCATION The location to run the job. --gbatch.mount MOUNT The list of mounts to mount to the VM, each in the format of SOURCE:TARGET, where SOURCE must be either a Google Storage Bucket path ( gs://... ) . You can also use named mounts like ` INDIR = gs://my-bucket/inputs ` and the directory will be mounted to ` /mnt/disks/INDIR ` in the VM ; then you can use environment variable ` $INDIR ` in the command/script to refer to the mounted path. You can also mount a file like ` INFILE = gs://my-bucket/inputs/file.txt ` . The parent directory will be mounted to ` /mnt/disks/INFILE/inputs ` in the VM, and the file will be available at ` /mnt/disks/INFILE/inputs/file.txt ` in the VM. ` $INFILE ` can also be used in the command/script to refer to the mounted path. [ default: []] --gbatch.mount-as-cwd MOUNT_AS_CWD The directory to mount as the current working directory of the command. This is a shortcut for ` --mount <cloudpath>:/mnt/disks/.cwd --cwd /mnt/disks/.cwd ` . The <cloudpath> must be a Google Storage Bucket path ( gs://... ) . When this option is used, and ` --workdir ` is not provided, the workdir will be set to ` <cloudpath>/.pipen/<command_name> ` , where <command_name> is the name of the command ( or the value of ` --name ` if provided ) . --gbatch.service-account SERVICE_ACCOUNT The service account to run the job. --gbatch.network NETWORK The network to run the job. --gbatch.subnetwork SUBNETWORK The subnetwork to run the job. --gbatch.no-external-ip-address Whether to disable external IP address for the VM. --gbatch.machine-type MACHINE_TYPE The machine type of the VM. --gbatch.provisioning-model { STANDARD,SPOT } The provisioning model of the VM. --gbatch.image-uri IMAGE_URI The custom image URI of the VM. --gbatch.runnables RUNNABLES The JSON string of extra settings of runnables add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Runnable for details. You can have an extra key 'order' for each runnable, where negative values mean to run before the main command, and positive values mean to run after the main command. --gbatch.allocationPolicy ALLOCATIONPOLICY The JSON string of extra settings of allocationPolicy add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#AllocationPolicy for details. [ default: {}] --gbatch.taskGroups TASKGROUPS The JSON string of extra settings of taskGroups add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#TaskGroup for details. [ default: []] --gbatch.labels LABELS The strings of labels to add to the job ( key = value ) . Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Job.FIELDS.labels for details. [ default: []] --gbatch.gcloud GCLOUD The path to the gcloud command. [ default: gcloud ] When --gbatch.profile is provided, the default scheduler options will be used from ~/.pipen.toml and ./pipen.toml . For example, you can add the following to ~/.pipen.toml : [gbatch.scheduler_opts] project = \"my-project\" location = \"us-central1\" Then you can run the pipeline using the following command: > immunopipe gbatch @config.toml --gbatch.profile gbatch To use the default project and location . You can also specify these options directly in the command line or under a section gbatch in the configuration file. The options specified in the command line will override the ones in the configuration file, which will override the ones in the profile. For example, you may have the following in config.toml : name = \"Immunopipe\" workdir = \"gs://my-bucket/immunopipe_workdir\" outdir = \"gs://my-bucket/immunopipe_outdir\" [gbatch] project = \"my-project\" location = \"us-central1\" machine-type = \"n2d-standard-4\" provisioning-model = \"SPOT\" # More scheduler options... There are other actions you can do with gbatch : immunopipe gbatch @config.toml --nowait : submit the job and exit without waiting for the job to finish. immunopipe gbatch @config.toml --view-logs : view the logs of the job for the detached job. immunopipe gbatch @config.toml --version : show the version of immunopipe , pipen-cli-gbatch and pipen . Here is a diagram showing the difference between using the gbatch scheduler and using pipen-cli-gbatch : Use Google Cloud Batch Jobs directly (not recommended) \u00b6 You can also run the pipeline using Google Cloud Batch Jobs directly. In this case, you need to create a job definition file and submit the job using gcloud batch jobs submit . The job definition file should specify the container image, the command to run the pipeline, and the resources required for the job. Here is an example of a job definition file ( job.json ): { \"allocationPolicy\" : { \"serviceAccount\" : { \"email\" : \"...\" }, \"network\" : \"...\" , \"instances\" : [ { \"policy\" : { \"machineType\" : \"n2d-standard-4\" , \"provisioningModel\" : \"SPOT\" } } ] }, \"taskGroups\" : [ { \"taskSpec\" : { \"runnables\" : [ { \"container\" : { \"image_uri\" : \"docker.io/justold/immunopipe:dev\" , \"entrypoint\" : \"/usr/local/bin/_entrypoint.sh\" , \"commands\" : [ \"immunopipe\" , \"@/mnt/disks/workdir/Immunopipe.config.toml\" ] } } ], \"volumes\" : [ { \"gcs\" : { \"remotePath\" : \"<bucket>/path/to/workdir\" }, \"mountPath\" : \"/mnt/disks/workdir\" } ] } } ], \"logsPolicy\" : { \"destination\" : \"CLOUD_LOGGING\" }, \"labels\" : \"...\" } Then you can submit the job using the following command: $ gcloud batch jobs submit <job-name> --location <location> --project <project-id> --config job.json","title":"Running the pipeline"},{"location":"running/#running-the-pipeline","text":"","title":"Running the pipeline"},{"location":"running/#run-the-pipeline-locally-via-cli","text":"Once the pipeline is installed, you can run it via CLI: $ immunopipe --help You can specify the options directly in the CLI. For example: $ immunopipe --forks 4 --TopExpressingGenes.envs.n 100 ... It's recommended to use a configuration file to specify all the options. For example: $ immunopipe @config.toml You can also use both ways together. The options specified in the CLI will override the ones in the configuration file. $ immunopipe @config.toml --forks 4 --TopExpressingGenes.envs.n 100 ... For configuration items, see configurations for more details. Tip If you want to run the pipeline on a cluster, see How to run the pipeline on a cluster? for more details. Attention For settings that determine the routes (a set of processes) of the pipeline, you should define them in the configuration file. For example, if you want to perform supervised clustering, you need to add [SeuratMap2Ref] in the configuration file with necessary parameters. If you just pass the section as a command line argument ( --SeuratMap2Ref ), it will not trigger the corresponding processes. To indicate whether the scTCR-/scBCR-seq data is available or not, you also need to specify the sample information file in the configuration file [SampleInfo.in.infile] . Passing the sample information file as a command line argument ( --Sample.in.infile ) does not trigger the corresponding processes. See Routes of the pipeline for more details.","title":"Run the pipeline locally via CLI"},{"location":"running/#run-the-pipeline-via-pipen-board","text":"pipen-board is a web-based dashboard for pipen . It provides a user-friendly interface to configure and run the pipeline. It also provides a way to monitor the running progress of the pipeline. pipen-board is installed by default with immunopipe . You can run it via CLI: $ pipen board immunopipe:Immunopipe * * __ __ __. . __ __ + __ __ * | __ )|| __ ) | _ | \\ | __ | __ ) / \\ / \\ | __ ) | \\ * | || | __ | \\| | __ ) \\_ _//-- \\| \\ | __/ * * version: 0 .11.1 * * Configure and run pipen pipelines from the web * * Serving Quart app 'pipen_board' * Environment: development * Debug mode: True * Running on http://0.0.0.0:18521 ( CTRL + C to quit ) [ 07 /31/23 21 :23:27 ] INFO Running on http://0.0.0.0:18521 ( CTRL + C to quit ) Then you can open the dashboard in your browser at http://localhost:18521 . In the Configuration tab, you can configure the pipeline and the processes. Then you can use the Generate Configuration button to generate the configuration file and then use the generated configuration file to run the pipeline via CLI. If you want to run the pipeline via pipen-board , you need an additional configuration file to tell pipen-board how to run the pipeline: $ pipen board immunopipe:Immunopipe -a gh:pwwang/immunopipe/board.toml@dev The additional file is available at immunopipe 's GitHub repo. You can also download it and modify it to fit your needs, but in most cases, you don't have to. With the additional file, you can find four running options , LOCAL , DOCKER , SINGULARITY and APPTAINER , on the left side of the Configuration tab. You can choose one of them to run the pipeline. Take LOCAL as an example. When clicking the Run the command button, a configuration file specified by configfile is saved and used to run the pipeline via CLI. Then the Previous Run tab is replaced by the Running tab to track the progress of the pipeline.","title":"Run the pipeline via pipen-board"},{"location":"running/#run-the-pipeline-using-docker-image","text":"","title":"Run the pipeline using docker image"},{"location":"running/#choose-the-right-tag-of-the-docker-image","text":"The docker image is tagged with the version of immunopipe , together with master and dev . They are listed here: https://hub.docker.com/repository/docker/justold/immunopipe/tags . dev is the latest development version of immunopipe . It may have unstable features. If you want to use a more stable version, please try master , or a specific semantic version. You can pull the images in advance using docker , singularity or apptainer . See help options of docker pull , singularity pull or apptainer pull for more details. You can also specify the tag when running the pipeline. See the following sections for more details. Using docker Using singularity Using apptainer To run the pipeline using the docker image with docker , you need to mount the current working directory to the /workdir directory in the container. You also need to specify the configuration file via @<configfile> option. For example: $ docker run \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using singularity . You also need to specify the configuration file via @<configfile> option. For example: $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml You also need to mount the current working directory to the /workdir directory in the container if you are using apptainer . You also need to specify the configuration file via @<configfile> option. For example: $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> \\ @config.toml","title":"Choose the right tag of the docker image"},{"location":"running/#run-the-pipeline-via-pipen-board-using-docker-image","text":"Using docker Using singularity Using apptainer You can also run the pipeline via pipen-board using the docker image with docker : $ docker run -p 18521 :18521 \\ --rm -w /workdir -v $( pwd ) :/workdir -v /tmp:/tmp \\ justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Note You should use LOCAL instead of DOCKER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the docker container. You can also run the pipeline via pipen-board using the docker image with singularity : $ singularity run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml The under the running options , choose LOCAL to run the pipeline. Similarly, you should use LOCAL instead of SINGULARITY to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. You can also run the pipeline via pipen-board using the docker image with apptainer : $ apptainer run \\ --pwd /workdir -B $( pwd ) :/workdir,/tmp -c -e --unsquash --writable-tmpfs \\ docker://justold/immunopipe:<tag> board \\ immunopipe:Immunopipe \\ -a /immunopipe/board.toml Also similarly, you should use LOCAL instead of APPTAINER to run the pipeline. Otherwise, the pipeline will be run in a docker container inside the container. When the command is running, you will see the following message: Then, You can open the dashboard in your browser at http://localhost:18521 .","title":"Run the pipeline via pipen-board using docker image"},{"location":"running/#run-the-pipeline-using-google-cloud-batch-jobs","text":"There are two ways to run the pipeline using Google Cloud Batch Jobs:","title":"Run the pipeline using Google Cloud Batch Jobs"},{"location":"running/#use-the-gbatch-scheduler-of-pipen","text":"When using the gbatch , the metadata of the processes (job status, job output, etc) are managed locally. Even though they are on the cloud, they are manipuated locally (using the API provided by panpath ). The processes are submitted to Google Cloud Batch Jobs using gcloud batch jobs submit . And the processes are run on Google Cloud Compute Engine VMs, and they need to be sumbitted one after another. See the documentation of cloud support of pipen .","title":"Use the gbatch scheduler of pipen"},{"location":"running/#use-pipen-cli-gbatch","text":"You need install the dependencies via pip install -U immunopipe[cli-gbatch] to use this feature. immunopipe has integrated with pipen-cli-gbatch to provide a seamless way to run the pipeline using Google Cloud Batch Jobs. The entire pipeline is wrapped (like it is running locally) and submitted as a single job to Google Cloud Batch Jobs. You just need to run the following: > immunopipe gbatch @config.toml To provide the scheduler options to run the wrapped job (daemon) on Google Cloud Batch Jobs, you can specify them by --gbatch.machine-type , --gbatch.provisioning-model , --gbatch.disk-size-gb , etc. See the help message of immunopipe gbatch --help for more details. > immunopipe gbatch --help # pipeline options Options For Pipen-cli-gbatch ( extra Options ) : --gbatch.profile PROFILE Use the ` scheduler_opts ` as the Scheduler Options of a given profile from pipen configuration files, including ~/.pipen.toml and ./pipen.toml. Note that if not provided, nothing will be loaded from the configuration files. --gbatch.loglevel { DEBUG,INFO,WARNING,ERROR,CRITICAL,debug,info,warning,error,critical } Set the logging level for the daemon process. [ default: INFO ] --gbatch.error-strategy { retry,halt } The strategy when there is error happened [ default: halt ] --gbatch.num-retries NUM_RETRIES The number of retries when there is error happened. Only valid when --error-strategy is 'retry' . [ default: 0 ] --gbatch.prescript PRESCRIPT The prescript to run before the main command. --gbatch.postscript POSTSCRIPT The postscript to run after the main command. --gbatch.recheck-interval RECHECK_INTERVAL The interval to recheck the job status, each takes about 0 .1 seconds. [ default: 600 ] --gbatch.cwd CWD The working directory to run the command. If not provided, the current directory is used. You can pass either a mounted path ( inside the VM ) or a Google Storage Bucket path ( gs://... ) . If a Google Storage Bucket path is provided, the mounted path will be inferred from the mounted paths of the VM. --gbatch.project PROJECT The Google Cloud project to run the job. --gbatch.location LOCATION The location to run the job. --gbatch.mount MOUNT The list of mounts to mount to the VM, each in the format of SOURCE:TARGET, where SOURCE must be either a Google Storage Bucket path ( gs://... ) . You can also use named mounts like ` INDIR = gs://my-bucket/inputs ` and the directory will be mounted to ` /mnt/disks/INDIR ` in the VM ; then you can use environment variable ` $INDIR ` in the command/script to refer to the mounted path. You can also mount a file like ` INFILE = gs://my-bucket/inputs/file.txt ` . The parent directory will be mounted to ` /mnt/disks/INFILE/inputs ` in the VM, and the file will be available at ` /mnt/disks/INFILE/inputs/file.txt ` in the VM. ` $INFILE ` can also be used in the command/script to refer to the mounted path. [ default: []] --gbatch.mount-as-cwd MOUNT_AS_CWD The directory to mount as the current working directory of the command. This is a shortcut for ` --mount <cloudpath>:/mnt/disks/.cwd --cwd /mnt/disks/.cwd ` . The <cloudpath> must be a Google Storage Bucket path ( gs://... ) . When this option is used, and ` --workdir ` is not provided, the workdir will be set to ` <cloudpath>/.pipen/<command_name> ` , where <command_name> is the name of the command ( or the value of ` --name ` if provided ) . --gbatch.service-account SERVICE_ACCOUNT The service account to run the job. --gbatch.network NETWORK The network to run the job. --gbatch.subnetwork SUBNETWORK The subnetwork to run the job. --gbatch.no-external-ip-address Whether to disable external IP address for the VM. --gbatch.machine-type MACHINE_TYPE The machine type of the VM. --gbatch.provisioning-model { STANDARD,SPOT } The provisioning model of the VM. --gbatch.image-uri IMAGE_URI The custom image URI of the VM. --gbatch.runnables RUNNABLES The JSON string of extra settings of runnables add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Runnable for details. You can have an extra key 'order' for each runnable, where negative values mean to run before the main command, and positive values mean to run after the main command. --gbatch.allocationPolicy ALLOCATIONPOLICY The JSON string of extra settings of allocationPolicy add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#AllocationPolicy for details. [ default: {}] --gbatch.taskGroups TASKGROUPS The JSON string of extra settings of taskGroups add to the job.json. Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#TaskGroup for details. [ default: []] --gbatch.labels LABELS The strings of labels to add to the job ( key = value ) . Refer to https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#Job.FIELDS.labels for details. [ default: []] --gbatch.gcloud GCLOUD The path to the gcloud command. [ default: gcloud ] When --gbatch.profile is provided, the default scheduler options will be used from ~/.pipen.toml and ./pipen.toml . For example, you can add the following to ~/.pipen.toml : [gbatch.scheduler_opts] project = \"my-project\" location = \"us-central1\" Then you can run the pipeline using the following command: > immunopipe gbatch @config.toml --gbatch.profile gbatch To use the default project and location . You can also specify these options directly in the command line or under a section gbatch in the configuration file. The options specified in the command line will override the ones in the configuration file, which will override the ones in the profile. For example, you may have the following in config.toml : name = \"Immunopipe\" workdir = \"gs://my-bucket/immunopipe_workdir\" outdir = \"gs://my-bucket/immunopipe_outdir\" [gbatch] project = \"my-project\" location = \"us-central1\" machine-type = \"n2d-standard-4\" provisioning-model = \"SPOT\" # More scheduler options... There are other actions you can do with gbatch : immunopipe gbatch @config.toml --nowait : submit the job and exit without waiting for the job to finish. immunopipe gbatch @config.toml --view-logs : view the logs of the job for the detached job. immunopipe gbatch @config.toml --version : show the version of immunopipe , pipen-cli-gbatch and pipen . Here is a diagram showing the difference between using the gbatch scheduler and using pipen-cli-gbatch :","title":"Use pipen-cli-gbatch"},{"location":"running/#use-google-cloud-batch-jobs-directly-not-recommended","text":"You can also run the pipeline using Google Cloud Batch Jobs directly. In this case, you need to create a job definition file and submit the job using gcloud batch jobs submit . The job definition file should specify the container image, the command to run the pipeline, and the resources required for the job. Here is an example of a job definition file ( job.json ): { \"allocationPolicy\" : { \"serviceAccount\" : { \"email\" : \"...\" }, \"network\" : \"...\" , \"instances\" : [ { \"policy\" : { \"machineType\" : \"n2d-standard-4\" , \"provisioningModel\" : \"SPOT\" } } ] }, \"taskGroups\" : [ { \"taskSpec\" : { \"runnables\" : [ { \"container\" : { \"image_uri\" : \"docker.io/justold/immunopipe:dev\" , \"entrypoint\" : \"/usr/local/bin/_entrypoint.sh\" , \"commands\" : [ \"immunopipe\" , \"@/mnt/disks/workdir/Immunopipe.config.toml\" ] } } ], \"volumes\" : [ { \"gcs\" : { \"remotePath\" : \"<bucket>/path/to/workdir\" }, \"mountPath\" : \"/mnt/disks/workdir\" } ] } } ], \"logsPolicy\" : { \"destination\" : \"CLOUD_LOGGING\" }, \"labels\" : \"...\" } Then you can submit the job using the following command: $ gcloud batch jobs submit <job-name> --location <location> --project <project-id> --config job.json","title":"Use Google Cloud Batch Jobs directly (not recommended)"},{"location":"processes/CDR3AAPhyschem/","text":"CDR3AAPhyschem \u00b6 CDR3 AA physicochemical feature analysis The idea is to perform a regression between two groups of cells (e.g. Treg vs Tconv) at different length of CDR3 AA sequences. The regression will be performed for each physicochemical feature of the AA (hydrophobicity, volume and isolectric point). Input \u00b6 scrfile : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains. Output \u00b6 outdir : Default: {{in.immdata | stem}}.cdr3aaphyschem . The output directory Environment Variables \u00b6 group : The key of group in metadata to define the groups to compare. For example, CellType , which has cell types annotated for each cell in the combined object (immdata + Seurat metadata) comparison ( type=auto ) : A dict of two groups, with keys as the group names and values as the group labels. For example, Treg = [ \"CD4 CTL\" , \"CD4 Naive\" , \"CD4 TCM\" , \"CD4 TEM\" ] Tconv = \"Tconv\" Or simply a list of two groups, for example, [\"Treg\", \"Tconv\"] when they are both in the group column. target : Which group to use as the target group. The target group will be labeled as 1, and the other group will be labeled as 0 in the regression. If not specified, the first group in comparison will be used as the target group. each ( auto ) : A column, or a list of columns or a string of columns separated by comma. The columns will be used to split the data into multiple groups and the regression will be applied to each group separately. If not provided, all the cells will be used. Reference \u00b6 Stadinski, Brian D., et al. \"Hydrophobic CDR3 residues promote the development of self-reactive T cells.\" Nature immunology 17.8 (2016): 946-955. Lagattuta, Kaitlyn A., et al. \"Repertoire analyses reveal T cell antigen receptor sequence features that influence T cell fate.\" Nature immunology 23.3 (2022): 446-457. Wimley, W. C. & White, S. H. Experimentally determined hydrophobicity scale for proteins at membrane - interfaces. Nat. Struct. Biol. 3, 842-848 (1996). Handbook of chemistry & physics 72nd edition. (CRC Press, 1991). Zamyatnin, A. A. Protein volume in solution. Prog. Biophys. Mol. Biol. 24, 107-123 (1972).","title":"CDR3AAPhyschem"},{"location":"processes/CDR3AAPhyschem/#cdr3aaphyschem","text":"CDR3 AA physicochemical feature analysis The idea is to perform a regression between two groups of cells (e.g. Treg vs Tconv) at different length of CDR3 AA sequences. The regression will be performed for each physicochemical feature of the AA (hydrophobicity, volume and isolectric point).","title":"CDR3AAPhyschem"},{"location":"processes/CDR3AAPhyschem/#input","text":"scrfile : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains.","title":"Input"},{"location":"processes/CDR3AAPhyschem/#output","text":"outdir : Default: {{in.immdata | stem}}.cdr3aaphyschem . The output directory","title":"Output"},{"location":"processes/CDR3AAPhyschem/#environment-variables","text":"group : The key of group in metadata to define the groups to compare. For example, CellType , which has cell types annotated for each cell in the combined object (immdata + Seurat metadata) comparison ( type=auto ) : A dict of two groups, with keys as the group names and values as the group labels. For example, Treg = [ \"CD4 CTL\" , \"CD4 Naive\" , \"CD4 TCM\" , \"CD4 TEM\" ] Tconv = \"Tconv\" Or simply a list of two groups, for example, [\"Treg\", \"Tconv\"] when they are both in the group column. target : Which group to use as the target group. The target group will be labeled as 1, and the other group will be labeled as 0 in the regression. If not specified, the first group in comparison will be used as the target group. each ( auto ) : A column, or a list of columns or a string of columns separated by comma. The columns will be used to split the data into multiple groups and the regression will be applied to each group separately. If not provided, all the cells will be used.","title":"Environment Variables"},{"location":"processes/CDR3AAPhyschem/#reference","text":"Stadinski, Brian D., et al. \"Hydrophobic CDR3 residues promote the development of self-reactive T cells.\" Nature immunology 17.8 (2016): 946-955. Lagattuta, Kaitlyn A., et al. \"Repertoire analyses reveal T cell antigen receptor sequence features that influence T cell fate.\" Nature immunology 23.3 (2022): 446-457. Wimley, W. C. & White, S. H. Experimentally determined hydrophobicity scale for proteins at membrane - interfaces. Nat. Struct. Biol. 3, 842-848 (1996). Handbook of chemistry & physics 72nd edition. (CRC Press, 1991). Zamyatnin, A. A. Protein volume in solution. Prog. Biophys. Mol. Biol. 24, 107-123 (1972).","title":"Reference"},{"location":"processes/CDR3Clustering/","text":"CDR3Clustering \u00b6 Cluster the TCR/BCR clones by their CDR3 sequences This process is used to cluster TCR/BCR clones based on their CDR3 sequences. It uses either GIANA Zhang, Hongyi, Xiaowei Zhan, and Bo Li. \"GIANA allows computationally-efficient TCR clustering and multi-disease repertoire classification by isometric transformation.\" Nature communications 12.1 (2021): 1-11. Or ClusTCR Sebastiaan Valkiers, Max Van Houcke, Kris Laukens, Pieter Meysman, ClusTCR: a Python interface for rapid clustering of large sets of CDR3 sequences with unknown antigen specificity, Bioinformatics, 2021. Both methods are based on the Faiss Clustering Library , for efficient similarity search and clustering of dense vectors, so both methods yield similar results. A text file will be generated with the cluster assignments for each cell, together with the immunarch object (in R ) with the cluster assignments at CDR3_Clsuter column. This information will then be merged to a Seurat object for further downstream analysis. The cluster assignments are prefixed with S_ or M_ to indicate whether a cluster has only one unique CDR3 sequence or multiple CDR3 sequences. Note that a cluster with S_ prefix may still have multiple cells, as the same CDR3 sequence may be shared by multiple cells. Input \u00b6 screpfile : The TCR/BCR data object loaded by scRepertoire::CombineTCR() , scRepertoire::CombineBCR() or scRepertoire::CombineExpression() Output \u00b6 outfile : Default: {{in.screpfile | stem}}.tcr_clustered.qs . The scRepertoire object in qs with TCR/BCR cluster information. Column CDR3_Cluster will be added to the metadata. Environment Variables \u00b6 type ( choice ) : Default: auto . The type of the data. TCR : T cell receptor data BCR : B cell receptor data auto : Automatically detect the type from the data. Try to find TRB or IGH genes in the CTgene column to determine whether it is TCR or BCR data. tool ( choice ) : Default: GIANA . The tool used to do the clustering, either GIANA or ClusTCR . For GIANA, using TRBV mutations is not supported GIANA : by Li lab at UT Southwestern Medical Center ClusTCR : by Sebastiaan Valkiers, etc python : Default: python . The path of python with GIANA 's dependencies installed or with clusTCR installed. Depending on the tool you choose. within_sample ( flag ) : Default: True . Whether to cluster the TCR/BCR clones within each sample. When in.screpfile is a Seurat object, the samples are marked by the Sample column in the metadata. args ( type=json ) : Default: {} . The arguments for the clustering tool For GIANA, they will be passed to python GIAna.py See https://github.com/s175573/GIANA#usage . For ClusTCR, they will be passed to clustcr.Clustering(...) See https://svalkiers.github.io/clusTCR/docs/clustering/how-to-use.html#clustering . chain ( choice ) : Default: both . The TCR/BCR chain to use for clustering. heavy : The heavy chain, TRB for TCR, IGH for BCR. For TCR, TRB is the second sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa2 column. For BCR, IGH is the first sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa1 column. light : The light chain, TRA for TCR, IGL/IGK for BCR. For TCR, TRA is the first sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa1 column. For BCR, IGL/IGK is the second sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa2 column. TRA : Only the TRA chain for TCR (light chain). TRB : Only the TRB chain for TCR (heavy chain). IGH : Only the IGH chain for BCR (heavy chain). IGLK : Only the IGL/IGK chain for BCR (light chain). both : Both sequences from the heavy and light chains (CTaa column).","title":"CDR3Clustering"},{"location":"processes/CDR3Clustering/#cdr3clustering","text":"Cluster the TCR/BCR clones by their CDR3 sequences This process is used to cluster TCR/BCR clones based on their CDR3 sequences. It uses either GIANA Zhang, Hongyi, Xiaowei Zhan, and Bo Li. \"GIANA allows computationally-efficient TCR clustering and multi-disease repertoire classification by isometric transformation.\" Nature communications 12.1 (2021): 1-11. Or ClusTCR Sebastiaan Valkiers, Max Van Houcke, Kris Laukens, Pieter Meysman, ClusTCR: a Python interface for rapid clustering of large sets of CDR3 sequences with unknown antigen specificity, Bioinformatics, 2021. Both methods are based on the Faiss Clustering Library , for efficient similarity search and clustering of dense vectors, so both methods yield similar results. A text file will be generated with the cluster assignments for each cell, together with the immunarch object (in R ) with the cluster assignments at CDR3_Clsuter column. This information will then be merged to a Seurat object for further downstream analysis. The cluster assignments are prefixed with S_ or M_ to indicate whether a cluster has only one unique CDR3 sequence or multiple CDR3 sequences. Note that a cluster with S_ prefix may still have multiple cells, as the same CDR3 sequence may be shared by multiple cells.","title":"CDR3Clustering"},{"location":"processes/CDR3Clustering/#input","text":"screpfile : The TCR/BCR data object loaded by scRepertoire::CombineTCR() , scRepertoire::CombineBCR() or scRepertoire::CombineExpression()","title":"Input"},{"location":"processes/CDR3Clustering/#output","text":"outfile : Default: {{in.screpfile | stem}}.tcr_clustered.qs . The scRepertoire object in qs with TCR/BCR cluster information. Column CDR3_Cluster will be added to the metadata.","title":"Output"},{"location":"processes/CDR3Clustering/#environment-variables","text":"type ( choice ) : Default: auto . The type of the data. TCR : T cell receptor data BCR : B cell receptor data auto : Automatically detect the type from the data. Try to find TRB or IGH genes in the CTgene column to determine whether it is TCR or BCR data. tool ( choice ) : Default: GIANA . The tool used to do the clustering, either GIANA or ClusTCR . For GIANA, using TRBV mutations is not supported GIANA : by Li lab at UT Southwestern Medical Center ClusTCR : by Sebastiaan Valkiers, etc python : Default: python . The path of python with GIANA 's dependencies installed or with clusTCR installed. Depending on the tool you choose. within_sample ( flag ) : Default: True . Whether to cluster the TCR/BCR clones within each sample. When in.screpfile is a Seurat object, the samples are marked by the Sample column in the metadata. args ( type=json ) : Default: {} . The arguments for the clustering tool For GIANA, they will be passed to python GIAna.py See https://github.com/s175573/GIANA#usage . For ClusTCR, they will be passed to clustcr.Clustering(...) See https://svalkiers.github.io/clusTCR/docs/clustering/how-to-use.html#clustering . chain ( choice ) : Default: both . The TCR/BCR chain to use for clustering. heavy : The heavy chain, TRB for TCR, IGH for BCR. For TCR, TRB is the second sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa2 column. For BCR, IGH is the first sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa1 column. light : The light chain, TRA for TCR, IGL/IGK for BCR. For TCR, TRA is the first sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa1 column. For BCR, IGL/IGK is the second sequence in CTaa , separated by _ if input is a Seurat object; otherwise, it is extracted from the cdr3_aa2 column. TRA : Only the TRA chain for TCR (light chain). TRB : Only the TRB chain for TCR (heavy chain). IGH : Only the IGH chain for BCR (heavy chain). IGLK : Only the IGL/IGK chain for BCR (light chain). both : Both sequences from the heavy and light chains (CTaa column).","title":"Environment Variables"},{"location":"processes/CellCellCommunication/","text":"CellCellCommunication \u00b6 Cell-cell communication inference This is implemented based on LIANA , which is a Python package for cell-cell communication inference and provides a list of existing methods including CellPhoneDB , Connectome , log2FC, NATMI , SingleCellSignalR , Rank_Aggregate, Geometric Mean, scSeqComm , and CellChat . You can also try python -c 'import liana; liana.mt.show_methods()' to see the methods available. Note that this process does not do any visualization. You can use CellCellCommunicationPlots to visualize the results. Input \u00b6 sobjfile : The seurat object file in RDS or h5seurat format or AnnData file. Output \u00b6 outfile : Default: {{in.sobjfile | stem}}-ccc.txt . The output file with the 'liana_res' data frame. Stats are provided for both ligand and receptor entities, more specifically: ligand and receptor are the two entities that potentially interact. As a reminder, CCC events are not limited to secreted signalling, but we refer to them as ligand and receptor for simplicity. Also, in the case of heteromeric complexes, the ligand and receptor columns represent the subunit with minimum expression, while * complex corresponds to the actual complex, with subunits being separated by . source and target columns represent the source/sender and target/receiver cell identity for each interaction, respectively *_props : represents the proportion of cells that express the entity. By default, any interactions in which either entity is not expressed in above 10%% of cells per cell type is considered as a false positive, under the assumption that since CCC occurs between cell types, a sufficient proportion of cells within should express the genes. *_means : entity expression mean per cell type. lr_means : mean ligand-receptor expression, as a measure of ligand-receptor interaction magnitude. cellphone_pvals : permutation-based p-values, as a measure of interaction specificity. A typical output will look like this: ligand ligand_complex ligand_props ligand_trimean mat_max receptor receptor_complex receptor_props receptor_trimean source target lr_probs cellchat_pvals mag_score spec_score VIM VIM 1.00 0.36 8.73 CD44 CD44 0.77 0.16 c7 c3 0.10 0.00 0.10 0.00 MIF MIF 0.97 0.22 8.73 CXCR4 CD74_CXCR4 0.87 0.26 c5 c6 0.10 0.00 0.10 0.00 HLA-B HLA-B 1.00 0.44 8.73 KLRD1 KLRD1 0.73 0.13 c9 c2 0.10 0.00 0.10 0.00 HMGB1 HMGB1 0.99 0.26 8.73 CXCR4 CXCR4 0.81 0.21 c2 c7 0.10 0.00 0.10 0.00 CD48 CD48 0.94 0.20 8.73 CD2 CD2 0.99 0.28 c7 c8 0.10 0.00 0.10 0.00 HLA-C HLA-C 1.00 0.38 8.73 CD8B CD8B 0.73 0.15 c1 c9 0.10 0.00 0.10 0.00 LGALS1 LGALS1 0.95 0.17 8.73 CD69 CD69 0.99 0.34 c10 c5 0.10 0.00 0.10 0.00 Environment Variables \u00b6 method ( choice ) : Default: cellchat . The method to use for cell-cell communication inference. CellPhoneDB : Use CellPhoneDB method. Magnitude Score: lr_means; Specificity Score: cellphone_pvals. Connectome : Use Connectome method. log2FC : Use log2FC method. NATMI : Use NATMI method. SingleCellSignalR : Use SingleCellSignalR method. Rank_Aggregate : Use Rank_Aggregate method. Geometric_Mean : Use Geometric Mean method. scSeqComm : Use scSeqComm method. CellChat : Use CellChat method. cellphonedb : alias for CellPhoneDB connectome : alias for Connectome log2fc : alias for log2FC natmi : alias for NATMI singlesignaler : alias for SingleCellSignalR rank_aggregate : alias for Rank_Aggregate geometric_mean : alias for Geometric_Mean scseqcomm : alias for scSeqComm cellchat : alias for CellChat subset : An expression in string to subset the cells. When a .rds or .h5seurat file is provided for in.sobjfile , you can provide an expression in R , which will be passed to base::subset() in R to subset the cells. But you can always pass an expression in python to subset the cells. See https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html#subsetting-using-metadata . You should use adata to refer to the AnnData object. For example, adata.obs.groups == \"g1\" will subset the cells with groups equal to g1 . subset_using : Default: auto . The method to subset the cells. auto : Automatically detect the method to use. Note that this is not always accurate. We simply check if [ is in the expression. If so, we use python to subset the cells; otherwise, we use R . python : Use python to subset the cells. r : Use R to subset the cells. split_by : The column name in metadata to split the cells to run the method separately. The results will be combined together with this column in the final output. assay : The assay to use for the analysis. Only works for Seurat object. seed ( type=int ) : Default: 1337 . The seed for the random number generator. ncores ( type=int ) : Default: 1 . The number of cores to use. groupby : The column name in metadata to group the cells. Typically, this column should be the cluster id. If provided input is a Seurat object, the default identity will be used by default. Otherwise, it is recommended to provide this parameter. \"seurat_clusters\" will be used with a warning if the input is in AnnData format and this parameter is not provided. group_by : alias for groupby species ( choice ) : Default: human . The species of the cells. human : Human cells, the 'consensus' resource will be used. mouse : Mouse cells, the 'mouseconsensus' resource will be used. expr_prop ( type=float ) : Default: 0.1 . Minimum expression proportion for the ligands and receptors (+ their subunits) in the corresponding cell identities. Set to 0 to return unfiltered results. min_cells ( type=int ) : Default: 5 . Minimum cells (per cell identity if grouped by groupby ) to be considered for downstream analysis. n_perms ( type=int ) : Default: 1000 . Number of permutations for the permutation test. Relevant only for permutation-based methods (e.g., CellPhoneDB ). If 0 is passed, no permutation testing is performed. rscript : Default: Rscript . The path to the Rscript executable used to convert RDS file to AnnData. if in.sobjfile is an RDS file, it will be converted to AnnData file (h5ad). You need Seurat , SeuratDisk and digest installed. <more> : Other arguments for the method. The arguments are passed to the method directly. See the method documentation for more details and also help(liana.mt.<method>.__call__) in Python. Reference \u00b6 Review . LIANA .","title":"CellCellCommunication"},{"location":"processes/CellCellCommunication/#cellcellcommunication","text":"Cell-cell communication inference This is implemented based on LIANA , which is a Python package for cell-cell communication inference and provides a list of existing methods including CellPhoneDB , Connectome , log2FC, NATMI , SingleCellSignalR , Rank_Aggregate, Geometric Mean, scSeqComm , and CellChat . You can also try python -c 'import liana; liana.mt.show_methods()' to see the methods available. Note that this process does not do any visualization. You can use CellCellCommunicationPlots to visualize the results.","title":"CellCellCommunication"},{"location":"processes/CellCellCommunication/#input","text":"sobjfile : The seurat object file in RDS or h5seurat format or AnnData file.","title":"Input"},{"location":"processes/CellCellCommunication/#output","text":"outfile : Default: {{in.sobjfile | stem}}-ccc.txt . The output file with the 'liana_res' data frame. Stats are provided for both ligand and receptor entities, more specifically: ligand and receptor are the two entities that potentially interact. As a reminder, CCC events are not limited to secreted signalling, but we refer to them as ligand and receptor for simplicity. Also, in the case of heteromeric complexes, the ligand and receptor columns represent the subunit with minimum expression, while * complex corresponds to the actual complex, with subunits being separated by . source and target columns represent the source/sender and target/receiver cell identity for each interaction, respectively *_props : represents the proportion of cells that express the entity. By default, any interactions in which either entity is not expressed in above 10%% of cells per cell type is considered as a false positive, under the assumption that since CCC occurs between cell types, a sufficient proportion of cells within should express the genes. *_means : entity expression mean per cell type. lr_means : mean ligand-receptor expression, as a measure of ligand-receptor interaction magnitude. cellphone_pvals : permutation-based p-values, as a measure of interaction specificity. A typical output will look like this: ligand ligand_complex ligand_props ligand_trimean mat_max receptor receptor_complex receptor_props receptor_trimean source target lr_probs cellchat_pvals mag_score spec_score VIM VIM 1.00 0.36 8.73 CD44 CD44 0.77 0.16 c7 c3 0.10 0.00 0.10 0.00 MIF MIF 0.97 0.22 8.73 CXCR4 CD74_CXCR4 0.87 0.26 c5 c6 0.10 0.00 0.10 0.00 HLA-B HLA-B 1.00 0.44 8.73 KLRD1 KLRD1 0.73 0.13 c9 c2 0.10 0.00 0.10 0.00 HMGB1 HMGB1 0.99 0.26 8.73 CXCR4 CXCR4 0.81 0.21 c2 c7 0.10 0.00 0.10 0.00 CD48 CD48 0.94 0.20 8.73 CD2 CD2 0.99 0.28 c7 c8 0.10 0.00 0.10 0.00 HLA-C HLA-C 1.00 0.38 8.73 CD8B CD8B 0.73 0.15 c1 c9 0.10 0.00 0.10 0.00 LGALS1 LGALS1 0.95 0.17 8.73 CD69 CD69 0.99 0.34 c10 c5 0.10 0.00 0.10 0.00","title":"Output"},{"location":"processes/CellCellCommunication/#environment-variables","text":"method ( choice ) : Default: cellchat . The method to use for cell-cell communication inference. CellPhoneDB : Use CellPhoneDB method. Magnitude Score: lr_means; Specificity Score: cellphone_pvals. Connectome : Use Connectome method. log2FC : Use log2FC method. NATMI : Use NATMI method. SingleCellSignalR : Use SingleCellSignalR method. Rank_Aggregate : Use Rank_Aggregate method. Geometric_Mean : Use Geometric Mean method. scSeqComm : Use scSeqComm method. CellChat : Use CellChat method. cellphonedb : alias for CellPhoneDB connectome : alias for Connectome log2fc : alias for log2FC natmi : alias for NATMI singlesignaler : alias for SingleCellSignalR rank_aggregate : alias for Rank_Aggregate geometric_mean : alias for Geometric_Mean scseqcomm : alias for scSeqComm cellchat : alias for CellChat subset : An expression in string to subset the cells. When a .rds or .h5seurat file is provided for in.sobjfile , you can provide an expression in R , which will be passed to base::subset() in R to subset the cells. But you can always pass an expression in python to subset the cells. See https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html#subsetting-using-metadata . You should use adata to refer to the AnnData object. For example, adata.obs.groups == \"g1\" will subset the cells with groups equal to g1 . subset_using : Default: auto . The method to subset the cells. auto : Automatically detect the method to use. Note that this is not always accurate. We simply check if [ is in the expression. If so, we use python to subset the cells; otherwise, we use R . python : Use python to subset the cells. r : Use R to subset the cells. split_by : The column name in metadata to split the cells to run the method separately. The results will be combined together with this column in the final output. assay : The assay to use for the analysis. Only works for Seurat object. seed ( type=int ) : Default: 1337 . The seed for the random number generator. ncores ( type=int ) : Default: 1 . The number of cores to use. groupby : The column name in metadata to group the cells. Typically, this column should be the cluster id. If provided input is a Seurat object, the default identity will be used by default. Otherwise, it is recommended to provide this parameter. \"seurat_clusters\" will be used with a warning if the input is in AnnData format and this parameter is not provided. group_by : alias for groupby species ( choice ) : Default: human . The species of the cells. human : Human cells, the 'consensus' resource will be used. mouse : Mouse cells, the 'mouseconsensus' resource will be used. expr_prop ( type=float ) : Default: 0.1 . Minimum expression proportion for the ligands and receptors (+ their subunits) in the corresponding cell identities. Set to 0 to return unfiltered results. min_cells ( type=int ) : Default: 5 . Minimum cells (per cell identity if grouped by groupby ) to be considered for downstream analysis. n_perms ( type=int ) : Default: 1000 . Number of permutations for the permutation test. Relevant only for permutation-based methods (e.g., CellPhoneDB ). If 0 is passed, no permutation testing is performed. rscript : Default: Rscript . The path to the Rscript executable used to convert RDS file to AnnData. if in.sobjfile is an RDS file, it will be converted to AnnData file (h5ad). You need Seurat , SeuratDisk and digest installed. <more> : Other arguments for the method. The arguments are passed to the method directly. See the method documentation for more details and also help(liana.mt.<method>.__call__) in Python.","title":"Environment Variables"},{"location":"processes/CellCellCommunication/#reference","text":"Review . LIANA .","title":"Reference"},{"location":"processes/CellCellCommunicationPlots/","text":"CellCellCommunicationPlots \u00b6 Visualization for cell-cell communication inference. Input \u00b6 cccfile : The output file from CellCellCommunication Output \u00b6 outdir : Default: {{in.cccfile | stem}}_plots . The output directory for the plots. Environment Variables \u00b6 subset : An expression to pass to dplyr::filter() to subset the ccc data. magnitude : The column name in the data to use as the magnitude of the communication. By default, the second last column will be used. See li.mt.show_methods() for the available methods in LIANA. or https://liana-py.readthedocs.io/en/latest/notebooks/basic_usage.html#Tileplot specificity : The column name in the data to use as the specificity of the communication. By default, the last column will be used. If the method doesn't have a specificity, set it to None. devpars ( ns ) : The parameters for the plot. res ( type=int ) : Default: 100 . The resolution of the plot height ( type=int ) : The height of the plot width ( type=int ) : The width of the plot more_formats ( type=list ) : Default: [] . The additional formats to save the plots. descr : Default: Cell-cell communication plot . The description of the plot. cases ( type=json ) : Default: {} . The cases for the plots. The keys are the names of the cases and the values are the arguments for the plots. The arguments include the ones inherited from envs . You can have a special plot_type \"table\" to generate a table for the ccc data to save as a text file and show in the report. If no cases are given, a default case will be used, with the key Cell-Cell Communication . <more> : Other arguments passed to scplotter::CCCPlot Examples \u00b6 Network Plot \u00b6 [CellCellCommunicationPlots.envs.cases. \"Cell-Cell Communication Network\" ] plot_type = \"network\" legend-position = \"none\" theme = \"theme_blank\" theme_args = { add_coord = false } Circos Plot \u00b6 Heatmap Plot \u00b6 Cell-Cell Communication Interaction (Box Plot) \u00b6 [CellCellCommunicationPlots.envs.cases. \"Cell-Cell Communication Interaction (Box Plot)\" ] plot_type = \"box\" x_text_angle = 90 method = \"interaction\"","title":"CellCellCommunicationPlots"},{"location":"processes/CellCellCommunicationPlots/#cellcellcommunicationplots","text":"Visualization for cell-cell communication inference.","title":"CellCellCommunicationPlots"},{"location":"processes/CellCellCommunicationPlots/#input","text":"cccfile : The output file from CellCellCommunication","title":"Input"},{"location":"processes/CellCellCommunicationPlots/#output","text":"outdir : Default: {{in.cccfile | stem}}_plots . The output directory for the plots.","title":"Output"},{"location":"processes/CellCellCommunicationPlots/#environment-variables","text":"subset : An expression to pass to dplyr::filter() to subset the ccc data. magnitude : The column name in the data to use as the magnitude of the communication. By default, the second last column will be used. See li.mt.show_methods() for the available methods in LIANA. or https://liana-py.readthedocs.io/en/latest/notebooks/basic_usage.html#Tileplot specificity : The column name in the data to use as the specificity of the communication. By default, the last column will be used. If the method doesn't have a specificity, set it to None. devpars ( ns ) : The parameters for the plot. res ( type=int ) : Default: 100 . The resolution of the plot height ( type=int ) : The height of the plot width ( type=int ) : The width of the plot more_formats ( type=list ) : Default: [] . The additional formats to save the plots. descr : Default: Cell-cell communication plot . The description of the plot. cases ( type=json ) : Default: {} . The cases for the plots. The keys are the names of the cases and the values are the arguments for the plots. The arguments include the ones inherited from envs . You can have a special plot_type \"table\" to generate a table for the ccc data to save as a text file and show in the report. If no cases are given, a default case will be used, with the key Cell-Cell Communication . <more> : Other arguments passed to scplotter::CCCPlot","title":"Environment Variables"},{"location":"processes/CellCellCommunicationPlots/#examples","text":"","title":"Examples"},{"location":"processes/CellCellCommunicationPlots/#network-plot","text":"[CellCellCommunicationPlots.envs.cases. \"Cell-Cell Communication Network\" ] plot_type = \"network\" legend-position = \"none\" theme = \"theme_blank\" theme_args = { add_coord = false }","title":"Network Plot"},{"location":"processes/CellCellCommunicationPlots/#circos-plot","text":"","title":"Circos Plot"},{"location":"processes/CellCellCommunicationPlots/#heatmap-plot","text":"","title":"Heatmap Plot"},{"location":"processes/CellCellCommunicationPlots/#cell-cell-communication-interaction-box-plot","text":"[CellCellCommunicationPlots.envs.cases. \"Cell-Cell Communication Interaction (Box Plot)\" ] plot_type = \"box\" x_text_angle = 90 method = \"interaction\"","title":"Cell-Cell Communication Interaction (Box Plot)"},{"location":"processes/CellTypeAnnotation/","text":"CellTypeAnnotation \u00b6 Annotate all or selected T/B cell clusters. Annotate the cell clusters. Currently, four ways are supported: Pass the cell type annotation directly Use ScType Use scCATCH Use hitype Use celltypist The annotated cell types will replace the original identity column in the metadata, so that the downstream processes will use the annotated cell types. Note When cell types are annotated, the original identity column (e.g. seurat_clusters ) will be renamed to envs.backup_col (e.g. seurat_clusters_id ), and the new identity column will be added. If you are using ScType , scCATCH , or hitype , a text file containing the mapping from the original identity to the new cell types will be generated and saved to cluster2celltype.tsv under <workdir>/<pipline_name>/CellTypeAnnotation/0/output/ . The <workdir> is typically ./.pipen and the <pipline_name> is Immunopipe by default. Note If you have other annotation processes, including SeuratClustering process or SeuratMap2Ref process enabled in the same run, you may want to specify a different name for the column to store the annotated cell types using envs.newcol , so that the results from different annotation processes won't overwrite each other. Input \u00b6 sobjfile : The single-cell object in RDS/qs/qs2/h5ad format. Output \u00b6 outfile : Default: {{in.sobjfile | stem}}.annotated.{{- ext0(in.sobjfile) if envs.outtype == 'input' else envs.outtype -}} . The rds/qs/qs2/h5ad file of seurat object with cell type annotated. A text file containing the mapping from the old identity to the new cell types will be generated and saved to cluster2celltype.tsv under the job output directory. Note that if envs.ident is specified, the output Seurat object will have the identity set to the specified column in metadata. Environment Variables \u00b6 tool ( choice ) : Default: direct . The tool to use for cell type annotation. sctype : Use scType to annotate cell types. See https://github.com/IanevskiAleksandr/sc-type hitype : Use hitype to annotate cell types. See https://github.com/pwwang/hitype sccatch : Use scCATCH to annotate cell types. See https://github.com/ZJUFanLab/scCATCH celltypist : Use celltypist to annotate cell types. See https://github.com/Teichlab/celltypist direct : Directly assign cell types sctype_tissue : The tissue to use for sctype . Avaiable tissues should be the first column ( tissueType ) of sctype_db . If not specified, all rows in sctype_db will be used. sctype_db : The database to use for sctype. Check examples at https://github.com/IanevskiAleksandr/sc-type/blob/master/ScTypeDB_full.xlsx ident : The column name in metadata to use as the clusters. If not specified, the identity column will be used when input is rds/qs/qs2 (supposing we have a Seurat object). If input data is h5ad, this is required to run cluster-based annotation tools. For celltypist , this is a shortcut to set over_clustering in celltypist_args . backup_col : Default: seurat_clusters_id . The backup column name to store the original identities. If not specified, the original identity column will not be stored. If envs.newcol is specified, this will be ignored. hitype_tissue : The tissue to use for hitype . Avaiable tissues should be the first column ( tissueType ) of hitype_db . If not specified, all rows in hitype_db will be used. hitype_db : The database to use for hitype. Compatible with sctype_db . See also https://pwwang.github.io/hitype/articles/prepare-gene-sets.html You can also use built-in databases, including hitypedb_short , hitypedb_full , and hitypedb_pbmc3k . cell_types ( type=auto ) : Default: [] . The cell types to use for direct annotation. If given as a list (array), you can use \"-\" or \"\" as the placeholder for the clusters that you want to keep the original cell types. If the length of cell_types is shorter than the number of clusters, the remaining clusters will be kept as the original cell types. You can also use NA to remove the clusters from downstream analysis. This only works when envs.newcol is not specified. If given as a dict (map), the keys are the original cluster names and the values are the new cell types. Note If tool is direct and cell_types is not specified or an empty list, the original cell types will be kept and nothing will be changed. more_cell_types ( type=json ) : The additional cell type annotations to add to the metadata. The keys are the new column names and the values are the cell types lists. The cell type lists work the same as cell_types above. This is useful when you want to keep multiple annotations of cell types. sccatch_args ( ns ) : The arguments for scCATCH::findmarkergene() if tool is sccatch . species : The specie of cells. cancer : Default: Normal . If the sample is from cancer tissue, then the cancer type may be defined. tissue : Tissue origin of cells must be defined. marker : The marker genes for cell type identification. if_use_custom_marker ( flag ) : Default: False . Whether to use custom marker genes. If True , no species , cancer , and tissue are needed. <more> : Other arguments for scCATCH::findmarkergene() . You can pass an RDS file to sccatch_args.marker to work as custom marker. If so, if_use_custom_marker will be set to TRUE automatically. celltypist_args ( ns ) : The arguments for celltypist::celltypist() if tool is celltypist . model : The path to model file. python : Default: python . The python path where celltypist is installed. majority_voting : Default: True . When true, it refines cell identities within local subclusters after an over-clustering approach at the cost of increased runtime. over_clustering ( type=auto ) : The column name in metadata to use as clusters for majority voting. Set to False to disable over-clustering. When in.sobjfile is rds/qs/qs2 (supposing we have a Seurat object), the default ident is used by default. Otherwise, it is False by default. assay : When converting a Seurat object to AnnData, the assay to use. If input is h5seurat, this defaults to RNA. If input is Seurat object in RDS, this defaults to the default assay. merge ( flag ) : Default: False . Whether to merge the clusters with the same cell types. Otherwise, a suffix will be added to the cell types (ie. .1 , .2 , etc). newcol : The new column name to store the cell types. If not specified, the identity column will be overwritten. If specified, the original identity column will be kept and Idents will be kept as the original identity. outtype ( choice ) : Default: input . The output file type. Currently only works for celltypist . An RDS file will be generated for other tools. input : Use the same file type as the input. rds : Use RDS file. qs : Use qs2 file. qs2 : Use qs2 file. h5ad : Use AnnData file. Examples \u00b6 [CellTypeAnnotation.envs] tool = \"direct\" cell_types = [ \"CellType1\" , \"CellType2\" , \"-\" , \"CellType4\" ] The cell types will be assigned as: 0 -> CellType1 1 -> CellType2 2 -> 2 3 -> CellType4 Metadata \u00b6 When envs.tool is direct and envs.cell_types is empty, the metadata of the Seurat object will be kept as is. When envs.newcol is specified, the original identity column (e.g. seurat_clusters ) will be kept is, and the annotated cell types will be saved in the new column. Otherwise, the original identity column will be replaced by the annotated cell types and the original identity column will be saved at envs.backup_col (e.g. seurat_clusters_id ).","title":"CellTypeAnnotation"},{"location":"processes/CellTypeAnnotation/#celltypeannotation","text":"Annotate all or selected T/B cell clusters. Annotate the cell clusters. Currently, four ways are supported: Pass the cell type annotation directly Use ScType Use scCATCH Use hitype Use celltypist The annotated cell types will replace the original identity column in the metadata, so that the downstream processes will use the annotated cell types. Note When cell types are annotated, the original identity column (e.g. seurat_clusters ) will be renamed to envs.backup_col (e.g. seurat_clusters_id ), and the new identity column will be added. If you are using ScType , scCATCH , or hitype , a text file containing the mapping from the original identity to the new cell types will be generated and saved to cluster2celltype.tsv under <workdir>/<pipline_name>/CellTypeAnnotation/0/output/ . The <workdir> is typically ./.pipen and the <pipline_name> is Immunopipe by default. Note If you have other annotation processes, including SeuratClustering process or SeuratMap2Ref process enabled in the same run, you may want to specify a different name for the column to store the annotated cell types using envs.newcol , so that the results from different annotation processes won't overwrite each other.","title":"CellTypeAnnotation"},{"location":"processes/CellTypeAnnotation/#input","text":"sobjfile : The single-cell object in RDS/qs/qs2/h5ad format.","title":"Input"},{"location":"processes/CellTypeAnnotation/#output","text":"outfile : Default: {{in.sobjfile | stem}}.annotated.{{- ext0(in.sobjfile) if envs.outtype == 'input' else envs.outtype -}} . The rds/qs/qs2/h5ad file of seurat object with cell type annotated. A text file containing the mapping from the old identity to the new cell types will be generated and saved to cluster2celltype.tsv under the job output directory. Note that if envs.ident is specified, the output Seurat object will have the identity set to the specified column in metadata.","title":"Output"},{"location":"processes/CellTypeAnnotation/#environment-variables","text":"tool ( choice ) : Default: direct . The tool to use for cell type annotation. sctype : Use scType to annotate cell types. See https://github.com/IanevskiAleksandr/sc-type hitype : Use hitype to annotate cell types. See https://github.com/pwwang/hitype sccatch : Use scCATCH to annotate cell types. See https://github.com/ZJUFanLab/scCATCH celltypist : Use celltypist to annotate cell types. See https://github.com/Teichlab/celltypist direct : Directly assign cell types sctype_tissue : The tissue to use for sctype . Avaiable tissues should be the first column ( tissueType ) of sctype_db . If not specified, all rows in sctype_db will be used. sctype_db : The database to use for sctype. Check examples at https://github.com/IanevskiAleksandr/sc-type/blob/master/ScTypeDB_full.xlsx ident : The column name in metadata to use as the clusters. If not specified, the identity column will be used when input is rds/qs/qs2 (supposing we have a Seurat object). If input data is h5ad, this is required to run cluster-based annotation tools. For celltypist , this is a shortcut to set over_clustering in celltypist_args . backup_col : Default: seurat_clusters_id . The backup column name to store the original identities. If not specified, the original identity column will not be stored. If envs.newcol is specified, this will be ignored. hitype_tissue : The tissue to use for hitype . Avaiable tissues should be the first column ( tissueType ) of hitype_db . If not specified, all rows in hitype_db will be used. hitype_db : The database to use for hitype. Compatible with sctype_db . See also https://pwwang.github.io/hitype/articles/prepare-gene-sets.html You can also use built-in databases, including hitypedb_short , hitypedb_full , and hitypedb_pbmc3k . cell_types ( type=auto ) : Default: [] . The cell types to use for direct annotation. If given as a list (array), you can use \"-\" or \"\" as the placeholder for the clusters that you want to keep the original cell types. If the length of cell_types is shorter than the number of clusters, the remaining clusters will be kept as the original cell types. You can also use NA to remove the clusters from downstream analysis. This only works when envs.newcol is not specified. If given as a dict (map), the keys are the original cluster names and the values are the new cell types. Note If tool is direct and cell_types is not specified or an empty list, the original cell types will be kept and nothing will be changed. more_cell_types ( type=json ) : The additional cell type annotations to add to the metadata. The keys are the new column names and the values are the cell types lists. The cell type lists work the same as cell_types above. This is useful when you want to keep multiple annotations of cell types. sccatch_args ( ns ) : The arguments for scCATCH::findmarkergene() if tool is sccatch . species : The specie of cells. cancer : Default: Normal . If the sample is from cancer tissue, then the cancer type may be defined. tissue : Tissue origin of cells must be defined. marker : The marker genes for cell type identification. if_use_custom_marker ( flag ) : Default: False . Whether to use custom marker genes. If True , no species , cancer , and tissue are needed. <more> : Other arguments for scCATCH::findmarkergene() . You can pass an RDS file to sccatch_args.marker to work as custom marker. If so, if_use_custom_marker will be set to TRUE automatically. celltypist_args ( ns ) : The arguments for celltypist::celltypist() if tool is celltypist . model : The path to model file. python : Default: python . The python path where celltypist is installed. majority_voting : Default: True . When true, it refines cell identities within local subclusters after an over-clustering approach at the cost of increased runtime. over_clustering ( type=auto ) : The column name in metadata to use as clusters for majority voting. Set to False to disable over-clustering. When in.sobjfile is rds/qs/qs2 (supposing we have a Seurat object), the default ident is used by default. Otherwise, it is False by default. assay : When converting a Seurat object to AnnData, the assay to use. If input is h5seurat, this defaults to RNA. If input is Seurat object in RDS, this defaults to the default assay. merge ( flag ) : Default: False . Whether to merge the clusters with the same cell types. Otherwise, a suffix will be added to the cell types (ie. .1 , .2 , etc). newcol : The new column name to store the cell types. If not specified, the identity column will be overwritten. If specified, the original identity column will be kept and Idents will be kept as the original identity. outtype ( choice ) : Default: input . The output file type. Currently only works for celltypist . An RDS file will be generated for other tools. input : Use the same file type as the input. rds : Use RDS file. qs : Use qs2 file. qs2 : Use qs2 file. h5ad : Use AnnData file.","title":"Environment Variables"},{"location":"processes/CellTypeAnnotation/#examples","text":"[CellTypeAnnotation.envs] tool = \"direct\" cell_types = [ \"CellType1\" , \"CellType2\" , \"-\" , \"CellType4\" ] The cell types will be assigned as: 0 -> CellType1 1 -> CellType2 2 -> 2 3 -> CellType4","title":"Examples"},{"location":"processes/CellTypeAnnotation/#metadata","text":"When envs.tool is direct and envs.cell_types is empty, the metadata of the Seurat object will be kept as is. When envs.newcol is specified, the original identity column (e.g. seurat_clusters ) will be kept is, and the annotated cell types will be saved in the new column. Otherwise, the original identity column will be replaced by the annotated cell types and the original identity column will be saved at envs.backup_col (e.g. seurat_clusters_id ).","title":"Metadata"},{"location":"processes/ClonalStats/","text":"ClonalStats \u00b6 Visualize the clonal information. Using scplotter to visualize the clonal information. Input \u00b6 screpfile : The scRepertoire object in RDS/qs format Output \u00b6 outdir : Default: {{in.screpfile | stem}}.clonalstats . The output directory containing the plots Environment Variables \u00b6 mutaters ( type=json;order=-9 ) : Default: {} . The mutaters passed to dplyr::mutate() to add new variables. When the object loaded form in.screpfile is a list, the mutaters will be applied to each element. The keys are the names of the new variables, and the values are the expressions. When it is a Seurat object, typically an output of scRepertoire::combineExpression() , the mutaters will be applied to the meta.data . cache ( type=auto ) : Default: /tmp . Whether to cache the plots. Currently only plots for features are supported, since creating the those plots can be time consuming. If True , the plots will be cached in the job output directory, which will be not cleaned up when job is rerunning. viz_type ( choice ) : The type of visualization to generate. volume : The volume of the clones using ClonalVolumePlot abundance : The abundance of the clones using ClonalAbundancePlot length : The length of the CDR3 sequences using ClonalLengthPlot residency : The residency of the clones using ClonalResidencyPlot stat : The stats of the clones using ClonalStatPlot composition : The composition of the clones using ClonalCompositionPlot overlap : The overlap of the clones using ClonalOverlapPlot diversity : The diversity of the clones using ClonalDiversityPlot geneusage : The gene usage of the clones using ClonalGeneUsagePlot positional : The positional information of the clones using ClonalPositionalPlot kmer : The kmer information of the clones using ClonalKmerPlot rarefaction : The rarefaction curve of the clones using ClonalRarefactionPlot subset : An expression to subset the data before plotting. Similar to mutaters , it will be applied to each element by dplyr::filter() if the object loaded form in.screpfile is a list; otherwise, it will be applied to subset(sobj, subset = <expr>) if the object is a Seurat object. devpars ( ns ) : The parameters for the plotting device. width ( type=int ) : The width of the device height ( type=int ) : The height of the device res ( type=int ) : Default: 100 . The resolution of the device more_formats ( list ) : Default: [] . The extra formats to save the plots in, other than PNG. save_code ( flag ) : Default: False . Whether to save the code used to generate the plots Note that the data directly used to generate the plots will also be saved in an rda file. Be careful if the data is large as it may take a lot of disk space. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. descr : The description of the plot, used to show in the report. <more> : The arguments for the plot function See the documentation of the corresponding plot function for the details cases ( type=json ) : Default: {'Clonal Volume': Diot({'viz_type': 'volume'}), 'Clonal Abundance': Diot({'viz_type': 'abundance'}), 'CDR3 Length': Diot({'viz_type': 'length'}), 'Clonal Diversity': Diot({'viz_type': 'diversity'})} . The cases to generate the plots if we have multiple cases. The keys are the names of the cases, and the values are the arguments for the plot function. The arguments in envs will be used if not specified in cases , except for mutaters . Sections can be specified as the prefix of the case name, separated by :: . For example, if you have a case named Clonal Volume::Case1 , the plot will be put in the section Clonal Volume . By default, when there are multiple cases for the same 'viz_type', the name of the 'viz_type' will be used as the default section name (for example, when 'viz_type' is 'volume', the section name will be 'Clonal Volume'). When there is only a single case, the section name will default to 'DEFAULT', which will not be shown in the report. Examples \u00b6 Clonal Volume \u00b6 [ClonalStats.envs.cases. \"Clonal Volume\" ] viz_type = \"volume\" x_text_angle = 45 Clonal Volume by Diagnosis \u00b6 [ClonalStats.envs.cases. \"Clonal Volume by Diagnosis\" ] viz_type = \"volume\" x = \"seurat_clusters\" group_by = \"Diagnosis\" comparisons = true Clonal Abundance \u00b6 [ClonalStats.envs.cases. \"Clonal Abundance\" ] viz_type = \"abundance\" Clonal Abundance Density \u00b6 [ClonalStats.envs.cases. \"Clonal Abundance Density\" ] viz_type = \"abundance\" plot_type = \"density\" CDR3 Length \u00b6 [ClonalStats.envs.cases. \"CDR3 Length\" ] viz_type = \"length\" CDR3 Length (Beta Chain) \u00b6 [ClonalStats.envs.cases. \"CDR3 Length (Beta Chain)\" ] viz_type = \"length\" chain = \"TRB\" Clonal Residency \u00b6 [ClonalStats.envs.cases. \"Clonal Residency\" ] viz_type = \"residency\" group_by = \"Diagnosis\" chain = \"TRB\" clone_call = \"gene\" groups = [ \"Colitis\" , \"NoColitis\" ] Clonal Residency (UpSet Plot) \u00b6 [ClonalStats.envs.cases. \"Clonal Residency (UpSet Plot)\" ] viz_type = \"residency\" plot_type = \"upset\" group_by = \"Diagnosis\" chain = \"TRB\" clone_call = \"gene\" groups = [ \"Colitis\" , \"NoColitis\" ] devpars = { width = 800 } Clonal Statistics with Expanded Clones \u00b6 [ClonalStats.envs.cases. \"Clonal Statistics with Expanded Clones\" ] viz_type = \"stat\" plot_type = \"pies\" group_by = \"Diagnosis\" groups = [ \"Colitis\" , \"NoColitis\" ] clones = { \"Expanded Clones In Colitis\" = \"sel(Colitis > 2)\" , \"Expanded Clones In NoColitis\" = \"sel(NoColitis > 2)\" } subgroup_by = \"seurat_clusters\" pie_size = \"sqrt\" show_row_names = true show_column_names = true devpars = { width = 720 } Hyperexpanded Clonal Dynamics \u00b6 [ClonalStats.envs.cases. \"Hyperexpanded Clonal Dynamics\" ] viz_type = \"stat\" plot_type = \"sankey\" group_by = \"Diagnosis\" chain = \"TRB\" groups = [ \"Colitis\" , \"NoColitis\" ] clones = { \"Hyper-Expanded Clones In Colitis\" = \"sel(Colitis > 5)\" , \"Hyper-Expanded Clones In NoColitis\" = \"sel(NoColitis > 5)\" } devpars = { width = 800 } Clonal Composition \u00b6 [ClonalStats.envs.cases. \"Clonal Composition\" ] viz_type = \"composition\" x_text_angle = 45 Clonal Overlapping \u00b6 viz_type = \"overlap\" chain = \"TRB\" clone_call = \"gene\" Clonal Diversity \u00b6 [ClonalStats.envs.cases. \"Clonal Diversity\" ] # method = \"shannon\" # default viz_type = \"diversity\" x_text_angle = 45 Clonal Diversity (gini.coeff, by Diagnosis) \u00b6 [ClonalStats.envs.cases. \"Clonal Diversity (gini.coeff, by Diagnosis)\" ] method = \"gini.coeff\" viz_type = \"diversity\" plot_type = \"box\" group_by = \"Diagnosis\" comparisons = true devpars = { height = 600 , width = 600 } Gene Usage Frequency \u00b6 [ClonalStats.envs.cases. \"Gene Usage Frequency\" ] viz_type = \"geneusage\" devpars = { width = 1200 } Positional amino acid frequency \u00b6 [ClonalStats.envs.cases. \"Positional amino acid frequency\" ] viz_type = \"positional\" # method = \"AA\" # default devpars = { width = 1600 } Positional shannon entropy \u00b6 [ClonalStats.envs.cases. \"Positional shannon entropy\" ] viz_type = \"positional\" method = \"shannon\" devpars = { width = 1200 } 3-Mer Frequency \u00b6 [ClonalStats.envs.cases. \"3-Mer Frequency\" ] viz_type = \"kmer\" k = 3 # default is 3 devpars = { width = 800 } Rarefaction Curve \u00b6 [ClonalStats.envs.cases. \"Rarefaction Curve\" ] viz_type = \"rarefaction\"","title":"ClonalStats"},{"location":"processes/ClonalStats/#clonalstats","text":"Visualize the clonal information. Using scplotter to visualize the clonal information.","title":"ClonalStats"},{"location":"processes/ClonalStats/#input","text":"screpfile : The scRepertoire object in RDS/qs format","title":"Input"},{"location":"processes/ClonalStats/#output","text":"outdir : Default: {{in.screpfile | stem}}.clonalstats . The output directory containing the plots","title":"Output"},{"location":"processes/ClonalStats/#environment-variables","text":"mutaters ( type=json;order=-9 ) : Default: {} . The mutaters passed to dplyr::mutate() to add new variables. When the object loaded form in.screpfile is a list, the mutaters will be applied to each element. The keys are the names of the new variables, and the values are the expressions. When it is a Seurat object, typically an output of scRepertoire::combineExpression() , the mutaters will be applied to the meta.data . cache ( type=auto ) : Default: /tmp . Whether to cache the plots. Currently only plots for features are supported, since creating the those plots can be time consuming. If True , the plots will be cached in the job output directory, which will be not cleaned up when job is rerunning. viz_type ( choice ) : The type of visualization to generate. volume : The volume of the clones using ClonalVolumePlot abundance : The abundance of the clones using ClonalAbundancePlot length : The length of the CDR3 sequences using ClonalLengthPlot residency : The residency of the clones using ClonalResidencyPlot stat : The stats of the clones using ClonalStatPlot composition : The composition of the clones using ClonalCompositionPlot overlap : The overlap of the clones using ClonalOverlapPlot diversity : The diversity of the clones using ClonalDiversityPlot geneusage : The gene usage of the clones using ClonalGeneUsagePlot positional : The positional information of the clones using ClonalPositionalPlot kmer : The kmer information of the clones using ClonalKmerPlot rarefaction : The rarefaction curve of the clones using ClonalRarefactionPlot subset : An expression to subset the data before plotting. Similar to mutaters , it will be applied to each element by dplyr::filter() if the object loaded form in.screpfile is a list; otherwise, it will be applied to subset(sobj, subset = <expr>) if the object is a Seurat object. devpars ( ns ) : The parameters for the plotting device. width ( type=int ) : The width of the device height ( type=int ) : The height of the device res ( type=int ) : Default: 100 . The resolution of the device more_formats ( list ) : Default: [] . The extra formats to save the plots in, other than PNG. save_code ( flag ) : Default: False . Whether to save the code used to generate the plots Note that the data directly used to generate the plots will also be saved in an rda file. Be careful if the data is large as it may take a lot of disk space. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. descr : The description of the plot, used to show in the report. <more> : The arguments for the plot function See the documentation of the corresponding plot function for the details cases ( type=json ) : Default: {'Clonal Volume': Diot({'viz_type': 'volume'}), 'Clonal Abundance': Diot({'viz_type': 'abundance'}), 'CDR3 Length': Diot({'viz_type': 'length'}), 'Clonal Diversity': Diot({'viz_type': 'diversity'})} . The cases to generate the plots if we have multiple cases. The keys are the names of the cases, and the values are the arguments for the plot function. The arguments in envs will be used if not specified in cases , except for mutaters . Sections can be specified as the prefix of the case name, separated by :: . For example, if you have a case named Clonal Volume::Case1 , the plot will be put in the section Clonal Volume . By default, when there are multiple cases for the same 'viz_type', the name of the 'viz_type' will be used as the default section name (for example, when 'viz_type' is 'volume', the section name will be 'Clonal Volume'). When there is only a single case, the section name will default to 'DEFAULT', which will not be shown in the report.","title":"Environment Variables"},{"location":"processes/ClonalStats/#examples","text":"","title":"Examples"},{"location":"processes/ClonalStats/#clonal-volume","text":"[ClonalStats.envs.cases. \"Clonal Volume\" ] viz_type = \"volume\" x_text_angle = 45","title":"Clonal Volume"},{"location":"processes/ClonalStats/#clonal-volume-by-diagnosis","text":"[ClonalStats.envs.cases. \"Clonal Volume by Diagnosis\" ] viz_type = \"volume\" x = \"seurat_clusters\" group_by = \"Diagnosis\" comparisons = true","title":"Clonal Volume by Diagnosis"},{"location":"processes/ClonalStats/#clonal-abundance","text":"[ClonalStats.envs.cases. \"Clonal Abundance\" ] viz_type = \"abundance\"","title":"Clonal Abundance"},{"location":"processes/ClonalStats/#clonal-abundance-density","text":"[ClonalStats.envs.cases. \"Clonal Abundance Density\" ] viz_type = \"abundance\" plot_type = \"density\"","title":"Clonal Abundance Density"},{"location":"processes/ClonalStats/#cdr3-length","text":"[ClonalStats.envs.cases. \"CDR3 Length\" ] viz_type = \"length\"","title":"CDR3 Length"},{"location":"processes/ClonalStats/#cdr3-length-beta-chain","text":"[ClonalStats.envs.cases. \"CDR3 Length (Beta Chain)\" ] viz_type = \"length\" chain = \"TRB\"","title":"CDR3 Length (Beta Chain)"},{"location":"processes/ClonalStats/#clonal-residency","text":"[ClonalStats.envs.cases. \"Clonal Residency\" ] viz_type = \"residency\" group_by = \"Diagnosis\" chain = \"TRB\" clone_call = \"gene\" groups = [ \"Colitis\" , \"NoColitis\" ]","title":"Clonal Residency"},{"location":"processes/ClonalStats/#clonal-residency-upset-plot","text":"[ClonalStats.envs.cases. \"Clonal Residency (UpSet Plot)\" ] viz_type = \"residency\" plot_type = \"upset\" group_by = \"Diagnosis\" chain = \"TRB\" clone_call = \"gene\" groups = [ \"Colitis\" , \"NoColitis\" ] devpars = { width = 800 }","title":"Clonal Residency (UpSet Plot)"},{"location":"processes/ClonalStats/#clonal-statistics-with-expanded-clones","text":"[ClonalStats.envs.cases. \"Clonal Statistics with Expanded Clones\" ] viz_type = \"stat\" plot_type = \"pies\" group_by = \"Diagnosis\" groups = [ \"Colitis\" , \"NoColitis\" ] clones = { \"Expanded Clones In Colitis\" = \"sel(Colitis > 2)\" , \"Expanded Clones In NoColitis\" = \"sel(NoColitis > 2)\" } subgroup_by = \"seurat_clusters\" pie_size = \"sqrt\" show_row_names = true show_column_names = true devpars = { width = 720 }","title":"Clonal Statistics with Expanded Clones"},{"location":"processes/ClonalStats/#hyperexpanded-clonal-dynamics","text":"[ClonalStats.envs.cases. \"Hyperexpanded Clonal Dynamics\" ] viz_type = \"stat\" plot_type = \"sankey\" group_by = \"Diagnosis\" chain = \"TRB\" groups = [ \"Colitis\" , \"NoColitis\" ] clones = { \"Hyper-Expanded Clones In Colitis\" = \"sel(Colitis > 5)\" , \"Hyper-Expanded Clones In NoColitis\" = \"sel(NoColitis > 5)\" } devpars = { width = 800 }","title":"Hyperexpanded Clonal Dynamics"},{"location":"processes/ClonalStats/#clonal-composition","text":"[ClonalStats.envs.cases. \"Clonal Composition\" ] viz_type = \"composition\" x_text_angle = 45","title":"Clonal Composition"},{"location":"processes/ClonalStats/#clonal-overlapping","text":"viz_type = \"overlap\" chain = \"TRB\" clone_call = \"gene\"","title":"Clonal Overlapping"},{"location":"processes/ClonalStats/#clonal-diversity","text":"[ClonalStats.envs.cases. \"Clonal Diversity\" ] # method = \"shannon\" # default viz_type = \"diversity\" x_text_angle = 45","title":"Clonal Diversity"},{"location":"processes/ClonalStats/#clonal-diversity-ginicoeff-by-diagnosis","text":"[ClonalStats.envs.cases. \"Clonal Diversity (gini.coeff, by Diagnosis)\" ] method = \"gini.coeff\" viz_type = \"diversity\" plot_type = \"box\" group_by = \"Diagnosis\" comparisons = true devpars = { height = 600 , width = 600 }","title":"Clonal Diversity (gini.coeff, by Diagnosis)"},{"location":"processes/ClonalStats/#gene-usage-frequency","text":"[ClonalStats.envs.cases. \"Gene Usage Frequency\" ] viz_type = \"geneusage\" devpars = { width = 1200 }","title":"Gene Usage Frequency"},{"location":"processes/ClonalStats/#positional-amino-acid-frequency","text":"[ClonalStats.envs.cases. \"Positional amino acid frequency\" ] viz_type = \"positional\" # method = \"AA\" # default devpars = { width = 1600 }","title":"Positional amino acid frequency"},{"location":"processes/ClonalStats/#positional-shannon-entropy","text":"[ClonalStats.envs.cases. \"Positional shannon entropy\" ] viz_type = \"positional\" method = \"shannon\" devpars = { width = 1200 }","title":"Positional shannon entropy"},{"location":"processes/ClonalStats/#3-mer-frequency","text":"[ClonalStats.envs.cases. \"3-Mer Frequency\" ] viz_type = \"kmer\" k = 3 # default is 3 devpars = { width = 800 }","title":"3-Mer Frequency"},{"location":"processes/ClonalStats/#rarefaction-curve","text":"[ClonalStats.envs.cases. \"Rarefaction Curve\" ] viz_type = \"rarefaction\"","title":"Rarefaction Curve"},{"location":"processes/ClusterMarkers/","text":"ClusterMarkers \u00b6 Markers for clusters of all or selected T/B cells. This process is extended from MarkersFinder from the biopipen package. MarkersFinder is a pipen process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found. The enrichment analysis is done by enrichr . Note Since this process is extended from MarkersFinder , other environment variables from MarkersFinder are also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for marker finding (See MarkersFinder for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform . Output \u00b6 outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified. SeeAlso \u00b6 MarkersFinder ClusterMarkersOfAllCells biopipen.ns.scrna.MarkersFinder Examples \u00b6 Visualize Log2 Fold Change of Markers \u00b6 [ClusterMarkers.envs.marker_plots. \"Volcano Plot (log2FC)\" ] plot_type = \"volcano_log2fc\" Visualize differential percentage of expression of Markers \u00b6 [ClusterMarkers.envs.marker_plots. \"Volcano Plot (pct_diff)\" ] plot_type = \"volcano_pct\" Visualize Average Expression of Markers with Dot Plot \u00b6 [ClusterMarkers.envs.marker_plots. \"Dot Plot (AvgExp)\" ] plot_type = \"dotplot\" order_by = \"desc(avg_log2FC)\" Visualize Average Expression of Markers with Heatmap \u00b6 [ClusterMarkers.envs.marker_plots. \"Heatmap (AvgExp)\" ] plot_type = \"heatmap\" order_by = \"desc(avg_log2FC)\" Visualize Expression of Markers with Violin Plots \u00b6 [ClusterMarkers.envs.marker_plots. \"Violin Plots\" ] plot_type = \"violin\" Visualize enrichment analysis results with Bar/EnrichMap/Network/WordCloud Plots \u00b6 # Visualize enrichment of markers [ClusterMarkers.envs.enrich_plots. \"Bar Plot\" ] # Default plot_type = \"bar\" [ClusterMarkers.envs.enrich_plots. \"Network\" ] plot_type = \"network\" [ClusterMarkers.envs.enrich_plots. \"Enrichmap\" ] plot_type = \"enrichmap\" [ClusterMarkers.envs.enrich_plots. \"Word Cloud\" ] plot_type = \"wordcloud\" Visualize top markers of all clusters with Heatmap \u00b6 [ClusterMarkers.envs.allmarker_plots. \"Top 10 markers of all clusters\" ] plot_type = \"heatmap\" Visualize Log2 Fold Change of all markers \u00b6 [ClusterMarkers.envs.allmarker_plots. \"Log2 Fold Change of all markers\" ] plot_type = \"heatmap_log2fc\" subset_by = \"seurat_clusters\" Visualize all markers in all clusters with Jitter Plots \u00b6 [ClusterMarkers.envs.allmarker_plots. \"Jitter Plots of all markers\" ] plot_type = \"jitter\" subset_by = \"seurat_clusters\" Visualize all enrichment analysis results of all clusters \u00b6 [ClusterMarkers.envs.allenrich_plots. \"Heatmap of enriched terms of all clusters\" ] plot_type = \"heatmap\" Overlapping markers \u00b6 [ClusterMarkers.envs.overlaps. \"Overlapping Markers\" ] plot_type = \"venn\"","title":"ClusterMarkers"},{"location":"processes/ClusterMarkers/#clustermarkers","text":"Markers for clusters of all or selected T/B cells. This process is extended from MarkersFinder from the biopipen package. MarkersFinder is a pipen process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found. The enrichment analysis is done by enrichr . Note Since this process is extended from MarkersFinder , other environment variables from MarkersFinder are also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for marker finding (See MarkersFinder for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly.","title":"ClusterMarkers"},{"location":"processes/ClusterMarkers/#input","text":"srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform .","title":"Input"},{"location":"processes/ClusterMarkers/#output","text":"outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots","title":"Output"},{"location":"processes/ClusterMarkers/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified.","title":"Environment Variables"},{"location":"processes/ClusterMarkers/#seealso","text":"MarkersFinder ClusterMarkersOfAllCells biopipen.ns.scrna.MarkersFinder","title":"SeeAlso"},{"location":"processes/ClusterMarkers/#examples","text":"","title":"Examples"},{"location":"processes/ClusterMarkers/#visualize-log2-fold-change-of-markers","text":"[ClusterMarkers.envs.marker_plots. \"Volcano Plot (log2FC)\" ] plot_type = \"volcano_log2fc\"","title":"Visualize Log2 Fold Change of Markers"},{"location":"processes/ClusterMarkers/#visualize-differential-percentage-of-expression-of-markers","text":"[ClusterMarkers.envs.marker_plots. \"Volcano Plot (pct_diff)\" ] plot_type = \"volcano_pct\"","title":"Visualize differential percentage of expression of Markers"},{"location":"processes/ClusterMarkers/#visualize-average-expression-of-markers-with-dot-plot","text":"[ClusterMarkers.envs.marker_plots. \"Dot Plot (AvgExp)\" ] plot_type = \"dotplot\" order_by = \"desc(avg_log2FC)\"","title":"Visualize Average Expression of Markers with Dot Plot"},{"location":"processes/ClusterMarkers/#visualize-average-expression-of-markers-with-heatmap","text":"[ClusterMarkers.envs.marker_plots. \"Heatmap (AvgExp)\" ] plot_type = \"heatmap\" order_by = \"desc(avg_log2FC)\"","title":"Visualize Average Expression of Markers with Heatmap"},{"location":"processes/ClusterMarkers/#visualize-expression-of-markers-with-violin-plots","text":"[ClusterMarkers.envs.marker_plots. \"Violin Plots\" ] plot_type = \"violin\"","title":"Visualize Expression of Markers with Violin Plots"},{"location":"processes/ClusterMarkers/#visualize-enrichment-analysis-results-with-barenrichmapnetworkwordcloud-plots","text":"# Visualize enrichment of markers [ClusterMarkers.envs.enrich_plots. \"Bar Plot\" ] # Default plot_type = \"bar\" [ClusterMarkers.envs.enrich_plots. \"Network\" ] plot_type = \"network\" [ClusterMarkers.envs.enrich_plots. \"Enrichmap\" ] plot_type = \"enrichmap\" [ClusterMarkers.envs.enrich_plots. \"Word Cloud\" ] plot_type = \"wordcloud\"","title":"Visualize enrichment analysis results with Bar/EnrichMap/Network/WordCloud Plots"},{"location":"processes/ClusterMarkers/#visualize-top-markers-of-all-clusters-with-heatmap","text":"[ClusterMarkers.envs.allmarker_plots. \"Top 10 markers of all clusters\" ] plot_type = \"heatmap\"","title":"Visualize top markers of all clusters with Heatmap"},{"location":"processes/ClusterMarkers/#visualize-log2-fold-change-of-all-markers","text":"[ClusterMarkers.envs.allmarker_plots. \"Log2 Fold Change of all markers\" ] plot_type = \"heatmap_log2fc\" subset_by = \"seurat_clusters\"","title":"Visualize Log2 Fold Change of all markers"},{"location":"processes/ClusterMarkers/#visualize-all-markers-in-all-clusters-with-jitter-plots","text":"[ClusterMarkers.envs.allmarker_plots. \"Jitter Plots of all markers\" ] plot_type = \"jitter\" subset_by = \"seurat_clusters\"","title":"Visualize all markers in all clusters with Jitter Plots"},{"location":"processes/ClusterMarkers/#visualize-all-enrichment-analysis-results-of-all-clusters","text":"[ClusterMarkers.envs.allenrich_plots. \"Heatmap of enriched terms of all clusters\" ] plot_type = \"heatmap\"","title":"Visualize all enrichment analysis results of all clusters"},{"location":"processes/ClusterMarkers/#overlapping-markers","text":"[ClusterMarkers.envs.overlaps. \"Overlapping Markers\" ] plot_type = \"venn\"","title":"Overlapping markers"},{"location":"processes/ClusterMarkersOfAllCells/","text":"ClusterMarkersOfAllCells \u00b6 Markers for clusters of all cells. When only group_by is specified as identity column in envs.cases , the markers will be found for all the clusters. You can also find the differentially expressed genes between any two groups of cells by setting group_by to a different column name in metadata. Follow envs.cases for more details. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform . Output \u00b6 outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html group_by : The column name in metadata to group the cells. If only group_by is specified, and ident_1 and ident_2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified. SeeAlso \u00b6 ClusterMarkers MarkersFinder biopipen.ns.scrna.MarkersFinder","title":"ClusterMarkersOfAllCells"},{"location":"processes/ClusterMarkersOfAllCells/#clustermarkersofallcells","text":"Markers for clusters of all cells. When only group_by is specified as identity column in envs.cases , the markers will be found for all the clusters. You can also find the differentially expressed genes between any two groups of cells by setting group_by to a different column name in metadata. Follow envs.cases for more details.","title":"ClusterMarkersOfAllCells"},{"location":"processes/ClusterMarkersOfAllCells/#input","text":"srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform .","title":"Input"},{"location":"processes/ClusterMarkersOfAllCells/#output","text":"outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots","title":"Output"},{"location":"processes/ClusterMarkersOfAllCells/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html group_by : The column name in metadata to group the cells. If only group_by is specified, and ident_1 and ident_2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 & avg_log2FC > 0 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {'Top 10 markers of all clusters': Diot({'plot_type': 'heatmap'})} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified.","title":"Environment Variables"},{"location":"processes/ClusterMarkersOfAllCells/#seealso","text":"ClusterMarkers MarkersFinder biopipen.ns.scrna.MarkersFinder","title":"SeeAlso"},{"location":"processes/LoadingRNAFromSeurat/","text":"LoadingRNAFromSeurat \u00b6 Load RNA data from a Seurat object, instead of RNAData from SampleInfo Input \u00b6 infile : An RDS or qs/qs2 format file containing a Seurat object. Output \u00b6 outfile : Default: {{in.infile | basename}} . Environment Variables \u00b6 prepared ( flag ) : Default: False . Whether the Seurat object is well-prepared for the pipeline (so that SeuratPreparing process is not needed). clustered ( flag ) : Default: False . Whether the Seurat object is clustered, so that SeuratClustering ( SeuratClusteringOfAllCells ) process or SeuratMap2Ref is not needed. Force prepared to be True if this is True . sample : Default: Sample . The column name in the metadata of the Seurat object that indicates the sample name. SeeAlso \u00b6 Preparing the input . Routes of the pipeline .","title":"LoadingRNAFromSeurat"},{"location":"processes/LoadingRNAFromSeurat/#loadingrnafromseurat","text":"Load RNA data from a Seurat object, instead of RNAData from SampleInfo","title":"LoadingRNAFromSeurat"},{"location":"processes/LoadingRNAFromSeurat/#input","text":"infile : An RDS or qs/qs2 format file containing a Seurat object.","title":"Input"},{"location":"processes/LoadingRNAFromSeurat/#output","text":"outfile : Default: {{in.infile | basename}} .","title":"Output"},{"location":"processes/LoadingRNAFromSeurat/#environment-variables","text":"prepared ( flag ) : Default: False . Whether the Seurat object is well-prepared for the pipeline (so that SeuratPreparing process is not needed). clustered ( flag ) : Default: False . Whether the Seurat object is clustered, so that SeuratClustering ( SeuratClusteringOfAllCells ) process or SeuratMap2Ref is not needed. Force prepared to be True if this is True . sample : Default: Sample . The column name in the metadata of the Seurat object that indicates the sample name.","title":"Environment Variables"},{"location":"processes/LoadingRNAFromSeurat/#seealso","text":"Preparing the input . Routes of the pipeline .","title":"SeeAlso"},{"location":"processes/MarkersFinder/","text":"MarkersFinder \u00b6 Find markers between different groups of cells MarkersFinder is a process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform . Output \u00b6 outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html .. See also mutating the metadata . group_by : The column name in metadata to group the cells. If only group_by is specified, and ident_1 and ident_2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. ident_1 : The first group of cells to compare When this is empty, the comparisons will be expanded to each group v.s. the rest of the cells in group_by . ident_2 : The second group of cells to compare If not provided, the rest of the cells are used for ident_2 . each : The column name in metadata to separate the cells into different cases. When this is specified, the case will be expanded for each value of the column in metadata. For example, when you have envs.cases.\"Cluster Markers\".each = \"Sample\" , then the case will be expanded as envs.cases.\"Cluster Markers - Sample1\" , envs.cases.\"Cluster Markers - Sample2\" , etc. You can specify allmarker_plots and overlaps to plot the markers for all cases in the same plot and plot the overlaps of the markers between different cases by values in this column. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified. cases ( type=json ) : Default: {} . If you have multiple cases for marker discovery, you can specify them here. The keys are the names of the cases and the values are the above options. If some options are not specified, the default values specified above (under envs ) will be used. If no cases are specified, the default case will be added with the default values under envs with the name Marker Discovery . SeeAlso \u00b6 biopipen.ns.scrna.MarkersFinder ClusterMarkers Examples \u00b6 The examples are for more general use of MarkersFinder , in order to demonstrate how the final cases are constructed. Suppose we have a metadata like this: id seurat_clusters Group 1 1 A 2 1 A 3 2 A 4 2 A 5 3 B 6 3 B 7 4 B 8 4 B Default \u00b6 By default, group_by is seurat_clusters , and ident_1 and ident_2 are not specified. So markers will be found for all clusters in the manner of \"cluster vs rest\" comparison. Cluster 1 (vs 2, 3, 4) 2 (vs 1, 3, 4) 3 (vs 1, 2, 4) 4 (vs 1, 2, 3) Each case will have the markers and the enrichment analysis for the markers as the results. With each group \u00b6 each is used to separate the cells into different cases. group_by is still seurat_clusters . [ < Proc > .envs] group_by = \"seurat_clusters\" each = \"Group\" A:Cluster 1 (vs 2) 2 (vs 1) B:Cluster 3 (vs 4) 4 (vs 3) With ident_1 only \u00b6 ident_1 is used to specify the first group of cells to compare. Then the rest of the cells in the case are used for ident_2 . [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" Cluster 1 (vs 2, 3, 4) With both ident_1 and ident_2 \u00b6 ident_1 and ident_2 are used to specify the two groups of cells to compare. [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" ident_2 = \"2\" Cluster 1 (vs 2) Multiple cases \u00b6 [ < Proc > .envs.cases] c1_vs_c2 = { ident_1 = \"1\" , ident_2 = \"2\" } c3_vs_c4 = { ident_1 = \"3\" , ident_2 = \"4\" } DEFAULT:c1_vs_c2 1 (vs 2) DEFAULT:c3_vs_c4 3 (vs 4) The DEFAULT section name will be ignored in the report. You can specify a section name other than DEFAULT for each case to group them in the report.","title":"MarkersFinder"},{"location":"processes/MarkersFinder/#markersfinder","text":"Find markers between different groups of cells MarkersFinder is a process that wraps the Seurat::FindMarkers() function, and performs enrichment analysis for the markers found.","title":"MarkersFinder"},{"location":"processes/MarkersFinder/#input","text":"srtobj : The seurat object loaded by SeuratPreparing If you have your Seurat object prepared by yourself, you can also use it here, but you should make sure that the object has been processed by PrepSCTFindMarkers if data is not normalized using SCTransform .","title":"Input"},{"location":"processes/MarkersFinder/#output","text":"outdir : Default: {{in.srtobj | stem0}}.markers . The output directory for the markers and plots","title":"Output"},{"location":"processes/MarkersFinder/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallel computing for some Seurat procedures. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html .. See also mutating the metadata . group_by : The column name in metadata to group the cells. If only group_by is specified, and ident_1 and ident_2 are not specified, markers will be found for all groups in this column in the manner of \"group vs rest\" comparison. NA group will be ignored. If None , Seurat::Idents(srtobj) will be used, which is usually \"seurat_clusters\" after unsupervised clustering. ident_1 : The first group of cells to compare When this is empty, the comparisons will be expanded to each group v.s. the rest of the cells in group_by . ident_2 : The second group of cells to compare If not provided, the rest of the cells are used for ident_2 . each : The column name in metadata to separate the cells into different cases. When this is specified, the case will be expanded for each value of the column in metadata. For example, when you have envs.cases.\"Cluster Markers\".each = \"Sample\" , then the case will be expanded as envs.cases.\"Cluster Markers - Sample1\" , envs.cases.\"Cluster Markers - Sample2\" , etc. You can specify allmarker_plots and overlaps to plot the markers for all cases in the same plot and plot the overlaps of the markers between different cases by values in this column. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. Available variables are p_val , avg_log2FC , pct.1 , pct.2 and p_val_adj . For example, \"p_val_adj < 0.05 & abs(avg_log2FC) > 1\" to select markers with adjusted p-value < 0.05 and absolute log2 fold change > 1. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler assay : The assay to use. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. subset : An expression to subset the cells for each case. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. rest ( ns ) : Rest arguments for Seurat::FindMarkers() . Use - to replace . in the argument name. For example, use min-pct instead of min.pct . <more> : See https://satijalab.org/seurat/reference/findmarkers allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/biopipen.utils.R/reference/VizDEGs.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : Other arguments passed to biopipen.utils::VizDEGs() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot (diff_pct)': Diot({'plot_type': 'volcano_pct'}), 'Volcano Plot (log2FC)': Diot({'plot_type': 'volcano_log2fc'}), 'Dot Plot': Diot({'plot_type': 'dot'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified. cases ( type=json ) : Default: {} . If you have multiple cases for marker discovery, you can specify them here. The keys are the names of the cases and the values are the above options. If some options are not specified, the default values specified above (under envs ) will be used. If no cases are specified, the default case will be added with the default values under envs with the name Marker Discovery .","title":"Environment Variables"},{"location":"processes/MarkersFinder/#seealso","text":"biopipen.ns.scrna.MarkersFinder ClusterMarkers","title":"SeeAlso"},{"location":"processes/MarkersFinder/#examples","text":"The examples are for more general use of MarkersFinder , in order to demonstrate how the final cases are constructed. Suppose we have a metadata like this: id seurat_clusters Group 1 1 A 2 1 A 3 2 A 4 2 A 5 3 B 6 3 B 7 4 B 8 4 B","title":"Examples"},{"location":"processes/MarkersFinder/#default","text":"By default, group_by is seurat_clusters , and ident_1 and ident_2 are not specified. So markers will be found for all clusters in the manner of \"cluster vs rest\" comparison. Cluster 1 (vs 2, 3, 4) 2 (vs 1, 3, 4) 3 (vs 1, 2, 4) 4 (vs 1, 2, 3) Each case will have the markers and the enrichment analysis for the markers as the results.","title":"Default"},{"location":"processes/MarkersFinder/#with-each-group","text":"each is used to separate the cells into different cases. group_by is still seurat_clusters . [ < Proc > .envs] group_by = \"seurat_clusters\" each = \"Group\" A:Cluster 1 (vs 2) 2 (vs 1) B:Cluster 3 (vs 4) 4 (vs 3)","title":"With each group"},{"location":"processes/MarkersFinder/#with-ident_1-only","text":"ident_1 is used to specify the first group of cells to compare. Then the rest of the cells in the case are used for ident_2 . [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" Cluster 1 (vs 2, 3, 4)","title":"With ident_1 only"},{"location":"processes/MarkersFinder/#with-both-ident_1-and-ident_2","text":"ident_1 and ident_2 are used to specify the two groups of cells to compare. [ < Proc > .envs] group_by = \"seurat_clusters\" ident_1 = \"1\" ident_2 = \"2\" Cluster 1 (vs 2)","title":"With both ident_1 and ident_2"},{"location":"processes/MarkersFinder/#multiple-cases","text":"[ < Proc > .envs.cases] c1_vs_c2 = { ident_1 = \"1\" , ident_2 = \"2\" } c3_vs_c4 = { ident_1 = \"3\" , ident_2 = \"4\" } DEFAULT:c1_vs_c2 1 (vs 2) DEFAULT:c3_vs_c4 3 (vs 4) The DEFAULT section name will be ignored in the report. You can specify a section name other than DEFAULT for each case to group them in the report.","title":"Multiple cases"},{"location":"processes/MetabolicExprImputation/","text":"MetabolicExprImputation \u00b6 This process imputes the dropout values in scRNA-seq data. It takes the Seurat object as input and outputs the Seurat object with imputed expression data. You can turn off the imputation by setting the noimpute option of the process group to True . Input \u00b6 infile : The input file in RDS/qs format of Seurat object Output \u00b6 outfile : Default: {{in.infile | stem}}.imputed.qs . The output file in RDS format of Seurat object Note that with rmagic and alra, the original default assay will be renamed to RAW and the imputed RNA assay will be renamed to RNA and set as default assay. Environment Variables \u00b6 tool ( choice ) : Default: alra . Either alra, scimpute or rmagic alra : Use RunALRA() from Seurat scimpute : Use scImpute() from scimpute rmagic : Use magic() from Rmagic scimpute_args ( ns ) : The arguments for scimpute drop_thre ( type=float ) : Default: 0.5 . The dropout threshold kcluster ( type=int ) : Number of clusters to use ncores ( type=int ) : Default: 1 . Number of cores to use refgene : Default: \"\" . The reference gene file rmagic_args ( ns ) : The arguments for rmagic python : Default: python . The python path where magic-impute is installed. threshold ( type=float ) : Default: 0.5 . The threshold for magic imputation. Only the genes with dropout rates greater than this threshold (No. of cells with non-zero expression / total number of cells) will be imputed. alra_args ( type=json ) : Default: {} . The arguments for RunALRA() Reference \u00b6 Linderman, George C., Jun Zhao, and Yuval Kluger. \"Zero-preserving imputation of scRNA-seq data using low-rank approximation.\" BioRxiv (2018): 397588. Li, Wei Vivian, and Jingyi Jessica Li. \"An accurate and robust imputation method scImpute for single-cell RNA-seq data.\" Nature communications 9.1 (2018): 997. Dijk, David van, et al. \"MAGIC: A diffusion-based imputation method reveals gene-gene interactions in single-cell RNA-sequencing data.\" BioRxiv (2017): 111591.","title":"MetabolicExprImputation"},{"location":"processes/MetabolicExprImputation/#metabolicexprimputation","text":"This process imputes the dropout values in scRNA-seq data. It takes the Seurat object as input and outputs the Seurat object with imputed expression data. You can turn off the imputation by setting the noimpute option of the process group to True .","title":"MetabolicExprImputation"},{"location":"processes/MetabolicExprImputation/#input","text":"infile : The input file in RDS/qs format of Seurat object","title":"Input"},{"location":"processes/MetabolicExprImputation/#output","text":"outfile : Default: {{in.infile | stem}}.imputed.qs . The output file in RDS format of Seurat object Note that with rmagic and alra, the original default assay will be renamed to RAW and the imputed RNA assay will be renamed to RNA and set as default assay.","title":"Output"},{"location":"processes/MetabolicExprImputation/#environment-variables","text":"tool ( choice ) : Default: alra . Either alra, scimpute or rmagic alra : Use RunALRA() from Seurat scimpute : Use scImpute() from scimpute rmagic : Use magic() from Rmagic scimpute_args ( ns ) : The arguments for scimpute drop_thre ( type=float ) : Default: 0.5 . The dropout threshold kcluster ( type=int ) : Number of clusters to use ncores ( type=int ) : Default: 1 . Number of cores to use refgene : Default: \"\" . The reference gene file rmagic_args ( ns ) : The arguments for rmagic python : Default: python . The python path where magic-impute is installed. threshold ( type=float ) : Default: 0.5 . The threshold for magic imputation. Only the genes with dropout rates greater than this threshold (No. of cells with non-zero expression / total number of cells) will be imputed. alra_args ( type=json ) : Default: {} . The arguments for RunALRA()","title":"Environment Variables"},{"location":"processes/MetabolicExprImputation/#reference","text":"Linderman, George C., Jun Zhao, and Yuval Kluger. \"Zero-preserving imputation of scRNA-seq data using low-rank approximation.\" BioRxiv (2018): 397588. Li, Wei Vivian, and Jingyi Jessica Li. \"An accurate and robust imputation method scImpute for single-cell RNA-seq data.\" Nature communications 9.1 (2018): 997. Dijk, David van, et al. \"MAGIC: A diffusion-based imputation method reveals gene-gene interactions in single-cell RNA-sequencing data.\" BioRxiv (2017): 111591.","title":"Reference"},{"location":"processes/MetabolicFeatures/","text":"MetabolicFeatures \u00b6 This process performs enrichment analysis for the metabolic pathways for each group in each subset. The enrichment analysis is done with fgsea package or the GSEA_R package. Input \u00b6 sobjfile : The Seurat object file in rds. It should be loaded as a Seurat object Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pathwayfeatures . The output directory. It will contain the GSEA results and plots. Environment Variables \u00b6 ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization for the comparisons for each subset and group. Defaults to ScrnaMetabolicLandscape.ncores . prerank_method ( choice ) : Default: signal_to_noise . Method to use for gene preranking. Signal to noise: the larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \u201cclass marker.\u201d. Absolute signal to noise: the absolute value of the signal to noise. T test: Uses the difference of means scaled by the standard deviation and number of samples. Ratio of classes: Uses the ratio of class means to calculate fold change for natural scale data. Diff of classes: Uses the difference of class means to calculate fold change for nature scale data Log2 ratio of classes: Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. signal_to_noise : Signal to noise s2n : Alias of signal_to_noise abs_signal_to_noise : absolute signal to noise abs_s2n : Alias of abs_signal_to_noise t_test : T test ratio_of_classes : Also referred to as fold change diff_of_classes : Difference of class means log2_ratio_of_classes : Log2 ratio of class means gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;type=auto;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. Multiple columns can be provided as a list, which is helpful when subsets have overlapping cells. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by comparisons ( type=list ) : Default: [] . The comparison groups to use for the analysis. If not provided, each group in the group_by column will be used to compare with the other groups. If a single group is provided as an element, it will be used to compare with all the other groups. For example, if we have group_by = \"cluster\" and we have 1 , 2 and 3 in the group_by column, we could have comparisons = [\"1\", \"2\"] , which will compare the group 1 with groups 2 and 3 , and the group 2 with groups 1 and 3 . We could also have comparisons = [\"1:2\", \"1:3\"] , which will compare the group 1 with group 2 and group 1 with group 3 . fgsea_args ( type=json ) : Default: {} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Summary Plot': Diot({'plot_type': 'summary', 'top_term': 10, 'devpars': Diot({'res': 100})}), 'Enrichment Plots': Diot({'plot_type': 'gsea', 'top_term': 10, 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . A key level is supported to specify the level of the plot. Possible values are case , which includes all subsets and groups in the case; subset , which includes all groups in the subset; otherwise, it will plot for the groups. For case / subset level plots, current plot_type only \"dot\" is supported for now, then the values will be passed to plotthis::DotPlot() cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots .","title":"MetabolicFeatures"},{"location":"processes/MetabolicFeatures/#metabolicfeatures","text":"This process performs enrichment analysis for the metabolic pathways for each group in each subset. The enrichment analysis is done with fgsea package or the GSEA_R package.","title":"MetabolicFeatures"},{"location":"processes/MetabolicFeatures/#input","text":"sobjfile : The Seurat object file in rds. It should be loaded as a Seurat object","title":"Input"},{"location":"processes/MetabolicFeatures/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pathwayfeatures . The output directory. It will contain the GSEA results and plots.","title":"Output"},{"location":"processes/MetabolicFeatures/#environment-variables","text":"ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization for the comparisons for each subset and group. Defaults to ScrnaMetabolicLandscape.ncores . prerank_method ( choice ) : Default: signal_to_noise . Method to use for gene preranking. Signal to noise: the larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \u201cclass marker.\u201d. Absolute signal to noise: the absolute value of the signal to noise. T test: Uses the difference of means scaled by the standard deviation and number of samples. Ratio of classes: Uses the ratio of class means to calculate fold change for natural scale data. Diff of classes: Uses the difference of class means to calculate fold change for nature scale data Log2 ratio of classes: Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. signal_to_noise : Signal to noise s2n : Alias of signal_to_noise abs_signal_to_noise : absolute signal to noise abs_s2n : Alias of abs_signal_to_noise t_test : T test ratio_of_classes : Also referred to as fold change diff_of_classes : Difference of class means log2_ratio_of_classes : Log2 ratio of class means gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;type=auto;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. Multiple columns can be provided as a list, which is helpful when subsets have overlapping cells. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by comparisons ( type=list ) : Default: [] . The comparison groups to use for the analysis. If not provided, each group in the group_by column will be used to compare with the other groups. If a single group is provided as an element, it will be used to compare with all the other groups. For example, if we have group_by = \"cluster\" and we have 1 , 2 and 3 in the group_by column, we could have comparisons = [\"1\", \"2\"] , which will compare the group 1 with groups 2 and 3 , and the group 2 with groups 1 and 3 . We could also have comparisons = [\"1:2\", \"1:3\"] , which will compare the group 1 with group 2 and group 1 with group 3 . fgsea_args ( type=json ) : Default: {} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Summary Plot': Diot({'plot_type': 'summary', 'top_term': 10, 'devpars': Diot({'res': 100})}), 'Enrichment Plots': Diot({'plot_type': 'gsea', 'top_term': 10, 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . A key level is supported to specify the level of the plot. Possible values are case , which includes all subsets and groups in the case; subset , which includes all groups in the subset; otherwise, it will plot for the groups. For case / subset level plots, current plot_type only \"dot\" is supported for now, then the values will be passed to plotthis::DotPlot() cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.prerank_method , envs.subset_by , envs.group_by , envs.comparisons , envs.fgsea_args and envs.plots .","title":"Environment Variables"},{"location":"processes/MetabolicInput/","text":"MetabolicInput \u00b6 This process takes Seurat object as input and pass it to the next processes in the ScrnaMetabolicLandscape group. There is no configuration for this process. Input \u00b6 infile : The input file Output \u00b6 outfile : Default: {{in.infile | basename}} . The output symbolic link to the input file","title":"MetabolicInput"},{"location":"processes/MetabolicInput/#metabolicinput","text":"This process takes Seurat object as input and pass it to the next processes in the ScrnaMetabolicLandscape group. There is no configuration for this process.","title":"MetabolicInput"},{"location":"processes/MetabolicInput/#input","text":"infile : The input file","title":"Input"},{"location":"processes/MetabolicInput/#output","text":"outfile : Default: {{in.infile | basename}} . The output symbolic link to the input file","title":"Output"},{"location":"processes/MetabolicPathwayActivity/","text":"MetabolicPathwayActivity \u00b6 This process calculates the pathway activities in different groups and subsets. The cells are first grouped by subsets and then the metabolic activities are examined for each groups in different subsets. For each subset, a heatmap and a violin plot will be generated. The heatmap shows the pathway activities for each group and each metabolic pathway The violin plot shows the distribution of the pathway activities for each group You may also have a merged heatmap to show all subsets in one plot. Input \u00b6 sobjfile : The Seurat object file. It should be loaded as a Seurat object Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pathwayactivity . The output directory. It will contain the pathway activity score files and plots. Environment Variables \u00b6 ntimes ( type=int ) : Default: 5000 . Number of permutations to estimate the p-values ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;type=auto;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. Multiple columns can be provided as a list, which is helpful when subsets have overlapping cells. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by plots ( type=json ) : Default: {'Pathway Activity (violin plot)': Diot({'plot_type': 'violin', 'add_box': True, 'devpars': Diot({'res': 100})}), 'Pathway Activity (heatmap)': Diot({'plot_type': 'heatmap', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the prefix for the output files. Values will be a dictionary with the following keys: plot_type is the type of plot to generate. One of heatmap , box , violin or merged_heatmap (all subsets in one plot). devpars is a dictionary with the device parameters for the plot. Other arguments for plotthis::Heatmap() , plotthis::BoxPlot() or plotthis::ViolinPlot() , depending on the plot_type . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots . The name of the case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots .","title":"MetabolicPathwayActivity"},{"location":"processes/MetabolicPathwayActivity/#metabolicpathwayactivity","text":"This process calculates the pathway activities in different groups and subsets. The cells are first grouped by subsets and then the metabolic activities are examined for each groups in different subsets. For each subset, a heatmap and a violin plot will be generated. The heatmap shows the pathway activities for each group and each metabolic pathway The violin plot shows the distribution of the pathway activities for each group You may also have a merged heatmap to show all subsets in one plot.","title":"MetabolicPathwayActivity"},{"location":"processes/MetabolicPathwayActivity/#input","text":"sobjfile : The Seurat object file. It should be loaded as a Seurat object","title":"Input"},{"location":"processes/MetabolicPathwayActivity/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pathwayactivity . The output directory. It will contain the pathway activity score files and plots.","title":"Output"},{"location":"processes/MetabolicPathwayActivity/#environment-variables","text":"ntimes ( type=int ) : Default: 5000 . Number of permutations to estimate the p-values ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile subset_by ( pgarg;type=auto;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. Multiple columns can be provided as a list, which is helpful when subsets have overlapping cells. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by plots ( type=json ) : Default: {'Pathway Activity (violin plot)': Diot({'plot_type': 'violin', 'add_box': True, 'devpars': Diot({'res': 100})}), 'Pathway Activity (heatmap)': Diot({'plot_type': 'heatmap', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the prefix for the output files. Values will be a dictionary with the following keys: plot_type is the type of plot to generate. One of heatmap , box , violin or merged_heatmap (all subsets in one plot). devpars is a dictionary with the device parameters for the plot. Other arguments for plotthis::Heatmap() , plotthis::BoxPlot() or plotthis::ViolinPlot() , depending on the plot_type . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots . The name of the case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.ntimes , envs.subset_by , envs.group_by , envs.group1 , envs.group2 , and envs.plots .","title":"Environment Variables"},{"location":"processes/MetabolicPathwayHeterogeneity/","text":"MetabolicPathwayHeterogeneity \u00b6 Calculate Metabolic Pathway heterogeneity. For each subset, the normalized enrichment score (NES) of each metabolic pathway is calculated for each group. The NES is calculated by comparing the enrichment score of the subset to the enrichment scores of the same subset in the permutations. The p-value is calculated by comparing the NES to the NESs of the same subset in the permutations. The heterogeneity can be reflected by the NES values and the p-values in different groups for the metabolic pathways. Input \u00b6 sobjfile : Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pathwayhetero . Environment Variables \u00b6 gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile select_pcs ( type=float ) : Default: 0.8 . Select the PCs to use for the analysis. pathway_pval_cutoff ( type=float ) : Default: 0.01 . The p-value cutoff to select the enriched pathways ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores subset_by ( pgarg;type=auto;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. Multiple columns can be provided as a list, which is helpful when subsets have overlapping cells. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by fgsea_args ( type=json ) : Default: {'scoreType': 'std', 'nproc': 1} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Pathway Heterogeneity': Diot({'plot_type': 'dot', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff .","title":"MetabolicPathwayHeterogeneity"},{"location":"processes/MetabolicPathwayHeterogeneity/#metabolicpathwayheterogeneity","text":"Calculate Metabolic Pathway heterogeneity. For each subset, the normalized enrichment score (NES) of each metabolic pathway is calculated for each group. The NES is calculated by comparing the enrichment score of the subset to the enrichment scores of the same subset in the permutations. The p-value is calculated by comparing the NES to the NESs of the same subset in the permutations. The heterogeneity can be reflected by the NES values and the p-values in different groups for the metabolic pathways.","title":"MetabolicPathwayHeterogeneity"},{"location":"processes/MetabolicPathwayHeterogeneity/#input","text":"sobjfile :","title":"Input"},{"location":"processes/MetabolicPathwayHeterogeneity/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pathwayhetero .","title":"Output"},{"location":"processes/MetabolicPathwayHeterogeneity/#environment-variables","text":"gmtfile ( pgarg ) : The GMT file with the metabolic pathways. Defaults to ScrnaMetabolicLandscape.gmtfile select_pcs ( type=float ) : Default: 0.8 . Select the PCs to use for the analysis. pathway_pval_cutoff ( type=float ) : Default: 0.01 . The p-value cutoff to select the enriched pathways ncores ( type=int;pgarg ) : Default: 1 . Number of cores to use for parallelization Defaults to ScrnaMetabolicLandscape.ncores subset_by ( pgarg;type=auto;readonly ) : Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. Defaults to ScrnaMetabolicLandscape.subset_by If None, the data will not be subsetted. Multiple columns can be provided as a list, which is helpful when subsets have overlapping cells. group_by ( pgarg;readonly ) : Group the data by the given column in the metadata. For example, cluster . Defaults to ScrnaMetabolicLandscape.group_by fgsea_args ( type=json ) : Default: {'scoreType': 'std', 'nproc': 1} . Other arguments for the fgsea::fgsea() function. For example, {\"minSize\": 15, \"maxSize\": 500} . See https://rdrr.io/bioc/fgsea/man/fgsea.html for more details. plots ( type=json ) : Default: {'Pathway Heterogeneity': Diot({'plot_type': 'dot', 'devpars': Diot({'res': 100})})} . The plots to generate. Names will be used as the title for the plot. Values will be the arguments passed to biopipen.utils::VizGSEA() function. See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . cases ( type=json ) : Default: {} . Multiple cases for the analysis. If you only have one case, you can specify the parameters directly to envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff . The name of this default case will be envs.subset_by . If you have multiple cases, you can specify the parameters for each case in a dictionary. The keys will be the names of the cases and the values will be dictionaries with the parameters for each case, where the values will be inherited from envs.subset_by , envs.group_by , envs.fgsea_args , envs.plots , envs.select_pcs , and envs.pathway_pval_cutoff .","title":"Environment Variables"},{"location":"processes/ModuleScoreCalculator/","text":"ModuleScoreCalculator \u00b6 Calculate the module scores for each cell The module scores are calculated by Seurat::AddModuleScore() or Seurat::CellCycleScoring() for cell cycle scores. The module scores are calculated as the average expression levels of each program on single cell level, subtracted by the aggregated expression of control feature sets. All analyzed features are binned based on averaged expression, and the control features are randomly selected from each bin. Input \u00b6 srtobj : The seurat object loaded by SeuratClustering Output \u00b6 rdsfile : Default: {{in.srtobj | stem}}.qs . The seurat object with module scores added to the metadata. Environment Variables \u00b6 defaults ( ns ) : The default parameters for modules . features : The features to calculate the scores. Multiple features should be separated by comma. You can also specify cc.genes or cc.genes.updated.2019 to use the cell cycle genes to calculate cell cycle scores. If so, three columns will be added to the metadata, including S.Score , G2M.Score and Phase . Only one type of cell cycle scores can be calculated at a time. nbin ( type=int ) : Default: 24 . Number of bins of aggregate expression levels for all analyzed features. ctrl ( type=int ) : Default: 100 . Number of control features selected from the same bin per analyzed feature. k ( flag ) : Default: False . Use feature clusters returned from DoKMeans . assay : The assay to use. seed ( type=int ) : Default: 8525 . Set a random seed. search ( flag ) : Default: False . Search for symbol synonyms for features in features that don't match features in object? keep ( flag ) : Default: False . Keep the scores for each feature? Only works for non-cell cycle scores. agg ( choice ) : Default: mean . The aggregation function to use. Only works for non-cell cycle scores. mean : The mean of the expression levels median : The median of the expression levels sum : The sum of the expression levels max : The max of the expression levels min : The min of the expression levels var : The variance of the expression levels sd : The standard deviation of the expression levels modules ( type=json ) : Default: {} . The modules to calculate the scores. Keys are the names of the expression programs and values are the dicts inherited from env.defaults . Here are some examples - { \"CellCycle\" : { \"features\" : \"cc.genes.updated.2019\" }, \"Exhaustion\" : { \"features\" : \"HAVCR2,ENTPD1,LAYN,LAG3\" }, \"Activation\" : { \"features\" : \"IFNG\" }, \"Proliferation\" : { \"features\" : \"STMN1,TUBB\" } } For CellCycle , the columns S.Score , G2M.Score and Phase will be added to the metadata. S.Score and G2M.Score are the cell cycle scores for each cell, and Phase is the cell cycle phase for each cell. You can also add Diffusion Components (DC) to the modules { \"DC\" : { \"features\" : 2 , \"kind\" : \"diffmap\" }} will perform diffusion map as a reduction and add the first 2 components as DC_1 and DC_2 to the metadata. diffmap is a shortcut for diffusion_map . Other key-value pairs will pass to destiny::DiffusionMap() . You can later plot the diffusion map by using reduction = \"DC\" in env.dimplots in SeuratClusterStats . This requires SingleCellExperiment and destiny R packages. - post_mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata after calculating the module scores. The mutaters will be applied in the order specified. This is useful when you want to create new scores based on the calculated module scores. Metadata \u00b6 The metadata of the Seurat object will be updated with the module scores:","title":"ModuleScoreCalculator"},{"location":"processes/ModuleScoreCalculator/#modulescorecalculator","text":"Calculate the module scores for each cell The module scores are calculated by Seurat::AddModuleScore() or Seurat::CellCycleScoring() for cell cycle scores. The module scores are calculated as the average expression levels of each program on single cell level, subtracted by the aggregated expression of control feature sets. All analyzed features are binned based on averaged expression, and the control features are randomly selected from each bin.","title":"ModuleScoreCalculator"},{"location":"processes/ModuleScoreCalculator/#input","text":"srtobj : The seurat object loaded by SeuratClustering","title":"Input"},{"location":"processes/ModuleScoreCalculator/#output","text":"rdsfile : Default: {{in.srtobj | stem}}.qs . The seurat object with module scores added to the metadata.","title":"Output"},{"location":"processes/ModuleScoreCalculator/#environment-variables","text":"defaults ( ns ) : The default parameters for modules . features : The features to calculate the scores. Multiple features should be separated by comma. You can also specify cc.genes or cc.genes.updated.2019 to use the cell cycle genes to calculate cell cycle scores. If so, three columns will be added to the metadata, including S.Score , G2M.Score and Phase . Only one type of cell cycle scores can be calculated at a time. nbin ( type=int ) : Default: 24 . Number of bins of aggregate expression levels for all analyzed features. ctrl ( type=int ) : Default: 100 . Number of control features selected from the same bin per analyzed feature. k ( flag ) : Default: False . Use feature clusters returned from DoKMeans . assay : The assay to use. seed ( type=int ) : Default: 8525 . Set a random seed. search ( flag ) : Default: False . Search for symbol synonyms for features in features that don't match features in object? keep ( flag ) : Default: False . Keep the scores for each feature? Only works for non-cell cycle scores. agg ( choice ) : Default: mean . The aggregation function to use. Only works for non-cell cycle scores. mean : The mean of the expression levels median : The median of the expression levels sum : The sum of the expression levels max : The max of the expression levels min : The min of the expression levels var : The variance of the expression levels sd : The standard deviation of the expression levels modules ( type=json ) : Default: {} . The modules to calculate the scores. Keys are the names of the expression programs and values are the dicts inherited from env.defaults . Here are some examples - { \"CellCycle\" : { \"features\" : \"cc.genes.updated.2019\" }, \"Exhaustion\" : { \"features\" : \"HAVCR2,ENTPD1,LAYN,LAG3\" }, \"Activation\" : { \"features\" : \"IFNG\" }, \"Proliferation\" : { \"features\" : \"STMN1,TUBB\" } } For CellCycle , the columns S.Score , G2M.Score and Phase will be added to the metadata. S.Score and G2M.Score are the cell cycle scores for each cell, and Phase is the cell cycle phase for each cell. You can also add Diffusion Components (DC) to the modules { \"DC\" : { \"features\" : 2 , \"kind\" : \"diffmap\" }} will perform diffusion map as a reduction and add the first 2 components as DC_1 and DC_2 to the metadata. diffmap is a shortcut for diffusion_map . Other key-value pairs will pass to destiny::DiffusionMap() . You can later plot the diffusion map by using reduction = \"DC\" in env.dimplots in SeuratClusterStats . This requires SingleCellExperiment and destiny R packages. - post_mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata after calculating the module scores. The mutaters will be applied in the order specified. This is useful when you want to create new scores based on the calculated module scores.","title":"Environment Variables"},{"location":"processes/ModuleScoreCalculator/#metadata","text":"The metadata of the Seurat object will be updated with the module scores:","title":"Metadata"},{"location":"processes/PseudoBulkDEG/","text":"PseudoBulkDEG \u00b6 Pseduo-bulk differential gene expression analysis This process performs differential gene expression analysis, instead of on single-cell level, on the pseudo-bulk data, aggregated from the single-cell data. Input \u00b6 sobjfile : The seurat object file in RDS or qs/qs2 format. Output \u00b6 outdir : Default: {{in.sobjfile | stem}}.pseudobulk_deg . The output containing the results of the differential gene expression analysis. Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use for parallelization. mutaters ( type=json ) : Default: {} . Mutaters to mutate the metadata of the seurat object. Keys are the new column names and values are the expressions to mutate the columns. These new columns can be used to define your cases. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . each : The column name in metadata to separate the cells into different cases. When specified, the case will be expanded to multiple cases for each value in the column. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. subset : An expression in string to subset the cells. aggregate_by : The column names in metadata to aggregate the cells. layer : Default: counts . The layer to pull and aggregate the data. assay : The assay to pull and aggregate the data. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. group_by : The column name in metadata to group the cells. ident_1 : The first identity to compare. ident_2 : The second identity to compare. If not specified, the rest of the identities will be compared with ident_1 . paired_by : The column name in metadata to mark the paired samples. For example, subject. If specified, the paired test will be performed. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The databases to use for enrichment analysis. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. The default is p_val_adj < 0.05 . If tool = 'DESeq2' , the variables that can be used for filtering are: baseMean , log2FC , lfcSE , stat , p_val , p_val_adj . If tool = 'edgeR' , the variables that can be used for filtering are: logCPM , log2FC , LR , p_val , p_val_adj . enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. enrichr : Use enrichr -style for the enrichment analysis. clusterProfiler : Use clusterProfiler -style for the enrichment analysis. allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot': Diot({'plot_type': 'volcano'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified. tool ( choice ) : Default: DESeq2 . The method to use for the differential expression analysis. DESeq2 : Use DESeq2 for the analysis. edgeR : Use edgeR for the analysis. plots_defaults ( ns ) : The default parameters for the plots. <more> : Parameters passed to biopipen.utils::VizBulkDEGs() . See: https://pwwang.github.io/biopipen.utils.R/reference/VizBulkDEGs.html plots ( type=json ) : The parameters for the plots. The keys are the names of the plots and the values are the parameters for the plots. The parameters will override the defaults in plots_defaults . If not specified, no plots will be generated. cases ( type=json ) : Default: {} . The cases for the analysis. The keys are the names of the cases and the values are the arguments for the analysis. The arguments include the ones inherited from envs . If no cases are specified, a default case will be added with the name DEG Analysis and the default values specified above. SeeAlso \u00b6 biopipen.ns.scrna.PseudoBulkDEG ClusterMarkers for examples of marker and enrichment plots","title":"PseudoBulkDEG"},{"location":"processes/PseudoBulkDEG/#pseudobulkdeg","text":"Pseduo-bulk differential gene expression analysis This process performs differential gene expression analysis, instead of on single-cell level, on the pseudo-bulk data, aggregated from the single-cell data.","title":"PseudoBulkDEG"},{"location":"processes/PseudoBulkDEG/#input","text":"sobjfile : The seurat object file in RDS or qs/qs2 format.","title":"Input"},{"location":"processes/PseudoBulkDEG/#output","text":"outdir : Default: {{in.sobjfile | stem}}.pseudobulk_deg . The output containing the results of the differential gene expression analysis.","title":"Output"},{"location":"processes/PseudoBulkDEG/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use for parallelization. mutaters ( type=json ) : Default: {} . Mutaters to mutate the metadata of the seurat object. Keys are the new column names and values are the expressions to mutate the columns. These new columns can be used to define your cases. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . each : The column name in metadata to separate the cells into different cases. When specified, the case will be expanded to multiple cases for each value in the column. cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. subset : An expression in string to subset the cells. aggregate_by : The column names in metadata to aggregate the cells. layer : Default: counts . The layer to pull and aggregate the data. assay : The assay to pull and aggregate the data. error ( flag ) : Default: False . Error out if no/not enough markers are found or no pathways are enriched. If False , empty results will be returned. group_by : The column name in metadata to group the cells. ident_1 : The first identity to compare. ident_2 : The second identity to compare. If not specified, the rest of the identities will be compared with ident_1 . paired_by : The column name in metadata to mark the paired samples. For example, subject. If specified, the paired test will be performed. dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The databases to use for enrichment analysis. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . sigmarkers : Default: p_val_adj < 0.05 . An expression passed to dplyr::filter() to filter the significant markers for enrichment analysis. The default is p_val_adj < 0.05 . If tool = 'DESeq2' , the variables that can be used for filtering are: baseMean , log2FC , lfcSE , stat , p_val , p_val_adj . If tool = 'edgeR' , the variables that can be used for filtering are: logCPM , log2FC , LR , p_val , p_val_adj . enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. enrichr : Use enrichr -style for the enrichment analysis. clusterProfiler : Use clusterProfiler -style for the enrichment analysis. allmarker_plots_defaults ( ns ) : Default options for the plots for all markers when ident_1 is not specified. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . allmarker_plots ( type=json ) : Default: {} . All marker plot cases. The keys are the names of the cases and the values are the dicts inherited from allmarker_plots_defaults . allenrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : Default: heatmap . The type of the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . allenrich_plots ( type=json ) : Default: {} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from allenrich_plots_defaults . The cases under envs.cases can inherit this options. marker_plots_defaults ( ns ) : Default options for the plots to generate for the markers. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html . Available types are violin , box , bar , ridge , dim , heatmap and dot . There are two additional types available - volcano_pct and volcano_log2fc . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. order_by : Default: desc(abs(log2FC)) . an expression to order the markers, passed by dplyr::arrange() . genes : Default: 10 . The number of top genes to show or an expression passed to dplyr::filter() to filter the genes. <more> : Other arguments passed to scplotter::FeatureStatPlot() . If plot_type is volcano_pct or volcano_log2fc , they will be passed to scplotter::VolcanoPlot() . marker_plots ( type=json ) : Default: {'Volcano Plot': Diot({'plot_type': 'volcano'})} . Cases of the plots to generate for the markers. Plot cases. The keys are the names of the cases and the values are the dicts inherited from marker_plots_defaults . The cases under envs.cases can inherit this options. enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. overlaps_defaults ( ns ) : Default options for investigating the overlapping of significant markers between different cases or comparisons. This means either ident_1 should be empty, so that they can be expanded to multiple comparisons. sigmarkers : The expression to filter the significant markers for each case. If not provided, envs.sigmarkers will be used. plot_type ( choice ) : Default: venn . The type of the plot to generate for the overlaps. venn : Use plotthis::VennDiagram() . upset : Use plotthis::UpsetPlot() . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : More arguments pased to plotthis::VennDiagram() ( https://pwwang.github.io/plotthis/reference/venndiagram1.html ) or plotthis::UpsetPlot() ( https://pwwang.github.io/plotthis/reference/upsetplot1.html ) overlaps ( type=json ) : Default: {} . Cases for investigating the overlapping of significant markers between different cases or comparisons. The keys are the names of the cases and the values are the dicts inherited from overlaps_defaults . There are two situations that we can perform overlaps: If ident_1 is not specified, the overlaps can be performed between different comparisons. If each is specified, the overlaps can be performed between different cases, where in each case, ident_1 must be specified. tool ( choice ) : Default: DESeq2 . The method to use for the differential expression analysis. DESeq2 : Use DESeq2 for the analysis. edgeR : Use edgeR for the analysis. plots_defaults ( ns ) : The default parameters for the plots. <more> : Parameters passed to biopipen.utils::VizBulkDEGs() . See: https://pwwang.github.io/biopipen.utils.R/reference/VizBulkDEGs.html plots ( type=json ) : The parameters for the plots. The keys are the names of the plots and the values are the parameters for the plots. The parameters will override the defaults in plots_defaults . If not specified, no plots will be generated. cases ( type=json ) : Default: {} . The cases for the analysis. The keys are the names of the cases and the values are the arguments for the analysis. The arguments include the ones inherited from envs . If no cases are specified, a default case will be added with the name DEG Analysis and the default values specified above.","title":"Environment Variables"},{"location":"processes/PseudoBulkDEG/#seealso","text":"biopipen.ns.scrna.PseudoBulkDEG ClusterMarkers for examples of marker and enrichment plots","title":"SeeAlso"},{"location":"processes/SampleInfo/","text":"SampleInfo \u00b6 List sample information and perform statistics This process is the entrance of the pipeline. It just pass by input file and list the sample information in the report. To specify the input file in the configuration file, use the following [SampleInfo.in] infile = [ \"path/to/sample_info.txt\" ] Or with pipen-board , find the SampleInfo process and click the Edit button. Then you can specify the input file here Multiple input files are supported by the underlying pipeline framework. However, we recommend to run it with a different pipeline instance with configuration files. For the content of the input file, please see details here . You can add some columns to the input file while doing the statistics or you can even pass them on to the next processes. See envs.mutaters and envs.save_mutated . But if you are adding a factor (categorical) column with desired levels, the order can't be guaranteed, because we are saving them to a text file, where we can't guarantee the order of the levels. If you want to add a factor column with desired levels, you can set envs.mutaters of the SeuratPreparing process to mutate the column. Once the pipeline is finished, you can see the sample information in the report Note that the required RNAData (if not loaded from a Seurat object) and TCRData / BCRData columns are not shown in the report. They are used to specify the paths of the scRNA-seq and scTCR-seq / scBCR-seq data, respectively. Also note that when RNAData is loaded from a Seurat object (specified in the LoadingRNAFromSeurat process), the metadata provided in this process will not be integrated into the Seurat object in the downstream processes. To incoporate these meta information into the Seurat object, please provide them in the Seurat object itself or use the envs.mutaters of the SeuratPreparing process to mutate the metadata of the Seurat object. But the meta information provided in this process can still be used in the statistics and plots in the report. You may also perform some statistics on the sample information, for example, number of samples per group. See next section for details. Tip This is the start process of the pipeline. Once you change the parameters for this process, the whole pipeline will be re-run. If you just want to change the parameters for the statistics, and use the cached (previous) results for other processes, you can set cache at pipeline level to \"force\" to force the pipeline to use the cached results and cache of SampleInfo to false to force the pipeline to re-run the SampleInfo process only. cache = \"force\" [SampleInfo] cache = false Input \u00b6 infile ( required ) : The input file to list sample information The input file should be a csv/tsv file with header. Required when LoadingRNAFromSeurat is not used in the pipeline. This is optional if LoadingRNAFromSeurat is used in the pipeline and no VDJ data is provided. The input file should have the following columns. Sample: A unique id for each sample. TCRData/BCRData: The directory for single-cell TCR/BCR data for this sample. Specifically, it should contain filtered_contig_annotations.csv or all_contig_annotations.csv from cellranger. RNAData: The directory for single-cell RNA data for this sample. Specifically, it should be able to be read by Seurat::Read10X() or Seurat::Read10X_h5() or SeuratDisk::LoadLoom() . See also https://satijalab.org/seurat/reference/read10x . Other columns are optional and will be treated as metadata for each sample. Output \u00b6 outfile : Default: {{in.infile | basename}} . The output file with sample information, with mutated columns if envs.save_mutated is True. The basename of the output file will be the same as the input file. The file name of each plot will be slugified from the case name. Each plot has 3 formats: pdf, png and code.zip, which contains the data and R code to reproduce the plot. Environment Variables \u00b6 sep : Default: . The separator of the input file. mutaters ( type=json ) : Default: {} . A dict of mutaters to mutate the data frame. The key is the column name and the value is the R expression to mutate the column. The dict will be transformed to a list in R and passed to dplyr::mutate . You may also use paired() to identify paired samples. The function takes following arguments: df : The data frame. Use . if the function is called in a dplyr pipe. id_col : The column name in df for the ids to be returned in the final output. compare_col : The column name in df to compare the values for each id in id_col . idents : The values in compare_col to compare. It could be either an an integer or a vector. If it is an integer, the number of values in compare_col must be the same as the integer for the id to be regarded as paired. If it is a vector, the values in compare_col must be the same as the values in idents for the id to be regarded as paired. uniq : Whether to return unique ids or not. Default is TRUE . If FALSE , you can mutate the meta data frame with the returned ids. Non-paired ids will be NA . save_mutated ( flag ) : Default: False . Whether to save the mutated columns. exclude_cols ( auto ) : Default: TCRData,BCRData,RNAData . The columns to exclude in the table in the report. Could be a list or a string separated by comma. defaults ( ns ) : The default parameters for envs.stats . plot_type : Default: bar . The type of the plot. See the supported plot types here: https://pwwang.github.io/plotthis/reference/index.html The plot_type should be lower case and the plot function used in plotthis should be used. The mapping from plot_type to the plot function is like bar -> BarPlot , box -> BoxPlot , etc. more_formats ( list ) : Default: [] . The additional formats to save the plot. By default, the plot will be saved in png, which is also used to display in the report. You can add more formats to save the plot. For example, more_formats = [\"pdf\", \"svg\"] . save_code ( flag ) : Default: False . Whether to save the R code to reproduce the plot. The data used to plot will also be saved. subset : An expression to subset the data frame before plotting. The expression should be a string of R expression that will be passed to dplyr::filter . For example, subset = \"Sample == 'A'\" . section : The section name in the report. In case you want to group the plots in the report. devpars ( ns ) : The device parameters for the plot. width ( type=int ) : The width of the plot. height ( type=int ) : The height of the plot. res ( type=int ) : Default: 100 . The resolution of the plot. descr : The description of the plot, shown in the report. <more> : You can add more parameters to the defaults. These parameters will be expanded to the envs.stats for each case, and passed to individual plot functions. stats ( type=json ) : Default: {} . The statistics to perform. The keys are the case names and the values are the parameters inheirted from envs.defaults . Examples \u00b6 Example data \u00b6 Sample Age Sex Diagnosis C1 62 F Colitis C2 71.2 F Colitis C3 56.2 M Colitis C4 61.5 M Colitis C5 72.8 M Colitis C6 78.4 M Colitis C7 61.6 F Colitis C8 49.5 F Colitis NC1 43.6 M NoColitis NC2 68.1 M NoColitis NC3 70.5 F NoColitis NC4 63.7 M NoColitis NC5 58.5 M NoColitis NC6 49.3 F NoColitis CT1 21.4 F Control CT2 61.7 M Control CT3 50.5 M Control CT4 43.4 M Control CT5 70.6 F Control CT6 44.3 M Control CT7 50.2 M Control CT8 61.5 F Control Count the number of samples per Diagnosis \u00b6 [SampleInfo.envs.stats. \"N_Samples_per_Diagnosis (pie)\" ] plot_type = \"pie\" x = \"sample\" split_by = \"Diagnosis\" What if we want a bar plot instead of a pie chart? [SampleInfo.envs.stats. \"N_Samples_per_Diagnosis (bar)\" ] plot_type = \"bar\" x = \"Sample\" split_by = \"Diagnosis\" Explore Age distribution \u00b6 The distribution of Age of all samples [SampleInfo.envs.stats. \"Age_distribution (histogram)\" ] plot_type = \"histogram\" x = \"Age\" How about the distribution of Age in each Diagnosis, and make it violin + boxplot? [SampleInfo.envs.stats. \"Age_distribution_per_Diagnosis (violin + boxplot)\" ] y = \"Age\" x = \"Diagnosis\" plot_type = \"violin\" add_box = true How about Age distribution per Sex in each Diagnosis? [SampleInfo.envs.stats. \"Age_distribution_per_Sex_in_each_Diagnosis (boxplot)\" ] y = \"Age\" x = \"Sex\" split_by = \"Diagnosis\" plot_type = \"box\" ncol = 3 devpars = { height = 450 }","title":"SampleInfo"},{"location":"processes/SampleInfo/#sampleinfo","text":"List sample information and perform statistics This process is the entrance of the pipeline. It just pass by input file and list the sample information in the report. To specify the input file in the configuration file, use the following [SampleInfo.in] infile = [ \"path/to/sample_info.txt\" ] Or with pipen-board , find the SampleInfo process and click the Edit button. Then you can specify the input file here Multiple input files are supported by the underlying pipeline framework. However, we recommend to run it with a different pipeline instance with configuration files. For the content of the input file, please see details here . You can add some columns to the input file while doing the statistics or you can even pass them on to the next processes. See envs.mutaters and envs.save_mutated . But if you are adding a factor (categorical) column with desired levels, the order can't be guaranteed, because we are saving them to a text file, where we can't guarantee the order of the levels. If you want to add a factor column with desired levels, you can set envs.mutaters of the SeuratPreparing process to mutate the column. Once the pipeline is finished, you can see the sample information in the report Note that the required RNAData (if not loaded from a Seurat object) and TCRData / BCRData columns are not shown in the report. They are used to specify the paths of the scRNA-seq and scTCR-seq / scBCR-seq data, respectively. Also note that when RNAData is loaded from a Seurat object (specified in the LoadingRNAFromSeurat process), the metadata provided in this process will not be integrated into the Seurat object in the downstream processes. To incoporate these meta information into the Seurat object, please provide them in the Seurat object itself or use the envs.mutaters of the SeuratPreparing process to mutate the metadata of the Seurat object. But the meta information provided in this process can still be used in the statistics and plots in the report. You may also perform some statistics on the sample information, for example, number of samples per group. See next section for details. Tip This is the start process of the pipeline. Once you change the parameters for this process, the whole pipeline will be re-run. If you just want to change the parameters for the statistics, and use the cached (previous) results for other processes, you can set cache at pipeline level to \"force\" to force the pipeline to use the cached results and cache of SampleInfo to false to force the pipeline to re-run the SampleInfo process only. cache = \"force\" [SampleInfo] cache = false","title":"SampleInfo"},{"location":"processes/SampleInfo/#input","text":"infile ( required ) : The input file to list sample information The input file should be a csv/tsv file with header. Required when LoadingRNAFromSeurat is not used in the pipeline. This is optional if LoadingRNAFromSeurat is used in the pipeline and no VDJ data is provided. The input file should have the following columns. Sample: A unique id for each sample. TCRData/BCRData: The directory for single-cell TCR/BCR data for this sample. Specifically, it should contain filtered_contig_annotations.csv or all_contig_annotations.csv from cellranger. RNAData: The directory for single-cell RNA data for this sample. Specifically, it should be able to be read by Seurat::Read10X() or Seurat::Read10X_h5() or SeuratDisk::LoadLoom() . See also https://satijalab.org/seurat/reference/read10x . Other columns are optional and will be treated as metadata for each sample.","title":"Input"},{"location":"processes/SampleInfo/#output","text":"outfile : Default: {{in.infile | basename}} . The output file with sample information, with mutated columns if envs.save_mutated is True. The basename of the output file will be the same as the input file. The file name of each plot will be slugified from the case name. Each plot has 3 formats: pdf, png and code.zip, which contains the data and R code to reproduce the plot.","title":"Output"},{"location":"processes/SampleInfo/#environment-variables","text":"sep : Default: . The separator of the input file. mutaters ( type=json ) : Default: {} . A dict of mutaters to mutate the data frame. The key is the column name and the value is the R expression to mutate the column. The dict will be transformed to a list in R and passed to dplyr::mutate . You may also use paired() to identify paired samples. The function takes following arguments: df : The data frame. Use . if the function is called in a dplyr pipe. id_col : The column name in df for the ids to be returned in the final output. compare_col : The column name in df to compare the values for each id in id_col . idents : The values in compare_col to compare. It could be either an an integer or a vector. If it is an integer, the number of values in compare_col must be the same as the integer for the id to be regarded as paired. If it is a vector, the values in compare_col must be the same as the values in idents for the id to be regarded as paired. uniq : Whether to return unique ids or not. Default is TRUE . If FALSE , you can mutate the meta data frame with the returned ids. Non-paired ids will be NA . save_mutated ( flag ) : Default: False . Whether to save the mutated columns. exclude_cols ( auto ) : Default: TCRData,BCRData,RNAData . The columns to exclude in the table in the report. Could be a list or a string separated by comma. defaults ( ns ) : The default parameters for envs.stats . plot_type : Default: bar . The type of the plot. See the supported plot types here: https://pwwang.github.io/plotthis/reference/index.html The plot_type should be lower case and the plot function used in plotthis should be used. The mapping from plot_type to the plot function is like bar -> BarPlot , box -> BoxPlot , etc. more_formats ( list ) : Default: [] . The additional formats to save the plot. By default, the plot will be saved in png, which is also used to display in the report. You can add more formats to save the plot. For example, more_formats = [\"pdf\", \"svg\"] . save_code ( flag ) : Default: False . Whether to save the R code to reproduce the plot. The data used to plot will also be saved. subset : An expression to subset the data frame before plotting. The expression should be a string of R expression that will be passed to dplyr::filter . For example, subset = \"Sample == 'A'\" . section : The section name in the report. In case you want to group the plots in the report. devpars ( ns ) : The device parameters for the plot. width ( type=int ) : The width of the plot. height ( type=int ) : The height of the plot. res ( type=int ) : Default: 100 . The resolution of the plot. descr : The description of the plot, shown in the report. <more> : You can add more parameters to the defaults. These parameters will be expanded to the envs.stats for each case, and passed to individual plot functions. stats ( type=json ) : Default: {} . The statistics to perform. The keys are the case names and the values are the parameters inheirted from envs.defaults .","title":"Environment Variables"},{"location":"processes/SampleInfo/#examples","text":"","title":"Examples"},{"location":"processes/SampleInfo/#example-data","text":"Sample Age Sex Diagnosis C1 62 F Colitis C2 71.2 F Colitis C3 56.2 M Colitis C4 61.5 M Colitis C5 72.8 M Colitis C6 78.4 M Colitis C7 61.6 F Colitis C8 49.5 F Colitis NC1 43.6 M NoColitis NC2 68.1 M NoColitis NC3 70.5 F NoColitis NC4 63.7 M NoColitis NC5 58.5 M NoColitis NC6 49.3 F NoColitis CT1 21.4 F Control CT2 61.7 M Control CT3 50.5 M Control CT4 43.4 M Control CT5 70.6 F Control CT6 44.3 M Control CT7 50.2 M Control CT8 61.5 F Control","title":"Example data"},{"location":"processes/SampleInfo/#count-the-number-of-samples-per-diagnosis","text":"[SampleInfo.envs.stats. \"N_Samples_per_Diagnosis (pie)\" ] plot_type = \"pie\" x = \"sample\" split_by = \"Diagnosis\" What if we want a bar plot instead of a pie chart? [SampleInfo.envs.stats. \"N_Samples_per_Diagnosis (bar)\" ] plot_type = \"bar\" x = \"Sample\" split_by = \"Diagnosis\"","title":"Count the number of samples per Diagnosis"},{"location":"processes/SampleInfo/#explore-age-distribution","text":"The distribution of Age of all samples [SampleInfo.envs.stats. \"Age_distribution (histogram)\" ] plot_type = \"histogram\" x = \"Age\" How about the distribution of Age in each Diagnosis, and make it violin + boxplot? [SampleInfo.envs.stats. \"Age_distribution_per_Diagnosis (violin + boxplot)\" ] y = \"Age\" x = \"Diagnosis\" plot_type = \"violin\" add_box = true How about Age distribution per Sex in each Diagnosis? [SampleInfo.envs.stats. \"Age_distribution_per_Sex_in_each_Diagnosis (boxplot)\" ] y = \"Age\" x = \"Sex\" split_by = \"Diagnosis\" plot_type = \"box\" ncol = 3 devpars = { height = 450 }","title":"Explore Age distribution"},{"location":"processes/ScFGSEA/","text":"ScFGSEA \u00b6 Gene set enrichment analysis for cells in different groups using fgsea This process allows us to do Gene Set Enrichment Analysis (GSEA) on the expression data, but based on variaties of grouping, including the from the meta data and the scTCR-seq data as well. The GSEA is done using the fgsea package, which allows to quickly and accurately calculate arbitrarily low GSEA P-values for a collection of gene sets. The fgsea package is based on the fast algorithm for preranked GSEA described in Subramanian et al. 2005 . For each case, the process will generate a table with the enrichment scores for each gene set, and GSEA plots for the top gene sets. Input \u00b6 srtobj : The seurat object in RDS format Output \u00b6 outdir : Default: {{(in.casefile or in.srtobj) | stem0}}.fgsea . The output directory for the results and plots Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores for parallelization Passed to nproc of fgseaMultilevel() . cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. The key-value pairs will be passed the dplyr::mutate() to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . group_by : The column name in metadata to group the cells. ident_1 : The first group of cells to compare ident_2 : The second group of cells to compare, if not provided, the rest of the cells that are not NA s in group_by column are used for ident_2 . assay : The assay to use. If not provided, the default assay will be used. each : The column name in metadata to separate the cells into different subsets to do the analysis. subset : An expression to subset the cells. gmtfile : Default: KEGG_2021_Human . The pathways in GMT format, with the gene names/ids in the same format as the seurat object. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . method ( choice ) : Default: s2n . The method to do the preranking. signal_to_noise : Signal to noise. The larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \"class marker\". s2n : Alias of signal_to_noise. abs_signal_to_noise : The absolute value of signal_to_noise. abs_s2n : Alias of abs_signal_to_noise. t_test : T test. Uses the difference of means scaled by the standard deviation and number of samples. ratio_of_classes : Also referred to as fold change. Uses the ratio of class means to calculate fold change for natural scale data. diff_of_classes : Difference of class means. Uses the difference of class means to calculate fold change for nature scale data log2_ratio_of_classes : Log2 ratio of class means. Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. top ( type=auto ) : Default: 20 . Do gsea table and enrich plot for top N pathways. If it is < 1, will apply it to padj , selecting pathways with padj < top . eps ( type=float ) : Default: 0 . This parameter sets the boundary for calculating the p value. See https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html alleach_plots_defaults ( ns ) : Default options for the plots to generate for all pathways. plot_type : Default: heatmap . The type of the plot, currently either dot or heatmap (default) devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . alleach_plots ( type=json ) : Default: {} . Cases of the plots to generate for all pathways. The keys are the names of the cases and the values are the dicts inherited from alleach_plots_defaults . minsize ( type=int ) : Default: 10 . Minimal size of a gene set to test. All pathways below the threshold are excluded. maxsize ( type=int ) : Default: 100 . Maximal size of a gene set to test. All pathways above the threshold are excluded. rest ( type=json;order=98 ) : Default: {} . Rest arguments for fgsea() See also https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html cases ( type=json;order=99 ) : Default: {} . If you have multiple cases, you can specify them here. The keys are the names of the cases and the values are the above options except mutaters . If some options are not specified, the default values specified above will be used. If no cases are specified, the default case will be added with the name GSEA . Examples \u00b6 The summary and GSEA plots \u00b6 Summary plot for all subsets or idents \u00b6 If you use each to separate the cells into different subsets, this is useful to make a summary plot for all subsets. Or if you don't specify ident_1 , the summary plot for all idents in group_by will be generated. [ScFGSEA.envs] group_by = \"Diagnosis\" ident_1 = \"Colitis\" ident_2 = \"Control\" each = \"seurat_clusters\" [ScFGSEA.envs.alleach_plots.Heatmap] plot_type = \"heatmap\" group_by = \"Diagnosis\"","title":"ScFGSEA"},{"location":"processes/ScFGSEA/#scfgsea","text":"Gene set enrichment analysis for cells in different groups using fgsea This process allows us to do Gene Set Enrichment Analysis (GSEA) on the expression data, but based on variaties of grouping, including the from the meta data and the scTCR-seq data as well. The GSEA is done using the fgsea package, which allows to quickly and accurately calculate arbitrarily low GSEA P-values for a collection of gene sets. The fgsea package is based on the fast algorithm for preranked GSEA described in Subramanian et al. 2005 . For each case, the process will generate a table with the enrichment scores for each gene set, and GSEA plots for the top gene sets.","title":"ScFGSEA"},{"location":"processes/ScFGSEA/#input","text":"srtobj : The seurat object in RDS format","title":"Input"},{"location":"processes/ScFGSEA/#output","text":"outdir : Default: {{(in.casefile or in.srtobj) | stem0}}.fgsea . The output directory for the results and plots","title":"Output"},{"location":"processes/ScFGSEA/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores for parallelization Passed to nproc of fgseaMultilevel() . cache ( type=auto ) : Default: /tmp . Where to cache the results. If True , cache to outdir of the job. If False , don't cache. Otherwise, specify the directory to cache to. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. The key-value pairs will be passed the dplyr::mutate() to mutate the metadata. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . group_by : The column name in metadata to group the cells. ident_1 : The first group of cells to compare ident_2 : The second group of cells to compare, if not provided, the rest of the cells that are not NA s in group_by column are used for ident_2 . assay : The assay to use. If not provided, the default assay will be used. each : The column name in metadata to separate the cells into different subsets to do the analysis. subset : An expression to subset the cells. gmtfile : Default: KEGG_2021_Human . The pathways in GMT format, with the gene names/ids in the same format as the seurat object. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . method ( choice ) : Default: s2n . The method to do the preranking. signal_to_noise : Signal to noise. The larger the differences of the means (scaled by the standard deviations); that is, the more distinct the gene expression is in each phenotype and the more the gene acts as a \"class marker\". s2n : Alias of signal_to_noise. abs_signal_to_noise : The absolute value of signal_to_noise. abs_s2n : Alias of abs_signal_to_noise. t_test : T test. Uses the difference of means scaled by the standard deviation and number of samples. ratio_of_classes : Also referred to as fold change. Uses the ratio of class means to calculate fold change for natural scale data. diff_of_classes : Difference of class means. Uses the difference of class means to calculate fold change for nature scale data log2_ratio_of_classes : Log2 ratio of class means. Uses the log2 ratio of class means to calculate fold change for natural scale data. This is the recommended statistic for calculating fold change for log scale data. top ( type=auto ) : Default: 20 . Do gsea table and enrich plot for top N pathways. If it is < 1, will apply it to padj , selecting pathways with padj < top . eps ( type=float ) : Default: 0 . This parameter sets the boundary for calculating the p value. See https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html alleach_plots_defaults ( ns ) : Default options for the plots to generate for all pathways. plot_type : Default: heatmap . The type of the plot, currently either dot or heatmap (default) devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/biopipen.utils.R/reference/VizGSEA.html . alleach_plots ( type=json ) : Default: {} . Cases of the plots to generate for all pathways. The keys are the names of the cases and the values are the dicts inherited from alleach_plots_defaults . minsize ( type=int ) : Default: 10 . Minimal size of a gene set to test. All pathways below the threshold are excluded. maxsize ( type=int ) : Default: 100 . Maximal size of a gene set to test. All pathways above the threshold are excluded. rest ( type=json;order=98 ) : Default: {} . Rest arguments for fgsea() See also https://rdrr.io/bioc/fgsea/man/fgseaMultilevel.html cases ( type=json;order=99 ) : Default: {} . If you have multiple cases, you can specify them here. The keys are the names of the cases and the values are the above options except mutaters . If some options are not specified, the default values specified above will be used. If no cases are specified, the default case will be added with the name GSEA .","title":"Environment Variables"},{"location":"processes/ScFGSEA/#examples","text":"","title":"Examples"},{"location":"processes/ScFGSEA/#the-summary-and-gsea-plots","text":"","title":"The summary and GSEA plots"},{"location":"processes/ScFGSEA/#summary-plot-for-all-subsets-or-idents","text":"If you use each to separate the cells into different subsets, this is useful to make a summary plot for all subsets. Or if you don't specify ident_1 , the summary plot for all idents in group_by will be generated. [ScFGSEA.envs] group_by = \"Diagnosis\" ident_1 = \"Colitis\" ident_2 = \"Control\" each = \"seurat_clusters\" [ScFGSEA.envs.alleach_plots.Heatmap] plot_type = \"heatmap\" group_by = \"Diagnosis\"","title":"Summary plot for all subsets or idents"},{"location":"processes/ScRepCombiningExpression/","text":"ScRepCombiningExpression \u00b6 Combine the scTCR/BCR data with the expression data This process combines the scTCR/BCR data with the expression data using scRepertoire::combineExpression function. The expression data should be in Seurat format. The scRepertoire object should be a combined contig object, usually generated by scRepertoire::combineTCR or scRepertoire::combineBCR . See also: https://www.borch.dev/uploads/screpertoire/reference/combineexpression . Input \u00b6 screpfile : The scRepertoire object in RDS/qs format srtobj : The Seurat object, saved in RDS/qs format Output \u00b6 outfile : Default: {{in.screpfile | stem}}.qs . The Seurat object with the TCR/BCR data combined In addition to the meta columns added by scRepertoire::combineExpression() , a new column VDJ_Presence will be added to the metadata. It indicates whether the cell has a TCR/BCR sequence or not. The value is TRUE if the cell has a TCR/BCR sequence, and FALSE otherwise. Environment Variables \u00b6 cloneCall : Default: aa . How to call the clone - VDJC gene (gene), CDR3 nucleotide (nt), CDR3 amino acid (aa), VDJC gene + CDR3 nucleotide (strict) or a custom variable in the data. chain : Default: both . indicate if both or a specific chain should be used e.g. \"both\", \"TRA\", \"TRG\", \"IGH\", \"IGL\". group_by : Default: Sample . The column label in the combined clones in which clone frequency will be calculated. NULL or \"none\" will keep the format of input.data. proportion ( flag ) : Default: True . Whether to proportion (TRUE) or total frequency (FALSE) of the clone based on the group_by variable. filterNA ( flag ) : Default: False . Method to subset Seurat/SCE object of barcodes without clone information cloneSize ( type=json ) : Default: {'Rare': 0.0001, 'Small': 0.001, 'Medium': 0.01, 'Large': 0.1, 'Hyperexpanded': 1} . The bins for the grouping based on proportion or frequency. If proportion is FALSE and the cloneSizes are not set high enough based on frequency, the upper limit of cloneSizes will be automatically updated. addLabel ( flag ) : Default: False . This will add a label to the frequency header, allowing the user to try multiple group_by variables or recalculate frequencies after subsetting the data.","title":"ScRepCombiningExpression"},{"location":"processes/ScRepCombiningExpression/#screpcombiningexpression","text":"Combine the scTCR/BCR data with the expression data This process combines the scTCR/BCR data with the expression data using scRepertoire::combineExpression function. The expression data should be in Seurat format. The scRepertoire object should be a combined contig object, usually generated by scRepertoire::combineTCR or scRepertoire::combineBCR . See also: https://www.borch.dev/uploads/screpertoire/reference/combineexpression .","title":"ScRepCombiningExpression"},{"location":"processes/ScRepCombiningExpression/#input","text":"screpfile : The scRepertoire object in RDS/qs format srtobj : The Seurat object, saved in RDS/qs format","title":"Input"},{"location":"processes/ScRepCombiningExpression/#output","text":"outfile : Default: {{in.screpfile | stem}}.qs . The Seurat object with the TCR/BCR data combined In addition to the meta columns added by scRepertoire::combineExpression() , a new column VDJ_Presence will be added to the metadata. It indicates whether the cell has a TCR/BCR sequence or not. The value is TRUE if the cell has a TCR/BCR sequence, and FALSE otherwise.","title":"Output"},{"location":"processes/ScRepCombiningExpression/#environment-variables","text":"cloneCall : Default: aa . How to call the clone - VDJC gene (gene), CDR3 nucleotide (nt), CDR3 amino acid (aa), VDJC gene + CDR3 nucleotide (strict) or a custom variable in the data. chain : Default: both . indicate if both or a specific chain should be used e.g. \"both\", \"TRA\", \"TRG\", \"IGH\", \"IGL\". group_by : Default: Sample . The column label in the combined clones in which clone frequency will be calculated. NULL or \"none\" will keep the format of input.data. proportion ( flag ) : Default: True . Whether to proportion (TRUE) or total frequency (FALSE) of the clone based on the group_by variable. filterNA ( flag ) : Default: False . Method to subset Seurat/SCE object of barcodes without clone information cloneSize ( type=json ) : Default: {'Rare': 0.0001, 'Small': 0.001, 'Medium': 0.01, 'Large': 0.1, 'Hyperexpanded': 1} . The bins for the grouping based on proportion or frequency. If proportion is FALSE and the cloneSizes are not set high enough based on frequency, the upper limit of cloneSizes will be automatically updated. addLabel ( flag ) : Default: False . This will add a label to the frequency header, allowing the user to try multiple group_by variables or recalculate frequencies after subsetting the data.","title":"Environment Variables"},{"location":"processes/ScRepLoading/","text":"ScRepLoading \u00b6 Load the single cell TCR/BCR data into a scRepertoire compatible object This process loads the single cell TCR/BCR data into a scRepertoire (>= v2.0.8, < v2.3.2) compatible object. Later, scRepertoire::combineExpression can be used to combine the expression data with the TCR/BCR data. For the data path specified at TCRData / BCRData in the input file ( in.metafile ), will be used to find the TCR/BCR data files and scRepertoire::loadContigs() will be used to load the data. A directory can be specified in TCRData / BCRData , then scRepertoire::loadContigs() will be used directly to load the data from the directory. Otherwise if a file is specified, it will be symbolically linked to a directory for scRepertoire::loadContigs() to load. Note that when the file name can not be recognized by scRepertoire::loadContigs() , envs.format must be set for the correct format of the data. Input \u00b6 metafile : The meta data of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. TCRData / BCRData to assign the path of the data to the samples, and this column will be excluded as metadata. Output \u00b6 outfile : Default: {{in.metafile | stem}}.scRep.qs . The scRepertoire compatible object in qs/qs2 format Environment Variables \u00b6 type ( choice ) : Default: auto . The type of the data to load. TCR : T cell receptor data BCR : B cell receptor data auto : Automatically detect the type from the metadata. If auto is selected, the type will be determined by the presence of TCRData or BCRData columns in the metadata. If both columns are present, TCR will be selected by default. combineTCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineTCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinetcr combineBCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineBCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinebcr exclude ( auto ) : Default: ['BCRData', 'TCRData', 'RNAData'] . The columns to exclude from the metadata to add to the object. A list of column names to exclude or a string with column names separated by , . By default, BCRData , TCRData and RNAData will be excluded. tmpdir : Default: /tmp . The temporary directory to store the symbolic links to the TCR/BCR data files. format ( choice ) : The format of the TCR/BCR data files. 10X : 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR : AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD : Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion : Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation : Immcantation data, which is usually in a file with data.tsv file. JSON : JSON format, which is usually in a file with .json extension. ParseBio : ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR : MiXCR data, which is usually in a file with clones.tsv file. Omniscope : Omniscope data, which is usually in a file with .csv extension. TRUST4 : TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R : WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html If not provided, the format will be guessed from the file name by scRepertoire::loadContigs() .","title":"ScRepLoading"},{"location":"processes/ScRepLoading/#screploading","text":"Load the single cell TCR/BCR data into a scRepertoire compatible object This process loads the single cell TCR/BCR data into a scRepertoire (>= v2.0.8, < v2.3.2) compatible object. Later, scRepertoire::combineExpression can be used to combine the expression data with the TCR/BCR data. For the data path specified at TCRData / BCRData in the input file ( in.metafile ), will be used to find the TCR/BCR data files and scRepertoire::loadContigs() will be used to load the data. A directory can be specified in TCRData / BCRData , then scRepertoire::loadContigs() will be used directly to load the data from the directory. Otherwise if a file is specified, it will be symbolically linked to a directory for scRepertoire::loadContigs() to load. Note that when the file name can not be recognized by scRepertoire::loadContigs() , envs.format must be set for the correct format of the data.","title":"ScRepLoading"},{"location":"processes/ScRepLoading/#input","text":"metafile : The meta data of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. TCRData / BCRData to assign the path of the data to the samples, and this column will be excluded as metadata.","title":"Input"},{"location":"processes/ScRepLoading/#output","text":"outfile : Default: {{in.metafile | stem}}.scRep.qs . The scRepertoire compatible object in qs/qs2 format","title":"Output"},{"location":"processes/ScRepLoading/#environment-variables","text":"type ( choice ) : Default: auto . The type of the data to load. TCR : T cell receptor data BCR : B cell receptor data auto : Automatically detect the type from the metadata. If auto is selected, the type will be determined by the presence of TCRData or BCRData columns in the metadata. If both columns are present, TCR will be selected by default. combineTCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineTCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinetcr combineBCR ( type=json ) : Default: {'samples': True} . The extra arguments for scRepertoire::combineBCR function. See also https://www.borch.dev/uploads/screpertoire/reference/combinebcr exclude ( auto ) : Default: ['BCRData', 'TCRData', 'RNAData'] . The columns to exclude from the metadata to add to the object. A list of column names to exclude or a string with column names separated by , . By default, BCRData , TCRData and RNAData will be excluded. tmpdir : Default: /tmp . The temporary directory to store the symbolic links to the TCR/BCR data files. format ( choice ) : The format of the TCR/BCR data files. 10X : 10X Genomics data, which is usually in a directory with filtered_contig_annotations.csv file. AIRR : AIRR format, which is usually in a file with airr_rearrangement.tsv file. BD : Becton Dickinson data, which is usually in a file with Contigs_AIRR.tsv file. Dandelion : Dandelion data, which is usually in a file with all_contig_dandelion.tsv file. Immcantation : Immcantation data, which is usually in a file with data.tsv file. JSON : JSON format, which is usually in a file with .json extension. ParseBio : ParseBio data, which is usually in a file with barcode_report.tsv file. MiXCR : MiXCR data, which is usually in a file with clones.tsv file. Omniscope : Omniscope data, which is usually in a file with .csv extension. TRUST4 : TRUST4 data, which is usually in a file with barcode_report.tsv file. WAT3R : WAT3R data, which is usually in a file with barcode_results.csv file. See also: https://rdrr.io/github/ncborcherding/scRepertoire/man/loadContigs.html If not provided, the format will be guessed from the file name by scRepertoire::loadContigs() .","title":"Environment Variables"},{"location":"processes/ScrnaMetabolicLandscape/","text":"ScrnaMetabolicLandscape \u00b6 Metabolic landscape analysis for scRNA-seq data An abstract from https://github.com/LocasaleLab/Single-Cell-Metabolic-Landscape . See also https://pwwang.github.io/biopipen/pipelines/scrna_metabolic/ . This is a group of processes to analyze the metabolic landscape of single cell RNA-seq data. It collects a set of processes and owns a set of arguments. These arguments could either preset the default values for the processes or define the relationships between the processes. Processes \u00b6 The processes in this group implement part of the pipeline below from the original paper. The data preparation, preprocessing and clustering already done by other processes of this pipeline. The processes in this group are used to analyze the metabolic landscape of the data. MetabolicInput : Input for the metabolic pathway analysis pipeline for scRNA-seq data MetabolicExprImputation : Impute the missing values in the expression data MetabolicPathwayActivity : Calculate the pathway activities for each group MetabolicPathwayHeterogeneity : Calculate the pathway heterogeneity MetabolicFeatures : Inter-subset metabolic features - Enrichment analysis in details Group arguments \u00b6 noimpute ( flag ): Whether to do imputation for the dropouts. If False , the values will be left as is. gmtfile : The GMT file with the metabolic pathways. The gene names should match the gene names in the gene list in RNAData or the Seurat object. You can also provide a URL to the GMT file. For example, from https://download.baderlab.org/EM_Genesets/current_release/Human/symbol/ . subset_by (pgarg;readonly): Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. If None, the data will not be subsetted. group_by (pgarg;readonly): Group the data by the given column in the metadata. For example, cluster . mutaters (type=json): Add new columns to the metadata for grouping/subsetting. They are passed to sobj@meta.data |> mutate(...) . For example, {\"timepoint\": \"if_else(treatment == 'control', 'pre', 'post')\"} will add a new column timepoint to the metadata with values of pre and post based on the treatment column. ncores (type=int): Number of cores to use for parallelization for each process Reference \u00b6 Xiao, Zhengtao, Ziwei Dai, and Jason W. Locasale. \"Metabolic landscape of the tumor microenvironment at single cell resolution.\" Nature communications 10.1 (2019): 1-12.","title":"Introduction & Group Arguments"},{"location":"processes/ScrnaMetabolicLandscape/#scrnametaboliclandscape","text":"Metabolic landscape analysis for scRNA-seq data An abstract from https://github.com/LocasaleLab/Single-Cell-Metabolic-Landscape . See also https://pwwang.github.io/biopipen/pipelines/scrna_metabolic/ . This is a group of processes to analyze the metabolic landscape of single cell RNA-seq data. It collects a set of processes and owns a set of arguments. These arguments could either preset the default values for the processes or define the relationships between the processes.","title":"ScrnaMetabolicLandscape"},{"location":"processes/ScrnaMetabolicLandscape/#processes","text":"The processes in this group implement part of the pipeline below from the original paper. The data preparation, preprocessing and clustering already done by other processes of this pipeline. The processes in this group are used to analyze the metabolic landscape of the data. MetabolicInput : Input for the metabolic pathway analysis pipeline for scRNA-seq data MetabolicExprImputation : Impute the missing values in the expression data MetabolicPathwayActivity : Calculate the pathway activities for each group MetabolicPathwayHeterogeneity : Calculate the pathway heterogeneity MetabolicFeatures : Inter-subset metabolic features - Enrichment analysis in details","title":"Processes"},{"location":"processes/ScrnaMetabolicLandscape/#group-arguments","text":"noimpute ( flag ): Whether to do imputation for the dropouts. If False , the values will be left as is. gmtfile : The GMT file with the metabolic pathways. The gene names should match the gene names in the gene list in RNAData or the Seurat object. You can also provide a URL to the GMT file. For example, from https://download.baderlab.org/EM_Genesets/current_release/Human/symbol/ . subset_by (pgarg;readonly): Subset the data by the given column in the metadata. For example, Response . NA values will be removed in this column. If None, the data will not be subsetted. group_by (pgarg;readonly): Group the data by the given column in the metadata. For example, cluster . mutaters (type=json): Add new columns to the metadata for grouping/subsetting. They are passed to sobj@meta.data |> mutate(...) . For example, {\"timepoint\": \"if_else(treatment == 'control', 'pre', 'post')\"} will add a new column timepoint to the metadata with values of pre and post based on the treatment column. ncores (type=int): Number of cores to use for parallelization for each process","title":"Group arguments"},{"location":"processes/ScrnaMetabolicLandscape/#reference","text":"Xiao, Zhengtao, Ziwei Dai, and Jason W. Locasale. \"Metabolic landscape of the tumor microenvironment at single cell resolution.\" Nature communications 10.1 (2019): 1-12.","title":"Reference"},{"location":"processes/SeuratClusterStats/","text":"SeuratClusterStats \u00b6 Statistics of the clustering. Including the number/fraction of cells in each cluster, the gene expression values and dimension reduction plots. It's also possible to perform stats on TCR clones/clusters or other metadata for each T-cell cluster. Input \u00b6 srtobj : The seurat object loaded by SeuratClustering Output \u00b6 outdir : Default: {{in.srtobj | stem}}.cluster_stats . The output directory. Different types of plots will be saved in different subdirectories. For example, clustree plots will be saved in clustrees subdirectory. For each case in envs.clustrees , both the png and pdf files will be saved. Environment Variables \u00b6 mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . cache ( type=auto ) : Default: /tmp . Whether to cache the plots. Currently only plots for features are supported, since creating the those plots can be time consuming. If True , the plots will be cached in the job output directory, which will be not cleaned up when job is rerunning. clustrees_defaults ( ns ) : The parameters for the clustree plots. devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. prefix ( type=auto ) : Default: True . string indicating columns containing clustering information. The trailing dot is not necessary and will be added automatically. When TRUE , clustrees will be plotted when there is FindClusters or FindClusters.* in the obj@commands . The latter is generated by SeuratSubClustering . This will be ignored when envs.clustrees is specified (the prefix of each case must be specified separately). <more> : Other arguments passed to scplotter::ClustreePlot . See https://pwwang.github.io/scplotter/reference/ClustreePlot.html clustrees ( type=json ) : Default: {} . The cases for clustree plots. Keys are the names of the plots and values are the dicts inherited from env.clustrees_defaults except prefix . There is no default case for clustrees . stats_defaults ( ns ) : The default parameters for stats . This is to do some basic statistics on the clusters/cells. For more comprehensive analysis, see https://pwwang.github.io/scplotter/reference/CellStatPlot.html . The parameters from the cases can overwrite the default parameters. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::CellStatPlot . See https://pwwang.github.io/scplotter/reference/CellStatPlot.html . stats ( type=json ) : Default: {'Number of cells in each cluster (Bar Chart)': Diot({'plot_type': 'bar', 'x_text_angle': 90}), 'Number of cells in each cluster by Sample (Bar Chart)': Diot({'plot_type': 'bar', 'group_by': 'Sample', 'x_text_angle': 90})} . The number/fraction of cells to plot. Keys are the names of the plots and values are the dicts inherited from env.stats_defaults . ngenes_defaults ( ns ) : The default parameters for ngenes . The default parameters to plot the number of genes expressed in each cell. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : Default: 800 . The height of the plots. width ( type=int ) : Default: 1000 . The width of the plots. ngenes ( type=json ) : Default: {'Number of genes expressed in each cluster': Diot({})} . The number of genes expressed in each cell. Keys are the names of the plots and values are the dicts inherited from env.ngenes_defaults . features_defaults ( ns ) : The default parameters for features . features ( type=auto ) : The features to plot. It can be either a string with comma separated features, a list of features, a file path with file:// prefix with features (one per line), or an integer to use the top N features from VariantFeatures(srtobj) . It can also be a dict with the keys as the feature group names and the values as the features, which is used for heatmap to group the features. order_by ( type=auto ) : The order of the clusters to show on the plot. An expression passed to dplyr::arrange() on the grouped meta data frame (by ident ). For example, you can order the clusters by the activation score of the cluster: desc(mean(ActivationScore, na.rm = TRUE)) , suppose you have a column ActivationScore in the metadata. You may also specify the literal order of the clusters by a list of strings (at least two). subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::FeatureStatPlot . See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html features ( type=json ) : Default: {} . The plots for features, include gene expressions, and columns from metadata. Keys are the titles of the cases and values are the dicts inherited from env.features_defaults . dimplots_defaults ( ns ) : The default parameters for dimplots . group_by : The identity to use. If it is from subclustering (reduction sub_umap_<ident> exists), this reduction will be used if reduction is set to dim or auto . split_by : The column name in metadata to split the cells into different plots. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. reduction ( choice ) : Default: dim . Which dimensionality reduction to use. dim : Use Seurat::DimPlot . First searches for umap , then tsne , then pca . If ident is from subclustering, sub_umap_<ident> will be used. auto : Same as dim umap : Use Seurat::UMAPPlot . tsne : Use Seurat::TSNEPlot . pca : Use Seurat::PCAPlot . <more> : See https://pwwang.github.io/scplotter/reference/CellDimPlot.html dimplots ( type=json ) : Default: {'Dimensional reduction plot': Diot({'label': True}), 'VDJ Presence': Diot({'group_by': 'VDJ_Presence'})} . The dimensional reduction plots. Keys are the titles of the plots and values are the dicts inherited from env.dimplots_defaults . It can also have other parameters from scplotter::CellDimPlot . Examples \u00b6 Clustree Plot \u00b6 [SeuratClusterStats.envs.clustrees. \"Clustree Plot\" ] prefix = \"seurat_clusters\" devpars = { height = 500 } Number of cells in each cluster (Bar Chart) \u00b6 [SeuratClusterStats.envs.stats. \"Number of cells in each cluster (Bar Chart)\" ] plot_type = \"bar\" x_text_angle = 90 Number of cells in each cluster by Sample (Bar Chart) \u00b6 [SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Sample (Bar Chart)\" ] plot_type = \"bar\" group_by = \"Sample\" x_text_angle = 90 Number of cells in each cluster by Diagnosis \u00b6 [SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Diagnosis\" ] plot_type = \"bar\" group_by = \"Diagnosis\" frac = \"group\" x_text_angle = 90 swap = true position = \"stack\" Number of cells in each cluster by Diagnosis (Circos Plot) \u00b6 [SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Diagnosis (Circos Plot)\" ] plot_type = \"circos\" group_by = \"Diagnosis\" Number of cells in each cluster by Diagnosis (Sankey Plot) \u00b6 [SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Diagnosis (Sankey Plot)\" ] plot_type = \"sankey\" group_by = [ \"seurat_clusters\" , \"Diagnosis\" ] links_alpha = 0.6 devpars = { width = 800 } Number of cells in each cluster by Sample (Spider Plot) \u00b6 [SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Sample (Spider Plot)\" ] plot_type = \"spider\" group_by = \"Diagnosis\" palette = \"Set1\" Number of genes detected in each cluster \u00b6 [SeuratClusterStats.envs.ngenes. \"Number of genes detected in each cluster\" ] plot_type = \"violin\" add_box = true add_point = true Feature Expression in Clusters (Violin Plots) \u00b6 [SeuratClusterStats.envs.features_defaults] features = [ \"CD3D\" , \"CD4\" , \"CD8A\" , \"MS4A1\" , \"CD14\" , \"LYZ\" , \"FCGR3A\" , \"NCAM1\" , \"KLRD1\" ] [SeuratClusterStats.envs.features. \"Feature Expression in Clusters (Violin Plots)\" ] plot_type = \"violin\" ident = \"seurat_clusters\" Feature Expression in Clusters (Ridge Plots) \u00b6 # Using the same features as above [SeuratClusterStats.envs.features. \"Feature Expression in Clusters (Ridge Plots)\" ] plot_type = \"ridge\" ident = \"seurat_clusters\" flip = true Feature Expression in Clusters by Diagnosis \u00b6 # Using the same features as above [SeuratClusterStats.envs.features. \"Feature Expression in Clusters by Diagnosis\" ] plot_type = \"violin\" group_by = \"Diagnosis\" ident = \"seurat_clusters\" comparisons = true sig_label = \"p.signif\" Feature Expression in Clusters (stacked) \u00b6 # Using the same features as above [SeuratClusterStats.envs.features. \"Feature Expression in Clusters (stacked)\" ] plot_type = \"violin\" ident = \"seurat_clusters\" add_bg = true stack = true add_box = true CD4 Expression on UMAP \u00b6 [SeuratClusterStats.envs.features. \"CD4 Expression on UMAP\" ] plot_type = \"dim\" feature = \"CD4\" highlight = \"seurat_clusters == 'c1'\" Feature Expression in Clusters by Diagnosis (Heatmap) \u00b6 [SeuratClusterStats.envs.features. \"Feature Expression in Clusters by Diagnosis (Heatmap)\" ] # Grouped features features = { \"T cell markers\" = [ \"CD3D\" , \"CD4\" , \"CD8A\" ], \"B cell markers\" = [ \"MS4A1\" ], \"Monocyte markers\" = [ \"CD14\" , \"LYZ\" , \"FCGR3A\" ], \"NK cell markers\" = [ \"NCAM1\" , \"KLRD1\" ]} plot_type = \"heatmap\" ident = \"Diagnosis\" columns_split_by = \"seurat_clusters\" name = \"Expression\" devpars = { height = 560 } Feature Expression in Clusters by Diagnosis (Heatmap with annotations) \u00b6 # Using the default features [SeuratClusterStats.envs.features. \"Feature Expression in Clusters by Diagnosis (Heatmap with annotations)\" ] ident = \"seurat_clusters\" cell_type = \"dot\" plot_type = \"heatmap\" name = \"Expression Level\" dot_size = \"nanmean\" dot_size_name = \"Percent Expressed\" add_bg = true rows_split_by = \"Diagnosis\" cluster_rows = false flip = true palette = \"YlOrRd\" column_annotation = [ \"percent.mt\" , \"VDJ_Presence\" ] column_annotation_type = { \"percent.mt\" = \"violin\" , VDJ_Presence = \"pie\" } column_annotation_params = { \"percent.mt\" = { show_legend = false }} devpars = { width = 1400 , height = 900 } Dimensional reduction plot \u00b6 [SeuratClusterStats.envs.features. \"Dimensional reduction plot\" ] label = true Dimensional reduction plot (with marks) \u00b6 [SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot (with marks)\" ] add_mark = true mark_linetype = 2 Dimensional reduction plot (with hex bins) \u00b6 [SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot (with hex bins)\" ] hex = true hex_bins = 50 Dimensional reduction plot (with Diagnosis stats) \u00b6 [SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot (with Diagnosis stats)\" ] stat_by = \"Diagnosis\" stat_plot_type = \"ring\" stat_plot_size = 0.15 Dimensional reduction plot by Diagnosis \u00b6 [SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot by Diagnosis\" ] facet_by = \"Diagnosis\" highlight = true theme = \"theme_blank\"","title":"SeuratClusterStats"},{"location":"processes/SeuratClusterStats/#seuratclusterstats","text":"Statistics of the clustering. Including the number/fraction of cells in each cluster, the gene expression values and dimension reduction plots. It's also possible to perform stats on TCR clones/clusters or other metadata for each T-cell cluster.","title":"SeuratClusterStats"},{"location":"processes/SeuratClusterStats/#input","text":"srtobj : The seurat object loaded by SeuratClustering","title":"Input"},{"location":"processes/SeuratClusterStats/#output","text":"outdir : Default: {{in.srtobj | stem}}.cluster_stats . The output directory. Different types of plots will be saved in different subdirectories. For example, clustree plots will be saved in clustrees subdirectory. For each case in envs.clustrees , both the png and pdf files will be saved.","title":"Output"},{"location":"processes/SeuratClusterStats/#environment-variables","text":"mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. You can also use the clone selectors to select the TCR clones/clusters. See https://pwwang.github.io/scplotter/reference/clone_selectors.html . cache ( type=auto ) : Default: /tmp . Whether to cache the plots. Currently only plots for features are supported, since creating the those plots can be time consuming. If True , the plots will be cached in the job output directory, which will be not cleaned up when job is rerunning. clustrees_defaults ( ns ) : The parameters for the clustree plots. devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. prefix ( type=auto ) : Default: True . string indicating columns containing clustering information. The trailing dot is not necessary and will be added automatically. When TRUE , clustrees will be plotted when there is FindClusters or FindClusters.* in the obj@commands . The latter is generated by SeuratSubClustering . This will be ignored when envs.clustrees is specified (the prefix of each case must be specified separately). <more> : Other arguments passed to scplotter::ClustreePlot . See https://pwwang.github.io/scplotter/reference/ClustreePlot.html clustrees ( type=json ) : Default: {} . The cases for clustree plots. Keys are the names of the plots and values are the dicts inherited from env.clustrees_defaults except prefix . There is no default case for clustrees . stats_defaults ( ns ) : The default parameters for stats . This is to do some basic statistics on the clusters/cells. For more comprehensive analysis, see https://pwwang.github.io/scplotter/reference/CellStatPlot.html . The parameters from the cases can overwrite the default parameters. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the clustree plot. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::CellStatPlot . See https://pwwang.github.io/scplotter/reference/CellStatPlot.html . stats ( type=json ) : Default: {'Number of cells in each cluster (Bar Chart)': Diot({'plot_type': 'bar', 'x_text_angle': 90}), 'Number of cells in each cluster by Sample (Bar Chart)': Diot({'plot_type': 'bar', 'group_by': 'Sample', 'x_text_angle': 90})} . The number/fraction of cells to plot. Keys are the names of the plots and values are the dicts inherited from env.stats_defaults . ngenes_defaults ( ns ) : The default parameters for ngenes . The default parameters to plot the number of genes expressed in each cell. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : Default: 800 . The height of the plots. width ( type=int ) : Default: 1000 . The width of the plots. ngenes ( type=json ) : Default: {'Number of genes expressed in each cluster': Diot({})} . The number of genes expressed in each cell. Keys are the names of the plots and values are the dicts inherited from env.ngenes_defaults . features_defaults ( ns ) : The default parameters for features . features ( type=auto ) : The features to plot. It can be either a string with comma separated features, a list of features, a file path with file:// prefix with features (one per line), or an integer to use the top N features from VariantFeatures(srtobj) . It can also be a dict with the keys as the feature group names and the values as the features, which is used for heatmap to group the features. order_by ( type=auto ) : The order of the clusters to show on the plot. An expression passed to dplyr::arrange() on the grouped meta data frame (by ident ). For example, you can order the clusters by the activation score of the cluster: desc(mean(ActivationScore, na.rm = TRUE)) , suppose you have a column ActivationScore in the metadata. You may also specify the literal order of the clusters by a list of strings (at least two). subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. descr : The description of the plot, showing in the report. more_formats ( type=list ) : Default: [] . The formats to save the plots other than png . save_code ( flag ) : Default: False . Whether to save the code to reproduce the plot. save_data ( flag ) : Default: False . Whether to save the data used to generate the plot. <more> : Other arguments passed to scplotter::FeatureStatPlot . See https://pwwang.github.io/scplotter/reference/FeatureStatPlot.html features ( type=json ) : Default: {} . The plots for features, include gene expressions, and columns from metadata. Keys are the titles of the cases and values are the dicts inherited from env.features_defaults . dimplots_defaults ( ns ) : The default parameters for dimplots . group_by : The identity to use. If it is from subclustering (reduction sub_umap_<ident> exists), this reduction will be used if reduction is set to dim or auto . split_by : The column name in metadata to split the cells into different plots. subset : An expression to subset the cells, will be passed to tidyrseurat::filter() . devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. reduction ( choice ) : Default: dim . Which dimensionality reduction to use. dim : Use Seurat::DimPlot . First searches for umap , then tsne , then pca . If ident is from subclustering, sub_umap_<ident> will be used. auto : Same as dim umap : Use Seurat::UMAPPlot . tsne : Use Seurat::TSNEPlot . pca : Use Seurat::PCAPlot . <more> : See https://pwwang.github.io/scplotter/reference/CellDimPlot.html dimplots ( type=json ) : Default: {'Dimensional reduction plot': Diot({'label': True}), 'VDJ Presence': Diot({'group_by': 'VDJ_Presence'})} . The dimensional reduction plots. Keys are the titles of the plots and values are the dicts inherited from env.dimplots_defaults . It can also have other parameters from scplotter::CellDimPlot .","title":"Environment Variables"},{"location":"processes/SeuratClusterStats/#examples","text":"","title":"Examples"},{"location":"processes/SeuratClusterStats/#clustree-plot","text":"[SeuratClusterStats.envs.clustrees. \"Clustree Plot\" ] prefix = \"seurat_clusters\" devpars = { height = 500 }","title":"Clustree Plot"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-bar-chart","text":"[SeuratClusterStats.envs.stats. \"Number of cells in each cluster (Bar Chart)\" ] plot_type = \"bar\" x_text_angle = 90","title":"Number of cells in each cluster (Bar Chart)"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-by-sample-bar-chart","text":"[SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Sample (Bar Chart)\" ] plot_type = \"bar\" group_by = \"Sample\" x_text_angle = 90","title":"Number of cells in each cluster by Sample (Bar Chart)"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-by-diagnosis","text":"[SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Diagnosis\" ] plot_type = \"bar\" group_by = \"Diagnosis\" frac = \"group\" x_text_angle = 90 swap = true position = \"stack\"","title":"Number of cells in each cluster by Diagnosis"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-by-diagnosis-circos-plot","text":"[SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Diagnosis (Circos Plot)\" ] plot_type = \"circos\" group_by = \"Diagnosis\"","title":"Number of cells in each cluster by Diagnosis (Circos Plot)"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-by-diagnosis-sankey-plot","text":"[SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Diagnosis (Sankey Plot)\" ] plot_type = \"sankey\" group_by = [ \"seurat_clusters\" , \"Diagnosis\" ] links_alpha = 0.6 devpars = { width = 800 }","title":"Number of cells in each cluster by Diagnosis (Sankey Plot)"},{"location":"processes/SeuratClusterStats/#number-of-cells-in-each-cluster-by-sample-spider-plot","text":"[SeuratClusterStats.envs.stats. \"Number of cells in each cluster by Sample (Spider Plot)\" ] plot_type = \"spider\" group_by = \"Diagnosis\" palette = \"Set1\"","title":"Number of cells in each cluster by Sample (Spider Plot)"},{"location":"processes/SeuratClusterStats/#number-of-genes-detected-in-each-cluster","text":"[SeuratClusterStats.envs.ngenes. \"Number of genes detected in each cluster\" ] plot_type = \"violin\" add_box = true add_point = true","title":"Number of genes detected in each cluster"},{"location":"processes/SeuratClusterStats/#feature-expression-in-clusters-violin-plots","text":"[SeuratClusterStats.envs.features_defaults] features = [ \"CD3D\" , \"CD4\" , \"CD8A\" , \"MS4A1\" , \"CD14\" , \"LYZ\" , \"FCGR3A\" , \"NCAM1\" , \"KLRD1\" ] [SeuratClusterStats.envs.features. \"Feature Expression in Clusters (Violin Plots)\" ] plot_type = \"violin\" ident = \"seurat_clusters\"","title":"Feature Expression in Clusters (Violin Plots)"},{"location":"processes/SeuratClusterStats/#feature-expression-in-clusters-ridge-plots","text":"# Using the same features as above [SeuratClusterStats.envs.features. \"Feature Expression in Clusters (Ridge Plots)\" ] plot_type = \"ridge\" ident = \"seurat_clusters\" flip = true","title":"Feature Expression in Clusters (Ridge Plots)"},{"location":"processes/SeuratClusterStats/#feature-expression-in-clusters-by-diagnosis","text":"# Using the same features as above [SeuratClusterStats.envs.features. \"Feature Expression in Clusters by Diagnosis\" ] plot_type = \"violin\" group_by = \"Diagnosis\" ident = \"seurat_clusters\" comparisons = true sig_label = \"p.signif\"","title":"Feature Expression in Clusters by Diagnosis"},{"location":"processes/SeuratClusterStats/#feature-expression-in-clusters-stacked","text":"# Using the same features as above [SeuratClusterStats.envs.features. \"Feature Expression in Clusters (stacked)\" ] plot_type = \"violin\" ident = \"seurat_clusters\" add_bg = true stack = true add_box = true","title":"Feature Expression in Clusters (stacked)"},{"location":"processes/SeuratClusterStats/#cd4-expression-on-umap","text":"[SeuratClusterStats.envs.features. \"CD4 Expression on UMAP\" ] plot_type = \"dim\" feature = \"CD4\" highlight = \"seurat_clusters == 'c1'\"","title":"CD4 Expression on UMAP"},{"location":"processes/SeuratClusterStats/#feature-expression-in-clusters-by-diagnosis-heatmap","text":"[SeuratClusterStats.envs.features. \"Feature Expression in Clusters by Diagnosis (Heatmap)\" ] # Grouped features features = { \"T cell markers\" = [ \"CD3D\" , \"CD4\" , \"CD8A\" ], \"B cell markers\" = [ \"MS4A1\" ], \"Monocyte markers\" = [ \"CD14\" , \"LYZ\" , \"FCGR3A\" ], \"NK cell markers\" = [ \"NCAM1\" , \"KLRD1\" ]} plot_type = \"heatmap\" ident = \"Diagnosis\" columns_split_by = \"seurat_clusters\" name = \"Expression\" devpars = { height = 560 }","title":"Feature Expression in Clusters by Diagnosis (Heatmap)"},{"location":"processes/SeuratClusterStats/#feature-expression-in-clusters-by-diagnosis-heatmap-with-annotations","text":"# Using the default features [SeuratClusterStats.envs.features. \"Feature Expression in Clusters by Diagnosis (Heatmap with annotations)\" ] ident = \"seurat_clusters\" cell_type = \"dot\" plot_type = \"heatmap\" name = \"Expression Level\" dot_size = \"nanmean\" dot_size_name = \"Percent Expressed\" add_bg = true rows_split_by = \"Diagnosis\" cluster_rows = false flip = true palette = \"YlOrRd\" column_annotation = [ \"percent.mt\" , \"VDJ_Presence\" ] column_annotation_type = { \"percent.mt\" = \"violin\" , VDJ_Presence = \"pie\" } column_annotation_params = { \"percent.mt\" = { show_legend = false }} devpars = { width = 1400 , height = 900 }","title":"Feature Expression in Clusters by Diagnosis (Heatmap with annotations)"},{"location":"processes/SeuratClusterStats/#dimensional-reduction-plot","text":"[SeuratClusterStats.envs.features. \"Dimensional reduction plot\" ] label = true","title":"Dimensional reduction plot"},{"location":"processes/SeuratClusterStats/#dimensional-reduction-plot-with-marks","text":"[SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot (with marks)\" ] add_mark = true mark_linetype = 2","title":"Dimensional reduction plot (with marks)"},{"location":"processes/SeuratClusterStats/#dimensional-reduction-plot-with-hex-bins","text":"[SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot (with hex bins)\" ] hex = true hex_bins = 50","title":"Dimensional reduction plot (with hex bins)"},{"location":"processes/SeuratClusterStats/#dimensional-reduction-plot-with-diagnosis-stats","text":"[SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot (with Diagnosis stats)\" ] stat_by = \"Diagnosis\" stat_plot_type = \"ring\" stat_plot_size = 0.15","title":"Dimensional reduction plot (with Diagnosis stats)"},{"location":"processes/SeuratClusterStats/#dimensional-reduction-plot-by-diagnosis","text":"[SeuratClusterStats.envs.dimplots. \"Dimensional reduction plot by Diagnosis\" ] facet_by = \"Diagnosis\" highlight = true theme = \"theme_blank\"","title":"Dimensional reduction plot by Diagnosis"},{"location":"processes/SeuratClustering/","text":"SeuratClustering \u00b6 Cluster all cells or selected T/B cells selected by TOrBCellSelection . If [TOrBCellSelection] is not set in the configuration, meaning all cells are T/B cells, this process will be run on all T/B cells. Otherwise, this process will be run on the selected T/B cells by TOrBCellSelection . Note If you have other annotation processes, including SeuratMap2Ref process or CellTypeAnnotation process enabled in the same run, you can specify a different name for the column to store the cluster information using envs.ident , so that the results from different annotation processes won't overwrite each other. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters or the name specified by envs.ident Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html ident : Default: seurat_clusters . The name in the metadata to save the cluster labels. A shortcut for envs[\"FindClusters\"][\"cluster.name\"] . RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. You can also specify features instead of dims to use specific features for UMAP. It can be a list with the following fields: order (the order of the markers to use for UMAP, e.g. \"desc(abs(avg_log2FC))\", and n (the number of total features to use for UMAP, e.g. 30). If features is a list, it will run biopipen.utils::RunSeuratDEAnalysis to get the markers for each group, and then select the top n / ngroups features for each group based on the order field. If features is a numeric value, it will be treated as the n field in the list above, with the default order being \"desc(abs(avg_log2FC))\". dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in cluster names and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <ident>_<resolution> . The final resolution will be used to define the clusters at <ident> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. SeeAlso \u00b6 SeuratClusteringOfAllCells Metadata \u00b6 The metadata of the Seurat object will be updated with the cluster assignments:","title":"SeuratClustering"},{"location":"processes/SeuratClustering/#seuratclustering","text":"Cluster all cells or selected T/B cells selected by TOrBCellSelection . If [TOrBCellSelection] is not set in the configuration, meaning all cells are T/B cells, this process will be run on all T/B cells. Otherwise, this process will be run on the selected T/B cells by TOrBCellSelection . Note If you have other annotation processes, including SeuratMap2Ref process or CellTypeAnnotation process enabled in the same run, you can specify a different name for the column to store the cluster information using envs.ident , so that the results from different annotation processes won't overwrite each other.","title":"SeuratClustering"},{"location":"processes/SeuratClustering/#input","text":"srtobj : The seurat object loaded by SeuratPreparing","title":"Input"},{"location":"processes/SeuratClustering/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters or the name specified by envs.ident","title":"Output"},{"location":"processes/SeuratClustering/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html ident : Default: seurat_clusters . The name in the metadata to save the cluster labels. A shortcut for envs[\"FindClusters\"][\"cluster.name\"] . RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. You can also specify features instead of dims to use specific features for UMAP. It can be a list with the following fields: order (the order of the markers to use for UMAP, e.g. \"desc(abs(avg_log2FC))\", and n (the number of total features to use for UMAP, e.g. 30). If features is a list, it will run biopipen.utils::RunSeuratDEAnalysis to get the markers for each group, and then select the top n / ngroups features for each group based on the order field. If features is a numeric value, it will be treated as the n field in the list above, with the default order being \"desc(abs(avg_log2FC))\". dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in cluster names and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <ident>_<resolution> . The final resolution will be used to define the clusters at <ident> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results.","title":"Environment Variables"},{"location":"processes/SeuratClustering/#seealso","text":"SeuratClusteringOfAllCells","title":"SeeAlso"},{"location":"processes/SeuratClustering/#metadata","text":"The metadata of the Seurat object will be updated with the cluster assignments:","title":"Metadata"},{"location":"processes/SeuratClusteringOfAllCells/","text":"SeuratClusteringOfAllCells \u00b6 Cluster all cells, including T cells/non-T cells and B cells/non-Bcells using Seurat. This process will perform clustering on all cells using Seurat package. The clusters will then be used to select T/B cells by TOrBCellSelection process. Note If all your cells are all T/B cells ( TOrBCellSelection is not set in configuration), you should not use this process. Instead, you should use SeuratClustering process for unsupervised clustering, or SeuratMap2Ref process for supervised clustering. Input \u00b6 srtobj : The seurat object loaded by SeuratPreparing Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters or the name specified by envs.ident Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html ident : Default: seurat_clusters . The name in the metadata to save the cluster labels. A shortcut for envs[\"FindClusters\"][\"cluster.name\"] . RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. You can also specify features instead of dims to use specific features for UMAP. It can be a list with the following fields: order (the order of the markers to use for UMAP, e.g. \"desc(abs(avg_log2FC))\", and n (the number of total features to use for UMAP, e.g. 30). If features is a list, it will run biopipen.utils::RunSeuratDEAnalysis to get the markers for each group, and then select the top n / ngroups features for each group based on the order field. If features is a numeric value, it will be treated as the n field in the list above, with the default order being \"desc(abs(avg_log2FC))\". dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in cluster names and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <ident>_<resolution> . The final resolution will be used to define the clusters at <ident> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. SeeAlso \u00b6 SeuratClustering","title":"SeuratClusteringOfAllCells"},{"location":"processes/SeuratClusteringOfAllCells/#seuratclusteringofallcells","text":"Cluster all cells, including T cells/non-T cells and B cells/non-Bcells using Seurat. This process will perform clustering on all cells using Seurat package. The clusters will then be used to select T/B cells by TOrBCellSelection process. Note If all your cells are all T/B cells ( TOrBCellSelection is not set in configuration), you should not use this process. Instead, you should use SeuratClustering process for unsupervised clustering, or SeuratMap2Ref process for supervised clustering.","title":"SeuratClusteringOfAllCells"},{"location":"processes/SeuratClusteringOfAllCells/#input","text":"srtobj : The seurat object loaded by SeuratPreparing","title":"Input"},{"location":"processes/SeuratClusteringOfAllCells/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with cluster information at seurat_clusters or the name specified by envs.ident","title":"Output"},{"location":"processes/SeuratClusteringOfAllCells/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/articles/future_vignette.html ident : Default: seurat_clusters . The name in the metadata to save the cluster labels. A shortcut for envs[\"FindClusters\"][\"cluster.name\"] . RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. You can also specify features instead of dims to use specific features for UMAP. It can be a list with the following fields: order (the order of the markers to use for UMAP, e.g. \"desc(abs(avg_log2FC))\", and n (the number of total features to use for UMAP, e.g. 30). If features is a list, it will run biopipen.utils::RunSeuratDEAnalysis to get the markers for each group, and then select the top n / ngroups features for each group based on the order field. If features is a numeric value, it will be treated as the n field in the list above, with the default order being \"desc(abs(avg_log2FC))\". dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap RunPCA ( ns ) : Arguments for RunPCA() . FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be saved in cluster names and prefixed with \"c\". The first cluster will be \"c1\", instead of \"c0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <ident>_<resolution> . The final resolution will be used to define the clusters at <ident> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Where to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results.","title":"Environment Variables"},{"location":"processes/SeuratClusteringOfAllCells/#seealso","text":"SeuratClustering","title":"SeeAlso"},{"location":"processes/SeuratMap2Ref/","text":"SeuratMap2Ref \u00b6 Map the seurat object to reference See: https://satijalab.org/seurat/articles/integration_mapping.html and https://satijalab.org/seurat/articles/multimodal_reference_mapping.html Note If you have other annotation processes, including SeuratClustering process or CellTypeAnnotation process enabled in the same run, you may want to specify a different name for the column to store the mapped cluster information using envs.ident , so that the results from different annotation processes won't overwrite each other. Input \u00b6 sobjfile : The seurat object Output \u00b6 outfile : Default: {{in.sobjfile | stem}}.qs . The rds file of seurat object with cell type annotated. Note that the reduction name will be ref.umap for the mapping. To visualize the mapping, you should use ref.umap as the reduction name. Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. When split_by is used, this will be the number of cores for each object to map to the reference. When split_by is not used, this is used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/archive/v3.0/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. This is helpful when we want to create new columns for split_by . use : A column name of metadata from the reference (e.g. celltype.l1 , celltype.l2 ) to transfer to the query as the cell types (ident) for downstream analysis. This field is required. If you want to transfer multiple columns, you can use envs.MapQuery.refdata . ident : Default: seurat_clusters . The name of the ident for query transferred from envs.use of the reference. ref : The reference seurat object file. Either an RDS file or a h5seurat file that can be loaded by Seurat::LoadH5Seurat() . The file type is determined by the extension. .rds or .RDS for RDS file, .h5seurat or .h5 for h5seurat file. refnorm ( choice ) : Default: auto . Normalization method the reference used. The same method will be used for the query. LogNormalize : Using NormalizeData . SCTransform : Using SCTransform . SCT : Alias of SCTransform. auto : Automatically detect the normalization method. If the default assay of reference is SCT , then SCTransform will be used. split_by : The column name in metadata to split the query into multiple objects. This helps when the original query is too large to process. skip_if_normalized : Default: True . Skip normalization if the query is already normalized. Since the object is supposed to be generated by SeuratPreparing , it is already normalized. However, a different normalization method may be used. If the reference is normalized by the same method as the query, the normalization can be skipped. Otherwise, the normalization cannot be skipped. The normalization method used for the query set is determined by the default assay. If SCT , then SCTransform is used; otherwise, NormalizeData is used. You can set this to False to force re-normalization (with or without the arguments previously used). SCTransform ( ns ) : Arguments for SCTransform() do-correct-umi ( flag ) : Default: False . Place corrected UMI matrix in assay counts layer? do-scale ( flag ) : Default: False . Whether to scale residuals to have unit variance? do-center ( flag ) : Default: True . Whether to center residuals to have mean zero? <more> : See https://satijalab.org/seurat/reference/sctransform . Note that the hyphen ( - ) will be transformed into . for the keys. NormalizeData ( ns ) : Arguments for NormalizeData() normalization-method : Default: LogNormalize . Normalization method. <more> : See https://satijalab.org/seurat/reference/normalizedata . Note that the hyphen ( - ) will be transformed into . for the keys. FindTransferAnchors ( ns ) : Arguments for FindTransferAnchors() normalization-method ( choice ) : Name of normalization method used. LogNormalize : Log-normalize the data matrix SCT : Scale data using the SCTransform method auto : Automatically detect the normalization method. See envs.refnorm . reference-reduction : Name of dimensional reduction to use from the reference if running the pcaproject workflow. Optionally enables reuse of precomputed reference dimensional reduction. <more> : See https://satijalab.org/seurat/reference/findtransferanchors . Note that the hyphen ( - ) will be transformed into . for the keys. MapQuery ( ns ) : Arguments for MapQuery() reference-reduction : Name of reduction to use from the reference for neighbor finding reduction-model : DimReduc object that contains the umap model. refdata ( type=json ) : Default: {} . Extra data to transfer from the reference to the query. <more> : See https://satijalab.org/seurat/reference/mapquery . Note that the hyphen ( - ) will be transformed into . for the keys. cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory. plots ( type=json ) : Default: {'Mapped Identity': Diot({'features': '{ident}:{use}'}), 'Mapping Score': Diot({'features': '{ident}.score'})} . The plots to generate. The keys are the names of the plots and the values are the arguments for the plot. The arguments will be passed to biopipen.utils::VizSeuratMap2Ref() to generate the plots. The plots will be saved to the output directory. See https://pwwang.github.io/biopipen.utils.R/reference/VizSeuratMap2Ref.html . Metadata \u00b6 The metadata of the Seurat object will be updated with the cluster assignments (column name determined by envs.name ):","title":"SeuratMap2Ref"},{"location":"processes/SeuratMap2Ref/#seuratmap2ref","text":"Map the seurat object to reference See: https://satijalab.org/seurat/articles/integration_mapping.html and https://satijalab.org/seurat/articles/multimodal_reference_mapping.html Note If you have other annotation processes, including SeuratClustering process or CellTypeAnnotation process enabled in the same run, you may want to specify a different name for the column to store the mapped cluster information using envs.ident , so that the results from different annotation processes won't overwrite each other.","title":"SeuratMap2Ref"},{"location":"processes/SeuratMap2Ref/#input","text":"sobjfile : The seurat object","title":"Input"},{"location":"processes/SeuratMap2Ref/#output","text":"outfile : Default: {{in.sobjfile | stem}}.qs . The rds file of seurat object with cell type annotated. Note that the reduction name will be ref.umap for the mapping. To visualize the mapping, you should use ref.umap as the reduction name.","title":"Output"},{"location":"processes/SeuratMap2Ref/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. When split_by is used, this will be the number of cores for each object to map to the reference. When split_by is not used, this is used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. See also: https://satijalab.org/seurat/archive/v3.0/future_vignette.html mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata. This is helpful when we want to create new columns for split_by . use : A column name of metadata from the reference (e.g. celltype.l1 , celltype.l2 ) to transfer to the query as the cell types (ident) for downstream analysis. This field is required. If you want to transfer multiple columns, you can use envs.MapQuery.refdata . ident : Default: seurat_clusters . The name of the ident for query transferred from envs.use of the reference. ref : The reference seurat object file. Either an RDS file or a h5seurat file that can be loaded by Seurat::LoadH5Seurat() . The file type is determined by the extension. .rds or .RDS for RDS file, .h5seurat or .h5 for h5seurat file. refnorm ( choice ) : Default: auto . Normalization method the reference used. The same method will be used for the query. LogNormalize : Using NormalizeData . SCTransform : Using SCTransform . SCT : Alias of SCTransform. auto : Automatically detect the normalization method. If the default assay of reference is SCT , then SCTransform will be used. split_by : The column name in metadata to split the query into multiple objects. This helps when the original query is too large to process. skip_if_normalized : Default: True . Skip normalization if the query is already normalized. Since the object is supposed to be generated by SeuratPreparing , it is already normalized. However, a different normalization method may be used. If the reference is normalized by the same method as the query, the normalization can be skipped. Otherwise, the normalization cannot be skipped. The normalization method used for the query set is determined by the default assay. If SCT , then SCTransform is used; otherwise, NormalizeData is used. You can set this to False to force re-normalization (with or without the arguments previously used). SCTransform ( ns ) : Arguments for SCTransform() do-correct-umi ( flag ) : Default: False . Place corrected UMI matrix in assay counts layer? do-scale ( flag ) : Default: False . Whether to scale residuals to have unit variance? do-center ( flag ) : Default: True . Whether to center residuals to have mean zero? <more> : See https://satijalab.org/seurat/reference/sctransform . Note that the hyphen ( - ) will be transformed into . for the keys. NormalizeData ( ns ) : Arguments for NormalizeData() normalization-method : Default: LogNormalize . Normalization method. <more> : See https://satijalab.org/seurat/reference/normalizedata . Note that the hyphen ( - ) will be transformed into . for the keys. FindTransferAnchors ( ns ) : Arguments for FindTransferAnchors() normalization-method ( choice ) : Name of normalization method used. LogNormalize : Log-normalize the data matrix SCT : Scale data using the SCTransform method auto : Automatically detect the normalization method. See envs.refnorm . reference-reduction : Name of dimensional reduction to use from the reference if running the pcaproject workflow. Optionally enables reuse of precomputed reference dimensional reduction. <more> : See https://satijalab.org/seurat/reference/findtransferanchors . Note that the hyphen ( - ) will be transformed into . for the keys. MapQuery ( ns ) : Arguments for MapQuery() reference-reduction : Name of reduction to use from the reference for neighbor finding reduction-model : DimReduc object that contains the umap model. refdata ( type=json ) : Default: {} . Extra data to transfer from the reference to the query. <more> : See https://satijalab.org/seurat/reference/mapquery . Note that the hyphen ( - ) will be transformed into . for the keys. cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory. plots ( type=json ) : Default: {'Mapped Identity': Diot({'features': '{ident}:{use}'}), 'Mapping Score': Diot({'features': '{ident}.score'})} . The plots to generate. The keys are the names of the plots and the values are the arguments for the plot. The arguments will be passed to biopipen.utils::VizSeuratMap2Ref() to generate the plots. The plots will be saved to the output directory. See https://pwwang.github.io/biopipen.utils.R/reference/VizSeuratMap2Ref.html .","title":"Environment Variables"},{"location":"processes/SeuratMap2Ref/#metadata","text":"The metadata of the Seurat object will be updated with the cluster assignments (column name determined by envs.name ):","title":"Metadata"},{"location":"processes/SeuratPreparing/","text":"SeuratPreparing \u00b6 Load, prepare and apply QC to data, using Seurat This process will - - Prepare the seurat object - Apply QC to the data - Integrate the data from different samples See also - https://satijalab.org/seurat/articles/pbmc3k_tutorial.html#standard-pre-processing-workflow-1) - https://satijalab.org/seurat/articles/integration_introduction This process will read the scRNA-seq data, based on the information provided by SampleInfo , specifically, the paths specified by the RNAData column. Those paths should be either paths to directoies containing matrix.mtx , barcodes.tsv and features.tsv files that can be loaded by Seurat::Read10X() , or paths of loom files that can be loaded by SeuratDisk::LoadLoom() , or paths to h5 files that can be loaded by Seurat::Read10X_h5() . Each sample will be loaded individually and then merged into one Seurat object, and then perform QC. In order to perform QC, some additional columns are added to the meta data of the Seurat object. They are: precent.mt : The percentage of mitochondrial genes. percent.ribo : The percentage of ribosomal genes. precent.hb : The percentage of hemoglobin genes. percent.plat : The percentage of platelet genes. For integration, two routes are available: Performing integration on datasets normalized with SCTransform Using NormalizeData and FindIntegrationAnchors Note When using SCTransform , the default Assay will be set to SCT in output, rather than RNA . If you are using cca or rpca interation, the default assay will be integrated . Note From biopipen v0.23.0, this requires Seurat v5.0.0 or higher. See also Preparing the input . Input \u00b6 metafile : The metadata of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. RNAData to assign the path of the data to the samples The path will be read by Read10X() from Seurat , or the path to the h5 file that can be read by Read10X_h5() from Seurat . It can also be an RDS or qs2 file containing a Seurat object. Note that it must has a column named Sample in the meta.data to specify the sample names. Output \u00b6 outfile : Default: {{in.metafile | stem}}.seurat.qs . The qs2 file with the Seurat object with all samples integrated. Note that the cell ids are prefixied with sample names. Environment Variables \u00b6 ncores ( type=int ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to the cells. These new columns will be added to the metadata of the Seurat object and will be saved in the output file. min_cells ( type=int ) : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. min_features ( type=int ) : Default: 0 . The minimum number of features that a cell must express to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. cell_qc : Filter expression to filter cells, using tidyrseurat::filter() . It can also be a dictionary of expressions, where the names of the list are sample names. You can have a default expression in the list with the name \"DEFAULT\" for the samples that are not listed. Available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . Example Including the columns added above, all available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . For example: [SeuratPreparing.envs] cell_qc = \"nFeature_RNA > 200 & percent.mt < 5\" will keep cells with more than 200 genes and less than 5%% mitochondrial genes. gene_qc ( ns ) : Filter genes. gene_qc is applied after cell_qc . min_cells : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. excludes : Default: [] . The genes to exclude. Multiple genes can be specified by comma separated values, or as a list. Example [SeuratPreparing.envs] gene_qc = { min_cells = 3 } will keep genes that are expressed in at least 3 cells. qc_plots ( type=json ) : Default: {'Violin Plots': Diot({'kind': 'cell', 'plot_type': 'violin', 'devpars': Diot({'res': 100, 'height': 600, 'width': 1200})}), 'Scatter Plots': Diot({'kind': 'cell', 'plot_type': 'scatter', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Ridge Plots': Diot({'kind': 'cell', 'plot_type': 'ridge', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Distribution of number of cells a gene is expressed in': Diot({'kind': 'gene', 'plot_type': 'histogram', 'devpars': Diot({'res': 100, 'height': 1200, 'width': 1200})})} . The plots for QC metrics. It should be a json (or python dict) with the keys as the names of the plots and the values also as dicts with the following keys: kind: The kind of QC. Either gene or cell (default). devpars: The device parameters for the plot. A dict with res , height , and width . more_formats: The formats to save the plots other than png . save_code: Whether to save the code to reproduce the plot. other arguments passed to biopipen.utils::VizSeuratCellQC when kind is cell or biopipen.utils::VizSeuratGeneQC when kind is gene . use_sct ( flag ) : Default: False . Whether use SCTransform routine to integrate samples or not. Before the following procedures, the RNA layer will be split by samples. If False , following procedures will be performed in the order: * NormalizeData . * FindVariableFeatures . * ScaleData . See https://satijalab.org/seurat/articles/seurat5_integration#layers-in-the-seurat-v5-object and https://satijalab.org/seurat/articles/pbmc3k_tutorial.html If True , following procedures will be performed in the order: * SCTransform . See https://satijalab.org/seurat/articles/seurat5_integration#perform-streamlined-one-line-integrative-analysis no_integration ( flag ) : Default: False . Whether to skip integration or not. NormalizeData ( ns ) : Arguments for NormalizeData() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/normalizedata FindVariableFeatures ( ns ) : Arguments for FindVariableFeatures() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/findvariablefeatures ScaleData ( ns ) : Arguments for ScaleData() . object and features is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/scaledata RunPCA ( ns ) : Arguments for RunPCA() . object and features is specified internally, and - in the key will be replaced with . . npcs ( type=int ) : The number of PCs to compute. For each sample, npcs will be no larger than the number of columns - 1. <more> : See https://satijalab.org/seurat/reference/runpca SCTransform ( ns ) : Arguments for SCTransform() . object is specified internally, and - in the key will be replaced with . . return-only-var-genes : Default: False . Whether to return only variable genes. min_cells : Default: 3 . The minimum number of cells that a gene must be expressed in to be kept. A hidden argument of SCTransform to filter genes. If you try to keep all genes in the RNA assay, you can set min_cells to 0 and return-only-var-genes to False . See https://github.com/satijalab/seurat/issues/3598#issuecomment-715505537 <more> : See https://satijalab.org/seurat/reference/sctransform verbose : Default: True . IntegrateLayers ( ns ) : Arguments for IntegrateLayers() . object is specified internally, and - in the key will be replaced with . . When use_sct is True , normalization-method defaults to SCT . method ( choice ) : Default: harmony . The method to use for integration. CCAIntegration : Use Seurat::CCAIntegration . CCA : Same as CCAIntegration . cca : Same as CCAIntegration . RPCAIntegration : Use Seurat::RPCAIntegration . RPCA : Same as RPCAIntegration . rpca : Same as RPCAIntegration . HarmonyIntegration : Use Seurat::HarmonyIntegration . Harmony : Same as HarmonyIntegration . harmony : Same as HarmonyIntegration . FastMNNIntegration : Use Seurat::FastMNNIntegration . FastMNN : Same as FastMNNIntegration . fastmnn : Same as FastMNNIntegration . scVIIntegration : Use Seurat::scVIIntegration . scVI : Same as scVIIntegration . scvi : Same as scVIIntegration . <more> : See https://satijalab.org/seurat/reference/integratelayers doublet_detector ( choice ) : Default: none . The doublet detector to use. none : Do not use any doublet detector. DoubletFinder : Use DoubletFinder to detect doublets. doubletfinder : Same as DoubletFinder . scDblFinder : Use scDblFinder to detect doublets. scdblfinder : Same as scDblFinder . DoubletFinder ( ns ) : Arguments to run DoubletFinder . See also https://demultiplexing-doublet-detecting-docs.readthedocs.io/en/latest/DoubletFinder.html . PCs ( type=int ) : Default: 10 . Number of PCs to use for 'doubletFinder' function. doublets ( type=float ) : Default: 0.075 . Number of expected doublets as a proportion of the pool size. pN ( type=float ) : Default: 0.25 . Number of doublets to simulate as a proportion of the pool size. ncores ( type=int ) : Default: 1 . Number of cores to use for DoubletFinder::paramSweep . Set to None to use envs.ncores . Since parallelization of the function usually exhausts memory, if big envs.ncores does not work for DoubletFinder , set this to a smaller number. scDblFinder ( ns ) : Arguments to run scDblFinder . dbr ( type=float ) : Default: 0.075 . The expected doublet rate. ncores ( type=int ) : Default: 1 . Number of cores to use for scDblFinder . Set to None to use envs.ncores . <more> : See https://rdrr.io/bioc/scDblFinder/man/scDblFinder.html . cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory. Metadata \u00b6 Here is the demonstration of basic metadata for the Seurat object. Future processes will use it and/or add more metadata to the Seurat object.","title":"SeuratPreparing"},{"location":"processes/SeuratPreparing/#seuratpreparing","text":"Load, prepare and apply QC to data, using Seurat This process will - - Prepare the seurat object - Apply QC to the data - Integrate the data from different samples See also - https://satijalab.org/seurat/articles/pbmc3k_tutorial.html#standard-pre-processing-workflow-1) - https://satijalab.org/seurat/articles/integration_introduction This process will read the scRNA-seq data, based on the information provided by SampleInfo , specifically, the paths specified by the RNAData column. Those paths should be either paths to directoies containing matrix.mtx , barcodes.tsv and features.tsv files that can be loaded by Seurat::Read10X() , or paths of loom files that can be loaded by SeuratDisk::LoadLoom() , or paths to h5 files that can be loaded by Seurat::Read10X_h5() . Each sample will be loaded individually and then merged into one Seurat object, and then perform QC. In order to perform QC, some additional columns are added to the meta data of the Seurat object. They are: precent.mt : The percentage of mitochondrial genes. percent.ribo : The percentage of ribosomal genes. precent.hb : The percentage of hemoglobin genes. percent.plat : The percentage of platelet genes. For integration, two routes are available: Performing integration on datasets normalized with SCTransform Using NormalizeData and FindIntegrationAnchors Note When using SCTransform , the default Assay will be set to SCT in output, rather than RNA . If you are using cca or rpca interation, the default assay will be integrated . Note From biopipen v0.23.0, this requires Seurat v5.0.0 or higher. See also Preparing the input .","title":"SeuratPreparing"},{"location":"processes/SeuratPreparing/#input","text":"metafile : The metadata of the samples A tab-delimited file Two columns are required: Sample to specify the sample names. RNAData to assign the path of the data to the samples The path will be read by Read10X() from Seurat , or the path to the h5 file that can be read by Read10X_h5() from Seurat . It can also be an RDS or qs2 file containing a Seurat object. Note that it must has a column named Sample in the meta.data to specify the sample names.","title":"Input"},{"location":"processes/SeuratPreparing/#output","text":"outfile : Default: {{in.metafile | stem}}.seurat.qs . The qs2 file with the Seurat object with all samples integrated. Note that the cell ids are prefixied with sample names.","title":"Output"},{"location":"processes/SeuratPreparing/#environment-variables","text":"ncores ( type=int ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to the cells. These new columns will be added to the metadata of the Seurat object and will be saved in the output file. min_cells ( type=int ) : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. min_features ( type=int ) : Default: 0 . The minimum number of features that a cell must express to be kept. This is used in Seurat::CreateSeuratObject() . Futher QC ( envs.cell_qc , envs.gene_qc ) will be performed after this. It doesn't work when data is loaded from loom files or RDS/qs2 files. cell_qc : Filter expression to filter cells, using tidyrseurat::filter() . It can also be a dictionary of expressions, where the names of the list are sample names. You can have a default expression in the list with the name \"DEFAULT\" for the samples that are not listed. Available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . Example Including the columns added above, all available QC keys include nFeature_RNA , nCount_RNA , percent.mt , percent.ribo , percent.hb , and percent.plat . For example: [SeuratPreparing.envs] cell_qc = \"nFeature_RNA > 200 & percent.mt < 5\" will keep cells with more than 200 genes and less than 5%% mitochondrial genes. gene_qc ( ns ) : Filter genes. gene_qc is applied after cell_qc . min_cells : Default: 0 . The minimum number of cells that a gene must be expressed in to be kept. excludes : Default: [] . The genes to exclude. Multiple genes can be specified by comma separated values, or as a list. Example [SeuratPreparing.envs] gene_qc = { min_cells = 3 } will keep genes that are expressed in at least 3 cells. qc_plots ( type=json ) : Default: {'Violin Plots': Diot({'kind': 'cell', 'plot_type': 'violin', 'devpars': Diot({'res': 100, 'height': 600, 'width': 1200})}), 'Scatter Plots': Diot({'kind': 'cell', 'plot_type': 'scatter', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Ridge Plots': Diot({'kind': 'cell', 'plot_type': 'ridge', 'devpars': Diot({'res': 100, 'height': 800, 'width': 1200})}), 'Distribution of number of cells a gene is expressed in': Diot({'kind': 'gene', 'plot_type': 'histogram', 'devpars': Diot({'res': 100, 'height': 1200, 'width': 1200})})} . The plots for QC metrics. It should be a json (or python dict) with the keys as the names of the plots and the values also as dicts with the following keys: kind: The kind of QC. Either gene or cell (default). devpars: The device parameters for the plot. A dict with res , height , and width . more_formats: The formats to save the plots other than png . save_code: Whether to save the code to reproduce the plot. other arguments passed to biopipen.utils::VizSeuratCellQC when kind is cell or biopipen.utils::VizSeuratGeneQC when kind is gene . use_sct ( flag ) : Default: False . Whether use SCTransform routine to integrate samples or not. Before the following procedures, the RNA layer will be split by samples. If False , following procedures will be performed in the order: * NormalizeData . * FindVariableFeatures . * ScaleData . See https://satijalab.org/seurat/articles/seurat5_integration#layers-in-the-seurat-v5-object and https://satijalab.org/seurat/articles/pbmc3k_tutorial.html If True , following procedures will be performed in the order: * SCTransform . See https://satijalab.org/seurat/articles/seurat5_integration#perform-streamlined-one-line-integrative-analysis no_integration ( flag ) : Default: False . Whether to skip integration or not. NormalizeData ( ns ) : Arguments for NormalizeData() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/normalizedata FindVariableFeatures ( ns ) : Arguments for FindVariableFeatures() . object is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/findvariablefeatures ScaleData ( ns ) : Arguments for ScaleData() . object and features is specified internally, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/scaledata RunPCA ( ns ) : Arguments for RunPCA() . object and features is specified internally, and - in the key will be replaced with . . npcs ( type=int ) : The number of PCs to compute. For each sample, npcs will be no larger than the number of columns - 1. <more> : See https://satijalab.org/seurat/reference/runpca SCTransform ( ns ) : Arguments for SCTransform() . object is specified internally, and - in the key will be replaced with . . return-only-var-genes : Default: False . Whether to return only variable genes. min_cells : Default: 3 . The minimum number of cells that a gene must be expressed in to be kept. A hidden argument of SCTransform to filter genes. If you try to keep all genes in the RNA assay, you can set min_cells to 0 and return-only-var-genes to False . See https://github.com/satijalab/seurat/issues/3598#issuecomment-715505537 <more> : See https://satijalab.org/seurat/reference/sctransform verbose : Default: True . IntegrateLayers ( ns ) : Arguments for IntegrateLayers() . object is specified internally, and - in the key will be replaced with . . When use_sct is True , normalization-method defaults to SCT . method ( choice ) : Default: harmony . The method to use for integration. CCAIntegration : Use Seurat::CCAIntegration . CCA : Same as CCAIntegration . cca : Same as CCAIntegration . RPCAIntegration : Use Seurat::RPCAIntegration . RPCA : Same as RPCAIntegration . rpca : Same as RPCAIntegration . HarmonyIntegration : Use Seurat::HarmonyIntegration . Harmony : Same as HarmonyIntegration . harmony : Same as HarmonyIntegration . FastMNNIntegration : Use Seurat::FastMNNIntegration . FastMNN : Same as FastMNNIntegration . fastmnn : Same as FastMNNIntegration . scVIIntegration : Use Seurat::scVIIntegration . scVI : Same as scVIIntegration . scvi : Same as scVIIntegration . <more> : See https://satijalab.org/seurat/reference/integratelayers doublet_detector ( choice ) : Default: none . The doublet detector to use. none : Do not use any doublet detector. DoubletFinder : Use DoubletFinder to detect doublets. doubletfinder : Same as DoubletFinder . scDblFinder : Use scDblFinder to detect doublets. scdblfinder : Same as scDblFinder . DoubletFinder ( ns ) : Arguments to run DoubletFinder . See also https://demultiplexing-doublet-detecting-docs.readthedocs.io/en/latest/DoubletFinder.html . PCs ( type=int ) : Default: 10 . Number of PCs to use for 'doubletFinder' function. doublets ( type=float ) : Default: 0.075 . Number of expected doublets as a proportion of the pool size. pN ( type=float ) : Default: 0.25 . Number of doublets to simulate as a proportion of the pool size. ncores ( type=int ) : Default: 1 . Number of cores to use for DoubletFinder::paramSweep . Set to None to use envs.ncores . Since parallelization of the function usually exhausts memory, if big envs.ncores does not work for DoubletFinder , set this to a smaller number. scDblFinder ( ns ) : Arguments to run scDblFinder . dbr ( type=float ) : Default: 0.075 . The expected doublet rate. ncores ( type=int ) : Default: 1 . Number of cores to use for scDblFinder . Set to None to use envs.ncores . <more> : See https://rdrr.io/bioc/scDblFinder/man/scDblFinder.html . cache ( type=auto ) : Default: /tmp . Whether to cache the information at different steps. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. The cached seurat object will be saved as <signature>.<kind>.RDS file, where <signature> is the signature determined by the input and envs of the process. See https://github.com/satijalab/seurat/issues/7849 , https://github.com/satijalab/seurat/issues/5358 and https://github.com/satijalab/seurat/issues/6748 for more details also about reproducibility issues. To not use the cached seurat object, you can either set cache to False or delete the cached file at <signature>.RDS in the cache directory.","title":"Environment Variables"},{"location":"processes/SeuratPreparing/#metadata","text":"Here is the demonstration of basic metadata for the Seurat object. Future processes will use it and/or add more metadata to the Seurat object.","title":"Metadata"},{"location":"processes/SeuratSubClustering/","text":"SeuratSubClustering \u00b6 Sub-clustering for all or selected T/B cells. Find clusters of a subset of cells. It's unlike [ Seurat::FindSubCluster ], which only finds subclusters of a single cluster. Instead, it will perform the whole clustering procedure on the subset of cells. One can use metadata to specify the subset of cells to perform clustering on. For the subset of cells, the reductions will be re-performed on the subset of cells, and then the clustering will be performed on the subset of cells. The reduction will be saved in object@reduction$<casename>.<reduction> of the original object and the clustering will be saved in the metadata of the original object using the casename as the column name. Input \u00b6 srtobj : The seurat object in RDS or qs/qs2 format. Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with the subclustering information in qs/qs2 format. Environment Variables \u00b6 ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. subset : An expression to subset the cells, will be passed to tidyseurat::filter() . RunPCA ( ns ) : Arguments for RunPCA() . object is specified internally as the subset object, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/runpca RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally as the subset object, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. You can also specify features instead of dims to use specific features for UMAP. It can be a list with the following fields: order (the order of the markers to use for UMAP, e.g. \"desc(abs(avg_log2FC))\", and n (the number of total features to use for UMAP, e.g. 30). If features is a list, it will run biopipen.utils::RunSeuratDEAnalysis to get the markers for each group, and then select the top n / ngroups features for each group based on the order field. If features is a numeric value, it will be treated as the n field in the list above, with the default order being \"desc(abs(avg_log2FC))\". dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, object@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be prefixed with \"s\". The first cluster will be \"s1\", instead of \"s0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <casename>_<resolution> . The final resolution will be used to define the clusters at <casename> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Whether to cache the results. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. cases ( type=json ) : Default: {} . The cases to perform subclustering. Keys are the names of the cases and values are the dicts inherited from envs except mutaters and cache . If empty, a case with name subcluster will be created with default parameters. The case name will be passed to biopipen.utils::SeuratSubCluster() as name . It will be used as the prefix for the reduction name, keys and cluster names. For reduction keys, it will be toupper(<name>) + \"PC_\" and toupper(<name>) + \"UMAP_\". For cluster names, it will be <name> + \".\" + resolution. And the final cluster name will be <name> . Note that the name should be alphanumeric and anything other than alphanumeric will be removed. Metadata \u00b6 The metadata of the Seurat object will be updated with the sub-clusters specified by names (keys) of envs.cases :","title":"SeuratSubClustering"},{"location":"processes/SeuratSubClustering/#seuratsubclustering","text":"Sub-clustering for all or selected T/B cells. Find clusters of a subset of cells. It's unlike [ Seurat::FindSubCluster ], which only finds subclusters of a single cluster. Instead, it will perform the whole clustering procedure on the subset of cells. One can use metadata to specify the subset of cells to perform clustering on. For the subset of cells, the reductions will be re-performed on the subset of cells, and then the clustering will be performed on the subset of cells. The reduction will be saved in object@reduction$<casename>.<reduction> of the original object and the clustering will be saved in the metadata of the original object using the casename as the column name.","title":"SeuratSubClustering"},{"location":"processes/SeuratSubClustering/#input","text":"srtobj : The seurat object in RDS or qs/qs2 format.","title":"Input"},{"location":"processes/SeuratSubClustering/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . The seurat object with the subclustering information in qs/qs2 format.","title":"Output"},{"location":"processes/SeuratSubClustering/#environment-variables","text":"ncores ( type=int;order=-100 ) : Default: 1 . Number of cores to use. Used in future::plan(strategy = \"multicore\", workers = <ncores>) to parallelize some Seurat procedures. mutaters ( type=json ) : Default: {} . The mutaters to mutate the metadata to subset the cells. The mutaters will be applied in the order specified. subset : An expression to subset the cells, will be passed to tidyseurat::filter() . RunPCA ( ns ) : Arguments for RunPCA() . object is specified internally as the subset object, and - in the key will be replaced with . . <more> : See https://satijalab.org/seurat/reference/runpca RunUMAP ( ns ) : Arguments for RunUMAP() . object is specified internally as the subset object, and - in the key will be replaced with . . dims=N will be expanded to dims=1:N ; The maximal value of N will be the minimum of N and the number of columns - 1 for each sample. You can also specify features instead of dims to use specific features for UMAP. It can be a list with the following fields: order (the order of the markers to use for UMAP, e.g. \"desc(abs(avg_log2FC))\", and n (the number of total features to use for UMAP, e.g. 30). If features is a list, it will run biopipen.utils::RunSeuratDEAnalysis to get the markers for each group, and then select the top n / ngroups features for each group based on the order field. If features is a numeric value, it will be treated as the n field in the list above, with the default order being \"desc(abs(avg_log2FC))\". dims ( type=int ) : The number of PCs to use reduction : The reduction to use for UMAP. If not provided, sobj@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/runumap FindNeighbors ( ns ) : Arguments for FindNeighbors() . object is specified internally, and - in the key will be replaced with . . reduction : The reduction to use. If not provided, object@misc$integrated_new_reduction will be used. <more> : See https://satijalab.org/seurat/reference/findneighbors FindClusters ( ns ) : Arguments for FindClusters() . object is specified internally, and - in the key will be replaced with . . The cluster labels will be prefixed with \"s\". The first cluster will be \"s1\", instead of \"s0\". resolution ( type=auto ) : Default: 0.8 . The resolution of the clustering. You can have multiple resolutions as a list or as a string separated by comma. Ranges are also supported, for example: 0.1:0.5:0.1 will generate 0.1, 0.2, 0.3, 0.4, 0.5 . The step can be omitted, defaulting to 0.1. The results will be saved in <casename>_<resolution> . The final resolution will be used to define the clusters at <casename> . <more> : See https://satijalab.org/seurat/reference/findclusters cache ( type=auto ) : Default: /tmp . Whether to cache the results. If True , the seurat object will be cached in the job output directory, which will be not cleaned up when job is rerunning. Set to False to not cache the results. cases ( type=json ) : Default: {} . The cases to perform subclustering. Keys are the names of the cases and values are the dicts inherited from envs except mutaters and cache . If empty, a case with name subcluster will be created with default parameters. The case name will be passed to biopipen.utils::SeuratSubCluster() as name . It will be used as the prefix for the reduction name, keys and cluster names. For reduction keys, it will be toupper(<name>) + \"PC_\" and toupper(<name>) + \"UMAP_\". For cluster names, it will be <name> + \".\" + resolution. And the final cluster name will be <name> . Note that the name should be alphanumeric and anything other than alphanumeric will be removed.","title":"Environment Variables"},{"location":"processes/SeuratSubClustering/#metadata","text":"The metadata of the Seurat object will be updated with the sub-clusters specified by names (keys) of envs.cases :","title":"Metadata"},{"location":"processes/TESSA/","text":"TESSA \u00b6 Tessa is a Bayesian model to integrate T cell receptor (TCR) sequence profiling with transcriptomes of T cells. Enabled by the recently developed single cell sequencing techniques, which provide both TCR sequences and RNA sequences of each T cell concurrently, Tessa maps the functional landscape of the TCR repertoire, and generates insights into understanding human immune response to diseases. As the first part of tessa, BriseisEncoder is employed prior to the Bayesian algorithm to capture the TCR sequence features and create numerical embeddings. We showed that the reconstructed Atchley Factor matrices and CDR3 sequences, generated through the numerical embeddings, are highly similar to their original counterparts. The CDR3 peptide sequences are constructed via a RandomForest model applied on the reconstructed Atchley Factor matrices. See https://github.com/jcao89757/TESSA When finished, two columns will be added to the meta.data of the Seurat object: TESSA_Cluster : The cluster assignments from TESSA. TESSA_Cluster_Size : The number of cells in each cluster. These columns can be then used for further downstream analysis to explore the functional landscape of the TCR repertoire. Input \u00b6 screpdata : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains. Output \u00b6 outfile : Default: {{in.screpdata | stem}}.tessa.qs . a qs fileof a Seurat object, with TESSA_Cluster and TESSA_Cluster_Size added to the meta.data Environment Variables \u00b6 python : Default: python . The path of python with TESSA 's dependencies installed within_sample ( flag ) : Default: False . Whether the TCR networks are constructed only within TCRs from the same sample/patient (True) or with all the TCRs in the meta data matrix (False). assay : Which assay to use to extract the expression matrix. Only works if in.srtobj is an RDS file of a Seurat object. By default, if SCTransform is performed, SCT will be used. predefined_b ( flag ) : Default: False . Whether use the predefined b or not. Please check the paper of tessa for more details about the b vector. If True, the tessa will not update b in the MCMC iterations. max_iter ( type=int ) : Default: 1000 . The maximum number of iterations for MCMC. save_tessa ( flag ) : Default: False . Save tessa detailed results to seurat object? It will be saved to sobj@misc$tessa . Reference \u00b6 'Mapping the Functional Landscape of TCR Repertoire.', Zhang, Z., Xiong, D., Wang, X. et al. 2021. link 'Deep learning-based prediction of the T cell receptor-antigen binding specificity.', Lu, T., Zhang, Z., Zhu, J. et al. 2021. link Metadata \u00b6 The metadata of the Seurat object will be updated with the TESSA clusters and the cluster sizes:","title":"TESSA"},{"location":"processes/TESSA/#tessa","text":"Tessa is a Bayesian model to integrate T cell receptor (TCR) sequence profiling with transcriptomes of T cells. Enabled by the recently developed single cell sequencing techniques, which provide both TCR sequences and RNA sequences of each T cell concurrently, Tessa maps the functional landscape of the TCR repertoire, and generates insights into understanding human immune response to diseases. As the first part of tessa, BriseisEncoder is employed prior to the Bayesian algorithm to capture the TCR sequence features and create numerical embeddings. We showed that the reconstructed Atchley Factor matrices and CDR3 sequences, generated through the numerical embeddings, are highly similar to their original counterparts. The CDR3 peptide sequences are constructed via a RandomForest model applied on the reconstructed Atchley Factor matrices. See https://github.com/jcao89757/TESSA When finished, two columns will be added to the meta.data of the Seurat object: TESSA_Cluster : The cluster assignments from TESSA. TESSA_Cluster_Size : The number of cells in each cluster. These columns can be then used for further downstream analysis to explore the functional landscape of the TCR repertoire.","title":"TESSA"},{"location":"processes/TESSA/#input","text":"screpdata : The data loaded by ScRepCombiningExpression , saved in RDS or qs/qs2 format. The data is actually generated by scRepertiore::combineExpression() . The data must have both TRA and TRB chains.","title":"Input"},{"location":"processes/TESSA/#output","text":"outfile : Default: {{in.screpdata | stem}}.tessa.qs . a qs fileof a Seurat object, with TESSA_Cluster and TESSA_Cluster_Size added to the meta.data","title":"Output"},{"location":"processes/TESSA/#environment-variables","text":"python : Default: python . The path of python with TESSA 's dependencies installed within_sample ( flag ) : Default: False . Whether the TCR networks are constructed only within TCRs from the same sample/patient (True) or with all the TCRs in the meta data matrix (False). assay : Which assay to use to extract the expression matrix. Only works if in.srtobj is an RDS file of a Seurat object. By default, if SCTransform is performed, SCT will be used. predefined_b ( flag ) : Default: False . Whether use the predefined b or not. Please check the paper of tessa for more details about the b vector. If True, the tessa will not update b in the MCMC iterations. max_iter ( type=int ) : Default: 1000 . The maximum number of iterations for MCMC. save_tessa ( flag ) : Default: False . Save tessa detailed results to seurat object? It will be saved to sobj@misc$tessa .","title":"Environment Variables"},{"location":"processes/TESSA/#reference","text":"'Mapping the Functional Landscape of TCR Repertoire.', Zhang, Z., Xiong, D., Wang, X. et al. 2021. link 'Deep learning-based prediction of the T cell receptor-antigen binding specificity.', Lu, T., Zhang, Z., Zhu, J. et al. 2021. link","title":"Reference"},{"location":"processes/TESSA/#metadata","text":"The metadata of the Seurat object will be updated with the TESSA clusters and the cluster sizes:","title":"Metadata"},{"location":"processes/TOrBCellSelection/","text":"TOrBCellSelection \u00b6 Separate T and non-T cells and select T cells; or separate B and non-B cells and select B cells. If all of your cells are T/B cells, do not set any configurations for this process. In such a case, SeuratClusteringOfAllCells should not be used, and SeuratClustering will be clustering all of the cells, which are all T/B cells. There are two ways to separate T and non-T cells; or B and non-B cells: Use the an expression indicator directly from the metadata. Use the expression values of indicator genes, and the clonotype percentage of the clusters. You can also use indicator gene expression values only to select T/B cells by setting envs.ignore_vdj to true. Input \u00b6 srtobj : Seurat object file in RDS/qs2 immdata : Immune repertoire data file in RDS/qs2 Output \u00b6 outfile : Default: {{in.srtobj | stem}}.qs . Seurat object file in qs2 format outdir : Default: details . Output directory with details Environment Variables \u00b6 ignore_vdj ( flag ) : Default: False . Ignore VDJ information for T/B cell selection. Use only the expression values of indicator genes if True. In this case, the Clonotype_Pct column does not exist in the metadata. If you want to use k-means to select T/B cells, you must have more than 1 indicator gene, and the first indicator gene in envs.indicator_genes must be a positive marker, which will be used to select the cluster with higher expression values as T/B cells. selector : The expression passed to tidyseurat::mutate(is_TCell = ...) to indicate whether a cell is a T cell. For example, Clonotype_Pct > 0.25 to indicate cells with clonotype percentage > 25% are T cells. If indicator_genes is provided, the expression values can also be used in the expression. For example, Clonotype_Pct > 0.25 & CD3E > 0 . If selector is not provided, a kmeans clustering will be performed on the expression values of indicator_genes and Clonotype_Pct , with K=2, and the cluster with higher clonotype percentage will be selected as T/B cells. indicator_genes ( list ) : Default: ['CD3E'] . A list of indicator genes whose expression values and clonotype percentage will be used to determine T/B cells. The markers could be either positive, such as CD3E , CD3D , CD3G , or negative, such as CD19 , CD14 , CD68 , for T cells. For B cells, markers such as CD19 , MS4A1 (CD20), CD79A , CD79B could be used. kmeans ( type=json ) : Default: {'nstart': 25} . The parameters for kmeans clustering. Other arguments for stats::kmeans can be provided here. If there are dots in the argument names, replace them with - . Examples \u00b6 Use T cell indicator directly \u00b6 If you have a metadata like this: id Clonotype_Pct seurat_clusters 1 0.1 1 2 0.3 2 3 0.5 3 With the configuration below: [TOrBCellSelection.envs] selector = \"Clonotype_Pct > 0.25\" The T cells will be selected as: id Clonotype_Pct seurat_clusters is_TCell 1 0.1 1 FALSE 2 0.3 2 TRUE 3 0.5 3 TRUE Use indicator genes \u00b6 Let's say we set the indicator genes to [\"CD3D\", \"CD3E\", \"CD3G\"] . The mean expression values will be calculated for each cluster: id Clonotype_Pct seurat_clusters CD3D CD3E CD3G 1 0.1 1 0.1 0.0 0.1 2 0.3 2 1.2 1.3 0.6 3 0.5 3 1.5 0.8 0.9 Then a kmeans clustering will be performed on the mean expression values of the indicator genes, together with Clonotype_Pct , with K=2. id Clonotype_Pct seurat_clusters CD3D CD3E CD3G is_TCell 1 0.1 1 0.1 0.0 0.1 FALSE 2 0.3 2 1.2 1.3 0.6 TRUE 3 0.5 3 1.5 0.8 0.9 TRUE The cluster with higher clonoype percentage will be selected as T/B cells ( is_selected = TRUE ), and sent to SeuratClustering for further clustering and downstream analysis.","title":"TOrBCellSelection"},{"location":"processes/TOrBCellSelection/#torbcellselection","text":"Separate T and non-T cells and select T cells; or separate B and non-B cells and select B cells. If all of your cells are T/B cells, do not set any configurations for this process. In such a case, SeuratClusteringOfAllCells should not be used, and SeuratClustering will be clustering all of the cells, which are all T/B cells. There are two ways to separate T and non-T cells; or B and non-B cells: Use the an expression indicator directly from the metadata. Use the expression values of indicator genes, and the clonotype percentage of the clusters. You can also use indicator gene expression values only to select T/B cells by setting envs.ignore_vdj to true.","title":"TOrBCellSelection"},{"location":"processes/TOrBCellSelection/#input","text":"srtobj : Seurat object file in RDS/qs2 immdata : Immune repertoire data file in RDS/qs2","title":"Input"},{"location":"processes/TOrBCellSelection/#output","text":"outfile : Default: {{in.srtobj | stem}}.qs . Seurat object file in qs2 format outdir : Default: details . Output directory with details","title":"Output"},{"location":"processes/TOrBCellSelection/#environment-variables","text":"ignore_vdj ( flag ) : Default: False . Ignore VDJ information for T/B cell selection. Use only the expression values of indicator genes if True. In this case, the Clonotype_Pct column does not exist in the metadata. If you want to use k-means to select T/B cells, you must have more than 1 indicator gene, and the first indicator gene in envs.indicator_genes must be a positive marker, which will be used to select the cluster with higher expression values as T/B cells. selector : The expression passed to tidyseurat::mutate(is_TCell = ...) to indicate whether a cell is a T cell. For example, Clonotype_Pct > 0.25 to indicate cells with clonotype percentage > 25% are T cells. If indicator_genes is provided, the expression values can also be used in the expression. For example, Clonotype_Pct > 0.25 & CD3E > 0 . If selector is not provided, a kmeans clustering will be performed on the expression values of indicator_genes and Clonotype_Pct , with K=2, and the cluster with higher clonotype percentage will be selected as T/B cells. indicator_genes ( list ) : Default: ['CD3E'] . A list of indicator genes whose expression values and clonotype percentage will be used to determine T/B cells. The markers could be either positive, such as CD3E , CD3D , CD3G , or negative, such as CD19 , CD14 , CD68 , for T cells. For B cells, markers such as CD19 , MS4A1 (CD20), CD79A , CD79B could be used. kmeans ( type=json ) : Default: {'nstart': 25} . The parameters for kmeans clustering. Other arguments for stats::kmeans can be provided here. If there are dots in the argument names, replace them with - .","title":"Environment Variables"},{"location":"processes/TOrBCellSelection/#examples","text":"","title":"Examples"},{"location":"processes/TOrBCellSelection/#use-t-cell-indicator-directly","text":"If you have a metadata like this: id Clonotype_Pct seurat_clusters 1 0.1 1 2 0.3 2 3 0.5 3 With the configuration below: [TOrBCellSelection.envs] selector = \"Clonotype_Pct > 0.25\" The T cells will be selected as: id Clonotype_Pct seurat_clusters is_TCell 1 0.1 1 FALSE 2 0.3 2 TRUE 3 0.5 3 TRUE","title":"Use T cell indicator directly"},{"location":"processes/TOrBCellSelection/#use-indicator-genes","text":"Let's say we set the indicator genes to [\"CD3D\", \"CD3E\", \"CD3G\"] . The mean expression values will be calculated for each cluster: id Clonotype_Pct seurat_clusters CD3D CD3E CD3G 1 0.1 1 0.1 0.0 0.1 2 0.3 2 1.2 1.3 0.6 3 0.5 3 1.5 0.8 0.9 Then a kmeans clustering will be performed on the mean expression values of the indicator genes, together with Clonotype_Pct , with K=2. id Clonotype_Pct seurat_clusters CD3D CD3E CD3G is_TCell 1 0.1 1 0.1 0.0 0.1 FALSE 2 0.3 2 1.2 1.3 0.6 TRUE 3 0.5 3 1.5 0.8 0.9 TRUE The cluster with higher clonoype percentage will be selected as T/B cells ( is_selected = TRUE ), and sent to SeuratClustering for further clustering and downstream analysis.","title":"Use indicator genes"},{"location":"processes/TopExpressingGenes/","text":"TopExpressingGenes \u00b6 Top expressing genes for clusters of all or selected T/B cells. This process finds the top expressing genes of clusters of T/B cells, and also performs the enrichment analysis against the genes. The enrichment analysis is done by enrichr . Note There are other environment variables also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for investigating top genes (See biopipen.ns.scrna.TopExpressingGenes for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly. Input \u00b6 srtobj : The seurat object in RDS or qs/qs2 format Output \u00b6 outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots Environment Variables \u00b6 dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case. SeeAlso \u00b6 TopExpressingGenesOfAllCells ClusterMarkers for examples of enrichment plots","title":"TopExpressingGenes"},{"location":"processes/TopExpressingGenes/#topexpressinggenes","text":"Top expressing genes for clusters of all or selected T/B cells. This process finds the top expressing genes of clusters of T/B cells, and also performs the enrichment analysis against the genes. The enrichment analysis is done by enrichr . Note There are other environment variables also available. However, they should not be used in this process. Other environment variables are used for more complicated cases for investigating top genes (See biopipen.ns.scrna.TopExpressingGenes for more details). If you are using pipen-board to run the pipeline (see here and here ), you may see the other environment variables of this process are hidden and readonly.","title":"TopExpressingGenes"},{"location":"processes/TopExpressingGenes/#input","text":"srtobj : The seurat object in RDS or qs/qs2 format","title":"Input"},{"location":"processes/TopExpressingGenes/#output","text":"outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots","title":"Output"},{"location":"processes/TopExpressingGenes/#environment-variables","text":"dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case.","title":"Environment Variables"},{"location":"processes/TopExpressingGenes/#seealso","text":"TopExpressingGenesOfAllCells ClusterMarkers for examples of enrichment plots","title":"SeeAlso"},{"location":"processes/TopExpressingGenesOfAllCells/","text":"TopExpressingGenesOfAllCells \u00b6 Top expressing genes for clusters of all cells. Input \u00b6 srtobj : The seurat object in RDS or qs/qs2 format Output \u00b6 outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots Environment Variables \u00b6 dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case. SeeAlso \u00b6 TopExpressingGenes ClusterMarkers for examples of enrichment plots","title":"TopExpressingGenesOfAllCells"},{"location":"processes/TopExpressingGenesOfAllCells/#topexpressinggenesofallcells","text":"Top expressing genes for clusters of all cells.","title":"TopExpressingGenesOfAllCells"},{"location":"processes/TopExpressingGenesOfAllCells/#input","text":"srtobj : The seurat object in RDS or qs/qs2 format","title":"Input"},{"location":"processes/TopExpressingGenesOfAllCells/#output","text":"outdir : Default: {{in.srtobj | stem}}.top_expressing_genes . The output directory for the tables and plots","title":"Output"},{"location":"processes/TopExpressingGenesOfAllCells/#environment-variables","text":"dbs ( list ) : Default: ['KEGG_2021_Human', 'MSigDB_Hallmark_2020'] . The dbs to do enrichment analysis for significant markers. You can use built-in dbs in enrichit , or provide your own gmt files. See also https://pwwang.github.io/enrichit/reference/FetchGMT.html . The built-in dbs include: \"BioCarta\" or \"BioCarta_2016\" \"GO_Biological_Process\" or \"GO_Biological_Process_2025\" \"GO_Cellular_Component\" or \"GO_Cellular_Component_2025\" \"GO_Molecular_Function\" or \"GO_Molecular_Function_2025\" \"KEGG\", \"KEGG_Human\", \"KEGG_2021\", or \"KEGG_2021_Human\" \"Hallmark\", \"MSigDB_Hallmark\", or \"MSigDB_Hallmark_2020\" \"Reactome\", \"Reactome_Pathways\", or \"Reactome_Pathways_2024\" \"WikiPathways\", \"WikiPathways_2024\", \"WikiPathways_Human\", or \"WikiPathways_2024_Human\" You can also fetch more dbs from https://maayanlab.cloud/Enrichr/#libraries . n ( type=int ) : Default: 250 . The number of top expressing genes to find. enrich_style ( choice ) : Default: enrichr . The style of the enrichment analysis. The enrichment analysis will be done by EnrichIt() from enrichit . Two styles are available: enrichr : enrichr style enrichment analysis (fisher's exact test will be used). clusterprofiler : clusterProfiler style enrichment analysis (hypergeometric test will be used). clusterProfiler : alias for clusterprofiler enrich_plots_defaults ( ns ) : Default options for the plots to generate for the enrichment analysis. plot_type : The type of the plot. See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.html . Available types are bar , dot , lollipop , network , enrichmap and wordcloud . more_formats ( type=list ) : Default: [] . The extra formats to save the plot in. save_code ( flag ) : Default: False . Whether to save the code to generate the plot. devpars ( ns ) : The device parameters for the plots. res ( type=int ) : Default: 100 . The resolution of the plots. height ( type=int ) : The height of the plots. width ( type=int ) : The width of the plots. <more> : See https://pwwang.github.io/scplotter/reference/EnrichmentPlot.htmll . enrich_plots ( type=json ) : Default: {'Bar Plot': Diot({'plot_type': 'bar', 'ncol': 1, 'top_term': 10})} . Cases of the plots to generate for the enrichment analysis. The keys are the names of the cases and the values are the dicts inherited from enrich_plots_defaults . The cases under envs.cases can inherit this options. subset : An expression to subset the cells for each case.","title":"Environment Variables"},{"location":"processes/TopExpressingGenesOfAllCells/#seealso","text":"TopExpressingGenes ClusterMarkers for examples of enrichment plots","title":"SeeAlso"}]}